\chapter{Functions}

\section{Elementary function}


\subsection{Kronecker delta}

\begin{definition}[Kronecker delta\index{Kronecker delta}]\label{def:kronecker_delta}
Kronecker delta\footnote{named after Leopold Kronecker}, is a function of two variables, usually integers. The function is 1 if the variables are equal, and 0 otherwise:
\be
\delta_{ij} = \left\{\begin{matrix} 0, & \mbox{if } i \ne j \\ 1, & \mbox{if } i=j \end{matrix}\right.
\ee
where Kronecker delta $\delta_{ij}$ is a piecewise function of variables $i$ and $j$. For example, $\delta_{12} = 0$, whereas $\delta_{33} = 1$.
\end{definition}


\subsection{Error Function}

\begin{definition}[error function\index{error function}]\label{def:error_function}
For $x\in \C$, the error function is defined by:
\be
\erf(x) = \frac{2}{\sqrt{\pi}} \int^x_0 e^{-t^2}dt .
\ee

By Proposition \footnote{Gaussian density function proposition needed.}, error function is well-defined and $\erf(x) \in [0,1]$ with $\erf(0) = 0$ and $\erf(\infty) = 1$.

Also, we can have that%\footnote{proof needed.}
\be
\erf(x) =  \frac{2}{\sqrt{\pi}}  \sum^\infty_{k=0} \frac{(-1)^kx^{2k+1}}{k!(2k+1)}  =\frac{2}{\sqrt{\pi}} e^{-x^2} \sum^\infty_{k=0} \frac{2^k x^{2k+1}}{1\cdot 3\cdot 5\cdots (2k+1)} .
\ee

Accordingly,
\be
\erfc(x) := 1 - \erf(x) = \frac{2}{\sqrt{\pi}} \int^\infty_x e^{-t^2}dt
\ee
is complementary error function\index{complementary error function}.
\end{definition}

\footnote{more error functions needed here.}

\subsection{Factorials}


\begin{definition}[factorial\index{factorial}]\label{def:factorial}
factorial of a non-negative integer $n$, denoted by $n!$, is the product of all positive integers less than or equal to $n$. That is,
\be
n! = \prod^n_{k=1} k = 1\cdot 2\cdot \dots \cdot (n-1)\cdot n.
\ee

For example,
\be
5!=5\times 4\times 3\times 2\times 1=120.
\ee

The value of $0!$ is 1, according to the convention for an empty product.
\end{definition}

\begin{definition}[double factorial\index{double factorial}]\label{def:double_factorial}
The product of all the odd integers up to some odd positive integer $n$ is called the double factorial of $n$,  denoted by $n!!$. For even $n$, its double factorial is defined by the product of all the even positive integers up to $n$. That is,
\be
n!! := \left\{\ba{ll}
(2k-1)!! = \prod^k_{i=1} (2i-1) = (2k-1)\cdot (2k-3)\cdot\dots\cdot 3 \cdot 1 \quad \quad & n= 2k-1 \\
(2k)!! = \prod^k_{i=1} (2i) = 2^k k! = 2k\cdot (2k-2)\cdot\dots\cdot 4 \cdot 2 \quad \quad & n= 2k \\
\ea\right.
\ee
\end{definition}

%$(n-k)!! := n\cdot (n-2)\cdot\dots\cdot (n-2(k-2)) \cdot (n-2(k-1))$


\section{Fundamental Series}

\subsection{Harmonic series}

\begin{definition}[harmonic series\index{harmonic series}]
The harmonic series is the divergent infinite series
\be
\sum^\infty_{n=1} \frac 1n = 1+ \frac 12 + \frac 13 + \dots.
\ee
\end{definition}

\begin{remark}
Harmonic series' name derives from the concept of overtones: the wavelengths of the overtones of a vibrating string are $1/2$, $1/3$, $1/4$, etc., of the string's fundamental wavelength.
\end{remark}

\begin{definition}[harmonic number]
The $n$th partial sum of the diverging harmonic series
\be
H_n := \int^1_0 \frac{1-x^n}{1-x}dx,\qquad H_n = \sum^n_{k=1}\frac 1k%H_n = \sum^n_{k=1} \frac 1k
\ee
is called the $n$th harmonic number.
\end{definition}

\subsection{Grandi's series}

\begin{definition}[Grandi's series]
The divergent infinite series $1-1+1-1+\dots$, also written
\be
\sum^\infty_{n=0} (-1)^n
\ee
is sometimes called Grandi's series.
\end{definition}

\begin{remark}
It is named after Italian mathematician Guido Grandi, who gave a memorable treatment of the series in 1703.
\end{remark}

\begin{proposition}
The Ces\'aro sum of Grandi series is 1/2.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\subsection{Telescoping series}

\begin{definition}[telescoping series\index{telescoping series}]\label{def:telescoping_series}
a telescoping series is a series whose partial sums eventually only have a fixed number of terms after cancellation.\footnote{The cancellation technique, with part of each term cancelling with part of the next term, is known as the method of differences.} That is, Let $a_{n}$ be a sequence of numbers. Then,
\be
\sum _{{n=1}}^{N}\left(a_{n}-a_{{n-1}}\right)=a_{N}-a_{{0}},
\ee
and, if $a_n \to 0$
\be
\sum _{{n=1}}^{\infty }\left(a_{n}-a_{{n-1}}\right)=-a_{{0}}.
\ee
\end{definition}

\begin{example}
The series
\be
\sum _{n=1}^{\infty }{\frac {1}{n(n+1)}}
\ee
(the series of reciprocals of pronic numbers) simplifies as
\beast
\sum _{n=1}^{\infty }{\frac {1}{n(n+1)}} & = & \sum _{n=1}^{\infty }\left({\frac {1}{n}}-{\frac {1}{n+1}}\right) = \lim _{N\to \infty }\sum _{n=1}^{N}\left({\frac {1}{n}}-{\frac {1}{n+1}}\right)\\
& = & \lim _{N\to \infty }\bb{{\left(1-{\frac {1}{2}}\right)+\left({\frac {1}{2}}-{\frac {1}{3}}\right)+\cdots +\left({\frac {1}{N}}-{\frac {1}{N+1}}\right)}}\\
& = & \lim _{N\to \infty }\bb{1+\left(-{\frac {1}{2}}+{\frac {1}{2}}\right)+\left(-{\frac {1}{3}}+{\frac {1}{3}}\right)+\cdots +\left(-{\frac {1}{N}}+{\frac {1}{N}}\right)-{\frac {1}{N+1}}} \\
& = & \lim _{N\to \infty }\bb{ {1-{\frac {1}{N+1}}}} =1.
\eeast
\end{example}

\subsection{Geometric series}

\begin{definition}[geometric series\index{geometric series!complex series}]\label{def:geometric_series_complex}
A geometric series is a series with a constant ratio between successive terms. That is, for $z\in \C$,
\be
\sum^\infty_{n=0} z^n.
\ee
\end{definition}

\begin{proposition}\label{pro:geometric_series_sum}
The geometric series is convergent for $\abs{z}<1$. Otherwise, the geometric series diverges (for $\abs{z}\geq 1$). In particular,
\be
\sum^\infty_{n=0} z^n = \frac 1{1-z},\quad \abs{z}<1.
\ee

Moreover, we have
\beast
\sum^\infty_{n=0} nz^n & = & \frac {z}{(1-z)^2},\quad \abs{z}<1,\\
\sum^\infty_{n=0} n(n-1)z^n & = & \frac {2z^2}{(1-z)^3},\quad \abs{z}<1.
\eeast%For $\abs{z}\geq $
\end{proposition}

\begin{proof}[\bf Proof]
First, it can be see that the radius of convergence of series $\sum^\infty_{n=0} z^n$ is 1. Then consider the partial sum
\be
\sum^N_{n=0}z^n = 1+z+z^2 + \dots + z^N = \frac{1-z^{N+1}}{1-z}.
\ee

By Proposition \ref{pro:convergence_of_complex_power_function}, we know that $\lim_{N\to \infty}z^{N+1} = 0$ for $\abs{z}<1$. Thus, we have for $\abs{z}<1$,
\be
\sum^\infty_{n=0} z^n = \lim_{N\to \infty} \sum^N_{n=0}z^n =  \lim_{N\to \infty}\frac{1-z^{N+1}}{1-z} = \frac{1}{1-z}.
\ee

By Lemma \ref{lem:complex_series_sum_convergence_imples_sequence_zero}, we have that the geometric series diverges since $z^n \not\to 0$ for $\abs{z}\geq 1$.


Furthermore, by Theorem \ref{thm:power_series_differentiation},
\be
\sum^\infty_{n=0} z^n,\qquad \sum^\infty_{n=0} nz^n,\qquad \sum^\infty_{n=0} n(n-1)z^n
\ee
have the same radius of convergence and
\beast
\sum^\infty_{n=0} nz^n = z\sum^\infty_{n=0} nz^{n-1} = z\sum^\infty_{n=0} \bb{z^{n}}' =  z\bb{\sum^\infty_{n=0} z^n}' = z \bb{\frac 1{1-z}}' = z\cdot \frac{1}{(1-z)^2} = \frac{z}{(1-z)^2},
\eeast
\beast
\sum^\infty_{n=0} n(n-1)z^n & = & z^2\sum^\infty_{n=0} n(n-1)z^{n-2} = z^2\sum^\infty_{n=0} n\bb{z^{n-1}}' =  z^2\bb{\sum^\infty_{n=0} n z^{n-1}}' = z^2\bb{\sum^\infty_{n=0} \bb{z^n}'}' = z^2\bb{\sum^\infty_{n=0} z^n}''\\
&  = & z^2 \bb{\frac 1{1-z}}'' = z^2\cdot \frac{2}{(1-z)^3} = \frac{2z^2}{(1-z)^3}
\eeast
as required.
\end{proof}

%\subsection{Geometric series}

%\begin{definition}% where $\F$ is $\R$ or $\C$. Then
%For $\rho\in \C$, the geometric series is
%\be
%\sum^\infty_{n=1} \rho^n.
%\ee
%\end{definition}

%\begin{proof}[\bf Proof]
%$\sum^\infty_{n=0}x^n$, $S_n =1+x+x^2+\dots+x^n$, $x\in\F$,
%\be
%x S_n = \underbrace{x+x^2 + \dots + x^n}_{S_n-1} + x^{n+1} = S_n -1 + x^{n+1} \ \ra \ 1-x^{n+1} = S_n(1-x).
%\ee

%If $x\neq 1, S_n = \frac{1-x^{n+1}}{1-x}=\frac{1}{1-x}-\frac{x^{n+1}}{1-x}$. (If $x=1$, the series clearly diverge.)

%Applying Lemma \ref{lem:sum_convergence_imples_sequence_zero}, we have
%\be
%\sum^n_{i=0}x^i\text{ converges }\ \ra \ x^n\to 0 \ \lra \ |x|^n\to 0 \ \lra\ |x|<1.
%\ee

%Also, we can see that if $|x|<1$, $S_n\to\frac{1}{1-x}= \sum^\infty_{n=0}x^n$.

%Thus, $\sum^n_{i=0}x^i$ converges iff $|x|<1$.
%\end{proof}




%\section{Natural Exponential Function}

\section{Exponential and Logarithm Functions}


\subsection{Natural exponential function of real numbers}

\begin{definition}[natural exponential function]\label{def:exponential_function_natural_real}
For $x\in\R$, we define the natural exponential function by
\be
\exp(x) := \sum^\infty_{n=0} \frac{x^n}{n!}.
\ee

$\exp(x)$ can be abbreviated as $e^x$.
\end{definition}

\begin{remark}
For $x=0$, we can easily have $\exp(0)=1$ by definition.

For $x\neq 0$, the series exists by ratio test (Theorem \ref{thm:ratio_test_real}). That is, for $a_n = \frac{\abs{x}^n}{n!} > 0$,
\be
\frac{a_{n+1}}{a_n} = \frac{\abs{x}^{n+1}/(n+1)!}{\abs{x}^n/n!} = \frac{\abs{x}}{n+1} \to 0
\ee
as $n\to \infty$. So the series converges absolutely and thus converges.
\end{remark}

\begin{proposition}
The natural exponential function bears power functions for real numbers. That is, for any $n>0$
\be
\frac{e^x}{x^n}\to \infty\ \text{ as }x\to\infty.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Take a positive integer $k$ such that $k>n$ and observe (from the definition of $e^x$ as a power series) that for $x>0$,
\be
e^x >\frac{x^k}{k!} \ \ra\ \frac {e^x}{x^n} > \frac{x^{k-n}}{k!} \to \infty \text{ as } x\to \infty
\ee
since $k>n$.
\end{proof}

\begin{proposition}\label{pro:exponential_1_plus_x_inequalities}
For $0\leq x<1$,
\be
1 + x \leq \exp(x) \leq (1-x)^{-1}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Clearly, the left-hand side inequality is directly implied by the definition.% Taylor expansion\footnote{theorem needed.}.

The right-hand side can be converted to
\beast
(1-x)e^x & = & (1-x)\bb{1 + x + \frac {x^2}{2!} + \frac {x^3}{3!}+\dots } \\
& = & 1 - x(1-1) - x^2\bb{1 - \frac 1{2!}} - x^3\bb{\frac{1}{2!} - \frac 1{3!}} \dots \leq 1.
\eeast

Note that we can switch the order of the terms as the series is absolutely convergent (see Theorem \ref{thm:absolute_convergence_change_term_order_same_sum_real}).
\end{proof}





%By definition of exponential function,
%\beast
%\exp\bb{x_1+x_2} & = & \sum^\infty_{n=0} \frac{(x_1+x_2)^n}{n!} = \sum^\infty_{n=0} \frac{1}{n!}\sum^n_{k=0}\binom{n}{k}x_1^kx_2^{n-k} = \sum^\infty_{n=0} \sum^n_{k=0} \frac{1}{n!} \frac{n!}{k!(n-k)!} x_1^kx_2^{n-k}\\
%& = &  \sum^\infty_{n=0} \sum^n_{k=0} \frac{x_1^k}{k!} \frac{x_2^{n-k}}{(n-k)!} = \sum^\infty_{n=0} \sum^\infty_{k=0} \frac{x_1^k}{k!} \frac{x_2^{n}}{n!} = \sum^\infty_{k=0} \frac{x_1^k}{k!} \sum^\infty_{n=0} \frac{x_2^{n}}{n!} = \exp\bb{x_1}\cdot \exp\bb{x_2}.
%\eeast
%Note that it is feasible to switch the order the terms since the series is absolute convergence (Theorem \ref{thm:absolute_convergence_change_term_order_same_sum_real})


\begin{proposition}\label{pro:natural_exponential_real_continuous}
The natural exponential $\exp:\R\to \R$ is continuous at every point $x\in \R$.
\end{proposition}

\begin{proof}[\bf Proof] For any $x\in \R$, we can find $r>0$ such that $\abs{x} < r$ and define $I := (-r,r)$. Thus, for any $x\in I$,
\be
\sum^\infty_{n=0} \abs{\frac{x^n}{n!}} \leq \sum^\infty_{n=0} \frac{r^n}{n!} = \sum^\infty_{n=0} a_n.
\ee

Apply the ratio test, as $n\to \infty$
\be
\frac{a_{n+1}}{a_n} = \frac{r^{n+1}/(n+1)!}{r^n/n!} = \frac{r}{n} \to 0 < 1
\ee
which implies that $\sum^\infty_{n=0} \frac{r^n}{n!}$ is convergent. Thus, $\sum^\infty_{n=0} \frac{x^n}{n!}$ converges absolutely and therefore converges (Theorem \ref{thm:absolutely_convergence_implies_convergence_real}). Moreover, $\sum^\infty_{n=0} \frac{r^n}{n!}$ is a Cauchy sequence on $I$ so for any given we can find $N\in\N$ such that for all $n>m>N$
\be
\abs{\sum^n_{k=m+1} \frac{r^k}{k!}} = \abs{\sum^n_{k=0} \frac{r^k}{k!} - \sum^n_{k=0} \frac{r^k}{k!}} < \ve.
\ee

Therefore, for any $x\in I$,
\be
\abs{\sum^n_{k=m+1} \frac{x^k}{k!}} \leq \sum^n_{k=m+1} \abs{\frac{x^k}{k!}} \leq \sum^n_{k=m+1} \abs{\frac{r^k}{k!}} = \abs{\sum^n_{k=m+1} \frac{r^k}{k!}} < \ve
\ee
which implies that $\sum^\infty_{n=0} \frac{x^n}{n!}$ converges uniformly on $I$. Since $\sum^n_{k=0} \frac{x^k}{k!}$ are continuous (as finite summation of power functions), its limit $\exp(x) = \sum^\infty_{n=0} \frac{x^n}{n!}$ is continuous on $I$ by Theorem \ref{thm:uniform_convergence_continuous_real}.
\end{proof}

\begin{proposition}\label{pro:natural_exponential_real_differentiable}
For any $x\in \R$, $\exp(x)$ is differentiable. In particular,
\be
\fd{}{x}\exp(x) = \exp(x).
\ee
\end{proposition}

\begin{proof}[\bf Proof]
For any $x_0\in \R$, consider the limit
\be
\lim_{x\to x_0}\frac{f(x) - f(x_0)}{x-x_0} = \lim_{x\to x_0} \frac{e^{x} - e^{x_0}}{x-x_0} = e^{x_0}\lim_{x\to x_0} \frac{e^{x-x_0} - 1}{x-x_0}.
\ee
by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_complex}. Let $h:=x-x_0$. The limit becomes
\be
e^{x_0}\lim_{h\to 0}\frac{e^{h} - 1}{h} = e^{x_0}\lim_{h\to 0}\frac{\bb{1+h+\frac 12 h^2 + o(h^2)} - 1}{h} =  e^{x_0}\lim_{h\to 0} \bb{1+\frac 12h + o(h)} = e^{x_0}.
\ee
by definition of $\exp$.
\end{proof}


\begin{proposition}\label{pro:exponential_of_sum_is_product_of_exponential_real}
For any $x_1,x_2\in \R$, we have
\be
\exp\bb{x_1+x_2} = \exp\bb{x_1} \cdot \exp\bb{x_2}.
\ee
\end{proposition}

\begin{remark}
Since $1 = \exp(0) = \exp(x-x)$,
\be
\exp(-x) = 1/\exp(x).
\ee
\end{remark}


\begin{proof}[\bf Proof]
Define function $f:\R\to \R$ for any $x_1,x_2\in \R$
\be
f(x) = \exp(x_1+x_2-x)\cdot \exp(x).
\ee

Then for any $x\in \R$, we take the derivative with respect to $x$ and get
\be
f'(x) = -\exp(x_1+x_2-x)\cdot \exp(x) + \exp(x_1+x_2-x)\cdot \exp(x) = 0.
\ee

Thus, by Corollary \ref{cor:derivative_greater_equal_to_zero}, $f$ is constant in $\R$. Therefore,
\be
\exp(x_1)\cdot \exp(x_2) = \exp(x_1+x_2-x_2)\cdot \exp(x_2) = f(x_2) = f(0) = \exp(x_1+x_2-0)\cdot \exp(0) = \exp(x_1 + x_2).
\ee
\end{proof}


\begin{proof}[\bf Alternative Proof]
By definition of exponential function,
\beast
\exp\bb{x_1+x_2} = \sum^\infty_{n=0} \frac{(x_1+x_2)^n}{n!} = \sum^\infty_{n=0} \frac{1}{n!}\sum^n_{k=0}\binom{n}{k}x_1^kx_2^{n-k} = \sum^\infty_{n=0} \sum^n_{k=0} \frac{1}{n!} \frac{n!}{k!(n-k)!} x_1^kx_2^{n-k}
=  \sum^\infty_{n=0} \sum^n_{k=0} \frac{x_1^k}{k!} \frac{x_2^{n-k}}{(n-k)!} .%= \sum^\infty_{n=0} \sum^\infty_{k=0} \frac{x_1^k}{k!} \frac{x_2^{n}}{n!} = \sum^\infty_{k=0} \frac{x_1^k}{k!} \sum^\infty_{n=0} \frac{x_2^{n}}{n!} = \exp\bb{x_1}\cdot \exp\bb{x_2}.
\eeast

Since $\exp(x)$ for $x\in\R$ is absolutely convergent, we have
\be
\exp\bb{x_1+x_2} = \exp\bb{x_1} \cdot \exp\bb{x_2}
\ee
by Mertens' theorem (Theorem \ref{thm:mertens_cauchy_product}).
\end{proof}

\begin{proposition}\label{pro:natural_exponential_real_properties}
Let $\exp:\R\to \R$ be real-valued natural exponential function. Then
\ben
\item [(i)] $\exp(x)>0$, for any $x\in\R$.
\item [(iv)] $\exp(x)$ is strictly increasing on $\R$.
\item [(v)] $\exp(x)\to \infty$ as $x\to\infty$, $e(x)\to 0$ as $x\to -\infty$.
\item [(vi)] The function $\exp:\R\to (0,\infty)$ is a bijection.
\een
\end{proposition}

\begin{proof}[{\bf Proof}]
\ben
\item [(i)] Clearly from the definition of $\exp(x)$, $\exp(x)>0$ if $x\geq 0$ and $\exp(0)=1$. Also, we have by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_real},
\be
1 = \exp(0) = \exp(x-x) = \exp(x)\exp(-x)\ \ra \ \exp(x)>0, \ \forall x\in\R.
\ee

\item [(ii)] By Proposition \ref{pro:natural_exponential_real_differentiable}, $\fd{}{x}\exp(x) = \exp(x)>0$, then $\exp$ is strictly increasing by Corollary \ref{cor:derivative_greater_equal_to_zero}.

\item [(iii)] From definition of (i), by $\exp(-x) = \frac 1{\exp(x)}$
\be
\exp(x) > 1+x,\quad x>0\ \ra \ \exp(x)\to \infty \text{ as }x\to\infty \ \ra \ \exp(x)\to 0 \text{ as }x\to-\infty.
\ee

\item [(vi)] If $x_1> x_2$, then $\exp(x_1)>\exp(x_2)$ since $\exp$ is strictly increasing. Thus,
\be
x_1 \neq x_2 \ \ra\ \exp(x_1) \neq \exp(x_2)
\ee
which implies that $\exp$ is injective.

For any $y\in (0,\infty)$, there exist $a,b\in \R$ such that $\exp(a)<y<\exp(b)$ by (iii). Thus, with intermediate value theorem (Theorem \ref{thm:intermediate_value}), $\exists x\in\R$ such that $\exp(x)=y$ since $\exp$ is continuous. This implies surjectivity.
\een
\end{proof}


\begin{proposition}\label{pro:one_plus_x_over_n_power_n_strictly_increasing}
For any $x> -n$ and $n\in \Z^+$, the sequence
\be
a_n := \bb{1+\frac xn}^n,\quad x\neq 0\quad\text{is strictly increasing ($a_{n+1} > a_n$)}
\ee% for $x\neq 0$. %Furthermore, for any $x\in \R\bs\bra{0}$, $(a_n)$ is eventually strictly increasing ($a_{n+1} > a_n$ for large enough $n$).
and the sequence
\be
b_n := \bb{1+\frac 1n}^{n+1},\quad\text{is strictly decreasing ($b_{n+1} < b_n$)}.
\ee
\end{proposition}

\begin{remark}
Note that $\bb{1+\frac xn}^{n+1}$ is not strictly decreasing. For instance,
\be
\bb{1 + \frac 32}^3 = 15.625, \qquad \bb{1+\frac 33}^4 = 16
\ee
\end{remark}

\begin{proof}[\bf Proof]
Consider the positive numbers
\be
x_1 = x_2 = \dots = x_n = \frac{n+x}{n}, \ x_{n+1} = 1.
\ee

Then arithmetic-geometric mean inequality (Theorem \ref{thm:arithmetic_geometric_mean_inequality}) implies
\be
\bb{\frac{n+x}{n}}^{\frac n{n+1}}= \bb{\prod^{n+1}_{k=1} a_k}^{\frac 1{n+1}} < \frac 1{n+1} \sum^{n+1}_{k=1} a_k = \frac 1{n+1}\bb{n\cdot \frac{n+x}{n} + 1} = \frac{n+x+1}{n+1}.
\ee

Note that the inequality is strict as $a_1\neq a_{n+1}$. Taking power $n+1$ on both sides we have
\be
\bb{1+\frac xn}^n < \bb{1 + \frac{x}{n+1}}^{n+1}.
\ee

%For any real number $x\neq 0$, we can find large enough $n$ such that $1 + \frac xn >0$ and the required result can be given by similar argument.

In particular, we can consider let $0<x<n$,
\be
\frac{\bb{1-\frac{x}{n+1}}^{n+1}}{{\bb{1-\frac{x}{n}}^{n+1}}} = \bb{1+\frac{x}{(n+1)(n-x)}}^{n+1} > 1+ \frac{(n+1)x}{(n+1)(n-x)} > 1+ \frac x{n-x} = \frac{n}{n-x}
\ee
by Bernoulli inequality (Theorem \ref{thm:bernoulli_inequality_one_plus_x_power_n}). Then
\be
\bb{1-\frac{x}{n+1}}^{n+1} > \frac{n}{n-x} \bb{1-\frac{x}{n}}^{n+1} = \bb{1-\frac{x}{n}}^{n}.
\ee


On the other hand,
\be
\frac{\bb{1+\frac{1}{n}}^{n+1}}{{\bb{1+\frac{1}{n+1}}^{n+1}}} = \bb{1+\frac{1}{n(n+2)}}^{n+1} > 1+ \frac{(n+1)}{n(n+2)} > 1+ \frac 1{n+1} = \frac{n+2}{n+1}
\ee
by Bernoulli inequality (Theorem \ref{thm:bernoulli_inequality_one_plus_x_power_n}). Then
\be
\bb{1+\frac{1}{n+1}}^{n+2} = \frac{n+2}{n+1} \bb{1+\frac{1}{n+1}}^{n+1} < \bb{1+\frac{1}{n}}^{n+1}.
\ee
\end{proof}




\begin{theorem}\label{thm:convergence_of_one_plus_x_over_n_power_n}
For any real $x$, then
\be
\lim_{n\to \infty}\bb{1+\frac xn}^n = e^x.
\ee
\end{theorem}


\begin{proof}[\bf Proof]
For $x=0$,
\be
\bb{1+\frac{x}{n}}^n = 1 = e^0 = e^x.
\ee

For $x>0$, by binomial theorem (Theorem \ref{thm:binomial_non_negative_integer_power}) we have
\beast
\bb{1+\frac xn}^n & = & \sum^n_{k=0}\binom{n}{k} \frac{x^k}{n^k} = \sum^n_{k=0} \frac{x^k}{n^k}\frac{n!}{(n-k)!k!} = \sum^n_{k=0} \frac{x^k}{k!}\frac{n!}{(n-k)!n^k} = \sum^n_{k=0} \frac{x^k}{k!}\frac{n(n-1)\dots (n-k+1)}{n^k} \\
& = & \sum^n_{k=0} \frac{x^k}{k!}\bb{\frac{n}{n}}\bb{\frac{n-1}n}\dots \bb{\frac{n-k+1}{n}} = \sum^n_{k=0} \frac{x^k}{k!}\bb{1 - \frac{1}n}\dots \bb{1 - \frac{k-1}{n}} \leq \sum^n_{k=0} \frac{x^k}{k!}.
\eeast

Thus, we can see that $\bb{1+\frac xn}^n$ converges as it is strictly increasing (Proposition \ref{pro:one_plus_x_over_n_power_n_strictly_increasing}) and bounded above by $\sum^\infty_{k=0} \frac{x^k}{k!} = e^x$. Also, by binomial theorem we can also that for any non-negative integer $p< n$,
\be
\sum^p_{k=0}\binom{n}{k} \frac{x^k}{n^k} \leq \bb{1+\frac xn}^n.
\ee

Then we can see that
\be
\lim_{n\to \infty} \binom{n}{k} \frac{x^k}{n^k} = \frac{x^k}{k!} \ \ra\ \lim_{n\to \infty} \sum^p_{k=0} \binom{n}{k} \frac{x^k}{n^k} = \sum^p_{k=0}  \frac{x^k}{k!}.
\ee

Thus, for any $p\in \N$,
\be
\sum^p_{k=0}  \frac{x^k}{k!} \leq \lim_{n\to \infty}\bb{1+\frac{x}n}^n \leq \sum^\infty_{k=0} \frac{x^k}{k!} = e^x.
\ee

Then we can let $p\to \infty$ to reveal that
\be
\lim_{n\to \infty}\bb{1+\frac{x}n}^n = \sum^\infty_{k=0} \frac{x^k}{k!} = e^x.
\ee

Again, by Proposition \ref{pro:one_plus_x_over_n_power_n_strictly_increasing}, we have $\bb{1-\frac xn}^n$ converges as it is strictly increasing and bounded above by 1. Thus, for $n\geq 2$,
\be
\bb{1-\frac{x}{n}}^n\bb{1+\frac xn}^n = \bb{1 - \frac{x^2}{n^2}}^n.
\ee

But by Bernoulli inequality (Theorem \ref{thm:bernoulli_inequality_one_plus_x_power_n}),
\be
1 \geq  \bb{1 - \frac{x^2}{n^2}}^n > 1 - \frac{nx^2}{n^2} = 1 - \frac{x^2}{n} \ \ra\ \lim_{n\to \infty}  \bb{1 - \frac{x^2}{n^2}}^n = 1.
\ee

Therefore, we have
\be
1 = \lim_{n\to \infty} \bb{1-\frac{x}{n}}^n \lim_{n\to \infty} \bb{1+\frac xn}^n \ \ra\ \lim_{n\to \infty} \bb{1-\frac xn}^n = \bb{\lim_{n\to \infty} \bb{1+\frac xn}^n}^{-1} = e^{-x}
\ee
as required.
\end{proof}

\begin{remark}
$\lim_{n\to \infty} \bb{1-\frac 1n}^n = e^{-1}$ can be given by taking the limit of the following equation,
\be
\bb{1-\frac 1{n+1}}^{n+1} \cdot\bb{1+\frac 1n}^{n+1} = 1
\ee
\end{remark}


\begin{corollary}
For $n\in \Z^+$,
\be
\bb{1+\frac 1n}^n < e < \bb{1+\frac 1{n}}^{n+1}.
\ee
\end{corollary}

\begin{proof}[\bf Proof]
Proposition \ref{pro:one_plus_x_over_n_power_n_strictly_increasing} gives that $\bb{1+\frac 1{n}}^{n}$ is strictly increasing and converges to $e$ by Theorem \ref{thm:convergence_of_one_plus_x_over_n_power_n}.

Also, Proposition \ref{pro:one_plus_x_over_n_power_n_strictly_increasing} gives that $\bb{1+\frac 1{n}}^{n+1}$ is strictly decreasing and bounded below. Therefore, it converges and
\be
\lim_{n\to \infty}\bb{1+\frac 1{n}}^{n+1} = \lim_{n\to \infty} \bb{1+\frac 1{n}}\bb{1+\frac 1{n}}^{n} = \lim_{n\to \infty} \bb{1+\frac 1{n}} \lim_{n\to \infty}\bb{1+\frac 1{n}}^{n} = 1 \cdot e = e
\ee
by Theorem \ref{thm:convergence_of_one_plus_x_over_n_power_n}.
\end{proof}


\begin{corollary}\label{cor:one_plus_x_over_n_power_n_smaller_than_exp_x}
For any $n\in \Z^+$,
\be
\bb{1+\frac xn}^n \leq e^x,\qquad x\geq -n.
\ee

The equality holds only for $x=0$.
\end{corollary}

\begin{proof}[\bf Proof]
We know that $\bb{1+\frac xn}^n$ is strictly increasing by Proposition \ref{pro:one_plus_x_over_n_power_n_strictly_increasing} and get the required result by \ref{thm:convergence_of_one_plus_x_over_n_power_n}.
\end{proof}




\subsection{Natural exponential function of complex numbers}

\begin{definition}[natural exponential function]\label{def:exponential_function_natural_complex}
For $z\in\C$, we define the natural exponential function by
\be
\exp(z) := \sum^\infty_{n=0} \frac{z^n}{n!}.
\ee

$\exp(z)$ can be abbreviated as $e^z$.
\end{definition}

\begin{proposition}\label{pro:natural_exponential_complex_continuous}
The natural exponential $\exp:\C\to \C$ is continuous at every point $z\in \C$.
\end{proposition}

\begin{proof}[\bf Proof]
For any $z\in \C$, we can find $r>0$ such that $\abs{z} < r$ and define the disc $A := \bra{z:\abs{z}<r}$. Thus, for any $z\in A$,
\be
\abs{\frac{z^n}{n!}} \leq M_n := \frac{r^n}{n!},\qquad \sum^\infty_{n=0}M_n \ \text{converges}
\ee
since the radius of convergence of $\sum^\infty_{n=0} \frac{z^n}{n!}$ is $\infty$. Then by Weierstrass M-test (Theorem \ref{thm:weierstrass_m_test}), we have that
\be
\sum^\infty_{n=0} \frac{z^n}{n!}\ \text{converges absolutely and uniformly on }A.
\ee

Since $\sum^n_{k=0} \frac{z^k}{k!}$ are continuous (as finite summation of power functions), its limit $\exp(z) = \sum^\infty_{n=0} \frac{z^n}{n!}$ is continuous on $A$ by Theorem \ref{thm:uniform_convergence_continuous_complex}.
\end{proof}


\begin{proposition}\label{pro:derivative_natural_exponential_complex}
The exponential function $\exp(z)$ is continuous and differentiable for any point on complex plane. In particular,
\be
\fd{}{z}\exp(z) = \exp(z),\qquad z\in \C.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Direct result by Proposition \ref{pro:differentiability_implies_continuity_complex_function} and Theorem \ref{thm:power_series_differentiation} as $\exp$ have radius of convergence $\infty$.
\be
\frac{d}{dz}\exp(z) = \sum^\infty_{n=1} na_nz^{n-1} = \sum^\infty_{n=1} \frac 1{(n-1)!} z^{n-1} = \sum^\infty_{n=0} \frac 1{n!} z^n = \exp(z).
\ee

Alternatively, we can see Example \ref{exa:derivative_of_exponential_complex}.%\footnote{add example in complex analysis here. or we can give a link of that exmaple}
\end{proof}

%\begin{remark}
%$F:\C\mapsto\C$ is differentiable. If $F'(z)=0,\ \forall z\in \C$, then $F$ is constant. Let $g(t)=F(tz)$, $g:[0,1]\mapsto \C$. Write
%\be
%g(t) = u(t) + iv(t), \quad \text{where } u,v:[0,1]\mapsto \R.
%\ee

%With chain rule, we have $g'(t) = F'(tz)z = 0 \ \ra \ u'(t)=v'(t)=0$. By Corollary \ref{cor:derivative_greater_equal_to_zero}, we have $u$ and $v$ are constants.


\begin{proposition}\label{pro:exponential_of_sum_is_product_of_exponential_complex}
For any $z_1,z_2\in \C$, we have
\be
\exp\bb{z_1+z_2} = \exp\bb{z_1} \cdot \exp\bb{z_2}.
\ee
\end{proposition}

%\begin{remark}
%This gives
%\be
%e^z = e^{x+iy} = e^x \bb{\cos x + i\sin y}.
%\ee
%which implies $e^z \neq 0$.

%Also, since $1 = \exp(0) = \exp(z-z)$,
%\be
%\exp(-z) = 1/\exp(z).
%\ee
%\end{remark}

\begin{remark}
Therefore, we have the following conclusions
\ben
\item [(i)] For $z = x + iy$,
\be
e^z = e^{x+iy} = e^x \bb{\cos x + i\sin y}
\ee
by Euler's formula.

\item [(ii)] (i) implies that $e^z \neq 0$ for any $z\in \C$. Also, for any $w\in \C\bs\bra{0}$, we can find $z\in \C$ such that $e^z = w$ by the argument of polar form.

\item [(iii)] Since $1 = \exp(0) = \exp(z-z)$, we have for any $z\in \C$,
\be
\exp(-z) = 1/\exp(z).
\ee
\een
\end{remark}

\begin{proof}[\bf Proof]%{\bf Approach 1.}
By definition of exponential function,
\beast
\exp\bb{z_1+z_2} = \sum^\infty_{n=0} \frac{(z_1+z_2)^n}{n!} = \sum^\infty_{n=0} \frac{1}{n!}\sum^n_{k=0}\binom{n}{k}z_1^kz_2^{n-k} = \sum^\infty_{n=0} \sum^n_{k=0} \frac{1}{n!} \frac{n!}{k!(n-k)!} z_1^kz_2^{n-k}= \sum^\infty_{n=0} \sum^n_{k=0} \frac{z_1^k}{k!} \frac{z_2^{n-k}}{(n-k)!}.% = \sum^\infty_{n=0} \sum^\infty_{k=0} \frac{z_1^k}{k!} \frac{z_2^{n}}{n!} = \sum^\infty_{k=0} \frac{z_1^k}{k!} \sum^\infty_{n=0} \frac{z_2^{n}}{n!} = \exp\bb{z_1}\cdot \exp\bb{z_2}.
\eeast

%Note that it is feasible to switch the order the terms since the series is absolute convergence (Theorem \ref{thm:absolute_convergence_change_term_order_same_sum_complex})

Since $\exp(z)$ for $x\in\C$ is absolutely convergent, we have
\be
\exp\bb{z_1+z_2} = \exp\bb{z_1} \cdot \exp\bb{z_2}
\ee
by Mertens' theorem (Theorem \ref{thm:mertens_cauchy_product}).
\end{proof}

\begin{proof}[\bf Alternative Proof.]
First we define the function $f:\C\to \C$ for any $z_1,z_2\in \C$
\be
f(z) = \exp(z_1+z_2-z)\cdot \exp(z).
\ee

Then by Proposition \ref{pro:derivative_natural_exponential_complex}.
\be
f'(z) = -\exp(z_1+z_2-z)\cdot \exp(z) + \exp(z_1+z_2-z)\cdot \exp(z) = 0
\ee
which implies that $f(z)$ is constant for any $z\in \C$ by Theorem \ref{thm:holomorphic_derivative_zero_on_open_connected_set_implies_constant}. %Corollary \ref{cor:holomorphic_derivative_zero_on_open_connected_set_implies_constant}%{pro:holomorphic_derivative_zero_implies_constant}.

%Thus, we claim $e(a+b)=e(a)e(b), \ a,b\in\C$ and define $F:\C\mapsto\C$

Therefore,
\be
f(z) = f(0) = \exp\bb{z_1+z_2}\cdot \exp(0) = \exp\bb{z_1+z_2}.
\ee

Meantime, for $z = z_2$, we have
\be
\exp\bb{z_1+z_2} = f(z_2) = \exp(z_1+z_2-z_2)\cdot \exp(z_2) = \exp(z_1)\cdot \exp(z_2)
\ee
as required.%Thus, $F(z) = F(0) = e(a+b)e(0)$. From the definition of $e$, $e(0)=1$, so $F(z)= e(a+b),\ \forall z\in\C$. Let $z=b$, we have $e(a+b)=e(a)e(b)$.
\end{proof}


%{\bf Approach 2.} Consider the function
%\be
%f(z_1,z_2) = \frac{e^{z_1}e^{z_2}}{e^{z_1+z_2}},\qquad z_1,z_2\in \C.
%\ee

%Taking partial differentiation\footnote{definition needed.} with respect to $z_1$, we have
%\be
%\fp{f}{z_1} = \frac{\bb{e^z_1}'e^{z_2}e^{z_1+z_2} - e^{z_1} e^{z_2}\bb{e^{z_1+z_2}}'}{\bb{e^{z_1+z_2}}^2} = \frac{e^{z_1}e^{z_2}e^{z_1+z_2} - e^{z_1} e^{z_2} e^{z_1+z_2}}{\bb{e^{z_1+z_2}}^2} = 0
%\ee
%by derivatives of exponential function $\exp$. Similarly,
%\be
%\fp{f}{z_2} = 0
%\ee
%which implies that $f$ is a constant function. But we know that $f(0,0) = 1$ by series definition, so we have
%\be
%\exp\bb{z_1+z_2} = \exp\bb{z_1} \cdot \exp\bb{z_2}
%\ee





%\subsection{Cauchy's functional equation}

%\section{Logarithm Function}


\subsection{Logarithm function of real numbers}



%\begin{remark}
%(vi) and (ii) are saying that the map $e:(\R,+)\mapsto ((0,\infty),\times)$ is group isomorphism. Since $e:\R\mapsto(0,\infty)$ is a bijection, $\exists l:(0,\infty)\mapsto \R$ s.t. $e(l(t))=t,\ \forall t\in(0,\infty)$ and $l(e(x))=x,\ \forall x\in\R$.
%\end{remark}

\begin{theorem}[logarithm function of real numbers]\label{thm:logarithm_function_real_numbers}
There exists a unique inverse function of $\exp:\R\to (0,\infty)$. We denote this function as logarithm function, $\log(x)$. That is,
\be
\log\bb{\exp(x)} = x,\quad \forall x\in \R,\qquad \exp\bb{\log(x)}=x,\quad \forall x\in (0,\infty).
\ee

Furthermore, $\log:(0,\infty)\to \R$ is strictly increasing, continuous and bijective.
\end{theorem}

%\begin{remark}
%Since $\exp$ and $\log$ are bijective, we have for any $x\in (0,\infty)$,
%\be
%\exp\bb{\log(x)} = x.
%\ee
%\end{remark}

\begin{proof}[\bf Proof]%Since $\exp$ is strictly increasing continuous bijection by Proposition and Proposition \ref{pro:natural_exponential_real_properties}, we have logarithm function by Theorem \ref{thm:real_strictly_increasing_continuous_bijective_inverse_strictly_increasing_continuous}.
Since $\exp:\R\to (0,\infty)$ is bijective by Proposition \ref{pro:natural_exponential_real_properties}, it has a unique inverse function, denoted by $\log:(0,\infty)\to \R$, by Theorem \ref{thm:bijective_function_has_unique_inverse}.

Then since $\exp$ is continuous and strictly increasing (see Proposition \ref{pro:natural_exponential_real_continuous} and Proposition \ref{pro:natural_exponential_real_properties}), $\log$ is also continuous and strictly increasing by Theorem \ref{thm:real_strictly_increasing_continuous_bijective_inverse_strictly_increasing_continuous}.

Finally, we have $\log:(0,\infty)\to \R$ is bijective by Corollary \ref{cor:inverse_of_bijective_function_is_bijective}.
\end{proof}


\begin{proposition}
Let $\log:(0,\infty)\to \R$ be logarithm function. Then $\log(x)$ is differentiable at any $x\in (0,\infty)$ and
\be
\fd{}{x}\log(x)=\frac 1x.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
$\log$ is differentiable by the inverse rule (Theorem \ref{thm:inverse_rule_real_function}). For any $x\in (0,\infty)$
\be
\fd{}{x}\log(x) = \frac{1}{e'(\log(x))} = \frac1{e(\log(x))} = \frac 1x
\ee
by Theorem \ref{thm:logarithm_function_real_numbers}.
\end{proof}

\begin{proposition}\label{pro:logarithm_product_is_summation_of_logarithm}
Let $\log:(0,\infty)\to \R$ be logarithm function. For any $x,y\in(0,\infty)$,
\be
\log(xy) = \log(x) + \log(y).
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Let $a = \exp(x)$ and $b= \exp(y)$. By Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_real}
\be
\log x + \log(y) = \log\bb{\exp\bb{\log x + \log(y)}} = \log\bb{\exp\bb{\log x}\exp\bb{\log y}} = \log\bb{xy}.
\ee
\end{proof}

The following proposition can be considered as the alternative proof of Theorem \ref{thm:convergence_of_one_plus_x_over_n_power_n}.

\begin{proposition}\label{pro:one_plus_one_over_n_power_n_converges_exp}
For $n\in \Z^+$,
\be
\lim_{n\to\infty} \bb{1+\frac 1n}^n = e.
\ee

Furthermore, for any $x\in \R$
\be
\lim_{n\to\infty} \bb{1+\frac xn}^n = e^x.
\ee
\end{proposition}

\begin{remark}
This is the definition of exponential function proposed by Leonhard Euler around 1730.\footnote{check if it can be $\C$.}%\footnote{see wiki} With the proposition, it is also easy to have for $x\in \R$
\end{remark}

\begin{proof}[\bf Proof]
First, we can pick large enough $n\in \N$ such that $1+\frac xn > 0$. Due to the continuity (see Definition \ref{def:continuous_function_real}) of $\exp$, we have that
\beast
\lim_{n\to\infty} \bb{1+\frac xn}^n & = & \lim_{n\to\infty} \exp\bb{\log\bb{1+\frac xn}^n } = \exp\bb{\lim_{n\to\infty} n\log\bb{1+\frac xn}} \\
& = &  \exp\bb{\lim_{n\to\infty}n\bb{\frac xn + O\bb{ \frac{1}{2n^2}}}} = \exp\bb{\lim_{n\to\infty} x  + O\bb{\frac 1{n}}} = e^x
\eeast
by Taylor expansion\footnote{theorem needed.} on real domain.
\end{proof}

\begin{proposition}\label{pro:exponential_limit_quadratic_power}
For $a,b,x\in \R$ with $a\neq 0$,
\be
\lim_{x\to \infty}e^{bx}\bb{1 + \frac{b}{ax}}^{-ax^2 - bx} = \exp\bb{-\frac{b^2}{2a}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Due to the continuity (see Definition \ref{def:continuous_function_real}) of $\exp$ and Taylor expansion\footnote{theorem needed.} on real domain, we have that
\beast
\lim_{x\to\infty}  e^{bx}\bb{1 + \frac{b}{ax}}^{-ax^2 - bx} & = & \exp\bb{\lim_{x\to\infty}  bx - \bb{ax^2 + bx} \log \bb{1 + \frac{b}{ax}}  }  \\
& = &  \exp\bb{\lim_{x\to\infty}bx - \bb{ax^2 + bx} \bb{\frac {b}{ax} - \frac{b^2}{2a^2x^2} + O\bb{ \frac{1}{2x^3}}}} \\
& = &  \exp\bb{\lim_{x\to\infty} - \frac{b^2}{2a} + O\bb{\frac 1{x}}} = \exp\bb{-\frac{b^2}{2a}}.
\eeast
\end{proof}

\begin{proposition}\label{pro:log_bound_of_summation_natural_inverse}
For any $n\in \Z^+$,
\be
\log n < \sum^n_{k=1}\frac 1k <  1+\log n.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Define real-valued function $f_1,f_2,f_3$ on $[1,n]$,
\be
f_1(x) = \frac 1{\floor{x}}, \quad f_2(x) = \frac 1{x}, \quad f_3(x) = \frac 1{\ceil{x}}.
\ee

\begin{center}
\begin{pspicture}(-0.5,-0.5)(10.4,4.5)
 \psaxes[Dx=1,Dy=1,dx=2,dy=4,labelFontSize=\scriptstyle]{->}(10.4,4.5)
 \psplot[plotpoints=100,linewidth=1pt,algebraic]{2}{10}{8/x}
\psStep[linecolor=magenta,fillstyle=hlines](2,10){4}{8 x div}
\psStep[linecolor=blue,StepType=upper,fillstyle=vlines](2,10){4}{8 x div}
\rput[lb](8,4){\textcolor{red}{$f_1(x) = 1/\floor{x}$}}
\rput[lb](8,3.5){\textcolor{black}{$f_2= 1/x$}}
\rput[lb](8,3){\textcolor{blue}{$f_3= 1/\ceil{x}$}}
\end{pspicture}
\end{center}

It obvious that $f_1>f_2>f_3$ on $[1,n]$. Then integrating these three functions from 1 to $n$, we have
\be
\sum^{n}_{k=2} \frac 1k < \int^n_1 \frac 1x dx = \log n < \sum^{n-1}_{k=1} \frac 1k < \sum^{n}_{k=1} \frac 1k \ \ra\ \log n < \sum^n_{k=1}\frac 1k < 1+\log n
\ee
as required.
\end{proof}

\begin{proposition}
We introduce a tuning parameter $\alpha \in [0,\infty]$.

Consider the sequence
\be
x_\alpha (n) := \bb{1+\frac 1n}^{n+\alpha}.
\ee

Then $\lim_{n\to \infty}x_\alpha (n) =e$ for any $\alpha$, but the monotonicity and the position of $x_\alpha(n)$ with respect to $e$ changes with $\alpha$ (i.e., they both can be tuned by varying $\alpha$). Then %the following statements can be proved.
\ben
\item [(i)] If $\alpha \geq 1/2$, then $x_\alpha(n)$ decreases strictly and converges to $e$ from above.
\item [(ii)] There exists a number $a\in (0,1/2)$ such that
\ben
\item [(a)] If $\alpha\in (0,a)$, then $x_\alpha(n)$ increases strictly and converges to $e$ from below.
\item [(b)] If $\alpha \in (a,1/2)$, then there exist $\nu = \nu(\alpha)\in \N$ such that $x_\alpha(n)$ decreases for $1\leq n\leq \nu$, increases for $n>\nu$ and converges to $e$ from below.
\een
\een
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{remark}
The number $a$ is something like $\ln 4 -1 \approx 0.3863$\footnote{proof needed. The proofs of these facts are tedious and lengthy but also elementary, for they rely on Differential Calculus.}

Moreover, a simple computation with Taylor series expansion yields that $x_{1/2}(n)$ is the sequence which has the best rate of convergence to $e$ among the $x_\alpha(n)$. In fact, we have for $\alpha \neq 1/2$,
\beast
x_\alpha(n) - e & = & \exp\bb{(n+\alpha)\log\bb{1+\frac 1n}} - e = \exp\bb{(n+\alpha)\bb{\frac 1n - \frac 1{2n^2} + o\bb{\frac 1{n^2}}}} - e \\
& = & \exp\bb{1 + \frac {2\alpha-1}{2n} + o\bb{\frac 1n}} - e = \frac {e(2\alpha-1)}{2n} + o\bb{\frac 1n}.
\eeast

However,
\beast
x_{1/2}(n) - e & = & \exp\bb{(n+1/2)\log\bb{1+\frac 1n}} - e = \exp\bb{(n+1/2)\bb{\frac 1n - \frac 1{2n^2} + \frac 1{3n^3} + o\bb{\frac 1{n^3}}}} - e \\
& = & \exp\bb{1 + \frac 1{12n^2} + o\bb{\frac 1{n^2}}} - e = \frac e{12n^2} + o\bb{\frac 1{n^2}}.
\eeast
\end{remark}



\subsection{Stirling's formula}

\begin{theorem}[Stirling's formula]\label{thm:stirling_formula}
As $n \to \infty$,
\be
\log\bb{\frac{n! e^n}{n^{n+\frac 12}} } = \log\bb{\sqrt{2\pi}} + O(1/n).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Let $c_n = \log (n!) + n - (n + \tfrac 12)\log n$, then
\be
c_n - c_{n+1} = (n + \tfrac 12 ) \log (1 + 1/n) - 1.\quad\quad (*)
\ee
For $0 < x < 1$, if we subtract the two expressions
\beast
\log(1 + x) - x & = & -\frac {x^2}2 + \frac{x^3}3 - \frac{x^4}4 + \dots \quad\quad (\dag)\\
\log(1 - x) + x & = & -\frac {x^2}2 - \frac{x^3}3 - \frac{x^4}4 - \dots \quad\quad (\dag\dag)
\eeast
and divide by $2x$, we obtain
\beast
\frac 1{2x} \log\bb{\frac{1 + x}{1 - x}} - 1 = \frac{x^2}3 + \frac{x^4}5 + \frac{x^6}7 + \dots \leq \frac{x^2}3 + \frac{x^4}3 + \frac{x^6}3 + \dots = \frac 13 \frac{x^2}{1 - x^2}.
\eeast
Now put $x = 1/(2n + 1)$ and we see from ($*$) that the left-hand side of ($\dag$) is then $c_n - c_{n+1}$, and furthermore from ($\dag$) that $c_n - c_{n+1} \geq 0$ and from ($\dag\dag$) that
\be
c_n - c_{n+1} \leq \frac 1{12} \bb{\frac 1n - \frac 1{n + 1}}.
\ee
This shows that $c_n$ is monotone non-increasing in $n$ and $c_n - 1/(12n)$ is monotone non-decreasing so that $c_n$ is bounded below and hence converges $c_n \to c$, for some $c$.

To determine the value of $c$, define $I_r = \int^{\pi/2}_0 \sin^r \theta d\theta$, for $r \geq 0$, so that $I_0 = \pi/2$ and $I_1 = 1$. Integrating by parts for $r > 1$, we have
\be
I_r = -[-\sin^{r-1} \theta \cos \theta ]^{\pi/2}_0 + (r - 1) \int^{\pi/2}_0 \sin^{r-2} \theta \cos^2 \theta d\theta = (r - 1) (I_{r-2} - I_r),
\ee
so that $rI_r = (r - 1)I_{r-2}$. It is immediate that $I_{2n+1} \leq I_{2n} \leq I_{2n-1}$, hence
\be
1 \leq \frac{I_{2n}}{I_{2n+1}} \leq \frac{I_{2n-1}}{I_{2n+1}} = \frac{2n + 1}{2n} \to 1,\quad\text{as }n \to \infty.
\ee
Calculate
\be
I_{2n} = \frac{2n-1}{2n} I_{2n-2} = \frac{(2n-1)(2n - 3) \dots 1}{(2n)(2n - 2) \dots 2}I_0 = \frac{(2n)!}{(2^n n!)^2}\frac{\pi}2.
\ee
\be
I_{2n+1} = \frac{2n}{2n + 1} I_{2n-1} = \frac{(2n)(2n - 2) \dots 2}{(2n + 1)(2n - 1) \dots 1}I_1 = \frac{(2^nn!)^2}{(2n + 1)!}.
\ee
Dividing these we see that, as $n \to \infty$,
\be
\frac{I_{2n}}{I_{2n+1}} = \frac{(2n + 1)((2n)!)^2}{ (2^nn!)^4} \frac{\pi}2 \to 1,\quad \text{ or } \quad \frac{(2^nn!)^2}{(2n)!} \frac 1{\sqrt{n}} \to \sqrt{\pi}.
\ee
Now note that
\be
2c_n - c_{2n} = \log\sqrt{2} + \log\bb{\frac{(2^nn!)^2}{(2n)!} \frac 1{\sqrt{n}}} \to \log \sqrt{2} + \log\sqrt{\pi} = \log\sqrt{2\pi},
\ee
so that $c = \lim_{n\to \infty} (2c_n - c_{2n}) = \log\sqrt{2\pi}$, as required.
\end{proof}

The most common statement of Stirling's formula is given as a corollary.

\begin{corollary}[Stirling's formula\index{Stirling's formula}]
As $n \to \infty$,
\be
n! \sim \sqrt{2\pi} e^{-n} n^{n+\frac 12},
\ee
where, in this context, $\sim$ indicates that the ratio of the two sides tends to 1.
\end{corollary}

\begin{example}
Suppose that $4n$ balls, of which $2n$ are red and $2n$ are black, are put at random into two urns, so that each urn contains $2n$ balls. What is the probability that each urn contains $n$ red balls and $n$ black balls? The probability is
\beast
p_n = \binom{2n}{n} \binom{2n}{n} \left/\binom{4n}{2n}\right. = \bb{\frac{(2n)!}{n!}}^4 \frac 1{(4n)!} \sim \bb{\frac{\sqrt{2\pi} e^{-2n} (2n)^{2n+\frac 12}}{\sqrt{2\pi} e^{-n} n^{n+\frac12}}}^4 \frac 1{\sqrt{2\pi} e^{-4n}(4n)^{4n+\frac 12}} = \sqrt{\frac{2}{\pi n}} = a_n.
\eeast
We may calculate the exact probability $p_n$, its approximant $a_n$ from Stirling's formula and their ratio for different values of $n$.
\begin{center}
\begin{tabular}{c|ccccccc}
$n$ & 1 & 10 & 13 & 20 & 40 & 60 & 100\\
\hline
$p_n$ & 0.667 & 0.248 & 0.218 & 0.177 & 0.126 & 0.103 & 0.080\\
$a_n$ & 0.798 & 0.252 & 0.221 & 0.178 & 0.126 & 0.103 & 0.080\\
$p_n/a_n$ & 0.836 & 0.981 & 0.986 & 0.991 & 0.995 & 0.997 & 0.998\\
\end{tabular}
\end{center}
The case $n = 13$ corresponds to dividing a standard pack of cards in two and obtaining equal numbers of red and black cards in each half.
\end{example}

\subsection{Logarithm function of complex numbers}

\begin{definition}[multi-valued logarithm function]
For $z\in \C\bs\bra{0}$, we define the multi-valued logarithm function by
\be
\log z = \log\abs{z} + i\arg z
\ee
where $\arg z$ is an argument of $z$ and $\log \abs{z}$ denotes the natural logarithm of the positive number $\abs{z}$. We can also write that
\be
\log z = \log\abs{z} + i\bb{\Arg z + 2k\pi}
\ee
where $k$ is an integer and $\Arg z$ is the principal value of argument of $z$.
\end{definition}

\begin{example}
By standard computations, we have
\be
\log(1+i)= \log\abs{1+i} + i\arg(1+i) = \frac 12 \ln 2 + i\bb{\frac {\pi}4 + 2k\pi},
\ee
where $n$ is an integer.
\end{example}


\begin{definition}[principal value of logarithm function]
For $z\in\C\bs\bra{0}$, we define the principal value of the logarithm function as
\be
\Log z = \log \abs{z} + i\Arg z, \quad \abs{z}>0, \ -\pi < \Arg z \leq \pi.
\ee
where $\Arg z$ is the principal value of argument of $z$ and $\log \abs{z}$ denotes the natural logarithm of the positive number $\abs{z}$. Indeed,
\be
\log(z) = \Log(z) + 2k\pi i,\qquad k\in \Z.
\ee

The branch cut of $\Log$ is $(-\infty,0]$, the negative axis plus the origin.
\end{definition}

\begin{example}[principal values of logarithm function]
\ben
\item [(i)] $z=i$,
\be
\Log(i) = \log\abs{i} + i\Arg(i) = 0 + \frac {\pi}2i = \frac {\pi i}2.
\ee
\item [(ii)] $z = i+1$,
\be
\Log (1+i) = \log\abs{1+i} + i\Arg(1+i)  = \frac 12 \ln 2 + \frac {\pi i}4.
\ee
\item [(iii)] $z = -e$,
\be
\Log (-e) = \log\abs{-e} + i\Arg(-e) = 1 + \pi i.
\ee
\een
\end{example}

\begin{proposition}\label{pro:exp_logarithm_composition}
Let $\Log$ be the logarithm function with principal value.
\ben
\item [(i)] $\exp\bb{\log(z)} = \exp\bb{\Log(z)} = z$, $z\in \C\bs\bra{0}$.
\item [(ii)] $\Log\bb{\exp(z)} = z$, $\Im(z) \in (-\pi,\pi]$.
\een
\end{proposition}

\begin{proof}[\bf Proof]
\ben
\item [(i)] Let $z = re^{i\theta}$ with $\abs{z} =r>0$ and $\theta = \arg z$. Then
\be
\log(z) = \log r + i\theta + 2k\pi i,\qquad k\in \Z
\ee
and
\be
\exp\bb{\log(z)} = \exp\bb{\log r + i\theta + 2k\pi i} = \exp\bb{\log r} \cdot \exp\bb{i\theta} \cdot \exp\bb{2k\pi i} = r e^{i\theta} = z.
\ee
by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_complex}. Similarly, we have
\be
\exp\bb{\Log(z)} = z
\ee
as required.

%Let $z = re^{i\theta}$ with $r>0$. Then
%\be
%\Log (z) = \Log \bb{re^{i\theta}} = \log r + i\theta + 2k\pi i,\qquad k\in \Z.
%\ee

%Thus, by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_complex},
%\be
%\exp\bb{\Log(z)} = \exp\bb{\log r + i\theta + 2k\pi i} = \exp\bb{\log r} \cdot \exp\bb{i\theta}\cdot 1 = r\exp\bb{i\theta} = z.
%\ee

\item [(ii)] Let $z=x+iy$ with $x,y\in \R$ and $y \in (-\pi,\pi]$. Thus, since $\exp(x)>0$
\beast
\Log\bb{\exp\bb{z}} & = & \Log\bb{\exp\bb{x+ iy}} = \log\abs{\exp\bb{x+ iy}} + i\Arg\bb{\exp\bb{x+ iy}} \\
& = & \log\abs{\exp\bb{x}}\log\abs{\exp\bb{iy}} + i\Arg\bb{\exp\bb{iy}} = \log\abs{\exp\bb{x}} + i\Arg\bb{\exp\bb{iy}} \\
& = & \log\bb{\exp\bb{x}} + iy = x + iy = z
\eeast
as $w=\Log z$ maps from domain $\bra{z:\abs{z}>0}$ to horizontal strip $\bra{w:\Im\bb{w}\in (-\pi,\pi]}$.
\een
\end{proof}



\begin{example}
Unlike real logarithm function, we have $\Log\bb{z_1z_2} =\Log (z_1) + \Log(z_2) $ is not always valid. For instance,
\be
z_1 = -\sqrt{3}+i,\ z_2 = -1+i\sqrt{3} \ \ra \ z_1z_2 = -4i \ \ra\ \Log(z_1z_2) = \ln 4 - i \frac {\pi}2.
\ee

However,
\be
\Log(z_1) + \Log(z_2) = \ln 2 + i \frac{5\pi}{6}  + \ln 2 + i \frac{2\pi}{3} = 2\ln 2 + i \bb{\frac{5\pi}{6} + \frac{2\pi}{3}} = \ln 4 + i\frac{3\pi}2 \neq \Log(z_1z_2)
\ee
\end{example}

\begin{proposition}\label{pro:principal_value_logarithm_product_summation}
For principal value logarithm function $\Log$, we have
\be
\Log\bb{z_1z_2} = \Log (z_1) + \Log(z_2) \quad \text{if and only if}\quad -\pi < \Arg z_1 + \Arg z_2 \leq \pi.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
For $z_1 = r_1e^{i\theta_1}$ and $z_1 = r_2e^{i\theta_2}$ with $\theta_1,\theta_2\in (-\pi,\pi]$
\beast
\Log\bb{z_1z_2} & = & \log\abs{z_1z_2} + \Arg(z_1z_2) = \ln(r_1r_2) + \Arg\bb{e^{i(\theta_1+\theta_2)}} = \ln r_1 + \ln r_2 + \Arg\bb{e^{i(\Arg z_1+ \Arg z_2)}} \\
& = & \ln r_1 + \ln r_2 + \Arg z_1+ \Arg z_2 = \Log (z_1) + \Log(z_2)
\eeast
if and only if $-\pi < \Arg z_1 + \Arg z_2 \leq \pi$.
\end{proof}

\begin{proposition}[continuity of $\Log$]
Let $\Log:\C\bs\bra{0}$ be the principal value logarithm function. The $\Log$ is continuous on $\Arg z\in (-\pi,\pi)$ and discontinuous on $\Arg z = \pi$.
\end{proposition}

\begin{proof}[\bf Proof]
Note that $\log\abs{z}$ and $\Arg z$ are real and imaginary parts of $\Log$.

It is easy to see that $\log \abs{z}$ is continuous by Proposition \ref{pro:basic_continuous_complex_property} at any point $z\in \C\bs\bra{0}$ since $\abs{\cdot}$ and $\log(\cdot)$ are continuous (see Proposition \ref{pro:complex_real_imaginary_conjugate_modulus_continuous} and Theorem \ref{thm:logarithm_function_real_numbers}) on the corresponding domain.

Also, $\Arg z$ is continuous on $\Arg z\in (-\pi,\pi)$ and discontinuous on $\Arg z = \pi$ by Theorem \ref{thm:principal_value_argument_continuous_discontinuous}.

Thus, we have $\Log(z)$ is continuous on $\Arg z\in (-\pi,\pi)$ and discontinuous on $\Arg z = \pi$ by Proposition \ref{pro:complex_continuous_iff_real_imaginary_parts_continuous}.
\end{proof}

\begin{proposition}[differentiability of $\Log$]\label{pro:principal_value_logarithm_derivative}
Let $\Log$ be the principal value logarithm function. Then
\be
\frac{d}{dz}\Log(z) = \frac 1{z},\qquad z\neq 0,\ \Arg z \in (-\pi,\pi).
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Let $z = re^{i\theta}$ for $r>0$ and $\theta\in (-\pi,\pi]$. Then
\be
\Log(z) = \log\abs{z} + i\Arg z = \ln r + i\theta := u(r,\theta) + iv(r,\theta)
\ee
with $(r,\theta) = \ln r$ and $v(r,\theta) = \theta$. Obviously, $\Arg z$ is discontinuous only at the points that lie on the negative real axis so $v_\theta(r,\theta)$ does not exists at $\theta = \pi$. Therefore, $\Log(z)$ is not differentiable for $\theta=\pi$ by Theorem \ref{thm:cauchy_riemann_equation_polar_form}.

Then for $\theta\in (-\pi,\pi)$, we have
\be
u_r(r,\theta) = \frac 1r = \frac 1r v_\theta(r,\theta),\qquad v_r(r,\theta) = 0 = -\frac 1r u_\theta(r,\theta)
\ee
which implies that $u_r$, $v_r$, $u_\theta$ and $v_\theta$ are continuous. Then we can apply Theorem \ref{thm:sufficient_conditions_differentiable_complex_polar_form},
\be
\Log'(z_0) = e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)} = e^{-i\theta_0}\bb{\frac 1{r_0} + i\cdot 0} = \bb{r_0e^{i\theta_0}}^{-1} = \frac 1{z_0}.
\ee
\end{proof}


\begin{theorem}\label{thm:principal_value_logarithm_expansion}
For $z\in \C$ and the (principal value) logarithm function $\Log$, we have
\beast
\Log(1-z) & = &  -\sum^\infty_{n=1}\frac{z^n}{n} = -z - \frac{z^2}2- \frac{z^3}{3} - \dots , \quad \abs{z}\leq 1,\ z\neq 1,\\
\Log(1+z) & = & \sum^\infty_{n=1} (-1)^{n+1} \frac{z^n}{n} = z - \frac{z^2}{2} + \frac{z^3}{3} - \dots,\quad \abs{z}\leq 1,\ z\neq -1.
\eeast
\end{theorem}

\begin{remark}
We can also apply Taylor expansion on $\Log(1-z)$ as $\fd{}{z}\Log(1-z)$ is well-defined since $\Arg(1-z)\neq \pi$ for $\abs{z}<1$.%$\Arg(1-z) \in (-\pi,\pi)$.
\end{remark}

\begin{proof}[\bf Proof]

We know from Proposition \ref{pro:geometric_series_sum} that for $\abs{z}<1$,
\be
\sum^\infty_{n=0} z^n = \frac 1{1-z} = \sum^k_{n=0}z^n + \frac{z^{k+1}}{1-z}.
\ee%\footnote{$\frac{d}{dz}\Log(z) = \frac 1z$ for $z=re^{i\theta}$ with $r>0$ and $\theta \in (-\pi,\pi)$. Theorem needed here. In this case, $\abs{1-z}>0$ and $\Arg(1-z)\in (-\pi,\pi)$.}

Integrate this along the straight line $L$ from 0 to $z$. By Proposition \ref{pro:principal_value_logarithm_derivative}, we know that the primitive function of $1/(1-z)$ is $-\Log(1-z)$. Then
\be
\int_L \frac 1{1-w} dw = -\Log(1-z) + \Log(1-0) = -\Log(1-z) 
\ee
by Theorem \ref{thm:contour_integral_primitive_function}. Thus,
\be
-\Log(1-z) = \sum^k_{n=0}\frac 1{n+1}z^{n+1} + \int_L\frac {w^{k+1}}{1-w}dw.
\ee

%We can find an upper bound for the absolute value of the integral
%\be
%\abs{\int_L\frac {w^{k+1}}{1-w}dw} \leq \abs{z} \frac{\abs{z}^{k+1}}{1-\abs{z}} = \frac {\abs{z}^{k+2}}{1-\abs{z}}
%\ee

Also, for all $w$ on $L$, we have $\abs{1-w} \geq \abs{1} - \abs{w} \geq 1 - \abs{z}$ and $\frac{w^{k+1}}{1-w} \leq \frac{\abs{z}^{k+1}}{1-\abs{z}}$. Thus, by modulus inequality (Proposition \ref{pro:contour_integral_continuous_basic_properties}),
\be
\abs{\int_L \frac{w^{k+1}}{1-w}dw} \leq \frac{\abs{z}^{k+1}}{1-\abs{z}} \int_L dw = \frac{\abs{z}^{k+1}}{1-\abs{z}}\abs{z} = \frac{\abs{z}^{k+2}}{1-\abs{z}}.
\ee
which implies
\be
\lim_{k\to \infty} \int_L\frac {w^{k+1}}{1-w}dw = 0 \ \ra\ -\Log(1-z) = \sum^\infty_{n=1}\frac 1n z^{n},\quad \abs{z}<1.\qquad (*)
\ee

Then for any $w$ with $\abs{w}=1$ and $w\neq 0$, we can find $r = \abs{1-w} > 0$. So we can define a domain
\be
E_r = \bra{z:\abs{z}\leq 1,\abs{1-z}\geq r}
\ee
such that $w\in E_r$. Also, for any $z$ satisfying $\abs{z}\leq 1$ and $z\neq 1$, we can define
\be
a_n=1/n,\quad b_n=z^n,\quad B_n = \sum^n_{k=1} b_k = \sum^n_{k=1} z^k = \frac{z-z^{n+1}}{1-z}
\ee
and thus for any $m\geq n$
\beast
\abs{\sum^m_{k=n} \frac{z^k}{k}} & = & \abs{\sum^m_{k=n} a_k b_k} = \abs{a_{m}\sum^m_{k=n}b_k + \sum^{m-1}_{k=n}b_k\bb{a_k-a_{m}}} = \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{k=n}b_k\sum^{m-1}_{i=k}\bb{a_i-a_{i+1}} } \\
& = & \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}\sum^i_{k=n}b_k } =  \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}\bb{B_i - B_{n-1}} }\\%\abs{a_mB_m - a_{n}B_{n-1} - \sum^{m-1}_{k=n}B_k(a_{k+1} - a_k)}
& = & \abs{a_{m}\bb{B_m - B_{n-1}} + \bb{a_m- a_n} B_{n-1}+ \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}B_i } = \abs{a_{m}B_m  - a_n B_{n-1}+ \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}B_i } \\
& \leq & \frac 2{\abs{1-z}}\bb{\frac 1m + \frac 1n + \sum^{m-1}_{i=n}\bb{\frac 1i - \frac 1{i+1}}} = \frac 4{n\abs{1-z}}.\qquad (\dag)
\eeast

Then we have that
\be
\abs{\sum^\infty_{k=n} \frac{z^k}{k}} \leq \frac 4{n\abs{1-z}}.
\ee

If not, we can find $\ve >0$ such that
\be
\abs{\sum^\infty_{k=n} \frac{z^k}{k}} - \frac 4{n\abs{1-z}} > \ve \ \ra\ \abs{\sum^\infty_{k=n} \frac{z^k}{k}} > \frac 4{n\abs{1-z}} + \ve.
\ee

But given such $\ve$, we can find $m$ large enough (since $\abs{\sum^m_{k=n} \frac{z^k}{k}}$ converges) such that
\be
\abs{\sum^\infty_{k=n} \frac{z^k}{k} - \sum^m_{k=n} \frac{z^k}{k}} < \ve.
\ee

Then by Proposition \ref{pro:real_number_inequality_absolute_value},
\beast
\abs{\sum^m_{k=n} \frac{z^k}{k}} & = & \abs{\sum^\infty_{k=n} \frac{z^k}{k}- \sum^m_{k=n} \frac{z^k}{k} - \sum^\infty_{k=n} \frac{z^k}{k}} \geq \abs{\abs{\sum^\infty_{k=n} \frac{z^k}{k} - \sum^m_{k=n} \frac{z^k}{k}} - \abs{\sum^\infty_{k=n} \frac{z^k}{k}}} \\
& \geq & \abs{\sum^\infty_{k=n} \frac{z^k}{k}} - \abs{\sum^\infty_{k=n} \frac{z^k}{k} - \sum^m_{k=n} \frac{z^k}{k}} > \frac 4{n\abs{1-z}} + \ve - \ve = \frac 4{n\abs{1-z}}
\eeast
which is a contradiction with ($\dag$).

Therefore, for any $z\in E_r$, we have
\be
\abs{\sum^\infty_{k=1} \frac{z^k}{k} - \sum^{n}_{k=1} \frac{z^k}{k}} = \abs{\sum^\infty_{k=n+1} \frac{z^k}{k}} \leq \frac 4{(n+1)\abs{1-z}} \leq \frac 4{(n+1)r}
\ee
which means that
\be
\sum^{n}_{k=1} \frac{z^k}{k} \ \text{ uniformly converges on }E_r.
\ee

Since $f_n(z) := \sum^{n}_{k=1} \frac{z^k}{k}$ are continuous, so we can have the
\be
\lim_{n\to \infty} f_n(z) = f(z) = \sum^{\infty}_{n=1} \frac{z^n}{n}\ \text{ is continuous on }E_r.
\ee

But $w\in E_r$ and thus
\be
\lim_{z\to w}\sum^{\infty}_{n=1} \frac{z^n}{n} = \sum^{\infty}_{n=1} \frac{w^n}{n}, \quad \abs{w}=1,\ w \neq 1.
\ee

So by ($*$) and continuity of $\Log$, we have that for any $\abs{z}\leq 1$ but $z\neq 1$,
\be
\sum^{\infty}_{n=1} \frac{z^n}{n} = \lim_{w\to z,\abs{w}<1}\sum^{\infty}_{n=1} \frac{w^n}{n} = -\lim_{w\to z,\abs{w}<1}\Log(1-w) = -\Log(1-z).
\ee

Then replace $z$ with $-z$ we can have
\be
\Log(1+z) = \sum^\infty_{n=1} \frac{(-1)^{n+1}}{n}z^n,\qquad \abs{z}\leq 1,\ z\neq -1.
\ee
\end{proof}


\begin{example}
Let $z=1$, we have
\be
\sum^\infty_{n=1} \frac{(-1)^{n+1}}{n} = \sum^\infty_{n=1} \frac{(-1)^{n+1}}{n}z^n =  \Log(1+z) = \Log(2) = \ln 2.
\ee

In other words,
\be
1 - \frac 12 + \frac 13 - \frac 14 + \frac 15 - \dots = \ln 2.
\ee
\end{example}

\subsection{Exponential function of real numbers}

%$a^z$
%For real $x$ and $a>0$, we have
%\be
%a^x = e^{x\ln a}
%\ee

\begin{definition}[exponential function of real numbers]
For $a>0$, $x\in \R$, the exponential function is defined by
\be
a^x := \exp\bb{x\log a}.
\ee
\end{definition}

\begin{remark}
Clearly,
\be
\log\bb{a^x} = \log\bb{\exp\bb{x\log a}} = x\log a
\ee
by definition of $\log$.
\end{remark}



\subsection{Exponential function of complex numbers}

\begin{definition}[exponential function of complex number]
Let $z\in \C$. If $a>0$,
\be
a^z := e^{z\log a}.
\ee

If $a\in \C\bs\bra{0}$,
\be
a^z := e^{z\log a} = e^{z\log\abs{a} + iz\Arg a + 2i k\pi z} .
\ee
\end{definition}

\begin{remark}
Clearly, if $a>0$ and $z = x+iy$,
\be
\abs{a^z} = \abs{e^{z\log a}} = \abs{e^{x\log a + iy\log a}} =\abs{e^{x\log a}} = e^{x\log a} = a^{\Re z}.
\ee
\end{remark}

\begin{example}
For $a=i$ and $z = i$, we have
\be
i^i = e^{i\log\abs{i} + i^2\Arg i + 2i^2 k\pi} = e^{0 - \frac {\pi}2 - 2 k\pi} = e^{-\bb{\frac {\pi}2 + 2k\pi}}.
\ee
\end{example}

\subsection{Additive functions}

\begin{definition}[additive function\index{additive function!real analysis}]\label{def:cauchy_equation_additive_function}
A function $f : \R \to \R$ is additive if it satisfies the Cauchy equation
\be
f(x+y)=f(x)+f(y) \qquad x,y\in \R.
\ee
\end{definition}

\begin{remark}
Clearly, linear functions are additive.
\end{remark}

We give the theorem about ``tam'' additive functions.

\begin{theorem}
Let $f : \R \to \R$ be an additive function, and let $I = [a,b]$ be an arbitrary interval (with $a < b$). Then $f$ is linear, that is, $\exists c$ such that $\forall x$, $f(x) = cx$ on $I$ if any one of the following is satisfied
\ben
\item [(i)] $f$ is monotone on $I$.
\item [(ii)] $f$ is continuous on $I$.\footnote{This is proved by Cauchy in 1821. This condition was weakened in 1875 by Darboux who showed that it was only necessary for the function to be continuous at one point.}
\item [(iii)] $f$ is bounded on $I$.
\item [(iv)] $f$ is Lebesgue measurable.
\een
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

%\subsection{Exponential function}

\begin{theorem}\label{thm:function_product_is_function_of_sum_continuous_version}
If a real non-zero continuous function (or it is also sufficient to be continuous at one point) has the property $f(x+y) = f(x)f(y)$ then $f(x) = a^{x}$ for some constant $a\in \R^+$.
\end{theorem}

\begin{proof}[\bf Proof]
First for any $x\in \R$, $f(x) = f(x/2 + x/2) = \bb{f(x/2)}^2 \geq 0$. Also if there is any value $y$ such that $f(y) = 0$ then
\be
f(x) = f(x-y+y) = f(x-y)f(y) = 0
\ee
which implies that $f$ is a zero function. Thus, $f(x)>0$. Then we have that $f(x) = f(x+0) = f(x)f(0) \ \ra\ f(0) = 1$. Therefore we assume that $f(1) = a>1$. Then $f(n+1) = f(n)f(1) = a^n$ for all $n\in\N$. Also, we have
\be
f(0) = f(n + (-n)) = f(n)f(-n) \ \ra\ f(-n) = a^{-n}\ \ra\ f(x) = a^x,\ x\in \Z.
\ee

Then we can pick $p\in \Z^+$, such that
\be
a = f(1) = f\bb{\frac 1p + \dots + \frac 1p} = \bb{f\bb{\frac 1p}}^p \ \ra\ f\bb{\frac 1p} = a^{\frac 1p}
\ee

Thus, we have $f(x) = a^x$ for all $x\in \Q$. Since $f$ is continuous everywhere it can be shown that $f(x) =a^x$ for all $x\in\R$ since $\Q$ is dense in $\R$. (Let $f$ and $g$ be continuous functions and $f(x) =g(x)$ for all rational $x$. Then for any real number $c$, there exists a Cauchy sequence of rational numbers such that $\lim_{n\to\infty}x_n =c$. Since $f$ and $g$ are continuous, $\lim_{n\to \infty}f(x_n) = f(c)$ and $\lim_{n\to \infty}g(x_n) = g(c)$. Since $x_n$ is rational, $f(x_n) = g(x_n)$ for all $n$, so the two limits must be equal and so $f(c) = g(c)$ for all real $c$.)%then by the similar argument, we have that $f$ is continuous at any point $y$ where $y = qx$ with rational $q$
\end{proof}

\begin{remark}
It is actually sufficient for $f$ to be continuous merely at one point. If $f$ is continuous at point $x$, then $f(x) = \lim_{\Delta x \to 0}f(x+\Delta x) = \lim_{\Delta x \to 0}f(x)f(\Delta x) = f(x)\lim_{\Delta x \to 0}f(\Delta x) $ which implies that $\lim_{\Delta x \to 0}f(\Delta x) = 1$. Then for any $y$, we have $\lim_{\Delta y \to 0} f(y+\Delta y) = \lim_{\Delta y \to 0} f(y)f(\Delta y) = f(y) \lim_{\Delta y \to 0} f(\Delta y) = f(y)$. Therefore, $f$ is continuous at any point.
\end{remark}

Furthermore, to get the same conclusion, it suffices to assume that the function is monotone. We give a slightly stronger result first\footnote{See \cite{Feller_1968_v2}.$P_{459}$}.

\begin{theorem}\label{thm:function_product_is_function_of_sum_bounded_version}
Let $f$ be a real-valued function satisfying
\be
f(x+y) = f(x)f(y),\qquad x,y>0\qquad (*)
\ee
defined for $x>0$ and bounded in some interval $[s,t]$. Then either $f(x)=0$ for all $x$, or else $f(x) = e^{\lm x}$ for some constant $\lm\in\R$.
\end{theorem}

\begin{remark}
$(*)$ is only a notational variant of the famous Cauchy equation (see Definition \ref{def:cauchy_equation_additive_function}) $f(x+y) = f(x) + f(y)$. We can prove that its solutions are either of the form $ax$ or else unbounded in every interval. It is known that no such function is a Baire function, that is, no such function can be obtained by series expansions or other limiting processes starting from continuous functions.
\end{remark}

\begin{proof}[\bf Proof]
With the same argument in Theorem \ref{thm:function_product_is_function_of_sum_continuous_version} we have $f(x)\geq 0$ and $f(x) = \bb{f\bb{\frac 12 x}}^2$. Suppose first that $f(x) =0$ for same value $x$. Then we conclude by induction that $f(2^{-n}x) = 0$ for all integers $n$, and from $(*)$ it is clear that $f(y)=0$ implies $f(x)=0$ for all $x>y$. Thus $f(x)=0$ implies that $f$ vanishes identically. So it remains only to consider strictly positive solution of $(*)$.

Put $e^{\lm} = f(1)$ and $g(x) = e^{-\lm x}f(x)$. Note that $\lm\in\R$, otherwise $f(x)$ is not bounded in any interval. Then
\be
g(x+y) = e^{-\lm (x+y)}f(x+y) = e^{-\lm x}f(x) e^{-\lm y}f(y) = g(x)g(y),\qquad g(1) = 1.
\ee

We have to prove that this implies $g(x) = 1$ for all $x$. Obviously for arbitrary positive integers $m,n$
\be
g\bb{\frac mn} = g^m\bb{\frac 1n} = \sqrt[n]{g^m(1)} = 1
\ee
and hence $g(x) =1$ for all rational $x$. Furthermore, if $g(x) =a$ then $g(x^n) = a^n$ for any posotive or negative integer $n$. It follows that if $g$ assumes some value $a\neq 1$ then it can also be assumed to be arbitrarily large values. But using $(*)$ with $x+y = z$ it is seen that
\be
g(z-x) = g(z),\qquad x\in \Q.
\ee

That is, if $g(z) = c$, since $x$ is dense, the same value can be assumed in every interval, however small. The boundedness of $f$ in some interval therefore precludes the possibility of any value $\neq 1$.

Thus, $g(x) =1$ for all $t>0$ which implies that $f(x) = e^{\lm x}$ for all $t>0$.
\end{proof}

\begin{corollary}
Let $f$ be a real-valued monotone function satisfying
\be
f(x+y) = f(x)f(y),\qquad x,y\in \R.
\ee

Then either $f(x)=0$ for all $x$, or else $f(x) = e^{\lm x}$ for some constant $\lm\in\R$.
\end{corollary}

\begin{proof}[\bf Proof]
Without loss of generality, we can assume that $f$ is a decreasing function so we only consider the positive real values. %If $f(x)\neq 0$ for all $x>0$ and we cannot find any interval whose $f$ value is bounded. Then

Using the same argument in Theorem \ref{thm:function_product_is_function_of_sum_bounded_version}, $f(x)>0$. Since $f(x) = f(x+0) = f(x)f(0)$ for all $x$, we have that $f(0) = 1$ and $f(x)\leq f(0)=1$ for all $x$. Thus, $f$ on all positive values is bounded. Thus, we can apply Theorem \ref{thm:function_product_is_function_of_sum_bounded_version} to get the required result. Then we use the fact $f(0)=1$ to get the corresponding result for negative real values.
\end{proof}




\section{Trigonometric Functions}

%\subsection{Trigonometric functions}

\subsection{Sine and cosine functions}

\begin{definition}[sine function\index{sine function}, cosine function\index{cosine function}]\label{def:sine_cosine_function}
For complex number $z$, we define the sine function $\sin:\C\to \C$ by
\be
\sin z = \sum^\infty_{n=0}\frac{(-1)^nz^{2n+1}}{(2n+1)!} = z - \frac {z^3}{3!}+ \frac {z^5}{5!} - \frac {z^7}{7!} + \dots
\ee
and cosine function $\cos:\C\to \C$ by
\be
\cos z= \sum^\infty_{n=0}\frac{(-1)^nz^{2n}}{(2n)!} = 1 - \frac {z^2}{2!} + \frac {z^4}{4!} - \frac {z^6}{6!} + \dots
\ee
\end{definition}

\begin{remark}
Both functions have infinite radius of convergence.

For sine function, by Proposition \ref{pro:ratio_test_convergence_radius}, %{pro:ratio_convergence_radius},%Cauchy-Hadamard theorem (Theorem \ref{thm:cauchy_hadamard_radius_of_convergence}),
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{(2n+1)!}{(2n+3)!}} = \abs{\frac{1}{(2n+2)(2n+3)}} \to 0 \ \ra\ \ R = \infty.
\ee

Similarly for cosine function.
\end{remark}


\begin{theorem}[Euler's formula\index{Euler's formula}]\label{thm:euler_formula_exponential}
Let $z\in \C$. Then
\be
e^{iz} = \cos z + i\sin z
\ee
where $\exp(\cdot)$ is the complex-valued exponential function.
\end{theorem}

\begin{proof}[\bf Proof]
Substituting $iz$ into the definition of exponential function, we have
\be
e^{iz} = \sum^\infty_{n=0}\frac 1{n!} (iz)^n = \sum^\infty_{n=0} \frac {(-1)^n}{(2n)!} z^{2n} + i\sum^\infty_{n=0} \frac {(-1)^n}{(2n+1)!} z^{2n+1} = \cos z + i\sin z
\ee
by infinite summation definitions of $\cos z$ and $\sin z$. Note that we can change the order of series terms since the series is absolutely convergent.
\end{proof}




\begin{proposition}\label{pro:sine_cosine_continuous_differentiable}
For any $z\in \C$, $\sin z$ and $\cos z$ are both continuous and differentiable. Furthermore,
\be
\frac{d}{dz} \sin z = \cos z,\qquad \frac{d}{dz}\cos z = -\sin z.
\ee

In particular, for any $x\in \R$, $\sin x$ and $\cos x$ are both continuous and differentiable. Then
\be
\frac{d}{dx} \sin x = \cos x,\qquad \frac{d}{dx}\cos x = -\sin x.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Direct result by Proposition \ref{pro:differentiability_implies_continuity_complex_function} and Theorem \ref{thm:power_series_differentiation} as both sine and cosine have radius of convergence $\infty$.

Note that we can have the derivative limit along the real axis and get the required results for real number $x$.
\end{proof}



%{\bf Approach 2.} Another proof is based on the fact that all the complex numbers can be expressed in polar coordinates\footnote{theorem needed.}. Therefore, for some $r$ and $\theta$ depending on $x$,
%\be
%e^{ix} = r\bb{\cos \theta + i\sin \theta},\qquad \theta\in [0,2\pi).
%\ee

%Since the derivative of $e^{ix}$ is $ie^{ix}$, we have
%\be
%r\bb{i\cos \theta - \sin \theta} = ie^{ix} = \frac{d}{dx}e^{ix} = \frac{d}{dx}\bb{r\bb{\cos\theta + i\sin\theta}} = \bb{\cos\theta + i\sin\theta}\frac{dr}{dx} + r\bb{-\sin\theta + i\cos \theta} \frac{d\theta}{dx}
%\ee

%Thus, equating the real and imaginary parts,
%\beast
%-r \sin \theta = \cos\theta \frac{dr}{dx} - r\sin \theta \frac{d\theta}{dx},\\
%r\cos\theta = \sin\theta \frac{dr}{dx} + r\cos\theta \frac{d\theta}{dx}.
%\eeast

%Thus these equations implies
%\be
%\frac{dr}{dx} = 0,\quad \frac{d\theta}{dx} = 1 \ \ra\ r = C_1,\quad \theta = x + C_2
%\ee
%where $C_1$ and $C_2$ are constant. But we have that $e^{i0} = 1$ which implies that $r(0) = 1$ and $\theta(0) = 0$ and therefore
%\be
%r = 1,\ \theta = 0 + x = x \ \ra\ e^{ix} = 1\cdot \bb{\cos\theta + i\sin x} = \cos x + i\sin x.
%\ee



\subsection{Basic properties of sine and cosine functions}


%\begin{remark}
%For any $z\in \C$,
%\be
%\sin z = \frac{e^{iz} - e^{-iz}}{2i},\qquad \cos z = \frac{e^{iz} + e^{-iz}}{2}.
%\ee
%\end{remark}


\begin{proposition}\label{pro:basic_properties_of_sine_and_cosine}
For any $z\in \C$,
\be
\sin (-z) = -\sin z,\qquad \cos(-z) = \cos z.
\ee

In other words, $\sin$ is an odd function and $\cos$ is an even functon.

Also,
\be
\sin z = \frac{e^{iz} - e^{-iz}}{2i},\qquad \cos z = \frac{e^{iz} + e^{-iz}}{2}.
\ee

Furthermore,
\be
\cos^2 z + \sin^2 z = 1.
\ee
\end{proposition}


\begin{remark}
Note that if $x\in \R$, we have
\be
\abs{\sin x} \leq 1,\quad \abs{\cos x}\leq 1.
\ee

However, $\abs{\sin z}$ and $\abs{\cos z}$ are not bounded in general for $z\in\C$. For instance, for $z = iy$, $y\in \R$
\be
\cos z  = \cos (iy) = \frac{e^{-y} + e^{y}}2 \to \infty
\ee
as $y\to \infty$.
\end{remark}

\begin{proof}[\bf Proof]
It is easy to have the first result by definitions of sine and cosine functions. Combining Euler's formula, we have
\be
\left\{\ba{l}
e^{iz} = \cos z + i\sin z,\\
e^{-iz} = \cos z - i\sin z
\ea\right. \ \ra\ \cos z = \frac{e^{iz} + e^{-iz}}2,\ \sin z  = \frac{e^{iz} - e^{-iz}}{2i}.
\ee

Then by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_complex}
\beast
\cos^2 z + \sin^2 z & = & \bb{\frac{e^{iz} + e^{-iz}}2}^2 + \bb{\frac{e^{iz} - e^{-iz}}{2i}}^2 \\
& = & \frac 14\bb{e^{2iz} + e^{-2iz} + 2e^0 - \bb{e^{2iz} + e^{-2iz} - 2e^0}} = 1.
\eeast
\end{proof}


\begin{proposition}\label{pro:sine_and_cosine_of_summation}
For any $z,w\in \C$,
\beast
\sin (z+w) & = & \sin z \cos w + \cos z \sin w,\\
\cos(z+w) & = & \cos z \cos w - \sin z\sin w.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
By Euler's formula (Theorem \ref{thm:euler_formula_exponential}), Proposition \ref{pro:basic_properties_of_sine_and_cosine} and \ref{pro:exponential_of_sum_is_product_of_exponential_complex}, we have
\beast
\sin (z+w) & = & \frac{e^{i(z+w)}-e^{-i(z+w)}}{2i} = \frac{e^{iz}e^{iw}-e^{-iz}e^{-iw}}{2i} = \frac{e^{iz}e^{iw}-e^{-iz}e^{iw} + e^{-iz}e^{iw} -e^{-iz}e^{-iw}}{2i} \\
& = &  \frac{\bb{e^{iz}-e^{-iz}}}{2i}e^{iw} + \frac{\bb{e^{iw} -e^{-iw}}}{2i}e^{-iz} =e^{iw} \sin z  + e^{-iz} \sin w  \\
& = & \sin z \bb{\cos w + i\sin w} + \sin w \bb{\cos z - i\sin z} = \sin z \cos w + \cos z \sin w.
\eeast

\beast
\cos (z+w) & = & \frac{e^{i(z+w)}+e^{-i(z+w)}}{2} = \frac{e^{iz}e^{iw}+e^{-iz}e^{-iw}}{2} = \frac{e^{iz}e^{iw}+e^{-iz}e^{iw} - e^{-iz}e^{iw} +e^{-iz}e^{-iw}}{2} \\
& = &  \frac{\bb{e^{iz}+e^{-iz}}}{2}e^{iw} - \frac{\bb{e^{iw} -e^{-iw}}}{2i} ie^{-iz} =e^{iw} \cos z  -i e^{-iz} \sin w  \\
& = & \cos z \bb{\cos w + i\sin w} - i\sin w \bb{\cos z - i\sin z} = \cos z \cos w - \sin z \sin w.
\eeast
\end{proof}


\begin{proposition}\label{pro:trigonometric_product_difference}
Let $\alpha,\beta,\theta \in \C$. Then% and $\in [0,2\pi]$
\beast
\sin\bb{(\alpha +1)\theta}\sin\bb{(\beta+1)\theta} - \sin\bb{\alpha\theta}\sin\bb{\beta\theta} & = & \sin\bb{(\alpha+\beta+1)\theta}\sin\theta \\
\sin\bb{(\alpha +1)\theta}\cos\bb{(\beta+1)\theta} - \sin\bb{\alpha\theta}\cos\bb{\beta\theta} &= & \cos\bb{(\alpha+\beta+1)\theta}\sin\theta.
\eeast
\end{proposition}

\begin{proof}[\bf proof]
First, we have
\beast
\sin\bb{(\alpha +1)\theta}\sin\bb{(\beta+1)\theta} & = & \frac 12\bb{\cos\bb{(\alpha-\beta)\theta} - \cos\bb{(\alpha+\beta+2)\theta}} \\
\sin\bb{\alpha\theta}\sin\bb{\beta\theta}  & = & \frac 12\bb{\cos\bb{(\alpha-\beta)\theta} - \cos\bb{(\alpha+\beta)\theta}}.
\eeast

Then we have the required result is
\be
\frac 12\bb{\cos\bb{(\alpha+\beta)\theta} - \cos\bb{(\alpha+\beta+2)\theta}} = \sin\bb{(\alpha+\beta+1)\theta}\sin\theta.
\ee

Second, we have
\beast
\sin\bb{(\alpha +1)\theta}\cos\bb{(\beta+1)\theta} & = & \frac 12\bb{\sin\bb{(\alpha+\beta+2)\theta} +\sin\bb{(\alpha-\beta)\theta} } \\
\sin\bb{\alpha\theta}\cos\bb{\beta\theta}  & = & \frac 12\bb{\sin\bb{(\alpha+\beta)\theta}+\sin\bb{(\alpha-\beta)\theta}}.
\eeast

Then we have the required result is
\be
\frac 12\bb{\sin\bb{(\alpha+\beta+2)\theta}-\sin\bb{(\alpha+\beta)\theta} } = \cos\bb{(\alpha+\beta+1)\theta}\sin\theta
\ee
as required.
\end{proof}


%\begin{remark}
%\footnote{check needed.}
%$\sin z, \cos z: \C\mapsto \C$. By Theorem \ref{thm:power_series_differentiation}, they are differentiable and
%\be
%(\sin z)' = \cos z,\quad (\cos z)' = -\sin z
%\ee

%\be
%e^{iz} = \sum^\infty_{n=0}\frac {(iz)^n}{n!} = \sum^\infty_{n=0}\frac{(iz)^{2n}}{(2n)!} + \sum^\infty_{n=0}\frac{(iz)^{2n+1}}{(2n+1)!} = \cos z + i\sin z.
%\ee

%From defintion,
%\be
%\cos (-z) = \cos z,\quad \sin(- z) = -\sin z.
%\ee
%\be
%\cos z = \frac{e^{iz}+e^{-iz}}{2},\quad \sin z = \frac{e^{iz}-e^{-iz}}{2}
%\ee



%Now we get using $e^{a+b} = e^a e^b$,
%\be
%\sin (z+w) = \sin z \cos w + \cos z \sin w,\quad \cos (z+w) = \cos z \cos w - \sin z \sin w, \quad z,w \in\C
%\ee

%Also, $\cos^2 z + \sin^2 z = 1$, $z\in\C$. If $x\in\R$, $|\sin x|\leq 1$ and $|\cos x|\leq 1$.

%\underline{Warning} $|\cos z|\ (|\sin z|)$ are not bounded for $z\in \C$. If $z=iy$, $\cos(iy)=\frac{e^y+e^{-y}}{2}\to \infty$ as $y\to \pm\infty$.
%\end{remark}

\begin{theorem}[De Moivre's formula\index{De Moivre's formula}]\label{thm:de_moivre_formula}%{cor:de_moivre_formula}
For any $\theta\in \R$ and $n\in \Z$,
\be
\bb{\cos \theta + i\sin\theta}^n = \cos (n\theta) + i\sin (n\theta)
\ee
\end{theorem}

\begin{proof}[\bf Proof]
{\bf Approach 1.} Direct result of Theorem \ref{thm:euler_formula_exponential} and Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_real}.

{\bf Approach 2.} First prove for the $n\geq 0$ case by induction. The $n=0$ case is true since it merely reads
\be
(\cos\theta + i\sin\theta)^0 =1=1 = \cos(0) + i\sin(0) = \cos(n\theta) + i\sin(n\theta).
\ee

Now assume the conclusion holds for case $n$. Then we have
\beast
(\cos \theta + i\sin\theta)^{n+1} & = & (\cos \theta + i\sin\theta)^{n}(\cos \theta + i\sin\theta) = (\cos(n\theta)+ i\sin(n\theta))(\cos \theta + i\sin\theta)\\
& = & \cos(n\theta)\cos\theta -  \sin(n\theta)\sin\theta + i\bb{\cos(n\theta)\sin\theta + \sin(n\theta)\cos\theta} \\
& = & \cos((n+1)\theta) + i\sin((n+1)\theta).
\eeast

If $n<0$, let $m=-n$. Then $m>0$ and
\beast
(\cos \theta + i\sin\theta)^{-m} & = & (\cos (m\theta) + i\sin(m\theta))^{-1} = \frac{(\cos (m\theta) -i\sin(m\theta))}{(\cos (m\theta) + i\sin(m\theta))(\cos (m\theta) - i\sin(m\theta))} \\
& = & \frac{(\cos (-m\theta) + i\sin(-m\theta))}{\cos^2(m\theta) + \sin^2(m\theta)} = \cos (-m\theta) + i\sin(-m\theta) = \cos (n\theta) + i\sin(n\theta).
\eeast
\end{proof}

\begin{example}
We have $\cos (5\theta) + i\sin(5\theta) = \bb{\cos \theta + i\sin \theta}^5$. By binomial expansion of the RHS we have
\beast
& & \cos (5\theta) + i\sin(5\theta) \\
& = & \cos^5\theta + 5i\cos^4\theta\sin \theta - 10\cos^3\theta\sin^2 \theta - 10i\cos^4\theta\sin^3 \theta + 5 \cos\theta\sin^4 \theta + i\sin^5\theta \\
& = & \cos^5\theta + 5i(1-\sin^2\theta)^2\sin \theta - 10\cos^3\theta(1-\cos^2 \theta) - 10i(1-\sin^2\theta)\sin^3 \theta + 5 \cos\theta(1-\cos^2 \theta)^2 + i\sin^5\theta
\eeast
and thus
\beast
\cos (5\theta) & = & 5\cos\theta - 20\cos^3\theta + 16\cos^5\theta, \\
\sin (5\theta) & = & 5\sin\theta - 20\sin^3\theta + 16\sin^5\theta
\eeast
by taking real and imaginary parts.
\end{example}



\subsection{Periodicity of the sine and cosine functions}

%\begin{proposition}
%There is a smallest positive number $w$ (when $\sqrt{2} < w/2 <\sqrt{3}$) s.t.
%\be
%\cos(w/2)=0.
%\ee
%\end{proposition}

%\begin{proof}[{\bf Proof}]
%If $0<x<2$,
%\be
%\sin x = \underbrace{\lob x - \frac {x^3}{3!}\rob}_{>0} + \underbrace{\lob \frac {x^5}{5!} - \frac {x^7}{7!}\rob}_{>0} + \dots \quad \lob \frac{x^{2n-1}}{(2n-1)!} >  \frac{x^{2n+1}}{(2n+1)!} \rob \ \ra \  \sin x>0.
%\ee

%But $(\cos x)'=-\sin x<0$, $x\in(0,2)$ implies that $\cos x$ is a strictly decreasing function in $(0,2)$. We will prove that $\cos \sqrt{2}>0, \cos\sqrt{3}<0$. By the Intermediate value theorem, there exists $w$ s.t. $w/2\in (\sqrt{2},\sqrt{3})$.
%\beast
%\cos x = 1 - \frac {x^2}{2!} + \frac {x^4}{4!} - \frac {x^6}{6!} + \dots \ \ra \
%\left\{
%\ba{rcl}
%\cos \sqrt{2} & = &  \underbrace{\lob 1 - \frac {\sqrt{2}^2}{2!}\rob}_{>0} + \underbrace{\lob \frac {\sqrt{2}^4}{4!} - \frac {\sqrt{2}^6}{6!}\rob}_{>0} + \dots  > 0 \\
%\cos \sqrt{3} & = & \underbrace{\lob 1 - \frac {\sqrt{3}^2}{2!} + \frac {\sqrt{3}^4}{4!} \rob}_{<0} - \underbrace{\lob \frac {\sqrt{3}^6}{6!} - \frac {\sqrt{3}^8}{8!} \rob}_{>0} + \dots < 0
%\ea\right.
%\eeast
%\end{proof}

%\begin{corollary}
%$\sin \frac w2 = 1$
%\end{corollary}

%\begin{proof}[{\bf Proof}]
%$\underbrace{\cos^2 \frac w2}_{=0} + \sin^2 \frac w2 = 1 \ \ra \ \sin^2 \frac w2 = 1 \ \ra \ \sin \frac w2 = 1 \text{ since } \sin x>0$.
%\end{proof}

%\begin{definition}
%$\pi := w$.
%\end{definition}

%\begin{theorem}
%(i) $\sin(z + \frac {\pi}2) = \cos z,\quad \cos(z + \frac {\pi}2) = - \sin z$;
%(ii) $\sin(z + \pi) = -\sin z,\quad \cos(z + \pi) = - \cos z$;
%(iii) $\sin(z + 2\pi) = \sin z,\quad \cos(z + 2\pi) = \cos z$.
%\end{theorem}
%Note that we $e^{z+2\pi i} = e^z$.


\begin{theorem}[$\pi$\index{$\pi$@pi} derived from trigonometric functions]\label{thm:pi_derived_from_trigonometric_function}
There exists a smallest positive real number $w$ such that
\be
\cos w = 0,\quad \sin w = 1.
\ee
in the interval $(\sqrt{2},\sqrt{3})$. Then we define $\pi := 2w$.
\end{theorem}

\begin{proof}[\bf Proof]
If $0<x<2$,
\be
\sin x = \underbrace{\bb{ x - \frac {x^3}{3!}}}_{>0} + \underbrace{\bb{ \frac {x^5}{5!} - \frac {x^7}{7!}}}_{>0} + \dots + \underbrace{ \bb{ \frac{x^{2n-1}}{(2n-1)!} -  \frac{x^{2n+1}}{(2n+1)!} }}_{>0} + \dots \ \ra \  \sin x>0.
\ee

Then $(\cos x)'=-\sin x<0$, $x\in(0,2)$ implies that $\cos x$ is a strictly decreasing function in $(0,2)$. Also,
\beast
\cos x = 1 - \frac {x^2}{2!} + \frac {x^4}{4!} - \frac {x^6}{6!} + \dots \ \ra \
\left\{
\ba{rcl}
\cos \sqrt{2} & = &  \underbrace{\bb{ 1 - \frac {\sqrt{2}^2}{2!}}}_{\geq 0} + \underbrace{\lob \frac {\sqrt{2}^4}{4!} - \frac {\sqrt{2}^6}{6!}\rob}_{>0} + \dots  > 0 \\
\cos \sqrt{3} & = & \underbrace{\lob 1 - \frac {\sqrt{3}^2}{2!} + \frac {\sqrt{3}^4}{4!} \rob}_{<0} - \underbrace{\lob \frac {\sqrt{3}^6}{6!} - \frac {\sqrt{3}^8}{8!} \rob}_{>0} + \dots < 0
\ea\right.
\eeast

Thus, by the intermediate value theorem (Theorem \ref{thm:intermediate_value}), there exists $w\in (\sqrt{2},\sqrt{3})$ such that
\be
\cos w = 0.
\ee
since cosine is continuous (Proposition \ref{pro:sine_cosine_continuous_differentiable}). Furthermore, by Proposition \ref{pro:basic_properties_of_sine_and_cosine} we have
\be
\sin^2 w = 1 \ \ra\ \sin w = 1
\ee
since $\sin w>0$ for $w\in (0,2)$.
\end{proof}

\begin{corollary}\label{cor:sine_cosine_pi_properties}
For sine and cosine functions
\beast
& & \sin 0 = 0,\quad \sin\frac{\pi}2 = 1,\quad \sin \pi = 0,\quad \sin\frac{3\pi}2 = -1.\\
& & \cos 0 = 1,\quad \cos\frac{\pi}2 = 0,\quad \cos \pi = -1,\quad \cos\frac{3\pi}2 = 0.
\eeast
\end{corollary}

\begin{proof}[\bf Proof]
For $x=0$, we can have the result by definition of sine and cosine functions. For $x= \pi/2$, the results are directly from Theorem \ref{thm:pi_derived_from_trigonometric_function}. Furthermore, by Proposition \ref{pro:sine_and_cosine_of_summation}
\beast
\sin \pi & = & \sin \bb{\frac{\pi}2 + \frac{\pi}2} = 2 \sin \frac{\pi}2 \cos \frac{\pi}2 = 0, \\
\cos \pi & = & \cos \bb{\frac{\pi}2 + \frac{\pi}2} = \cos^2 \frac{\pi}2 - \sin^2\frac{\pi}2 = 0-1 = -1, \\
\sin\frac{3\pi}2 & = & \sin \bb{\pi + \frac{\pi}2} = \sin \pi\cos\frac{\pi}2 + \cos \pi \sin \frac{\pi}2 = 0 -1 = -1, \\
\cos\frac{3\pi}2 & = & \cos \bb{\pi + \frac{\pi}2} = \cos \pi\cos\frac{\pi}2 - \sin \pi \sin \frac{\pi}2 = 0 + 0 = 0.
\eeast
\end{proof}

\begin{proposition}\label{pro:sine_cosine_relation_with_pi_over_2_difference}
Let $z\in \C$.
\ben
\item [(i)] $\sin (z + \frac {\pi}2) = \cos z$, $\cos (z + \frac {\pi}2) = -\sin z$.
\item [(ii)] $\sin (z + \pi) = -\sin z$, $\cos (z + \pi) = -\cos z$.
\item [(iii)] $\sin (z + 2 \pi) = \sin z$, $\cos (z + 2\pi) = \cos z$.
\een

That is, sine and cosine functions have period of $2\pi$.
\end{proposition}

\begin{remark}
It is implied that $e^{iz} = e^{iz + 2i k\pi}$ for $z\in \C$.
\end{remark}

\begin{proof}[\bf Proof]
We use Proposition \ref{pro:sine_and_cosine_of_summation} and \ref{cor:sine_cosine_pi_properties}.
\beast
\sin \bb{z + \frac {\pi}2} & = & \sin z \cos \frac {\pi}2 + \cos z \sin \frac {\pi}2 = 0 \cdot \sin z + 1 \cdot \cos z = \cos z,\\
\cos \bb{z + \frac {\pi}2} & = & \cos z \cos \frac {\pi}2 - \sin z \sin \frac {\pi}2 = 0 \cdot \cos z - 1 \cdot \sin z = -\sin z.
\eeast

\beast
\sin \bb{z + \pi} & = & \sin z \cos \pi + \cos z \sin \pi = -1 \cdot \sin z + 0 \cdot \cos z = - \sin z,\\
\cos \bb{z + \pi} & = & \cos z \cos \pi - \sin z \sin \pi = -1 \cdot \cos z - 0 \cdot \sin z = -\cos z.
\eeast

\beast
\sin \bb{z + 2\pi} & = & \sin \bb{z + \pi} \cos \pi + \cos \bb{z + \pi} \sin \pi = -1 \cdot (-\sin z) + 0 \cdot (-\cos z) = \sin z,\\
\cos \bb{z + 2\pi} & = & \cos \bb{z + \pi} \cos \pi - \sin \bb{z + \pi} \sin \pi = -1 \cdot (-\cos z) - 0 \cdot (-\sin z) = \cos z.
\eeast
\end{proof}

\begin{proposition}
Let $\sin(x)$ and $\cos(x)$ be sine function and cosine function. Then for $x\in [0,2\pi] \subseteq \R$,
\be
\sin x \left\{\ba{ll}
>0\quad\quad & x\in \bb{0,\pi},\\
<0 & x \in \bb{\pi,2\pi} \\
=0 & x= 0,\pi,2\pi \ea\right.,\qquad \qquad \cos x \left\{\ba{ll}
>0\quad\quad & x\in \left[0,\frac{\pi}2\right)\cup\left(\frac{3\pi}2,2\pi\right] \\
<0 & x\in \bb{\frac{\pi}2,\frac{3\pi}2} \\
=0 & x = \frac{\pi}2 , \frac{3\pi}2
\ea\right.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
For all the values in $[0,\pi]$, we have the following arguments.
\ben
\item [(i)] For $x\in \bb{0,\frac{\pi}2}$, we have that $\sin x >0$ and $(\cos x)' = - \sin x <0$ ($\cos x$ is also concave since $\bb{\cos x}'' = -\cos x <0$). Since cosine function is continuous on $[0,\frac{\pi}2]$ with $\cos 0 = 1$ and $\cos \frac{\pi}{2}=0$, $\cos x$ takes every value in $[-1,1]$. Therefore, $\cos x$ is continuous decreasing function from 1 to 0 in $\bsb{0,\frac{\pi}2}$.

Since $\sin\bb{x+\frac{\pi}2} = \cos x$, we can shift the same values of $\cos x$ for $x\in \bsb{0,\frac{\pi}2}$ to $\sin x$ for $x\in \bsb{\frac{\pi}2,\pi}$.

\item [(ii)] For $x\in \bb{\frac{\pi}2,\pi}$, we have that $\sin x >0$ and $(\cos x)' = - \sin x <0$ so $\cos x$ is decreasing function from 0 to -1 in $\bsb{\frac{\pi}2,\pi}$. Since $\sin\bb{x+\frac{\pi}2} = \cos x$, we can shift the same values of $\cos x$ for $x\in \bsb{\frac{\pi}2,\pi}$ to $\sin x$ for $x\in \bsb{\pi,\frac{3\pi}2}$.

\item [(iii)] For $x\in \bb{\pi,\frac{3\pi}2}$, we have that $\sin x <0$ and $(\cos x)' = - \sin x >0$ so $\cos x$ is increasing function from -1 to 0 in $\bsb{\pi,\frac{3\pi}2}$. Since $\sin\bb{x+\frac{\pi}2} = \cos x$, we can shift the same values of $\cos x$ for $x\in \bsb{\pi,\frac{3\pi}2}$ to $\sin x$ for $x\in \bsb{\frac{3\pi}2,2\pi}$.

\item [(iv)]For $x\in \bb{\frac{3\pi}2,2\pi}$, we have that $\sin x <0$ and $(\cos x)' = - \sin x >0$ so $\cos x$ is increasing function from 0 to 1 in $\bsb{\frac{3\pi}2,2\pi}$. Since $\sin\bb{x+\frac{\pi}2} = \cos x$, we can shift the same values of $\cos x$ for $x\in \bsb{\frac{3\pi}2,2\pi}$ to $\sin x$ for $x\in \bsb{2\pi,\frac{5\pi}2}$ and these values are the same with $\sin x$ for $x\in \bsb{0,\frac{\pi}2}$ since $\sin(x+2\pi) = \sin x$.
\een

\begin{figure}[h]
\begin{center}%1.5708, 3.1416
\begin{pspicture}(-1,-3)(8,3)
\psaxes[dy =2,Dy=1]{->}(0,0)(-1,-3)(8,3)
\psset{plotpoints=500,linewidth=1pt}
\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=red]{0}{1.5708}
\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=blue]{1.5708}{3.1416}
\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=green]{3.1416}{4.7124}
\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=magenta]{4.7124}{6.2832}

\psFourier[cosCoeff=0,sinCoeff=2,linecolor=magenta]{0}{1.5708}
\psFourier[cosCoeff=0,sinCoeff=2,linecolor=red]{1.5708}{3.1416}
\psFourier[cosCoeff=0,sinCoeff=2,linecolor=blue]{3.1416}{4.7124}
\psFourier[cosCoeff=0,sinCoeff=2,linecolor=green]{4.7124}{6.2832}
\psFourier[cosCoeff=0,sinCoeff=2,linecolor=magenta]{6.2832}{7.8540}

\pstGeonode[PointSymbol=none,PointName=none](1.5708,3){A}
\pstGeonode[PointSymbol=none,PointName=none](1.5708,-3){AA}
\pstLineAB[linestyle=dashed]{A}{AA}

\pstGeonode[PointSymbol=none,PointName=none](3.1416,3){B}
\pstGeonode[PointSymbol=none,PointName=none](3.1416,-3){BB}
\pstLineAB[linestyle=dashed]{B}{BB}

\pstGeonode[PointSymbol=none,PointName=none](4.7124,3){C}
\pstGeonode[PointSymbol=none,PointName=none](4.7124,-3){CC}
\pstLineAB[linestyle=dashed]{C}{CC}

\pstGeonode[PointSymbol=none,PointName=none](6.2832,3){D}
\pstGeonode[PointSymbol=none,PointName=none](6.2832,-3){DD}
\pstLineAB[linestyle=dashed]{D}{DD}

\psline[linecolor=red,linestyle=dashed]{->}(1.1,1.2)(2.4,1.2)
\psline[linecolor=magenta,linestyle=dashed]{->}(5.5,1.2)(6.8,1.2)
\psline[linecolor=magenta,linestyle=dashed]{->}(6.4,0.5)(0.3,0.5)
\psline[linecolor=blue,linestyle=dashed]{->}(2.3,-1.2)(3.6,-1.2)
\psline[linecolor=green,linestyle=dashed]{->}(4.2,-1.2)(5.5,-1.2)


\rput[lb](0.2,2.1){$\cos x$}
\rput[lb](1.7,2.1){$\sin x$}

\rput[lb](1.6,-2.9){$\frac{\pi}2$}
\rput[lb](3.2,-2.9){$\pi$}
\rput[lb](4.75,-2.9){$\frac{3\pi}2$}
\rput[lb](6.3,-2.9){$2\pi$}
\end{pspicture}
\end{center}
\end{figure}
\end{proof}

\begin{proposition}\label{pro:sine_cosine_real_particular_interval_bijective}
The sine function, $\sin:\bsb{-\frac{\pi}2,\frac{\pi}2}\to [-1,1]$ is bijective.

The cosine function, $\cos:\bsb{0,\pi}\to [-1,1]$ is bijective.
\end{proposition}

\begin{proof}[\bf Proof]
For cosine function, we have it is continuous on $[0,\pi]$ by Proposition \ref{pro:sine_cosine_continuous_differentiable}. Then since $\cos 0 = 1$ and $\cos \pi = -1$, we have $\cos x$ takes every value in $[-1,1]$ by intermediate value theorem (Theorem \ref{thm:intermediate_value}). This implies that $\cos x$ is surjective from $[0,\pi]$ to $[-1,1]$.

Let $x_1,x_2\in [0,\pi]$ with $\cos x_1 = \cos x_2$. Then since for any $x\in \R$,
\be
\cos^2 x + \sin^2 x =1,
\ee
we have that $\sin x_1 = \pm \sin x_2$.

If $\sin x_1 = \sin x_2$, we have that
\be
\cos\bb{x_1-x_2} = \cos x_1\cos x_2 + \sin x_1 \sin x_2 = 1 \ \ra\ x_1 -x_2 = 2k\pi, \ k\in \N
\ee
and we have $x_1-x_2 = 0$ since $x_1-x_2\in [-\pi,\pi]$. This implies that $x_1=x_2$.

If $\sin x_1 = -\sin x_2$, we have that
\be
\cos\bb{x_1+x_2} = \cos x_1\cos x_2 - \sin x_1 \sin x_2 = 1 \ \ra\ x_1 +x_2 = 2k\pi, \ k\in \N
\ee
and we have $x_1+x_2 = 0,2\pi$ since $x_1+x_2\in [0,2\pi]$. This implies that $x_1=x_2=0$ or $\pi$. Thus, both cases give the conclusion $x_1=x_2$. Thus, $\cos x$ is injective.

Therefore, $\cos:\bsb{0,\pi}\to [-1,1]$ is bijective.

Similar for $\sin:\bsb{-\frac{\pi}2,\frac{\pi}2}\to [-1,1]$.
\end{proof}

\subsection{Tangent and cotangent functions}

\begin{definition}[tangent function\index{tangent function}, cotangent function\index{cotangent function}]
The tangent function $\tan$ of complex domain is defined by
\be
\tan z = \frac{\sin z}{\cos z} = \frac{e^{iz} - e^{-iz}}{i\bb{e^{iz} + e^{-iz}}} = \frac{e^{2iz}-1}{i\bb{e^{2iz}+1}}.
\ee

The cotangent function $\cot$ of complex domain is defined by
\be
\cot z = \frac 1{\tan z} =  \frac{\cos z}{\sin z} = \frac{i\bb{e^{iz} + e^{-iz}}}{e^{iz} - e^{-iz}} = i\frac{e^{2iz}+1}{e^{2iz}-1}.
\ee
\end{definition}

\begin{remark}%$\tan z$ is not defined at $\cos z = 0$.
Note that since $\cos \bb{k\pi + \frac{\pi}2} = 0$, $\tan\bb{k\pi + \frac{\pi}2}$ is not well-defined.\footnote{We can see later that $\cos z = 0$ gives $z = k\pi + \frac{\pi}2$ for $k\in \Z$ in this case.}. Also, $\sin\bb{k\pi} = 0, \tan\bb{k\pi}$ is not well-defined. However, by convention, we define
\be
\tan \bb{2k\pi + \frac{\pi}2} = \infty,\qquad \tan\bb{2k\pi-\frac{\pi}2}= -\infty,
\qquad \cot \bb{2k\pi} = \infty,\qquad \tan\bb{2k\pi+\pi}= -\infty .
\ee

Also, $\tan (-z) = - \tan z$ and $\cot (-z) = - \cot z$ since $\sin (-z) = - \sin z$ and $\cos (-z) = \cos z$ by Proposition \ref{pro:basic_properties_of_sine_and_cosine}. In other words, $\tan$ is an odd function.

%\end{remark}\begin{remark}

%\be
%\tan z = \frac{e^{2iz}-1}{i\bb{e^{2iz}+1}}.
%\ee

Tangent and cotangent function both have a period of $\pi$ by definition.
\end{remark}

\begin{proposition}\label{pro:tan_inverse_is_pi_over_2_minus_angle}
For $\theta \in \R\bs\bra{\frac{k\pi}2,k\in \Z}$,
\be
\tan\bb{\pm\frac{\pi}2- \theta}\tan \theta = 1.
\ee

That is, $\tan\bb{\pm\frac{\pi}2- \theta} = \cot \theta$.
\end{proposition}

\begin{proof}[\bf Proof]
For $\theta \in \R\bs\bra{\frac{k\pi}2,k\in \Z}$,
\be
\tan\bb{\pm\frac{\pi}2- \theta}\tan \theta = \frac{e^{\pm\pi i-2i\theta}-1}{i\bb{e^{\pm\pi i-2i\theta}+1}}\frac{e^{2i\theta}-1}{i\bb{e^{2i\theta}+1}} = -\frac{-e^{-2i\theta}-1}{-e^{-2i\theta}+1}\frac{e^{2i\theta}-1}{e^{2i\theta}+1} = \frac{e^{2i\theta} - e^{-2i\theta}}{e^{2i\theta} - e^{-2i\theta}} = 1.
\ee
\end{proof}


\begin{proposition}\label{pro:sine_cosine_tangent_relation}
For $z\in \C$,
\be
\cos^2 z = \frac 1{1+\tan^2z},\qquad \sin^2 z = \frac{\tan^2z }{1+\tan^2z}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Obviously, by Proposition \ref{pro:basic_properties_of_sine_and_cosine}
\be
1 + \tan^2z = 1 + \frac{\sin^2 z}{\cos^2 z} = \frac{\sin^2 z + \cos^2 z}{\cos^2 z} = \frac{1}{\cos^2 z}
\ee
as required.
\end{proof}

\begin{proposition}\label{pro:sum_tangent_complex}
For $z,w\in \C$ with $z,w,z+w\notin \bra{k\pi + \frac{\pi}2,k\in \Z}$,
\be
\tan(z+w) =  \frac{\tan z + \tan w}{1 - \tan z \tan w}.
\ee

In particular, $z\in \C\bs\bra{k\pi + \frac{\pi}2, \frac{k\pi}2 \pm \frac{\pi}4,k\in \Z}$,
\be
\tan(2z) =  \frac{2\tan z}{1 - \tan^2 z }.
\ee
\end{proposition}

\begin{remark}
The second equation is called universal formula of trigonometric function\index{universal formula of trigonometric function}. Accordingly, the universal formula have the following alternative forms
%\beast
%\sin(2z) & = & \cos(2z) \tan (2z) = \cos(z+z)\frac{2\tan z}{1-\tan^2 z} = \bb{\cos^2 z - \sin^2 z}\frac{2\tan z}{1-\tan^2 z} \\
%& = & \bb{\cos^2 z - \sin^2 z}\frac{2\sin z\cos z}{\cos^2 z - \sin^2 z}
%\eeast
\beast
\cos(2z) & = & \cos^2 z - \sin^2 z = \frac{1-\tan^2z }{1+\tan^2z},\\
\sin(2z) & = & \cos (2z)\tan(2z) = \frac{1-\tan^2z }{1+\tan^2z} \cdot \frac{2\tan z}{1 - \tan^2 z } = \frac{2\tan z}{1 + \tan^2 z }.
\eeast
by Proposition \ref{pro:sine_cosine_tangent_relation}.
\end{remark}

\begin{proof}[\bf Proof]
For $z,w\in \C$, by Proposition \ref{pro:sine_and_cosine_of_summation}
\beast
\tan(z+w) = \frac{\sin(z+w)}{\cos(z+w)} = \frac{\sin z \cos w + \cos z \sin w}{\cos z \cos w - \sin z \sin w} = \frac{\frac{\sin z}{\cos z} + \frac{\sin w}{\cos w}}{1 - \frac{\sin z \sin w}{\cos z \cos w}} = \frac{\tan z + \tan w}{1 - \tan z \tan w}
\eeast
as required.
\end{proof}


\begin{proposition}\label{pro:tangent_differentiable_continuous}
The tangent function, $\tan$, is continuous and differentiable on $\C\bs\bra{k\pi + \frac {\pi}2}$, $k\in \Z$ and
\be
\fd{}{z} \tan z = \frac 1{\cos^2 z}= \sec^2 z.
\ee

In particular, $\tan$ is continuous and differentiable on $\bb{k\pi-\frac{\pi}2,k\pi+\frac{\pi}2}$, $k\in \Z$ and
\be
\fd{}{x} \tan x = \frac 1{\cos^2 x}= \sec^2 x.
\ee

The cotangent function, $\cot$, is continuous and differentiable on $\C\bs\bra{k\pi}$, $k\in \Z$ and
\be
\fd{}{z} \cot z = -\frac 1{\sin^2 z}= -\csc^2 z.
\ee

In particular, $\cot$ is continuous and differentiable on $\bb{k\pi,(k+1)\pi}$, $k\in \Z$ and
\be
\fd{}{x} \cot x = -\frac 1{\sin^2 x}= -\csc^2 x.
\ee
\end{proposition}


\begin{proof}[\bf Proof]
Excluding the case $\cos z = 0$ for $z\in \bra{k\pi + \frac {\pi}2}$, we have that by definition
\be
\fd{}{z}\tan z = \bb{\frac{\sin z}{\cos z}}' = \frac{\bb{\sin z}'\cos z - \bb{\cos z}'\sin z}{\cos^2 z} = \frac{\cos^2 z +\sin^2 z}{\cos^2 z} = \frac 1{\cos^2 z}.
\ee

Then the fact that differentiability implies continuous gives the required result.

The proof is similar for the real case and cotangent function.
\end{proof}

\begin{proposition}\label{pro:tangent_real_particular_interval_bijective}
The real tangent function, $\tan:\bb{-\frac{\pi}2,\frac{\pi}2}\to (-\infty,\infty)$ is bijective.
\end{proposition}

\begin{proof}[\bf Proof]
First, we have $\tan x$ is continuous on $\bb{-\frac{\pi}2,\frac{\pi}2}$ since $\sin x$ and $\cos x$ ($\neq 0$) are continuous with derivative
\be
\bb{\tan x}' = \frac 1{\cos^2 x}>0,\qquad \cos x \neq 0.
\ee%So for any $y\in (-\infty,\infty)$, we can find $y',y''$ such that $y' < y < y''$.

%Then  := \frac{x-\pi/2}2$ and $x' := \frac{x+\pi/2}2$ such $x'<x<x''$. Then we can have $\tan x' < \tan x < \tan x''$.

Thus, $\tan x$ is strictly increasing on $\bb{-\frac{\pi}2,\frac{\pi}2}$. Then for any $x_1,x_2\in \bb{-\frac{\pi}2,\frac{\pi}2}$ with $x_1<x_2$, $\tan : [x_1,x_2]\to [\tan x_1,\tan x_2]$ is bijective by Theorem \ref{thm:inverse_rule_real_function}.%\footnote{strictly increasing and continuous theorem.}.

For any $M>0$, we can find $x>0$ (as $\cos$ is continuous) such that
\be
\cos x = \frac 1{M+1} \ \ra\ \sin x = \frac{\sqrt{M^2+ 2M}}{M+1} \ \ra\ \tan x = \sqrt{M^2+ 2M} > M.
\ee

So we have that $\tan x\to \infty$ as $x \to \frac{\pi}2$. We have the similar argument for $x \to -\frac{\pi}2$.%$\delta >0$ such that $\abs{x-\frac{\pi}2}<\delta$ and $\abs{\tan x} > M$.
\end{proof}



\begin{proposition}
\beast
\tan z & =& \sum^\infty_{n=0} \frac{U_{2n+1}}{(2n+1)!} z^{2n+1} = \sum^\infty_{n=1} \frac{(-1)^{n-1}2^{2n}\bb{2^{2n}-1}B_{2n}}{(2n)!} z^{2n-1} \\
& = & z + \frac 13 z^3 + \frac 2{15}z^5 + \frac{17}{315}z^7 + \dots,\qquad \abs{z} < \frac{\pi}2
\eeast
where $U_n$ is the $n$th up/down number\footnote{details needed.} and $B_n$ is the $n$th Bernoulli number (of first kind)\footnote{definition needed.}.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\subsection{Secant and cosecant functions}

\begin{definition}[secant function\index{secant function}, cosecant function\index{cosecant function}]
The secant function $\sec$ of complex domain is defined by
\be
\sec z = \frac 1{\cos z} = \frac 2{e^{iz} + e^{-iz}}.
\ee

The cosecant function $\csc$ of complex domain is defined by
\be
\csc z = \frac 1{\sin z} = \frac {2i}{e^{iz} - e^{-iz}}.
\ee
\end{definition}


\begin{proposition}\label{pro:relation_between_tangent_secant}
For any $z\in \C$, we have
\be
1 + \tan^2 z = \sec^2 z, \qquad z \neq k\pi + \frac{\pi}2,
\ee
\be
1 + \cot^2 z = \csc^2 z, \qquad z \neq k\pi .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
For any $z\in \C\bs\bra{k\pi + \frac{\pi}2,k\in \Z}$,
\be
1 + \tan^2 z = 1 + \frac{\sin^2 z}{\cos^2 z} = \frac{\cos^2 z + \sin^2 z}{\cos^2 z} = \frac 1{\cos^2 z} = \sec^2 z
\ee
by Proposition \ref{pro:basic_properties_of_sine_and_cosine}. Similar for the cosecant case.
\end{proof}

\begin{proposition}\label{pro:secant_differentiable_continuous}
The secant function, $\sec$, is continuous and differentiable on $\C\bs\bra{k\pi + \frac {\pi}2}$, $k\in \Z$ and
\be
\fd{}{z} \sec z = \sec z \tan z.
\ee

In particular, $\sec$ is continuous and differentiable on $\bb{k\pi-\frac{\pi}2,k\pi+\frac{\pi}2}$, $k\in \Z$ and
\be
\fd{}{x} \sec x = \sec x \tan x.
\ee

The cosecant function, $\csc$, is continuous and differentiable on $\C\bs\bra{k\pi}$, $k\in \Z$ and
\be
\fd{}{z} \csc z = -\csc z\cot z.
\ee

In particular, $\csc$ is continuous and differentiable on $\bb{k\pi,(k+1)\pi}$, $k\in \Z$ and
\be
\fd{}{x} \csc x = -\csc x\cot x.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Excluding the case $\cos z = 0$ for $z\in \bra{k\pi + \frac {\pi}2}$, we have that by definition
\be
\fd{}{z}\sec z = \bb{\frac{1}{\cos z}}' = \frac{- \bb{\cos z}'}{\cos^2 z} = \frac{\sin z}{\cos^2 z} = \frac{1}{\cos z} \frac{\sin z}{\cos z} = \sec z \tan z.
\ee

Then the fact that differentiability implies continuous gives the required result.

The proof is similar for the real case and cosecant function.
\end{proof}


\subsection{Properties of summations}

\begin{proposition}[partial sum of trigonometric functions]\label{pro:partial_sum_multiple_trigonometric_function}
For real $x$ and $m,n\in \Z^+$,
\be
\sin\bb{\frac {x}2}\sum^m_{n=1} \sin(nx) = \sin\bb{\frac{mx}2}\sin\bb{\frac{(m+1)x}2},\qquad
\sin\bb{\frac {x}2}\bb{\frac 12 + \sum^m_{n=1} \cos(nx)} = \frac 12 \sin\bb{\frac{(2m+1)x}2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
{\bf Approach 1.} By Proposition \ref{pro:trigonometric_product_difference}, let
\be
\alpha = n-1,\quad \beta = n,\quad \theta = \frac{x}2,
\ee
then
\beast
\sin\bb{\frac{mx}2}\sin\bb{\frac{(m+1)x}2}  & = & \sin\bb{\frac{(m-1)x}2}\sin\bb{\frac{mx}2} + \sin\bb{\frac{(2m-1+1)x}2}\sin\bb{\frac{x}2} \\
& = &  \sin\bb{\frac{(m-1)x}2}\sin\bb{\frac{mx}2} + \sin\bb{mx}\sin\bb{\frac{x}2} \\
& = & \sin\bb{\frac{(m-2)x}2}\sin\bb{\frac{(m-1)x}2} + \sin\bb{(m-1)x}\sin\bb{\frac{x}2}  + \sin\bb{mx}\sin\bb{\frac{x}2} \\
& = & \dots = \sin\bb{\frac{x}2} \sum^m_{n=1} \sin(nx).
\eeast

By Proposition \ref{pro:trigonometric_product_difference} again, let
\beast
\sin\bb{\frac{x}2} \sum^m_{n=1} \cos(nx) & = & \sum^m_{n=1} \sin\bb{\frac{x}2}  \cos(nx) =  \sum^m_{n=1} \bb{\sin\bb{\frac {nx}2}\cos\bb{\frac{(n+1)x}2} - \sin\bb{\frac {(n-1)x}2}\cos\bb{\frac{nx}2}} \\
& = & \sin\bb{\frac {mx}2}\cos\bb{\frac{(m+1)x}2} = \frac 12\bb{\sin\bb{\frac{(2m+1)x}2} - \sin\bb{\frac {x}2}}
\eeast
as required.

{\bf Approach 2.} For real $x\neq 0$,
\be
\frac 12 + \sum^m_{n=1} \cos(nx)\quad \text{and }\quad \sum^m_{n=1} \sin(nx)
\ee
are the real and imaginary parts of function of $z= e^{ix}$
\be
\frac 12 + z + z^2 +\dots + z^m = \frac 12 + \frac{z-z^{m+1}}{1-z} = \frac{1+z-2z^{m+1}}{2(1-z)}.
\ee

Then substitute $z = \cos x + i\sin x$ into the function,
\beast
&  & \frac{1+\cos x + i\sin x - 2\cos((m+1)x) - 2i\sin((m+1)x)}{2(1-\cos x - i\sin x)} \\
& = & \frac{\bb{1+\cos x  - 2\cos((m+1)x) + i\bb{\sin x - 2\sin((m+1)x)} }\cdot \bb{1-\cos x + i\sin x}}{2\bb{(1-\cos x)^2 + \sin^2 x}}.
\eeast

Its real part is
\beast
& & \frac{\bb{1+\cos x  - 2\cos((m+1)x)(1-\cos x) -\sin x \bb{\sin x - 2\sin((m+1)x)}}}{2\bb{(1-\cos x)^2 + \sin^2 x}} \\
& = & \frac{\sin x \sin((m+1)x) - \cos((m+1)x)(1-\cos x) }{2\bb{(1-\cos x}} = \frac{\cos(mx) - \cos((m+1)x)}{4\sin^2\bb{\frac x2}} \\
& = & \frac{\cos\bb{\frac{(2m+1)x}2 - \frac x2} - \cos\bb{\frac{(2m+1)x}2 + \frac x2}}{4\sin^2\bb{\frac x2}} = \frac{2\sin\bb{\frac{(2m+1)x}2} \sin\bb{\frac x2}}{4\sin^2\bb{\frac x2}} = \frac{\sin\bb{\frac{(2m+1)x}2}}{2\sin\bb{\frac x2}}
\eeast
as required. Its imaginary part is
\beast
& & \frac{\sin x\bb{1+\cos x  - 2\cos((m+1)x) +(1-\cos x)\bb{\sin x - 2\sin((m+1)x)}}}{2\bb{(1-\cos x)^2 + \sin^2 x}} \\
& = &  \frac{2\sin x - 2\sin x\cos((m+1)x) - 2(1-\cos x)\sin((m+1)x) }{8\sin^2\bb{\frac x2}} = \frac{\sin x - \sin((m+1)x) + \sin (mx) }{4\sin^2\bb{\frac x2}} \\
& = & \frac{2\sin\bb{\frac x2}\cos\bb{\frac x2} - 2\cos\bb{\frac{(2m+1)x}2}\sin\bb{\frac{x}2}}{4\sin^2\bb{\frac x2}} = \frac{\cos\bb{\frac x2} - \cos\bb{\frac{(2m+1)x}2}}{2\sin\bb{\frac x2}} \\
& = & \frac{\cos\bb{\frac {(m+1)x}2 - \frac {mx}2} - \cos\bb{\frac {(m+1)x}2 + \frac {mx}2}}{2\sin\bb{\frac x2}} = \frac{\sin\bb{\frac {(m+1)x}2} \sin\bb{\frac {mx}2}}{\sin\bb{\frac x2}}
\eeast
as required.
\end{proof}

It is obvious that neither of
\be
\sum^\infty_{n=1} \sin(nx) \quad \text{nor}\quad \sum^\infty_{n=1} \cos(nx)
\ee
converges since neither of $\sin(nx)$ nor $\cos (nx)$ converges to zero (see Lemma \ref{lem:real_series_sum_convergence_imples_sequence_zero}).

However, we have the following propositions.

\begin{proposition}
For real $0\leq r <1$ and $x\in [-\pi,\pi]$,
\be
\sum^\infty_{n=1} r^n \cos (nx) = \frac{r\bb{\cos x -r}}{1-2r\cos x + r^2},\qquad \sum^\infty_{n=1} r^n \sin (nx) = \frac{r\sin x}{1-2r\cos x + r^2}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First we have for $z = re^{ix}$ with $\abs{z} <1$,
\beast
\sum^\infty_{n=1}z^n = \frac{z}{1-z} & \ra & \frac 12 + \sum^\infty_{n=1}z^n = \frac{z}{1-z} = \frac 12 \frac{1+z}{1-z} = \frac 12\frac{1+r\cos x + ir \sin x}{1-r\cos x - ir\sin x} \\
& = & \frac{1-r^2 +2 ir\sin x} {2\bb{1-2r\cos x + r^2}} = \frac{1-r^2} {2\bb{1-2r\cos x + r^2}} + i\frac{r\sin x} {\bb{1-2r\cos x + r^2}}.
\eeast

Then we can split the series and its sum into their respective real and imaginary parts.
\beast
\sum^\infty_{n=1} r^n \cos (nx) & = & \frac{1-r^2} {2\bb{1-2r\cos x + r^2}} - \frac 12 = \frac{r\bb{\cos x -r}}{1-2r\cos x + r^2}, \\
\sum^\infty_{n=1} r^n \sin (nx) & = & \frac{r\sin x}{1-2r\cos x + r^2}
\eeast
as required.
\end{proof}


\begin{proposition}
For real $x \in [-\pi,0)\cup (0,\pi]$ for $k\in \Z$,
\be
\sum^\infty_{n=1} \frac 1n \cos (nx) = - \log\abs{2\sin\bb{\frac x2}},\qquad \sum^\infty_{n=1} \frac 1n \sin (nx) = \left\{\ba{ll}\frac 12\pi - \frac 12 x & x\in (0,\pi) \\
-\frac 12\pi - \frac 12 x \quad\quad & x\in (-\pi,0)
\ea\right.
\ee
\end{proposition}

\begin{remark}
Let $a_n = \frac 1n$, $b_n = \sin (nx)$ or $\cos(nx)$. So we can apply Dirichlet's test (Theorem \ref{thm:dirichlet_test}) as
\be
\abs{\sum^m_{n=1} \sin (nx)} = \abs{\frac {\sin\bb{\frac {mx}2}\sin\bb{\frac {(m+1)x}2}}{\sin \bb{\frac x2}}} \leq \frac 1{\abs{\sin \bb{\frac x2}}},
\ee
\be
\abs{\sum^m_{n=1} \cos (nx)} = \abs{\frac {\sin\bb{\frac {(2m+1)x}2}}{2\sin \bb{\frac x2}} -\frac 12} \leq \frac 1{2\abs{\sin \bb{\frac x2}}} + \frac 12
\ee
by Proposition \ref{pro:partial_sum_multiple_trigonometric_function}.
\end{remark}


\begin{proof}[\bf Proof]
By Theorem \ref{thm:principal_value_logarithm_expansion} on $z = e^{ix}$ with $x\neq 2k\pi$, we have
\beast
\sum^\infty_{n=1} \frac 1n\cos(nx) + i\sum^\infty_{n=1} \frac 1n\sin(nx) & = & \sum^\infty_{n=1} \frac 1n e^{inx} = \sum^\infty_{n=1} \frac 1n z^{n} = -\Log\bb{1-z} \\
& = & -\Log\bb{1-e^{ix}} = -\log\abs{1-e^{ix}} - i\Arg\bb{1-e^{ix}}.
\eeast

Then we can split the series and its sum into their respective real and imaginary parts we get two nice formulas.
\beast
\sum^\infty_{n=1} \frac 1n\cos(nx) & = & -\log\abs{1-e^{ix}} = -\log\abs{1-\cos x - i\sin x} = -\frac 12 \log\abs{(1-\cos x)^2 + \sin^2 x} \\
& = & -\frac 12 \log\bb{2-2\cos x} = -\frac 12 \log\bb{4\sin^2\bb{\frac x2}} = -\log\abs{2\sin\bb{\frac x2}}.
\eeast

For $x\in (0,\pi]$,
\beast
\sum^\infty_{n=1} \frac 1n\sin(nx) & = & - \Arg\bb{1-e^{ix}} = - \Arg\bb{1-\cos x - i\sin x} = \arctan\bb{\frac{\sin x}{1-\cos x}}\\
& = & \arctan\bb{\frac{2\sin \bb{\frac x2}\cos \bb{\frac x2}}{2\sin^2 \bb{\frac x2}}} = \arctan\bb{\frac{\cos \bb{\frac x2}}{\sin \bb{\frac x2}}} = \arctan\bb{\tan \bb{\frac 12\pi - \frac 12 x}} = \frac 12\pi - \frac 12 x.
\eeast

The sum must be an odd function so
\be
\sum^\infty_{n=1} \frac 1n\sin(nx) = -\frac 12\pi - \frac 12x,\quad x \in [-\pi,0).
\ee
\end{proof}




\begin{proposition}
For real $0\leq r<1$ and $x\in [-\pi,\pi]$,
\be
\sum^\infty_{n=1} \frac 1n r^n\cos (nx) = -\frac 12 \log\abs{1-2r \cos x +r^2},\qquad \sum^\infty_{n=1} \frac 1n r^n \sin (nx) = \arctan\bb{\frac{r\sin x}{1-r\cos x}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
By Theorem\footnote{Log expansion} on $z = r e^{ix}$, we have
\beast
\sum^\infty_{n=1} \frac 1n r^n\cos(nx) + i\sum^\infty_{n=1} \frac 1n r^n\sin(nx) & = & \sum^\infty_{n=1} \frac 1n r^n e^{inx} = \sum^\infty_{n=1} \frac 1n z^{n} = -\Log\bb{1-z} \\
& = & -\Log\bb{1- r e^{ix}} = -\log\abs{1- r e^{ix}} - i\Arg\bb{1-r e^{ix}}.
\eeast

Then we can split the series and its sum into their respective real and imaginary parts.
\beast
\sum^\infty_{n=1} \frac 1n r^n \cos(nx) & = & -\log\abs{1-r e^{ix}} = -\log\abs{1-r\cos x - ir \sin x} = -\frac 12 \log\abs{(1-r\cos x)^2 + r^2\sin^2 x} \\
& = & -\frac 12 \log\abs{1-2r \cos x +r^2} .
\eeast

\be
\sum^\infty_{n=1} \frac 1n r^n \sin(nx) = - \Arg\bb{1-r e^{ix}} = - \Arg\bb{1-r\cos x - ir\sin x} = \arctan\bb{\frac{r\sin x}{1-r\cos x}}.
\ee
\end{proof}

\begin{example}
Let $x = \pi/2$. We have that $\sin x = 1$ and $\cos x = 0$ and thus
\be
\arctan(r) = \arctan\bb{\frac{r\sin x}{1-r\cos x}} = \sum^\infty_{n=1} \frac 1n r^n \sin(nx) = \sum^\infty_{n=0}\frac{(-1)^n}{2n+1}r^{2n+1}
\ee
which is the Taylor expansion of $\arctan$ function.
\end{example}


%%%%%%%%%

\begin{proposition}
\be
\sum^\infty_{n=-\infty} \frac{(-1)^n}{z-n} = \frac 1z - 2z\sum^\infty_{n=1}\frac{(-1)^n}{n^2 -z^2} = \frac{\pi}{\sin(\pi z)}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
\be
\frac{\pi^2}{\sin^2(\pi z)} = \sum^\infty_{n=-\infty} \frac 1{(z-n)^2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

%\subsection{Infinite products}

\subsection{Properties of products}

\begin{proposition}\label{pro:trigonometric_function_multiangle_finite_product}
\be
\prod^{n-1}_{k=1} \sin\bb{\frac{k\pi}n} = \frac n{2^{n-1}},\qquad \prod^{n-1}_{k=1} \cos\bb{\frac{k\pi}n} = \frac{\sin\bb{\frac{n\pi}2}}{2^{n-1}}, \qquad \prod^{n-1}_{k=1} \tan\bb{\frac{k\pi}n} = \frac n{\sin\bb{\frac{n\pi}2}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed (Edwards 2001, pp. 18 and 47; Borwein et al. 2004, p. 5). Edwards, H. M. Riemann's Zeta Function. New York: Dover, 2001, Borwein, J.; Bailey, D.; and Girgensohn, R. Experimentation in Mathematics: Computational Paths to Discovery. Wellesley, MA: A K Peters, 2004.}
\end{proof}

\begin{theorem}\label{thm:trigonometric_function_infinite_product}
For $z\in \C$,%\bs\bra{ n\pi:n\in \Z}
\be
\sin z = z\prod^\infty_{n=1}\bb{1-\frac{z^2}{n^2\pi^2}}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{theorem needed. $\sin x = x\prod^\infty_{n=1}\bb{1 - \frac{x^2}{n^2\pi^2}}$. See Whittaker Watson book, 7.5, example 1.}
\end{proof}

%\footnote{see wiki list of trigonometric identities for other functions.}

\subsection{Multiple-angle formula}



\begin{theorem}[multiple-angle formula of sine and cosine functions, binomial form]\label{thm:multple_angle_sine_cosine_binomial}
Let $n\in \Z^+$. For any $z\in \C$,
\beast
\sin\bb{nz} & = & \sum^n_{k=0} \binom{n}{k} \bb{\cos z}^k \bb{\sin z}^{n-k}\sin \bb{\frac {(n-k)\pi}2} = \sum^n_{k=0} \binom{n}{k}  \bb{\sin z}^k \bb{\cos z}^{n-k} \sin \bb{\frac {k\pi}2}\\
& = & \sum^{\floor{(n-1)/2}}_{k=0} (-1)^k\binom{n}{2k+1} \bb{\sin z}^{2k+1} \bb{\cos z}^{n-2k-1} = \sin z \sum^{\floor{(n-1)/2}}_{k=0} (-1)^k\binom{n-k-1}{k} 2^{n-2k-1} \bb{\cos z}^{n-2k-1}.
\eeast
\beast%\footnote{check needed.}
\cos\bb{nz} & = & \sum^n_{k=0} \binom{n}{k} \bb{\cos z}^k \bb{\sin z}^{n-k}\sin \bb{\frac {(n-k)\pi}2} = \sum^n_{k=0} \binom{n}{k}  \bb{\sin z}^k \bb{\cos z}^{n-k} \sin \bb{\frac {k\pi}2}\\
& = & \sum^{\floor{n/2}}_{k=0} (-1)^k\binom{n}{2k} \bb{\sin z}^{2k} \bb{\cos z}^{n-2k} = 2^{n-1}\cos^n z + n \sum^{\floor{n/2}}_{k=1} \frac{(-1)^k}k \binom{n-k-1}{k-1} 2^{n-2k-1} \bb{\cos z}^{n-2k}.
\eeast
\end{theorem}

\begin{proof}[\bf Proof]
For any $z\in \C$, by Euler's formula (Theorem \ref{thm:euler_formula_exponential})
\beast
\sin\bb{nz} & = & \frac{e^{inz} - e^{-inz}}{2i} = \frac{\bb{e^{iz}}^n - \bb{e^{-iz}}^n}{2i} = \frac{\bb{\cos z + i\sin z}^n - \bb{\cos z - i\sin z}^n}{2i} \\
& = & \sum^n_{k=0}\binom{n}{k} \frac{\bb{\cos z}^k\bb{i\sin z}^{n-k}- \bb{\cos z}^k\bb{-i\sin z}^{n-k}}{2i} = \sum^n_{k=0}\binom{n}{k} \bb{\cos z}^k\bb{\sin z}^{n-k} \frac{i^{n-k} - (-i)^{n-k}}{2i}\\
& = & \sum^n_{k=0}\binom{n}{k} \bb{\cos z}^k\bb{\sin z}^{n-k} \frac{e^{i\frac{(n-k)\pi}2} - e^{-i\frac{(n-k)\pi}2}}{2i} = \sum^n_{k=0} \binom{n}{k} \bb{\cos z}^k \bb{\sin z}^{n-k}\sin \bb{\frac {(n-k)\pi}2}.
\eeast

Let $k = n-k$ then
\be
\sin\bb{nz} = \sum^n_{k=0} \binom{n}{k}  \bb{\sin z}^k \bb{\cos z}^{n-k} \sin \bb{\frac {k\pi}2}.
\ee

This summation only has non-zero terms for odd $k$. So
\beast
\sin\bb{nz} & = & \sum^{\floor{(n-1)/2}}_{k=0} (-1)^k\binom{n}{2k+1} \bb{\sin z}^{2k+1} \bb{\cos z}^{n-2k-1} = \sin z \sum^{\floor{(n-1)/2}}_{k=0} (-1)^k\binom{n}{2k+1} \bb{1-\cos^2 z}^{k} \bb{\cos z}^{n-2k-1} \\
& = & \sin z \sum^{\floor{(n-1)/2}}_{k=0} \binom{n}{2k+1} \sum^k_{p=0}(-1)^{2k-p}\binom{k}{k-p}\bb{\cos z}^{n-2k+2(k-p)-1}\\
 & = & \sin z \sum^{\floor{(n-1)/2}}_{p=0} (-1)^{p}\bb{\cos z}^{n-2p-1} \sum^{\floor{(n-1)/2}}_{k=p}\binom{k}{p}\binom{n}{2k+1} \\
 & = & \sin z \sum^{\floor{(n-1)/2}}_{p=0} (-1)^{p} \binom{n-p-1}{p} 2^{n-2p-1} \bb{\cos z}^{n-2p-1}
\eeast
by Proposition \ref{pro:binomial_odd_even_choice}. Similarly,
\beast
\cos\bb{nz} & = & \frac{e^{inz} + e^{-inz}}{2} = \frac{\bb{e^{iz}}^n + \bb{e^{-iz}}^n}{2} = \frac{\bb{\cos z + i\sin z}^n + \bb{\cos z - i\sin z}^n}{2} \\
& = & \sum^n_{k=0}\binom{n}{k} \frac{\bb{\cos z}^k\bb{i\sin z}^{n-k} + \bb{\cos z}^k\bb{-i\sin z}^{n-k}}{2} = \sum^n_{k=0}\binom{n}{k} \bb{\cos z}^k\bb{\sin z}^{n-k} \frac{i^{n-k} + (-i)^{n-k}}{2}\\
& = & \sum^n_{k=0}\binom{n}{k} \bb{\cos z}^k\bb{\sin z}^{n-k} \frac{e^{i\frac{(n-k)\pi}2} + e^{-i\frac{(n-k)\pi}2}}{2} = \sum^n_{k=0} \binom{n}{k} \bb{\cos z}^k \bb{\sin z}^{n-k}\cos \bb{\frac {(n-k)\pi}2}.
\eeast

Let $k = n-k$ then
\be
\cos\bb{nz} = \sum^n_{k=0} \binom{n}{k}  \bb{\sin z}^k \bb{\cos z}^{n-k} \cos\bb{\frac {k\pi}2}.
\ee

This summation only has non-zero terms for even $k$. So
\beast
\cos\bb{nz} & = & \sum^{\floor{n/2}}_{k=0} (-1)^k\binom{n}{2k} \bb{\sin z}^{2k} \bb{\cos z}^{n-2k} = \sum^{\floor{n/2}}_{k=0} (-1)^k\binom{n}{2k} \bb{1-\cos^2 z}^{k} \bb{\cos z}^{n-2k} \\
& = & \sum^{\floor{n/2}}_{k=0} (-1)^{2k-p}\binom{n}{2k} \sum^k_{p=0}\binom{k}{k-p}\bb{\cos z}^{n-2k+2(k-p)} = \sum^{\floor{n/2}}_{p=0} (-1)^{p}\bb{\cos z}^{n-2p} \sum^{\floor{n/2}}_{k=p}\binom{k}{p}\binom{n}{2k} \\
 & = & \sum^{\floor{n/2}}_{p=0} (-1)^{p}\bb{\cos z}^{n-2p} 2^{n-2p-1}\frac{n}{n-p}\binom{n-p}{p} \\
 & = & 2^{n-1}\cos^n z +  n\sum^{\floor{n/2}}_{p=1} \frac{(-1)^{p}}p \binom{n-p-1}{p-1} 2^{n-2p-1} \bb{\cos z}^{n-2p}
\eeast
by Proposition \ref{pro:binomial_odd_even_choice} again.
\end{proof}


\begin{theorem}[multiple-angle formula of sine and cosine functions, polynomial form]\label{thm:multple_angle_sine_cosine_polynomial}
%For $n$ a positive integer and $x\in \C$, the expressions of the form $\sin( nx)$ can be expressed in terms of $\sin x$ and $\cos x$ only using the Euler formula and binomial theorem. That is\footnote{should replace $x$ with $z$},
%\be
%\sin(nx) = \sum^n_{k=0}\binom{n}{k}\bb{\cos x}^k \bb{\sin x}^{n-k}\sin\bb{\frac 12\bb{n-k}\pi}.
%\ee
%\beast
%\sin(nx)  & = & \sin x \sum^{\floor{(n-1)/2}}_{k=0} (-1)^k\binom{n-k-1}{k} 2^{n-2k-1} \bb{\cos x}^{n-2k-1}\\
%& = &  \sum^{\floor{(n-1)/2}}_{k=0}(-1)^k\binom{n}{2k+1} \bb{\sin x}^{2k+1}\bb{\cos x}^{n-2k-1}.
%\eeast
$\sin(nx)$ can be expressed as a polynomial in $\sin x$ (for $n$ odd) or $\cos x$ times a polynomial in $\sin x$ (for $n$ even) as
\be
\sin (nx) = \left\{\ba{ll}
(-1)^{(n-1)/2}T_n(\sin x)  & n \text{ is odd}\\
(-1)^{(n-1)/2}\cos x U_n\bb{\sin x}\quad\quad &n \text{ is even}
\ea
\right.
\ee
where $T_n$ is a Chebyshev polynomial of the first kind and $U_n$ is a Chebyshev polynomial of the second kind\footnote{link needed}.

Similarly, $\sin(nx)$ can be expressed as $\sin x$ times a polynomial in $\cos x$ as
\be
\sin(nx) = \sin x \cdot U_{n-1}(\cos x).
\ee
\end{theorem}
%, $\cos(nx)$ and $\tan (nx)$

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{example}
For binomial form,
\beast
\sin(2z) & = & \binom{2}{1}\sin z \cos z = \sin z \binom{1}{0} 2^1 \cos z = 2\sin z \cos z.\\
\sin(3z) & = & \binom{3}{1}\sin z \cos^2 z -  \binom{3}{3}\sin^3 z = \sin z \bb{\binom{2}{0} 2^2 \cos^2 z - \binom{1}{1}} = \sin z \bb{3-4\sin^2 z}.\\
\sin(4z) & = & \binom{4}{1}\sin z \cos^3 z -  \binom{4}{3}\sin^3 z \cos z = \sin z \bb{\binom{3}{0} 2^3 \cos^3 z - \binom{2}{1}2^1\cos z} \\
& = & \cos z \bb{4\sin z-8\sin^3 z}= 4\sin z \cos z \bb{1-2\sin^2 z}.\\
\sin(5z) & = & \binom{5}{1}\sin z \cos^4 z -  \binom{5}{3}\sin^3 z \cos^2 z + \binom{5}{5}\sin^5z = \sin z \bb{\binom{4}{0} 2^4 \cos^4 z - \binom{3}{1}2^2\cos^2 z + \binom{2}{2}} \\
& = & \sin z \bb{1 - 12\cos^2 z + 16\cos^4 z} = \sin z \bb{5 - 20\sin^2 z + 16\sin^4 z}.
\eeast

\beast
\cos(2z) & = & \binom{2}{0}\cos^2 z - \binom{2}{2}\sin^2 z = 2\cos^2 z - 2 \binom{0}{0}2^{-1}  = 2\cos^2 z - 1 = \cos^2 z - \sin^2 z.\\
\cos(3z) & = & \binom{3}{0}\cos^3 z -  \binom{3}{2}\sin^2 z\cos z = 2^2\cos^3 z - 3\binom{1}{0} \cos z = \cos z\bb{4\cos^2 z-3} = \cos z\bb{1- 4\sin^2 z} .\\
\cos(4z) & = & \binom{4}{0}\cos^4 z -  \binom{4}{2}\sin^2 z \cos^2 z + \binom{4}{4}\sin^4 z = 2^3 \cos^4 z - 4\binom{2}{0} 2 \cos^2 z + 4\binom{1}{1}\frac 12 2^{-1}\\
& = & 1 - 8\cos^2 z + 8\cos^4 z = 1 - 8\sin^2 z + 8\sin^4 z.\\
\cos(5z) & = & \binom{5}{0}\cos^5 z -  \binom{5}{2}\cos^3 z \sin^2 z + \binom{5}{4}\cos z \sin^4 z = 2^4 \cos^5 z - 5\binom{3}{0} 2^2 \cos^3 z + 5\binom{2}{1}\frac 12 2^{0}\cos z\\
& = & \cos z \bb{5 - 20\cos^2 z + 16\cos^4 z} = \cos z \bb{1 - 12\sin^2 z + 16\sin^4 z}.
\eeast
\end{example}


\begin{example}\label{exa:sin_pi_divided_by_5}
The trigonometric formulas for $\pi/5$ can be derived using the multiple-angle formula
\be
\sin(5\theta)=5\sin\theta-20\bb{\sin \theta}^3+16\bb{\sin \theta}^5. 	
\ee

Letting $\theta=\pi/5$ and $x=\sin\theta$ then gives
\be
\sin\pi = 0 = 5x- 20x^3+16x^5.
\ee 	

Factoring out one power of $x$ gives
\be
16x^4-20x^2+5=0. 	
\ee

Solving the quadratic equation for $x^2$ gives
\be
x^2=\frac 18 \bb{5 \pm \sqrt{5}}. 	
\ee

But $x=\sin(\pi/5)$ must be less than
\be
\sin(\pi/4)=\frac 12\sqrt{2}, 	
\ee
so taking the minus sign and simplifying gives
\be
\sin(\pi/5)=\sqrt{\frac{5-\sqrt{5}}{8}}=\frac 14\sqrt{10-2\sqrt{5}}.
\ee
\end{example}

\subsection{Special values in trigonometric functions}

\be
\ba{|c|cccccccccc|}
{\begin{matrix}{\text{Radian}}\\{\text{Degree}}\end{matrix}} &
{\begin{matrix}0\\0^{\circ }\end{matrix}} &
{\begin{matrix}{\frac {\pi }{12}}\\15^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{8}}\\22.5^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{6}}\\30^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{5}}\\36^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{4}}\\45^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{3}}\\60^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {2\pi }{5}}\\72^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {5\pi }{12}}\\75^{\circ }\end{matrix}}&
{\begin{matrix}{\frac {\pi }{2}}\\90^{\circ }\end{matrix}}\\
\hline
\sin &0&{\frac {{\sqrt {6}}-{\sqrt {2}}}{4}}&{\frac {\sqrt {2-{\sqrt {2}}}}{2}}&{\frac {1}{2}}& {\frac {\sqrt{10-2\sqrt{5}}}4} & {\frac {\sqrt {2}}{2}}&{\frac {\sqrt {3}}{2}} & \frac {\sqrt{10+2\sqrt{5}}}4&{\frac {{\sqrt {6}}+{\sqrt {2}}}{4}}&1\\
\cos &1&{\frac {{\sqrt {6}}+{\sqrt {2}}}{4}}&{\frac {\sqrt {2+{\sqrt {2}}}}{2}}&{\frac {\sqrt {3}}{2}}& \frac{\sqrt{5}+1}4& {\frac {\sqrt {2}}{2}}&{\frac {1}{2}}& \frac{\sqrt{5}-1}4& {\frac {{\sqrt {6}}-{\sqrt {2}}}{4}}&0\\
\tan &0&2-{\sqrt {3}}&{\sqrt {2}}-1&{\frac {\sqrt {3}}{3}}& \sqrt{5-2\sqrt{5}}& 1&{\sqrt {3}}& \sqrt{5+2\sqrt{5}}&2+{\sqrt {3}}&\infty \\
\cot &\infty &2+{\sqrt {3}}&{\sqrt {2}}+1&{\sqrt {3}}& \frac{\sqrt{25+10\sqrt{5}}}5 & 1&{\frac {\sqrt {3}}{3}}& \frac{\sqrt{25-10\sqrt{5}}}5 &2-{\sqrt {3}}&0\\
\sec &1&{\sqrt {6}}-{\sqrt {2}}&{\sqrt {2}}{\sqrt {2-{\sqrt {2}}}}&{\frac {2{\sqrt {3}}}{3}}& \sqrt{5}-1& {\sqrt {2}}&2& \sqrt{5}+1&{\sqrt {6}}+{\sqrt {2}}&\infty \\
\csc &\infty &{\sqrt {6}}+{\sqrt {2}}&{\sqrt {2}}{\sqrt {2+{\sqrt {2}}}}&  2 & \frac{\sqrt{50+10\sqrt{5}}}5&{\sqrt {2}}&{\frac {2{\sqrt {3}}}{3}}& \frac{\sqrt{50-10\sqrt{5}}}5 & {\sqrt {6}}-{\sqrt {2}}&1\\
\ea
\ee

\subsection{Inequalities}

\begin{proposition}
For any real $x\in \bsb{0,\frac{\pi}2}$, we have
\be
\sin x \leq x,\qquad \tan x\geq x,\qquad \sin x \geq \frac{2x}{\pi}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Taking the derivative of the difference of the functions, we have
\be
\bb{x - \sin x}' = 1 - \cos x \geq 0 \ \ra\ x - \sin x \text{ is increasing on }[0,\infty) \ \ra\ x\geq \sin x
\ee

\be
\bb{\tan x - x}' = \sec^2 x - 1 \geq 0 \ \ra\ \tan x - x \text{ is increasing on }[0,\infty) \ \ra\ \tan x \geq x.
\ee

The line pass through $(0,0)$ and $(\pi/2,1)$ is $y = \frac{2x}{\pi}$. Since $\bb{\sin x}'' = -\sin x <0$ on $\bb{0,\frac{\pi}2}$, we have that $\sin x$ is strictly concave in $\bsb{0,\frac{\pi}2}$ by Theorem \ref{thm:second_order_derivative_implis_convex_concave_strictly}. So $\sin x \geq \frac{2x}{\pi}$ on $\bsb{0,\frac{\pi}2}$.
\end{proof}

\begin{proposition}
For any $x\in \R$,
\be
\abs{e^{ix}-1} \leq \abs{x}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Clearly, $\sin\abs{\frac x2} \leq \abs{\frac{x}2}$. Thus,
\beast
x^2 \geq 4\sin^2 \bb{\frac{x}2} = 2 - 2\cos x = \bb{\cos x -1}^2 + \sin^2 x = \abs{e^{ix}- 1}^2 \ \ra\ \abs{x} \geq \abs{e^{ix}- 1}
\eeast
as required.
\end{proof}

\subsection{Other properties}

\be
\sin(nx) = 2^{n-1}\prod^{n-1}_{k=0}\sin\bb{\frac {\pi k}n + x}.
\ee

Finally\footnote{given by Bromwich (1991), Bromwich, T. J. I'A. and MacRobert, T. M. An Introduction to the Theory of Infinite Series, 3rd ed. New York: Chelsea, pp. 202-207, 1991.},
\be
\sin(na)=\left\{\ba{ll}
nx-\frac{n(n^2-1^2)x^3}{3!}+\frac{n(n^2-1^2)(n^2-3^2)x^5}{5!} - ...& n \text{ is odd}\\
n \cos a\bsb{x-\frac{(n^2-2^2)x^3}{3!}+\frac{(n^2-2^2)(n^2-4^2)x^5}{5!} - ...} \quad\quad &  n \text{ is even} 	
\ea
\right.
\ee
where $x=\sin a$.\footnote{proof needed.}



\section{Power Function}

\subsection{Power function of real numbers}

\begin{definition}[power function of real numbers]
Let $a$ be real number and $x>0$. The power function with the base $x$ and the exponent $a$ defined by
\be
x^a := \exp\bb{a\log (x)}.
\ee
\end{definition}

\begin{remark}
Clearly,
\beast
x^1 & = & \exp\bb{\log (x)} = x,\\
x^0 & = & \exp\bb{0} = 1,\\
x^{-1} & = & \exp\bb{-\log(x)} = \frac 1{\exp\bb{\log(x)}} = \frac 1x.
\eeast

For any positive integer $n$,
\be
x^n = \exp\bb{n\log(x)} = \exp\bb{\underbrace{\log(x) +\dots + \log(x)}_{n\text{ times}}} = \underbrace{\exp\bb{\log(x)}\dots \exp\bb{\log(x)}}_{n\text{ times}} = \underbrace{x \dots x}_{n\text{ times}}.
\ee

\beast
x^{-n} & = & \exp\bb{-n\log(x)} = \exp\bb{\underbrace{-\log(x) -\dots - \log(x)}_{n\text{ times}}} = \underbrace{\exp\bb{-\log(x)}\dots \exp\bb{-\log(x)}}_{n\text{ times}} \\
& = & \underbrace{\frac 1x \dots \frac 1x}_{n\text{ times}} = \bb{x^{-1}}^{n}
\eeast

We we can see the power function is consistent with exponentiation (Definition \ref{def:exponentiation_natural_number}, \ref{def:exponentiation_negative_integer})
\end{remark}

\begin{proposition}\label{pro:basic_properties_real_power_function}
Let $a,b\in \R$ and $x,y>0$. Then
\ben
\item [(i)] $(xy)^a = x^a y^a$.
\item [(ii)] $x^{a+b} = x^a x^b$.
\item [(iii)] $\bb{x^a}^b = x^{ab}$.
\een
\end{proposition}

\begin{proof}[\bf Proof]
By the property of $\exp$ and $\log$ (Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_real}, \ref{pro:logarithm_product_is_summation_of_logarithm}),
\beast
(xy)^a & = & e^{a\log(xy)} = e^{a\log x +a\log y} = e^{a\log x}e^{a\log y} = x^a y^a,\\
x^{a+b} & = & e^{(a+b)\log x} = e^{a\log x + b\log x} = e^{a\log x} e^{b\log x} = x^a x^b,\\
\bb{x^a}^b & = & e^{b\log \bb{x^a}} = e^{b\log \bb{e^{a\log x}}} =  e^{b\bb{a\log x}} = e^{ab\log x} = x^{ab}.
\eeast
\end{proof}


\begin{remark}
For any positive integer $n$ and $b>0$,
\be
\bb{b^{1/n}}^n = b^{\frac 1n \cdot n} = b^1 = b
\ee
which implies that $b^{1/n}$ solves $x^n = b$.
\end{remark}

\begin{proposition}
Let $a\in \R$ and $x>0$. Then
\be
\fd{}{x}x^a = a x^{a-1}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
By chain rule of real function (Theorem \ref{thm:chain_rule_real_function}),
\beast
\fd{}{x}x^a & = & \fd{}{x}e^{a\log x} = \bb{e^{a\log x}}' \bb{a\log x}' = e^{a\log x} \frac ax \\
& = & a e^{a\log x} e^{-\log x} =  a e^{(a-1)\log x} = ax^{a-1}.
\eeast
\end{proof}



\subsection{Integer power function of complex numbers}

\begin{definition}[integer power function of complex number]
Let $z\in \C$ and $a\in \Z$. The integer power function (also known as exponentiation) is defined by
\be
z^a  := \left\{\ba{ll}
\underbrace{z\times z \times \dots \times z}_{a\text{ times}} \quad\quad & a>0 \\
1 & a= 0\\
1\left/z^{-a}\right. & a<0
\ea\right.
\ee
\end{definition}

\begin{remark}
Clearly, for $k,n\in \Z$,
\be
z^{kn} = \bb{z^{k}}^n = \bb{z^{n}}^k.
\ee
\end{remark}

\begin{example}
For $z = 1+i$, we have
\be
z^3 = (1+i)^3 = (1+i)(1+i)(1+i) = 2i(1+i) = -2 + 2i
\ee
and
\be
z^{-3} = \frac{1}{z^3} = \frac{1}{-2+2i} = \frac{-2-2i}{\abs{-2+2i}^2} = -\frac 14\bb{1+i}.
\ee
\end{example}

\subsection{Root of unity}

\begin{definition}[root of unity\index{root of unity}]\label{def:root_of_unity}
Let $n$ be a positive integer. Then the $n$th root of unity is a complex number satisfying the equation
\be
z^n = 1.
\ee
\end{definition}

\begin{remark}
Any integer (maybe negative) power of an $n$th root of unity is also $n$th root of unity. That is
\be
\bb{z^k}^n = z^{kn} = \bb{z^n}^k = 1^k = 1.
\ee
\end{remark}

\begin{theorem}\label{thm:nth_roots_of_unity}
The $n$th roots of unity are
\be
\cos\frac{2k\pi}{n} + i\sin\frac{2k\pi}{n},\qquad k\in \Z.
\ee

Furthermore, the sum of unit roots is zero.
\end{theorem}

\begin{proof}[\bf Proof]
Let $z$ be an $n$th root of unity and $z = \abs{z} e^{i\theta} = \abs{z}\bb{\cos \theta + i\sin \theta}$. Then by $\abs{z}^n = 1$, $\abs{z} = 1$. Then $z = \cos \theta + i\sin \theta$ and by De Moivre's formula\footnote{Corollary needed.}
\be
1 = z^n = \cos \bb{n\theta} + i\sin\bb{n\theta} \ \ra\ n\theta = 2k\pi, \quad k\in \Z
\ee
which implies that
\be
z = \cos\frac{2k\pi}{n} + i\sin\frac{2k\pi}{n},\qquad k\in \Z.
\ee

By Euler's formula, $n$ roots can be represented by
\be
z_k = \cos\frac{2k\pi}n + i\sin \frac{2k\pi}n = e^{\frac{2k\pi }n i}, \qquad k=1,\dots,n.
\ee

Then assuming $w = z_1$, we have
\be
\sum^n_{k=1} z_k = w + w^2 + \dots + w^{n-1} + w^n = 1 + w + \dots + w^{n-1} =  \frac{w^n-1}{w-1} = \frac{1-1}{w-1} = 0.
\ee
\end{proof}



\begin{proposition}\label{pro:root_of_unity_equivalent_modulo_n_implies_equivalent_power}
If $z$ is an $n$th root of unity and $a\equiv b \lmod{n}$ for $a,b\in \Z$, then $z^a = z^b$.
\end{proposition}

\begin{remark}
Therefore, given a power $z^k$ of $z$, it can be assumed that $1\leq k\leq n$.
\end{remark}


\begin{proof}[\bf Proof]
By definition of congruence, $a = b+ kn$ for some $k\in \Z$ and
\be
z^a = z^{b+kn} = z^b z^{kn} = z^b \bb{z^n}^k = z^b \cdot 1^k = z^b \cdot 1 = z^b.
\ee
\end{proof}


\begin{example}
The reciprocal of an $n$th root of unity is its complex conjugate, and is also an $n$th root of unity. That is, for the $n$th root of unity, $z = \cos \frac{2k\pi}{n} + i\sin\frac{2k\pi}{n}$ for $k=0,1,\dots,n-1$,
\beast
\frac 1z = z^{-1} = z^{n-1} & = & \cos\frac{2(n-1)k\pi}{n} + i\sin\frac{2(n-1)k\pi}{n} = \cos\frac{-2k\pi}{n} + i\sin\frac{-2k\pi}{n} \\
& = & \cos\frac{2k\pi}{n} - i\sin\frac{2k\pi}{n} = \ol{z}.
\eeast
\end{example}


\begin{definition}[primitive root of unity]
An $n$th root of unity is called primitive if it is not a $k$th root of unity for some smaller positive integer $k\in \Z^+$. That is,
\be
z^k \neq 1,\qquad k=1,2,\dots, n-1.
\ee
\end{definition}


\begin{remark}
\ben
\item [(i)] Every $n$th root of unity, $z$, is a primitive $k$th root of unity for some $k$ where $1\leq k\leq n$.
\item [(ii)] The $n$th root of unity
\be
z = \cos\frac{2\pi}{n} + i\sin\frac{2\pi}{n}\quad \text{ is primitive.}
\ee
\een
\end{remark}

\begin{proposition}
If $n$ is prime number, then all $n$th roots of unity, except 1, are primitive.
\end{proposition}

\begin{proof}[\bf Proof]
Assume $z$ is one of $n$th roots of unity ($z^n = 1$). Then if there exists a positive integer $1\leq k<n$ such that $z^k = 1$, we have there exist $x,y\in \Z$ such that
\be
xk + yn = 1
\ee
since $k$ and $n$ are coprime\footnote{Corollary in Number theorem needed.}. Then
\be
z = z^1 = z^{xk+yn} = z^{xk}z^{yn} = \bb{z^k}^x\bb{z^n}^y = 1^x \cdot 1^y = 1.
\ee

Therefore, there is no such integer $k$ for $n$th root of unity, except 1.
\end{proof}

\begin{lemma}\label{lem:primitive_root_of_unity_power_are_roots_of_unity_and_distinct}
Let $z$ be a primitive $n$th root of unity. Then the powers $z,z^2,\dots,z^{n-1},z^n= z^0=1$ are all of the $n$th roots of unity and distinct.
\end{lemma}

\begin{proof}[\bf Proof]
Obviously, the powers $z^k$ with $k\in \bra{1,2,\dots,n}$ are all $n$th roots of unity as
\be
\bb{z^k}^n = z^{kn} = \bb{z^n}^k = 1^k = 1.
\ee

If the powers $z,z^2,\dots,z^{n-1},z^n$ are not distinct, we can find that $a,b\in \Z$ such that $z^a= z^b$ with $1\leq a<b\leq n$. Then $z^{b-a} = 1$ which is contradicts $z$ being primitive as $0<b-a<n$. Thus, the powers $z,z^2,\dots,z^{n-1},z^n= z^0=1$ are all distinct.

Since an $n$th-degree polynomial equation can only have $n$ distinct roots\footnote{theorem needed.}, this implies that the powers of a primitive root $z,z^2,\dots,z^{n-1},z^n= z^0=1$ are all of the $n$th roots of unity.
\end{proof}


\begin{theorem}
If $z$ is a primitive $n$th root of unity, then for $a,b\in \Z$
\be
z^a = z^b \ \lra \ a \equiv b \lmod{n}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
($\la$). This is direct result of Proposition \ref{pro:root_of_unity_equivalent_modulo_n_implies_equivalent_power}.


($\ra$). Let $a' \equiv a\lmod{n}$ and $b' \equiv b\lmod{n}$ such that $0\leq a',b'\leq n-1$ and by Proposition \ref{pro:root_of_unity_equivalent_modulo_n_implies_equivalent_power},
\be
z^{a'} = z^a = z^b = z^{b'}.
\ee

Then by Lemma \ref{lem:primitive_root_of_unity_power_are_roots_of_unity_and_distinct}, we have $a' = b'$ which implies $a \equiv b \lmod{n}$, as required.
\end{proof}

\subsection{Rational power function of complex numbers}

\begin{definition}[rational power function of complex number]
Let $z\in \C$ and $a\in \Q$. We can define
\be
z^{\frac 1n} := \abs{z}^{\frac 1n} \cdot e^{i\frac{\Arg z}{n}} \cdot e^{i\frac{2k\pi}n }, \qquad n\in \Z^+,\ k = 0,1,\dots,n-1.
\ee

If $a = m/n$ with $\gcd(m,n)=1$, then
\be
z^a := \bb{z^{\frac 1n}}^m
\ee
with $n$ different values.

Sometimes we only take $k=0$ for $z^{1/n}$,
\be
z^{\frac 1n} = \abs{z}^{\frac 1n}e^{i\frac{\Arg z}{n}}.
\ee
which is principal $n$th root function.
\end{definition}


\subsection{Complex power function of complex numbers}

\begin{definition}[power function of complex numbers]
Let $z\in \C$. Then we have the following definition. % and $a\in\R$.
\ben
\item [(i)] Consider real $a$. Define
\be
z^a := e^{a\log z} = e^{a\log\abs{z} + ia\arg z} = \abs{z}^a\cdot e^{ia\arg z} = \abs{z}^a\cdot e^{ia\bb{\Arg z + 2k\pi}},\qquad k\in \Z
\ee
with infinitely many values. Obviously,
\be
\abs{z^a} = \abs{z}^a,\qquad \arg \bb{z^a} = a\cdot \arg z.
\ee

\item [(ii)] Consider complex $a = \alpha + i\beta$. Define
\beast
z^a := e^{a\log z} & = & e^{\bb{\alpha + i\beta}\bb{\log\abs{z} + i\arg z}} = e^{\alpha \log\abs{z} - \beta\arg z}\cdot e^{i\bb{\alpha \arg z + \beta \log\abs{z}}}\\
& = & e^{\alpha \log\abs{z} - \beta\bb{\Arg z + 2k\pi}}\cdot e^{i\bb{\alpha \bb{\Arg z + 2k\pi} + \beta \log\abs{z}}}\\
& = & \abs{z}^\alpha \cdot e^{ - \beta\bb{\Arg z + 2k\pi}}\cdot e^{i\bb{\alpha \bb{\Arg z + 2k\pi} + \beta \log\abs{z}}}
\eeast
one value for each $k\in \Z$.
\een
\end{definition}

\begin{example}
The function $z^{\frac 12} = \sqrt{z}$ is two-valued for all $z\in \C$.
\be
\sqrt{\abs{z}} e^{\frac 12i\Arg z},\qquad -\sqrt{\abs{z}} e^{\frac 12i\Arg z} = \sqrt{\abs{z}} e^{\frac 12i\Arg z + i\pi}.
\ee

Since $\arg z = \Arg z + 2k\pi$ for $k\in \Z$, we can have these two values for odd and even $k$, respectively. So the branch point is $(-\infty,0]$, the negative axis plus the origin.
\end{example}


\begin{example}
For $z = i$ and $a = i$, we have $\ln\abs{z} = 0$, $\Arg z = \pi/2$, $\alpha = 0$ and $\beta = 1$. Then for $k\in \Z$,
\be
i^i = e^{0\cdot 0 - 1\cdot \bb{\pi/2 + 2k\pi}}\cdot e^{i\bb{0\cdot \bb{\pi/2 + 2k\pi} + 1\cdot 0}} = e^{- \bb{\pi/2 + 2k\pi}}.
\ee
\end{example}




\section{Inverse Trigonometric Functions}

\subsection{Inverse sine and cosine functions of real numbers}


\begin{definition}[real inverse sine, real inverse cosine]\label{def:inverse_sine_cosine_real}
The inverse sine function is the inverse of sine function $\sin:\bsb{-\frac{\pi}2,\frac{\pi}2}\to [-1,1]$, denoted by
\be
\arcsin:[-1,1]\to \bsb{-\frac{\pi}2,\frac{\pi}2}.
\ee


\begin{center}
\psset{yunit=2cm,xunit=2cm}
\begin{pspicture}(-2,-2)(2,2)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[]{->}(0,0)(-1.9,-1.9)(2,2)%axesstyle=frame,dx=2,dy=2
  \psset{algebraic,linewidth=1.5pt}

\pstGeonode[PointSymbol=*,PointName=none,dotscale=1,linecolor=red](-1,-1.5708){A}(1,1.57083){B}
\pstGeonode[PointSymbol=*,PointName=none,dotscale=1,linecolor=blue](-1.5708,-1){C}(1.5708,1){D}
  \psplot[linecolor=blue]{-1.5708}{1.5708}{sin(x)}
  \psplot[linecolor=red]{-1}{1}{ASIN(x)}
  \psplot[linecolor=black,linestyle=dashed,linewidth=0.5pt]{-1.8}{1.8}{x}

  \rput[cb](1.5,0.5){\textcolor{blue}{$\sin x$}}
  \rput[cb](0.5,1.8){\textcolor{red}{$\arcsin x$}}

        \rput[cb](-2,-0.8){\textcolor{blue}{$\bb{-\frac{\pi}2,-1}$}}
      \rput[cb](1.9,0.9){\textcolor{blue}{$\bb{\frac{\pi}2,1}$}}
    \rput[cb](-1,-1.8){\textcolor{red}{$\bb{-1,-\frac{\pi}2}$}}
      \rput[cb](1.3,1.7){\textcolor{red}{$\bb{1,\frac{\pi}2}$}}
\end{pspicture}
\end{center}


The inverse cosine function is the inverse of cosine function $\cos:\bsb{0,\pi}\to [-1,1]$, denoted by
\be
\arccos:[-1,1]\to \bsb{0,\pi}.
\ee

\begin{center}
\psset{yunit=1.8cm,xunit=1.8cm}
\begin{pspicture}(-2,-1.1)(3.3,3.3)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[]{->}(0,0)(-2.3,-1.1)(3.3,3.3)%axesstyle=frame,dx=2,dy=2
  \psset{algebraic,linewidth=1.5pt}

\pstGeonode[PointSymbol=*,PointName=none,dotscale=1,linecolor=red](1,0){A}(-1,3.1416){B}
\pstGeonode[PointSymbol=*,PointName=none,dotscale=1,linecolor=blue](0,1){C}(3.1416,-1){D}
  \psplot[linecolor=blue]{0}{3.1416}{cos(x)}
  \psplot[linecolor=red]{-1}{1}{ACOS(x)}
  \psplot[linecolor=black,linestyle=dashed,linewidth=0.5pt]{-1}{3}{x}

  \rput[cb](2,-0.8){\textcolor{blue}{$\cos x$}}
  \rput[cb](-0.5,2.8){\textcolor{red}{$\arccos x$}}


      \rput[cb](3,-0.8){\textcolor{blue}{$(\pi,-1)$}}
      \rput[cb](-0.4,0.8){\textcolor{blue}{$(0,1)$}}
    \rput[cb](-1.4,3){\textcolor{red}{$(-1,\pi)$}}
      \rput[cb](0.7,-0.15){\textcolor{red}{$(1,0)$}}
\end{pspicture}
\end{center}

\end{definition}


\begin{remark}
The existence and uniqueness are guaranteed by Proposition \ref{pro:sine_cosine_real_particular_interval_bijective} and Theorem \ref{thm:bijective_function_has_unique_inverse}.

Clearly, inverse sine function is odd function as
\be
\arcsin(-x) = -\arcsin x.
\ee
\end{remark}

\begin{example}
\be
\arcsin 0 = 0,\quad \arcsin\bb{-\frac {1}{2}} = -\frac{\pi}6,\quad \arcsin \bb{-\frac{\sqrt{2}}2} = -\frac{\pi}4, \quad \arcsin\bb{ -\frac{\sqrt{3}}2} = -\frac{\pi}3,
\ee
\be
\arccos 0 = \frac{\pi}2,\quad \arccos\bb{-\frac {1}{2}} = \frac{2\pi}3,\quad \arccos \bb{-\frac{\sqrt{2}}2} = \frac{3\pi}4, \quad \arccos\bb{ -\frac{\sqrt{3}}2} = \frac{5\pi}6.
\ee
\end{example}

\begin{theorem}\label{thm:inverse_sine_inverse_cosine_sum_pi_over_2}
For any $x\in [-1,1]$, we have
\be
\arcsin x +  \arccos x = \frac {\pi}2
\ee
\end{theorem}

\begin{proof}[\bf Proof]
For any $x\in [-1,1]$,
\be
\cos\bb{\frac {\pi}2 - \arcsin x} = \cos \bb{\arcsin x}\cos \frac{\pi}2 + \sin\bb{\arcsin x}\sin \frac{\pi}2 = \sin\bb{\arcsin x} = x = \cos\bb{\arccos x}
\ee

For any $x\in \bsb{0,\pi}$, by Proposition \ref{pro:sine_cosine_relation_with_pi_over_2_difference} (as $x - \frac {\pi}2\in \bsb{-\frac{\pi}2,\frac{\pi}2}$),
\beast
\frac {\pi}2 - \arcsin (\cos x) & = & \frac {\pi}2 + \arcsin (-\cos x) =  \frac {\pi}2 + \arcsin \bb{\cos \bb{x-\pi}} \\
& = & \frac {\pi}2 + \arcsin \bb{\sin \bb{x - \frac {\pi}2}} = \frac {\pi}2 + \bb{x - \frac {\pi}2} = x = \arccos\bb{\cos x}
\eeast
since $\arcsin$ is odd function. So $\frac {\pi}2 - \arcsin x$ is also the inverse of $\cos$. Since the inverse is unique, we have that for any $x\in [-1,1]$
\be
\frac {\pi}2 - \arcsin x = \arccos x \ \ra\ \arcsin x +  \arccos x = \frac {\pi}2.
\ee
\end{proof}

\begin{theorem}
The inverse sine function $\arcsin:[-1,1]\to \bsb{-\frac{\pi}2,\frac{\pi}2}$ and cosine function $\arccos:[-1,1]\to \bsb{0,\pi}$ are continuous on $[-1,1]$ and differentiable on $(-1,1)$. Furthermore,
\be
\fd{}{x} \arcsin(x) = \frac{1}{\sqrt{1-x^2}},\qquad \fd{}{x} \arccos(x) = -\frac{1}{\sqrt{1-x^2}},\qquad x\in (-1,1).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Since $\sin:\bsb{-\frac{\pi}2,\frac{\pi}2}\to [-1,1]$ is continuous and strictly increasing, we have that it is bijective and the inverse function $\arcsin:[-1,1]\to \bsb{-\frac{\pi}2,\frac{\pi}2}$ is continuous on $[-1,1]$ and differentiable on $(-1,1)$ by Theorem \ref{thm:inverse_rule_real_function}. Moreover, the theorem implies that for $x\in (-1,1)$
\be
\bb{\arcsin x}' = \frac{1}{\sin'\bb{\arcsin x}} = \frac{1}{\cos\bb{\arcsin x}}.
\ee

Since $\arcsin x \in \bb{-\frac{\pi}2,\frac{\pi}2}$, we have $\cos\bb{\arcsin x}>0$. Thus,
\be
\bb{\arcsin x}' = \frac{1}{\sqrt{\cos^2\bb{\arcsin x}}} = \frac{1}{\sqrt{1 - \sin^2\bb{\arcsin x}}} = \frac{1}{\sqrt{1-x^2}}.
\ee

%Let $y = \arcsin x$, we have $\sin y = x$, Then
%Consider the limit
%\be
%\lim_{x\ua 1} \arcsin x \ \ra \sin\bb{\lim_{x\ua 1} \arcsin x} = \lim_{x\ua 1} \sin\bb{\arcsin x} = \lim_{x\ua 1} x = 1 = \arcsin\frac{\pi}2
%\ee
%since $\sin$ is continuous. Thus, $fef$



Take the limit
\be
L = \lim_{x\ua 1} \frac{\arcsin x - \arcsin 1}{x-1} =  \lim_{x\ua 1} \frac{\arcsin x -\frac{\pi}2}{x-1}.
\ee

Now let $x=\sin u$ with $u\ua \frac{\pi}2$ and $x\ua 1$ since $\sin$ is continuous. Then since $\arcsin$ is continuous on [-1,1] ($\sin u\to 1$ implies that $u\to \frac{\pi}2$)
\be
L = \lim_{\sin u\ua 1} \frac{u -\frac{\pi}2}{\sin u -1} = \lim_{ u\to \frac{\pi}2 } \frac{u -\frac{\pi}2}{\sin u -1} = \lim_{ u\to \frac{\pi}2 } \frac{1}{\cos u } = \infty
\ee
by L'H\^optial's rule (Theorem \ref{thm:lhopital_rule_special}). Thus $\arcsin$ is not differentiable at $x=1$.

Similar, we have the conclusion for cosine function. Note that we can get
\be
\fd{}{x} \arccos(x) = -\frac{1}{\sqrt{1-x^2}},\qquad x\in (-1,1)
\ee
directly by Theorem \ref{thm:inverse_sine_inverse_cosine_sum_pi_over_2}.
\end{proof}


\subsection{Inverse tangent function of real numbers}

\begin{definition}[real inverse tangent]
The inverse tangent function is the inverse of tangent function $\tan:\bb{-\frac{\pi}2,\frac{\pi}2}\to (-\infty,\infty)$, denoted by
\be
\arctan:(-\infty,\infty) \to \bb{-\frac{\pi}2,\frac{\pi}2}.
\ee
\end{definition}


\begin{center}
\psset{yunit=1cm,xunit=1cm}
\begin{pspicture}(-5,-5.3)(5,5)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[Dx=2,Dy=2]{->}(0,0)(-5.2,-5)(5.2,5)%axesstyle=frame,
  \psset{algebraic,linewidth=1.5pt}
  \psplot[linecolor=red]{-5}{5}{ATAN(x)}
  \psplot[linecolor=blue]{-1.36}{1.36}{tan(x)}

    \psplot[linecolor=black,linestyle=dashed,linewidth=0.5pt]{-4.5}{4.5}{x}

  \psline[linecolor=blue,linestyle=dashed](1.5708,5)(1.5708,-5)
    \psline[linecolor=blue,linestyle=dashed](-1.5708,5)(-1.5708,-5)
      \psline[linecolor=red,linestyle=dashed](-5,1.5708,5)(5,1.5708)
        \psline[linecolor=red,linestyle=dashed](-5,-1.5708,5)(5,-1.5708)

  \rput[cb](0.8,4.5){\textcolor{blue}{$\tan x$}}
  \rput[cb](4,1){\textcolor{red}{$\arctan x$}}

   \rput[cb](1.5,-5.4){\textcolor{blue}{$-\frac{\pi}2$}}
      \rput[cb](-1.5,-5.4){\textcolor{blue}{$\frac{\pi}2$}}
    \rput[cb](-5.5,-1.5){\textcolor{red}{$-\frac{\pi}2$}}
      \rput[cb](-5.5,1.5){\textcolor{red}{$\frac{\pi}2$}}
\end{pspicture}
\end{center}


\begin{remark}
The existence and uniqueness are guaranteed by Proposition \ref{pro:tangent_real_particular_interval_bijective} and Theorem \ref{thm:bijective_function_has_unique_inverse}.

Usually, we write $\arctan \bb{\infty} = \frac {\pi}2$ and $\arctan \bb{-\infty} = -\frac {\pi}2$ by convention.
\end{remark}

\begin{example}
For $x\in \R$,
\be
\arctan 0 = 0,\quad \arctan \frac {\sqrt{3}}{3} = \frac{\pi}6,\quad \arctan 1 = \frac{\pi}4, \quad \arctan \sqrt{3} = \frac{\pi}3.
\ee
\end{example}

\begin{proposition}
For any $x>0$, %\in\R \bs\bra{0}$,
\be
\arctan x + \arctan \frac 1{x} = \frac{\pi}2.
\ee
\end{proposition}



\begin{proof}[\bf Proof]
{\bf Approach 1.} By Proposition \ref{pro:sum_tangent_complex},
\be
\tan\bb{\arctan x + \arctan \frac 1{x}} = \frac{\tan\bb{\arctan x} + \tan\bb{\arctan \frac 1{x}}}{1 - \tan\bb{\arctan x} \tan\bb{\arctan \frac 1{x}}} = \frac {x+\frac 1x}{1-x\frac 1x} = \frac {x+\frac 1x}{1-1} = \infty.\qquad (*)
\ee

Since $\arctan x + \arctan \frac 1{x} \in (0,\pi)$, the only possible value to satisfies $(*)$ is $\frac{\pi}2$.

{\bf Approach 2.} Since $\frac{\pi}2 - \arctan \frac 1{x}\in \bb{0,\frac{\pi}2}$, by Proposition \ref{pro:tan_inverse_is_pi_over_2_minus_angle}
\be
\tan\bb{\frac{\pi}2 - \arctan \frac 1{x}} = \frac 1{\tan\bb{ \arctan \frac 1x}} = \frac 1{\frac 1x} = x \ \ra\ \frac{\pi}2 - \arctan \frac 1{x} = \arctan x
\ee
as required.
\end{proof}

\begin{remark}
For any $x<0$,
\be
\arctan x + \arctan \frac 1{x} = -\frac{\pi}2.
\ee
since $\arctan$ is odd function.
\end{remark}



\begin{theorem}
The inverse tangent function $\arctan:(-\infty,\infty)\to \bb{-\frac{\pi}2,\frac{\pi}2}$ is continuous and differentiable on $(-\infty,\infty)$. Furthermore,
\be
\fd{}{x} \arctan(x) = \frac{1}{1+x^2},\qquad x\in (-\infty,\infty).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Since $\tan:\bb{-\frac{\pi}2,\frac{\pi}2}\to (-\infty,\infty)$ is continuous and strictly increasing, we have that it is bijective and the inverse function $\arctan:(-\infty,\infty)\to \bb{-\frac{\pi}2,\frac{\pi}2}$ is continuous and differentiable on $(-\infty,\infty)$ by Theorem \ref{thm:inverse_rule_real_function}. Moreover, the theorem implies that for $x\in (-\infty,\infty)$
\be
\bb{\arctan x}' = \frac{1}{\tan'\bb{\arctan x}} = \frac 1{\sec^2\bb{\arctan x}} = \frac{1}{1+\tan^2\bb{\arctan x}} = \frac 1{1+x^2}.
\ee
\end{proof}


\subsection{Inverse sine and inverse cosine function of complex numbers}

\begin{definition}[complex inverse sine]
The inverse sine function $\arcsin:\C \to D$ is defined by
\be
\arcsin z :=  -i\log\bb{iz + \sqrt{1-z^2}}
\ee
where $\log$ is the logarithm of complex number. Since $\log$ is multi-valued function on $\C$, $\arctan$ is also multi-valued with branch point $\pm i$.

Furthermore, the principal value of inverse sine function $\Arcsin:\C \to D$ is defined by
\be
\Arcsin z =  -i\Log\bb{iz + \sqrt{1-z^2}}
\ee
where $D = \bra{z: \Re(z) \in \bsb{-\frac{\pi}2,\frac{\pi}2}}$.

%The inverse cosine function $\Arccos :\C \to E$ is defined by
%\be
%\Arccos z = \frac{\pi}2  + i\Log\bb{iz + \sqrt{1-z^2}} % i\log\bb{z + \sqrt{z^2-1}}
%\ee
%where $E = \bra{z: \Re(z) \in \bsb{0,\pi}}$.

%The branch cut of these two functions is $(-\infty,-1)\cup (1,\infty)$.

Obviously, for any $z\in \C$
\be
\arcsin z = \Arcsin z + 2k\pi ,\qquad  k\in \Z.
\ee

The branch cut of these two functions is $(-\infty,-1)\cup (1,\infty)$ as it is the branch cut of $\sqrt{1-z^2}$.
\end{definition}

\begin{proof}[\bf Proof]
For $z = \sin w$, we want to find such $w = x+iy$ with $x,y\in \R$.

Start with $w = u+iv$ with $\Re(w)\in (-\pi,\pi]$ since $\sin$ has period $2\pi$.
\be
z = \sin w = \frac{e^{iw} - e^{-iw}}{2i} = e^{2iw} - 2ize^{iw} -1 =0\ \ra\ e^{iw} = \frac{2iz \pm\sqrt{-4z^2+4}}2 = iz\pm \sqrt{1-z^2}.
\ee

For $\sqrt{1-z^2}$ with $z = x+iy$, $1-z^2\neq -r$ for $r> 0$ since $\sqrt{1-z^2}$ cannot have multiple values. That is, we want to these values,
\be
1 - x^2 + y^2 -2ixy = -r \ \ra\ xy =0.
\ee

If $x = 0$, we have $-r=1+y^2 > 1$ which is a contradiction. Thus, $y=0$ and
\be
1-x^2 < 0 \ \ra\ x^2 < 1 \ \ra\ x \in (-\infty,-1)\cup (1,\infty)
\ee
which is the branch cut of $\sqrt{1-z^2}$. Since $z = \sin w = \frac{e^{iw} - e^{-iw}}{2i}$, we have
\beast
\sqrt{1-z^2} & = & \bb{1-\bb{\frac{e^{iw} - e^{-iw}}{2i}}^2}^{1/2} =  \bb{1+ \frac{e^{2iw} +  e^{-2iw} - 2}{4}}^{1/2}  = \bb{\frac{e^{2iw} +  e^{-2iw} +2}{4}}^{1/2} \\
& = & \bb{\bb{\frac{e^{iw} +  e^{-iw}}{2}}^2}^{1/2} = \bb{\bb{\frac{e^{iu-v} +  e^{-iu+v}}{2}}^2}^{1/2} = \bb{\bb{\frac{e^{-v}\bb{\cos u+ i\sin u} +  e^{v}\bb{\cos u- i\sin u}}{2}}^2}^{1/2}.
\eeast

If $u\in \bb{-\frac{\pi}2,\frac{\pi}2}$, $\frac 12\bb{e^{-v} + e^v}\cos u > 0$, then
\be
\sqrt{1-z^2} = \frac{e^{-v}\bb{\cos u+ i\sin u} +  e^{v}\bb{\cos u- i\sin u}}{2} = \frac{e^{iu-v} +  e^{-iu+v}}{2} = \frac{e^{iw} + e^{-iw}}{2}.
\ee

If $u\in \bb{-\pi,-\frac{\pi}2}$, $\frac 12\bb{e^{-v} + e^v}\cos u <0$ and $\Re\bb{1-z^2} < 0$, then
\be
\sqrt{1-z^2} =-\frac{e^{iw} + e^{-iw}}{2}= -\frac{e^{iu-v} +  e^{-iu+v}}{2} = \frac{e^{i(u+\pi)-v} +  e^{-i(u+\pi)+v}}{2}.
\ee

%\cup \bb{\frac{\pi}2,\pi}$

Similarly, if $u\in \left(\frac{\pi}2,\pi\right]$,
\be
\sqrt{1-z^2} = -\frac{e^{iw} + e^{-iw}}{2} = -\frac{e^{iu-v} +  e^{-iu+v}}{2} = \frac{e^{i(u-\pi)-v} +  e^{-i(u-\pi)+v}}{2}.
\ee

If $u = \pm \frac{\pi}2$, $\frac 12\bb{e^{-v} + e^v}\cos u =0$,
\be
 = \bb{i\frac{e^{-v}- e^{v}}{2}\sin u }^2 = - \bb{\frac{e^{-v}- e^{v}}{2}\cdot (\pm 1) }^2 =  - \bb{\frac{e^{-v}- e^{v}}{2}}^2
\ee
which implies that $\sqrt{1-z^2}$ is well-defined only if $v = 0$. Then
\be
iz + \sqrt{1-z^2} = \left\{\ba{ll}
i\frac{e^{iw} - e^{-iw}}{2i} + \frac{e^{iw} + e^{-iw}}{2} = e^{iw} = e^{-v}e^{iu} & u\in \bb{-\frac{\pi}2,\frac{\pi}2}\\
i\frac{e^{iw} - e^{-iw}}{2i} - \frac{e^{iw} + e^{-iw}}{2} = -e^{-iw} = -e^{v}e^{-iu} = e^{v}e^{i(\pi-u)} \quad\quad & u \in \left(\frac{\pi}2,\pi\right]\\
i\frac{e^{iw} - e^{-iw}}{2i} - \frac{e^{iw} + e^{-iw}}{2} = -e^{-iw} = -e^{v}e^{-iu} = e^{v}e^{i(-\pi-u)} \quad\quad & u \in \bb{-\pi,-\frac{\pi}2} \\
i\frac{e^{iw} - e^{-iw}}{2i} = \frac 12\bb{e^{iu}- e^{-iu}} = \pm i & u = \pm \frac{\pi}2
\ea\right.
\ee

\be
iz - \sqrt{1-z^2} = \left\{\ba{ll}
i\frac{e^{iw} - e^{-iw}}{2i} - \frac{e^{iw} + e^{-iw}}{2} = -e^{-iw} = -e^{v}e^{-iu} = e^{v}e^{i(\pi-u)} \quad\quad & u\in \bb{0,\frac{\pi}2}\\
i\frac{e^{iw} - e^{-iw}}{2i} - \frac{e^{iw} + e^{-iw}}{2} = -e^{-iw} = -e^{v}e^{-iu} = e^{v}e^{i(-\pi-u)} \quad\quad & u\in \bb{-\frac{\pi}2,0}\\
i\frac{e^{iw} - e^{-iw}}{2i} - \frac{e^{iw} + e^{-iw}}{2} = -e^{-iw} = -e^{v} \quad\quad & u=0\\
i\frac{e^{iw} - e^{-iw}}{2i} + \frac{e^{iw} + e^{-iw}}{2} = e^{iw} = e^{-v}e^{iu} = e^{-v}e^{iu} \quad\quad & u \in \left(\frac{\pi}2,\pi\right]\\
i\frac{e^{iw} - e^{-iw}}{2i} + \frac{e^{iw} + e^{-iw}}{2} = e^{iw} = e^{-v}e^{iu} = e^{-v}e^{iu} \quad\quad & u \in \bb{-\pi,-\frac{\pi}2} \\
i\frac{e^{iw} - e^{-iw}}{2i} = \frac 12\bb{e^{iu}- e^{-iu}} = \pm i & u = \pm \frac{\pi}2
\ea\right.
\ee

Since they are all of the form of $e^{v'}e^{iu'}$ where $u' \in (-\pi,\pi]$, we have by Proposition \ref{pro:exp_logarithm_composition},
\be
w = -i\Log\bb{iz + \sqrt{1-z^2}} = \left\{\ba{ll}
-i\bb{-v + iu} = u + iv & u\in \bb{-\frac{\pi}2,\frac{\pi}2}\\
-i\bb{v + i(\pi-u)} = \pi - u - iv \quad\quad & u \in \left(\frac{\pi}2,\pi\right]\\
-i\bb{v - i(\pi+u)} = -\pi - u - iv\quad\quad & u \in \bb{-\pi,-\frac{\pi}2} \\
-i \cdot \bb{\pm \frac{\pi}2 i} = \pm \frac{\pi}2 & u = \pm \frac{\pi}2
\ea\right.
\ee

\be
w' = -i\Log\bb{iz - \sqrt{1-z^2}} = \left\{\ba{ll}
-i\bb{v+i(\pi-u)} = \pi - u - iv\quad\quad & u\in \bb{0,\frac{\pi}2}\\
-i\bb{v-i(\pi+u)} = -\pi -u -iv \quad\quad & u\in \bb{-\frac{\pi}2,0}\\
-i\bb{v+i\pi} = \pi - iv \quad\quad & u=0\\
-i\bb{-v+iu} = u + iv \quad\quad & u \in \left(\frac{\pi}2,\pi\right]\\
-i\bb{-v+iu} = u + iv \quad\quad & u \in \bb{-\pi,-\frac{\pi}2} \\
-i \cdot \bb{\pm \frac{\pi}2 i} = \pm \frac{\pi}2 & u = \pm \frac{\pi}2
\ea\right.
\ee

%
%\beast
%iz \pm \sqrt{1-z^2} & = & \frac{e^{iw} - e^{-iw}}{2} \pm \bb{1-\bb{\frac{e^{iw} - e^{-iw}}{2i}}^2}^{1/2} =\frac{e^{iw} - e^{-iw}}{2} \pm \bb{1+ \frac{e^{2iw} +  e^{-2iw} - 2}{4}}^{1/2} \\
%& = & \frac{e^{iw} - e^{-iw}}{2} \pm \bb{\frac{e^{2iw} +  e^{-2iw} +2}{4}}^{1/2}.
%\eeast
%
%Also, let $w = u+iv$ with $u,v\in \R$ and $u\in (-\pi,\pi]$,
%\beast
%iz \pm \sqrt{1-z^2} & = & \frac{e^{iw} - e^{-iw}}{2} \pm \bb{\frac{e^{2iu-2v} +  e^{-2iu+2v} +2}{4}}^{1/2} \\
%& = & \frac{e^{iw} - e^{-iw}}{2} \pm \bb{\bb{\frac{e^{iu-v} +  e^{-iu+v}}{2}}^2}^{1/2} \\
%& = & \frac{e^{iw} - e^{-iw}}{2} \pm \bb{\bb{\frac{e^{-v}\bb{\cos u+ i\sin u} +  e^{v}\bb{\cos u- i\sin u}}{2}}^2}^{1/2}
%\eeast
%
%Also, let $w = u+ iv$ with $u,v\in \R$ and $u\in (-\pi,\pi]$%
%\be
%iz + \sqrt{1-z^2} = i\frac{e^{iw} - e^{-iw}}{2i} \pm \frac{e^{iw} + e^{-iw}}{2} = \left\{\ba{ll}
%e^{iw} = e^{-v}e^{iu} & u\in \bb{-\frac{\pi}2,\frac{\pi}2}\\
%-e^{-iw} = -e^{v}e^{-iu} = e^{v}e^{-iu+\pi i} \quad\quad & u \in \bb{-\pi,-\frac{\pi}2} \cup \bb{\frac{\pi}2,\pi}
%\ea\right.
%\ee
%
%Since $e^v$ and $e^{-v}$ are positive for all $v$, we can have that
%\be
%\Log\bb{iz + \sqrt{1-z^2}} = \left\{\ba{l}
%\log(e^{-v}) + i\Arg\bb{e^{iu}} = -v + iu\\
%\log(e^{v}) + i\Arg\bb{e^{(\pi-u)i}} = \left\{\ba{ll}
%v + i\bb{\pi-u}\quad\quad & u\in [0,\pi] \\
%v - i\bb{u+\pi}\quad\quad & u\in [-\pi,0)
%\ea\right.
%\ea\right.
%\ee
%
%Therefore,
%\be
%-i\Log\bb{iz + \sqrt{1-z^2}} = \left\{\ba{l}
%u+iv = w\\
%\left\{\ba{ll}
%\pi-u-iv = \pi -w \quad\quad & u\in [0,\pi] \\
%-\pi-u-iv = -\pi - w \quad\quad & u\in [-\pi,0)
%\ea\right.
%\ea\right.
%\ee

This means that if $\Re(w)\in [0,\pi]$ two solutions must lie on different sides of $\Re(w) = \frac{\pi}2$. Also, if $\Re(w)\in (-\pi,0)$ two solutions must lie on different sides of $\Re(w) = -\frac{\pi}2$. Therefore, we only define $w$ within strip $\bsb{-\frac{\pi}2,\frac{\pi}2}$ by $-i\Log\bb{iz + \sqrt{1-z^2}}$.

Note that we need $iz + \sqrt{1-z^2}\neq 0$ so $\Log\bb{iz + \sqrt{1-z^2}}$ is well-defined. That is,
\be
iz + \sqrt{1-z^2} \neq 0 \ \ra\ -z^2 \neq 1-z^2 \ \ra\ 0 \neq 1
\ee
which implies that it holds for all complex numbers. The branch cut of $\Log\bb{iz + \sqrt{1-z^2}}$ is $iz + \sqrt{1-z^2} = -x$ for $x>0$. So
\be
iz + \sqrt{1-z^2} = -x \ \ra\ x+iz = \sqrt{1-z^2} \ \ra\ x^2 + 2izx - z^2 = 1 - z^2 \ \ra\ z = \frac{x^2-1}{2x}i
\ee

Plug this value into the formula,
\be
iz + \sqrt{1-z^2} = -\frac{x^2-1}{2x} + \sqrt{1+\bb{\frac{x^2-1}{2x}}^2} = -\frac{x^2-1}{2x} + \frac{x^2+1}{2x} = \frac{2}{2x} = \frac 1x>0
\ee

So the branch cut of the composition of $iz+\sqrt{1-z^2}$ and $\Log(z)$ is still $(-\infty,-1)\cup (1,\infty)$.

\begin{figure}[t]
\begin{center}%1.5708, 3.1416
\begin{pspicture}(-5,-3)(5,3)
\psaxes[ticks=none,labels=none]{->}(0,0)(-5,-3)(5,3)
\psset{plotpoints=500,linewidth=1pt,arrowscale =2}
%\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=red]{0}{1.5708}
%\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=blue]{1.5708}{3.1416}
%\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=green]{3.1416}{4.7124}
%\psFourier[cosCoeff=0 2,sinCoeff=0,linecolor=magenta]{4.7124}{6.2832}

%\psFourier[cosCoeff=0,sinCoeff=2,linecolor=magenta]{0}{1.5708}
%\psFourier[cosCoeff=0,sinCoeff=2,linecolor=red]{1.5708}{3.1416}
%\psFourier[cosCoeff=0,sinCoeff=2,linecolor=blue]{3.1416}{4.7124}
%\psFourier[cosCoeff=0,sinCoeff=2,linecolor=green]{4.7124}{6.2832}
%\psFourier[cosCoeff=0,sinCoeff=2,linecolor=magenta]{6.2832}{7.8540}

\pstGeonode[PointSymbol=none,PointName=none](2,3){A}
\pstGeonode[PointSymbol=none,PointName=none](2,-3){AA}
\pstLineAB[linestyle=dashed]{A}{AA}

\pstGeonode[PointSymbol=none,PointName=none](4,3){B}
\pstGeonode[PointSymbol=none,PointName=none](4,-3){BB}
\pstLineAB[linestyle=dashed]{B}{BB}

\pstGeonode[PointSymbol=none,PointName=none](-2,3){C}
\pstGeonode[PointSymbol=none,PointName=none](-2,-3){CC}
\pstLineAB[linestyle=dashed]{C}{CC}

\pstGeonode[PointSymbol=none,PointName=none](-4,3){D}
\pstGeonode[PointSymbol=none,PointName=none](-4,-3){DD}
\pstLineAB[linestyle=dashed]{D}{DD}

\psline[linecolor=red]{->}(0,0)(1.5,2.5)
\psline[linecolor=red]{->}(0,0)(2.5,-2.5)
\psline[linestyle=dashed](1.5,2.5)(4,0)
\psline[linestyle=dashed](2.5,-2.5)(4,0)

\psline[linecolor=green]{->}(0,0)(-3,1)
\psline[linecolor=green]{->}(0,0)(-1,-1)
\psline[linestyle=dashed](-3,1)(-4,0)
\psline[linestyle=dashed](-1,-1)(-4,0)

\psline[linecolor=blue]{->}(0,0)(0,2)
\psline[linecolor=blue]{->}(0,0)(4,-2)
\psline[linestyle=dashed](0,2)(4,0)
%\psline[linestyle=dashed](4,-2)(4,0)

%\psline[linecolor=magenta,linestyle=dashed]{->}(5.5,1.2)(6.8,1.2)
%\psline[linecolor=magenta,linestyle=dashed]{->}(6.4,0.5)(0.3,0.5)
%\psline[linecolor=blue,linestyle=dashed]{->}(2.3,-1.2)(3.6,-1.2)
%\psline[linecolor=green,linestyle=dashed]{->}(4.2,-1.2)(5.5,-1.2)

%
\rput[lb](-2.9,1.1){$w$}
\rput[lb](-1.4,-1.4){$w'$}

\rput[lb](1.1,2.4){$w$}
\rput[lb](2.7,-2.5){$w'$}

\rput[lb](0.1,2){$w$}
\rput[lb](3.6,-2.3){$w'$}

\rput[lb](2.05,-2.9){$\frac{\pi}2$}
\rput[lb](4.05,-2.9){$\pi$}
\rput[lb](-2.6,-2.9){$-\frac{\pi}2$}
\rput[lb](-4.6,-2.9){$-\pi$}

\pspolygon[fillstyle=solid, fillcolor=blue,opacity=0.1,linestyle=none](A)(C)(CC)(AA)

\end{pspicture}
\end{center}
\end{figure}

\end{proof}



\begin{remark}
Since $\Arcsin z = -i\Log\bb{iz + \sqrt{1-z^2}} $, we have
\beast
\Arcsin(1) & = & -i\Log\bb{i + 0} = -i \bb{\log \abs{i} + i\Arg(i)} = -i \ln 1 + \Arg(i) = 0 + \frac{\pi}2 =  \frac{\pi}2,\\
\Arcsin(0) & = & -i\Log\bb{0 + 1} = -i \ln 1 = 0, \\
\Arcsin(-1) & = & -i\Log\bb{-i + 0} = -i \bb{\log \abs{-i} + i\Arg(-i)} = -i \ln 1 + \Arg(-i) = 0 - \frac{\pi}2 = - \frac{\pi}2.
\eeast
\beast
\Arcsin\bb{\frac12} & = &  -i\Log\bb{\frac{\sqrt{3}+i}2} = \Arg \bb{\frac{\sqrt{3}+ i}2} = \frac {\pi}6,\\
\Arcsin\bb{-\frac12} & = &  -i\Log\bb{\frac{\sqrt{3}-i}2} = \Arg \bb{\frac{\sqrt{3}- i}2} = -\frac {\pi}6,\\
\Arcsin(i) & = &  -i\Log\bb{-1 + \sqrt{2}} = -i \ln\bb{\sqrt{2}- 1}, \\
\Arcsin(-i) & = & -i\Log\bb{1 + \sqrt{2}} = -i \ln\bb{\sqrt{2}+ 1}.
\eeast
\end{remark}

\begin{definition}[complex inverse cosine]
The inverse cosine function $\arccos :\C \to \C$ is defined by%\frac{\pi}2  + i\log\bb{iz + \sqrt{1-z^2}}
\be
\arccos z =  \frac{\pi}2  + i\log\bb{iz + \sqrt{1-z^2}} % - i \log \bb{z + \sqrt{z^2-1}} % i\log\bb{z + \sqrt{z^2-1}}
\ee
where $\log$ is the logarithm of complex number. Since $\log$ is multi-valued function on $\C$, $\arctan$ is also multi-valued with branch point $\pm i$.

Furthermore, the principal value of inverse cosine function $\Arccos :\C \to E$ is defined by
\be
\Arccos z = \frac{\pi}2  + i\Log\bb{iz + \sqrt{1-z^2}} %- i \Log \bb{z + \sqrt{z^2-1}} %\frac{\pi}2  + i\Log\bb{iz + \sqrt{1-z^2}} % i\log\bb{z + \sqrt{z^2-1}}
\ee
where $E = \bra{z: \Re(z) \in \bsb{0,\pi}}$.

Obviously, for any $z\in \C$
\be
\arccos z = \Arccos z + 2k\pi ,\qquad  k\in \Z.
\ee

The branch cut of these two functions is $(-\infty,-1)\cup (1,\infty)$ as it is the branch cut of $\sqrt{1-z^2}$.
\end{definition}

\begin{remark}
By definition, for any $z\in \C$,
\be
\Arcsin z + \Arccos z = \frac {\pi}2.
\ee

Indeed, since $\cos\bb{\frac {\pi}2 - z} = \sin z$, we have that
\beast
z = \cos w = \sin \bb{\frac{\pi}2-w} & \ra & \frac{\pi}2 -w = -i\Log\bb{iz + \sqrt{1-z^2}} \\
& \ra & \Arccos z = w =  \frac{\pi}2 + i\Log\bb{iz + \sqrt{1-z^2}} .
\eeast
\end{remark}

%\begin{proof}[\bf Proof]
%{\bf Approach 1.} By definition, since $\Arcsin z + \Arccos z\in \bsb{-\frac{\pi}2,\frac{3\pi}2}$,
%\beast
%\Arcsin z + \Arccos z & = & -i\bb{\Log\bb{iz + \sqrt{1-z^2}} + \Log\bb{z + \sqrt{z^2-1}}} =   -i\bb{\Log\bb{iz + \sqrt{1-z^2}} + \Log\bb{z + i\sqrt{1-z^2}}}
%\eeast
%

%{\bf 	Approach 2.}

%Thus, $\Arcsin z + \Arccos z = \frac {\pi}2$.
%\end{proof}

\begin{remark}
Since $\Arccos z = \frac{\pi}2 - \Arcsin z$, we have
\beast
\Arccos(1) & = & \frac{\pi}2 - \frac{\pi}2 = 0 \\
\Arccos(0) & = & \frac{\pi}2 - 0 = \frac{\pi}2 , \\
\Arccos(-1) & = & \frac{\pi}2 + \frac{\pi}2 = \pi,
\eeast
\beast
\Arccos\bb{\frac12} & = &  \frac{\pi}2 -\frac{\pi}6 = \frac {\pi}3,\\
\Arccos\bb{-\frac12} & = & \frac{\pi}2 + \frac{\pi}6= \frac {2\pi}3,\\
\Arccos(i) & = & \frac{\pi}2 + i\ln\bb{\sqrt{2}-1} ,\\
\Arccos(-i) & = & \frac{\pi}2 + i\ln\bb{\sqrt{2}+1}.
\eeast
\end{remark}

\begin{proposition}
For any $z\in \C$, we have %for $z \notin (-\infty,-1]\cup[1,\infty)$,
\beast
\frac{d}{dz}\Arcsin z = \frac 1{\sqrt{1-z^2}} ,\qquad \frac{d}{dz}\Arccos z =  -\frac 1{\sqrt{1-z^2}},\qquad z\neq \pm 1.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
By Proposition \ref{pro:principal_value_logarithm_derivative}, we have to pick $z$ such that $\Arg\bb{iz + \sqrt{1-z^2}} \neq \pi$ ($iz + \sqrt{1-z^2} = -x$ for real number $x>0$). Thus,
\be
(iz + x)^2 = 1-z^2 \ \ra\ x^2 + 2izx - z^2 = 1-z^2 \ \ra\ z = \frac{x^2-1}{2x}i : = yi,\quad y\in \R
\ee

But we have
\be
iz + \sqrt{1-z^2} = -y + \sqrt{1+y^2} > 0 \ \ra\ \Arg\bb{iz + \sqrt{1-z^2}} \in (-\pi,\pi) \quad \text{for all }z\in \C.
\ee

%
%and
%\be
%iz + \sqrt{1-z^2}
%\ee
%%e^{i\theta} = iz + \sqrt{1-z^2} \ \ra\ e^{2i\theta} - z^2 - 2ize^{i\theta} = 1 - z^2 \ \ra\ z = \frac{}{}
%%\ee

Therefore, we use $\bb{\Log z}' = \frac 1z$ and have for $z\neq \pm 1$,
\be
\frac{d}{dz}\Arcsin z = -i \frac{d}{dz} \Log\bb{iz + \sqrt{1-z^2}} = -i \frac{i - \frac{z}{\sqrt{1-z^2}}}{iz + \sqrt{1-z^2}}  = \frac{1 + \frac{iz}{\sqrt{1-z^2}}}{iz + \sqrt{1-z^2}} = \frac 1{\sqrt{1-z^2}}.
\ee

%Again, by Proposition \ref{pro:principal_value_logarithm_derivative}, we have to pick $z$ such that $\Arg\bb{z + \sqrt{z^2-1}} \neq \pi$ ($z + \sqrt{z^2-1} = -x$ for real number $x>0$). Thus,
%\be
%(z + x)^2 = z^2 - 1 \ \ra\ x^2 + 2zx + z^2 = z^2-1 \ \ra\ z = \frac{-x^2-1}{2x} \leq -1
%\ee

%Therefore, we use $\bb{\Log z}' = \frac 1z$ and have for $z\neq  1$ and $z\notin (-\infty,-1]$,
%\be
%\frac{d}{dz}\arccos z = -i \frac{d}{dz} \Log\bb{z + \sqrt{z^2-1}} = -i \frac{1 + \frac{z}{\sqrt{z^2-1}}}{z + \sqrt{z^2-1}}  = - \frac{i}{\sqrt{z^2-1}} =  - \frac {\sqrt{-1}}{\sqrt{\bb{z^2-1}}} = - \frac {1}{\sqrt{\bb{1-z^2}}}.
%\ee

Since $\Arccos z = \frac{\pi}2 - \Arcsin z$, we have the required result for inverse cosine.
\end{proof}

\subsection{Inverse tangent function pf complex numbers}

\begin{definition}[inverse tangent function\index{inverse tangent function!complex}]\label{def:inverse_tangent_function_complex}
The inverse tangent function $\arctan:\C\to \C$ on complex domain by
\be
\arctan z := \frac 1{2i}\log\bb{\frac {1+iz}{1-iz}},\qquad z\neq\pm i
\ee
where $\log$ is the logarithm of complex number. Since $\log$ is multi-valued function on $\C$, $\arctan$ is also multi-valued with branch point $\pm i$.

Furthermore, the principal value of inverse tangent function $\Arctan:\C\to D$ is deifned by
\be
\Arctan z := \frac 1{2i}\Log\bb{\frac {1+iz}{1-iz}},\qquad z\neq\pm i
\ee
where $D = \bra{z: \Re(z) \in \bb{-\frac{\pi}2,\frac{\pi}2}}$.

Obviously, for any $z\in \C$
\be
\arctan z = \Arctan z + k\pi ,\qquad  k\in \Z, \qquad z\neq \pm i.
\ee

The branch cut is $(-i \infty,-i]\cup [i,i\infty)$.  %,\ \abs{\Arg z} \leq \frac{\pi}2.
\end{definition}

\begin{remark}
$\Arctan z$ is a composition
\be
z \mapsto \frac{1+iz}{1-iz} \mapsto \frac 1{2i} \Log\bb{\frac{1+iz}{1-iz}}.
\ee

The function maps $i$ to 0 and $-i$ to $\infty$, which are branch points of $\Log z$. So $i$ and $-i$ are branch points of $\arctan z$.
\end{remark}

\begin{proof}[\bf Proof]
For $z = \tan w$, we want to know $w = \arctan z$. Start with $\Re(w) \in (-\pi/2,\pi/2]$
\be
z = \frac{\sin w}{\cos w} = \frac 1i \frac{e^{iw} - e^{-iw}}{e^{iw} + e^{-iw}} = \frac 1i\frac{e^{2iw}-1}{e^{2iw}+1} \ \ra\ e^{2iw} = \frac {1+iz}{1-iz}\ \ra\ 2iw = \Log\bb{\frac {1+iz}{1-iz}}.
\ee%by Proposition\footnote{proposition needed $z = \exp\bb{\log(z)}$}.
by Proposition \ref{pro:exp_logarithm_composition}. Therefore,
\be
w = \frac 1{2i}\Log\bb{\frac {1+iz}{1-iz}}.
\ee

%Furthermore,
%\be
%\Log\bb{\frac {1+iz}{1-iz}} = \Log\bb{\frac {1-y+ix}{1+y-ix}} = \Log\bb{\frac {1-y+ix}{1+y-ix}} = \Log\bb{\frac {1-y^2-x^2 + 2ix}{(1+y)^2+x^2}}
%\ee

Thus, since $\tan z$ has period $\pi$, $z = \tan w$ for
\be
w = \frac 1{2i}\Log\bb{\frac {1+iz}{1-iz}} + k\pi = \frac 1{2i}\log\bb{\frac {1+iz}{1-iz}},\quad k\in \Z,\ z\neq \pm 1.
\ee


Note that the branch cut of $\Log\bb{\frac {1+iz}{1-iz}}$ is $\frac {1+iz}{1-iz}=-x$ for $x\in[ 0,1)\cup (1,\infty)$ (negaive axis plus origin). This is
\be
1+iz = ixz - x \ \ra\ z = \frac{1+x}{1-x}i.
\ee

But $\frac{1+x}{1-x} = (-\infty,-1)\cup [1,\infty)$. So the branch cut is $(-i \infty,-i]\cup [i,i\infty)$.

%Thus, for $z=x$ with real $x$ we have for any case,
%\beast
%w & = & \frac 1{4i} \log\abs{\frac {1+x^2}{1+x^2}} + \frac 1{2} \Arg \bb{\frac{1-x^2 + 2ix}{1+x^2}} + k\pi  = \frac 1{4i} \log\abs{\frac {1+x^2}{1+x^2}} + \frac 1{2} \arctan \bb{\frac{2x}{1-x^2}} + k\pi \\
%& = & 0 + \frac 1{2} 2 \arctan x + k\pi = \arctan x + k\pi
%\eeast
%by universal substitution for rational trigonometric functions\footnote{proposition needed.}.

%For $z = iy$ with real $y\neq \pm 1$ we have
%\be
%w = \frac 1{2i} \log\abs{\frac {1-y}{1+y}} + k\pi = \frac i2   \log\abs{\frac {1+y}{1-y}} + k\pi.
%\ee

\begin{figure}[t]
\begin{center}
\begin{pspicture}(-4,-2.5)(12,3)
\pstGeonode[PosAngle=-135](0,0){O}%\pstGeonode[PosAngle=-135](0,0){O}
\psaxes[labels=none,ticks=none]{-}(0,0)(-3,-3)(3,3)
\psset{PointSymbol=none,PointName=none,linewidth=2pt}
\pstGeonode[](0,2){A}(0,-2){B}(0,3){C}(0,-3){D}
\pstArcnOAB[linecolor=red]{O}{B}{A}
\pstArcnOAB[linecolor=blue]{O}{A}{B}
\pstLineAB[linecolor=black]{A}{C}
\pstLineAB[linecolor=black]{B}{D}
\pstLineAB[linecolor=green]{A}{B}

\pstGeonode[PointSymbol=o,linecolor=red](-2,0){E}
\pstGeonode[PointSymbol=o,linecolor=blue](2,0){F}
\pstGeonode[PointSymbol=o,linecolor=black](0,2){AA}
\pstGeonode[PointSymbol=o,linecolor=black](0,-2){BB}
\pstGeonode[PointSymbol=o,linecolor=green](0,0){OO}

\rput[lb](-0.4,2.8){$\infty$}
\rput[lb](-2.4,0.2){-1}
\rput[lb](2.2,-0.25){1}
\rput[lb](0.2,2.2){$i$}
\rput[lb](-0.5,-2.3){$-i$}
\rput[lb](-2,2){$z$}
%\end{pspicture}
%\begin{pspicture}(-4,-3)(4,3)
\psaxes[labels=none,ticks=none]{-}(8,0)(5,-3)(11,3)
\pstGeonode[PosAngle=-135,](8,0){O1}
\psset{PointSymbol=none,PointName=none,linewidth=2pt}
\pstGeonode[](8,3){A1}(8,-3){B1}(5,0){C1}(11,0){D1}
\pstLineAB[linecolor=black]{O1}{C1}
\pstLineAB[linecolor=red]{O1}{B1}
\pstLineAB[linecolor=blue]{O1}{A1}
\pstLineAB[linecolor=green]{O1}{D1}

\pstGeonode[PointSymbol=o,linecolor=red](8,-2){E1}
\pstGeonode[PointSymbol=o,linecolor=blue](8,2){F1}
\pstGeonode[PointSymbol=o,linecolor=black](6,0){AA1}
\pstGeonode[PointSymbol=o,linecolor=green](10,0){BB1}
\pstGeonode[PointSymbol=o,linecolor=black](8,0){OO1}

\rput[lb](-7.8,-0.2){O}
\rput[lb](4.9,0.2){$\infty$}
\rput[lb](6.1,0.2){-1}
\rput[lb](9.9,0.2){1}
\rput[lb](8.2,1.8){$i$}
\rput[lb](8.2,-1.9){$-i$}
\rput[lb](10,2){$\frac{1+iz}{1-iz}$}

\psset{linewidth=1pt}
\pscurve[showpoints=false,linecolor=black,linestyle=dashed]{->}(0.1,2.1)(3,2)(6,1)(7.9,0.1)
\pscurve[showpoints=false,linecolor=black,linestyle=dashed]{->}(0.1,-2)(2,-1.9)(4,-0.5)(4.9,0)
\pscurve[showpoints=false,linecolor=black,linestyle=dashed]{->}(0.1,2.9)(3,2.7)(5,2)(5.9,0.1)
\pscurve[showpoints=false,linecolor=blue,linestyle=dashed]{->}(2.1,0.1)(3,1)(6,2)(7.9,2)
\pscurve[showpoints=false,linecolor=red,linestyle=dashed]{->}(-2,-0.1)(-1.5,-2)(0,-2.5)(4,-2.3)(7.9,-2)
\pscurve[showpoints=false,linecolor=green,linestyle=dashed]{->}(0.1,-0.1)(5,-1)(9.9,-0.1)
\end{pspicture}
\end{center}
\end{figure}
%\begin{pspicture}(-4,-3)(4,3)
%\pstGeonode[PosAngle=-135](0,0){O}
%\psaxes[labels=none,ticks=none]{-}(0,0)(-3,-3)(3,3)
%\psset{PointSymbol=none,PointName=none,linewidth=2pt}
%\pstGeonode[](0,3){A}(0,-3){B}(-3,0){C}(3,0){D}
%\pstLineAB[linecolor=black]{O}{C}
%\pstLineAB[linecolor=red]{O}{B}
%\pstLineAB[linecolor=blue]{O}{A}
%\pstLineAB[linecolor=green]{O}{D}
%
%\pstGeonode[PointSymbol=o,linecolor=red](0,-2){E}
%\pstGeonode[PointSymbol=o,linecolor=blue](0,2){F}
%\pstGeonode[PointSymbol=o,linecolor=black](-2,0){AA}
%\pstGeonode[PointSymbol=o,linecolor=green](2,0){BB}
%\pstGeonode[PointSymbol=o,linecolor=black](0,0){OO}
%
%\rput[lb](-3.1,0.2){$\infty$}
%\rput[lb](-1.9,0.2){-1}
%\rput[lb](1.9,0.2){1}
%\rput[lb](0.2,1.8){$i$}
%\rput[lb](0.2,-1.9){$-i$}
%\rput[lb](-2.2,2,2){$\frac{1+iz}{1-iz}$}
%\end{pspicture}

For $\log\bb{\frac {1+iz}{1-iz}}$, we can use the different branch cuts (see the picture) with the same branch points $\pm i$.
\end{proof}



\begin{example}
Since $\Arctan z = \frac 1{2i}\Log\bb{\frac{1+iz}{1-iz}}$, we have
\beast
\Arctan(1) & = & \frac 1{2i}\Log\bb{\frac{1+i}{1-i}} = \frac 1{2i}\Log\bb{i} = \frac 1{2i} \frac {\pi}2i = \frac{\pi}4,\\
\Arctan(0) & = & \frac 1{2i}\Log\bb{1} = \frac 1{2i}\cdot 0 = 0, \\
\Arctan(-1) & = & \frac 1{2i}\Log\bb{\frac{1-i}{1+i}} = \frac 1{2i}\Log\bb{-i} = -\frac 1{2i} \frac {\pi}2i = -\frac{\pi}4,\\
\Arctan(\sqrt{3}) & = & \frac 1{2i}\Log\bb{\frac{1+i\sqrt{3}}{1-i\sqrt{3}}} = \frac 1{2i}\Log\bb{\frac{-2+2i\sqrt{3}}4} = \frac 1{2i}\Log\bb{\frac{-1+i\sqrt{3}}2} = \frac 1{2i} \frac {2\pi}3 i = \frac{\pi}3,\\
\Arctan(-\sqrt{3}) & = & \frac 1{2i}\Log\bb{\frac{1-i\sqrt{3}}{1+i\sqrt{3}}} = \frac 1{2i}\Log\bb{\frac{-2-2i\sqrt{3}}4} = \frac 1{2i}\Log\bb{\frac{-1-i\sqrt{3}}2} = -\frac 1{2i} \frac {2\pi}3 i = -\frac{\pi}3.
\eeast

\beast
\Arctan\bb{-2+i} & = & \frac 1{2i}\Log\bb{\frac {1+i(-2+i)}{1-i(-2+i)}} = \frac 1{2i}\Log\bb{\frac {-i}{1+i}} = \frac{1}{2i}\bb{\log\frac{1}{\sqrt{2}} + i\Arg\bb{-1-i}} \\
& = & -\frac {3\pi}8 + \frac i4\ln 2.
\eeast
\end{example}


\begin{proposition}
Let $\Arctan z$ be principal value of inverse tangent function. Then
\be
\frac{d}{dz}\Arctan z = \frac 1{1+z^2},\qquad z\neq \pm i
\ee
where branch cut $D:= (-i\infty,-i]\cup [i,i\infty)$.
\end{proposition}

\begin{proof}[\bf Proof]
As we can see in the proof of definition (Definition \ref{def:inverse_tangent_function_complex}), we can take the derivative of $\Log(\cdot)$ since it does not have multiple values in the region $\C\bs D$. Thus, by Proposition \ref{pro:properties_differentiable_function_complex}
\beast
\frac{d}{dz}\Arctan z & = & \frac 1{2i}\frac{d}{dz} \Log\bb{\frac{1+iz}{1-iz}} = \frac 1{2i} \frac{1-iz}{1+iz}\frac{d}{dz}\bb{\frac{1+iz}{1-iz}}\\
& = & \frac 1{2i} \frac{1-iz}{1+iz}\frac{i(1-iz)+i(1+iz)}{\bb{1-iz}^2} = \frac{1}{(1-iz)(1+iz)} = \frac 1{1+z^2}
\eeast
as required.
\end{proof}


%\begin{theorem}
%For $z\in \C$, the inverse tangent function $\arctan$ can be expressed by
%\be
%\arctan z = \sum^\infty_{n=0}\frac{(-1)^nz^{2n+1}}{2n+1} = z -\frac {z^3}3 + \frac {z^5}5 - \frac{z^7}7 + \dots.\qquad \abs{z}\leq 1,\ z\neq \pm i.
%\ee
%\end{theorem}


\begin{theorem}\label{thm:complex_inverse_tangent_infinite_sum}
For $z\in \C$, the inverse tangent function $\arctan$ can be expressed by
\be
\Arctan z = \sum^\infty_{n=0} \frac{(-1)^nz^{2n+1}}{2n+1} = z - \frac {z^3}3 + \frac{z^5}5 - \frac{z^7}7 + \dots \qquad \abs{z}\leq 1,\ z\neq \pm i.
\ee
\end{theorem}


\begin{proof}[\bf Proof]
By definition of $\arctan z = \frac 1{2i}\Log\bb{\frac{1+iz}{1-iz}}$, we have that $\frac{1+iz}{1-iz} \neq -x$ for $x\geq 0$ in the region $D:=\bra{z:\abs{z}\leq 1,z\neq \pm i}$. That is,
\be
\frac{1+iz}{1-iz} = -x \ \ra\ 1+ iz = ixz - x \ \ra\ z = \frac{1+x}{1-x}i \in [-i\infty,-i) \cup [i,i\infty].
\ee

This means that $\Log$ does not have multiple values in $D$. Thus, in this region,
\be
\frac{1+iz}{1-iz} = \frac{i-z}{z+i}
\ee
gives that $\Arg(i-z) \in (0,\pi)$, $\Arg(z+i) \in (0,\pi)$ so $\Arg\bb{\frac{1}{z+i}} = - \Arg(z+i)$ and
\be
\Arg(i-z) + \Arg\bb{\frac{1}{z+i}} = \Arg(i-z) - \Arg(z+i) \in (-\pi,\pi).
\ee

\begin{figure}[t]
\begin{center}
\begin{pspicture}(-4,-3)(4,3.5)
\psaxes[ticks=none,labels=none]{->}(0,0)(-4,-3.5)(4,3.5)
\psset{plotpoints=500,linewidth=1pt,arrowscale =2}

\pstGeonode[PointSymbol=none,PointName=none](0,3){A}(0,-3){B}(4,-3){C}(2.5,1){Z}(4,1){D}
\pstCircleOA[PointSymbol=none,PointName=none,linestyle=dashed,linecolor=green]{O}{A}

\psline[linecolor=blue]{->}(O)(Z)
\psline[linecolor=red]{->}(Z)(A)
\psline[linecolor=red]{->}(B)(Z)
\psline[linestyle=dashed,linecolor=green](B)(C)
\psline[linestyle=dashed,linecolor=green](Z)(D)

\pstMarkAngle[MarkAngleRadius=0.2,LabelAngleOffset=-15,LabelSep=1.2]{C}{B}{Z}{$\Arg(z+i)$}
\pstMarkAngle[MarkAngleRadius=0.2,LabelAngleOffset=-15,LabelSep=0.6]{D}{Z}{A}{$\Arg(i-z)$}

\rput[lb](0.1,3.1){$i$}
\rput[lb](0.1,-3.4){$-i$}

\rput[lb](0.5,1.8){$i-z$}
\rput[lb](1.5,-1){$z+i$}

\rput[lb](1.1,0.6){$z$}

\pstGeonode[PointSymbol=o,PointName=none](0,3){AA}(0,-3){BB}

\rput[lb](2.5,2.5){$\abs{z}\leq 1,z\neq \pm i$}
\end{pspicture}
\end{center}
\end{figure}

Thus, by Proposition \ref{pro:principal_value_logarithm_product_summation}
\beast
\Log\bb{\frac{1+iz}{1-iz}} &=&\Log\bb{\frac{i-z}{z+i}} = \Log\bb{i-z} - \Log\bb{z+i} \\
& = & \Log\bb{-i(i-z)} + \Log(i)- \bb{\Log\bb{(-i)(z+i)} + \Log(i)} \\
& =& \Log\bb{1+iz} - \Log\bb{1-iz}
\eeast

Then by Theorem \ref{thm:principal_value_logarithm_expansion} for $z\in D$
\be
\Log\bb{1+iz} = \sum^\infty_{n=1} (-1)^{n+1} \frac{(iz)^n}{n},\qquad  \Log\bb{1-iz}  = - \sum^\infty_{n=1}\frac{(iz)^n}{n}
\ee

Therefore,
\beast
\Log\bb{\frac{1+iz}{1-iz}} & = & 2\sum^\infty_{n\text{ is odd}} (-1)^{n+1} \frac{(iz)^n}{n} = 2\sum^\infty_{n=0} (-1)^{2n+2} \frac{(iz)^{2n+1}}{2n+1} \\
& = & 2i\sum^\infty_{n=0} (-1)^{2n+2}(-1)^n \frac{z^{2n+1}}{2n+1} = 2i\sum^\infty_{n=0} (-1)^n \frac{z^{2n+1}}{2n+1}
\eeast

Hence, for $z\in D$,
\be
\Arctan z = \frac 1{2i}\Log\bb{\frac{1+iz}{1-iz}} = \frac 1{2i}2i\sum^\infty_{n=0} (-1)^n \frac{z^{2n+1}}{2n+1}= \sum^\infty_{n=0} (-1)^n \frac{z^{2n+1}}{2n+1}
\ee
as required.
\end{proof}

\begin{corollary}[Leibniz formula for $\pi$\index{Leibniz formula for $\pi$}]
\be
\sum_{n=0}^{\infty} \frac{(-1)^{n}}{2n+1} = \frac{\pi }{4}.
\ee
\end{corollary}

\begin{remark}
See Proposition \ref{pro:alternative_odd_series} for alternative proof.
\end{remark}



%\begin{remark}
%Note that we cannot apply the Taylor expansion of $\Log(\frac{1+iz}{1-iz})$ (see Theorem \ref{thm:principal_value_logarithm_expansion}) as we must have that
%\be
%\abs{\frac{1+iz}{1-iz} - 1} \leq 1,\quad \bb{\frac{1+iz}{1-iz} - 1}\neq -1 \ \ra\ \abs{\frac{2iz}{1-iz}} \leq 1,\ z\neq\pm i.
%\ee

%This implies that for $z = x+iy$,
%\be
%4\bb{x^2 + y^2} \leq x^2 + (y+1)^2 \ \ra\ x^2 + \bb{y-\frac 13}^2 \leq \frac 49.
%\ee
%This region can only cover $\bsb{-\frac {\sqrt{3}}3,\frac {\sqrt{3}}3}$ on real axis.
%\end{remark}

In particular, we can only prove the real case.

\begin{proposition}\label{pro:arctan_real_series_module_smaller_than_equal_1}
For $x\in \R$ with $\abs{x} \leq 1$,
\be
\arctan x = \sum^\infty_{n=0} \frac{(-1)^n}{2n+1}x^{2n+1}.
\ee
\end{proposition}


\begin{proof}[\bf Proof]
For $x\in (0,1)$,
\beast
\arctan x & = & \int^x_0 \frac{1}{1+t^2}dt = \int^x_0 \frac{1}{1-(-t^2)}dt = \int^x_0 \bb{1+(-t^2) + (-t^2)^2 + \dots  } dt = \int^x_0 \bb{1 - t^2 + t^4 + \dots  } dt \\
& = & x - \frac{x^3}{3} + \frac{x^5}{5}- \frac{x^7}{7} + \dots = \sum^\infty_{n=0} \frac{(-1)^n}{2n+1}x^{2n+1}.
\eeast

For $x=1$,
\beast
\frac{\pi}4 = \arctan(1) & = & \int^1_0 \frac 1{1+x^2}dx = \int^1_0 \bb{\sum^n_{k=0}(-1)^k x^{2k} + \frac{(-1)^{n+1}x^{2n+2}}{1+x^2}}dx\\
& = & \sum^n_{k=0} \frac{(-1)^k}{2k+1} + (-1)^{n+1}\int^1_0 \frac{x^{2n+2}}{1+x^2}dx.
\eeast

Considering only the integral in the last line, we have
\be
0< \int^1_0 \frac{x^{2n+2}}{1+x^2}dx < \int^1_0 x^{2n+2}dx = \frac{1}{2n+3}\to 0
\ee
as $n\to \infty$. Thus, we can have the required result by symmetry of $\arctan x$.
\end{proof}



%\begin{proposition}%[arctangent function\index{arctangent function!complex}]\label{def:arctangent_function_complex}
%Let $z = \tan w$ on complex domain. So we can have that %, we want to know $w = \arctan z$. The arctangent function $\arctan$  is defined by
%\be
%w = \frac 1{2i}\Log\bb{\frac {1+iz}{1-iz}} + k\pi,\qquad z\neq \pm i,\ k\in \Z.
%\ee
%\end{proposition}

%\begin{proof}[\bf Proof]
%Start with
%\be
%z = \frac{\sin w}{\cos w} = \frac 1i \frac{e^{iw} - e^{-iw}}{e^{iw} + e^{-iw}} = \frac 1i\frac{e^{2iw}-1}{e^{2iw}+1} \ \ra\ e^{2iw} = \frac {1+iz}{1-iz}\ \ra\ 2iw = \log\bb{\frac {1+iz}{1-iz}}
%\ee
%by Proposition\footnote{proposition needed $z = \exp\bb{\log(z)}$}. Thus,
%\be
%w = \frac 1{2i}\log\bb{\frac {1+iz}{1-iz}} = \frac 1{2i}\Log\bb{\frac {1+iz}{1-iz}} + k\pi.
%\ee


%Thus, for $z = x + iy = re^{i\theta}$ with $x,y\in\R$ and $\theta\in (-\pi,\pi]$ %\in (-\pi,\pi]
%\be
%\Arg\bb{\frac {1+iz}{1-iz}}  = \Arg\bb{\frac {1-y+ix}{1+y-ix}} = \Arg\bb{\frac {(1-x^2-y^2 + 2ix} {(1+y)^2+x^2}}. %\left\{\ba{ll} \arctan \bb{\frac{2x}{1-x^2-y^2}} \quad\quad & x\geq 0 \\ \pi + \arctan \bb{\frac{2x}{1-x^2-y^2}} & \\ \ea\right.
%\ee

%If $r = 1$, we have for
%\be
%\Arg\bb{\frac {1+iz}{1-iz}} = \frac {\pi}2\sgn(x)
%\ee
%for $y\neq \pm 1$ ($z\neq \pm i$). Thus, if $r<1$
%\be
%\Arg\bb{\frac {1+iz}{1-iz}} = \arctan \bb{\frac{2x}{1-x^2-y^2}}.
%\ee

%If $r>1$,
%\be
%\Arg\bb{\frac {1+iz}{1-iz}} = \left\{\ba{ll}
%\arctan \bb{\frac{2x}{1-x^2-y^2}} + \pi \quad\quad & x \geq 0\\
%\arctan \bb{\frac{2x}{1-x^2-y^2}} - \pi \quad\quad & x < 0
%\ea\right.
%\ee

%Let $z=x$ where $x$ is real number. We have for $\arg z \in (-\pi/2,\pi/2]$,
%\beast
%w & = & \frac 1{2i} \Log\bb{\frac {1+iz}{1-iz}} + k\pi = \frac 1{2i} \log\abs{\frac {1+iz}{1-iz}} + \frac 1{2i} i \Arg\bb{\frac {1+iz}{1-iz}} + k\pi .%& = & \frac 1{4i} \log\abs{\frac {(1-y)^2+x^2}{(1+y)^2+x^2}} + \frac 1{2} \arctan \bb{\frac{2x}{1-x^2-y^2}} + k\pi.
%\eeast
%\end{proof}







%\subsection{Applications}






\section{Gamma Function}

\subsection{Gamma function}

Historically, the gamma function was first defined by Euler as the limit of a product (see Theorem \ref{thm:euler_formula_for_gamma_function}) from which can be derived the infinite integral $\int^\infty_0 t^{z-1}e^{-t} dt$. However, in developing the theory of the function, it is more convenient to define it by means of an infinite product of Weierstrass' canonical form. We use the result in Whittaker and Watson \cite{Whittaker_Watson_1963}.

\begin{definition}[gamma function (Weierstrass' canonical form)\index{gamma function}]\label{def:gamma_function_weierstrass_canonical_form}
For any $z\in \C\bs\bra{0,-1,-2,\dots}$, we define gamma function by the product
\be
\frac 1{\Gamma(z)} := ze^{\gamma z} \prod^\infty_{n=1}\bb{\bb{1+\frac zn}e^{-\frac zn}}
\ee% Corollary \ref{cor:euler_constant_definition}
where $\gamma$ is Euler constant (see Definition \ref{def:euler_mascheroni_constant}) given by
\be
\gamma = \lim_{n\to \infty}\bb{\sum^n_{k=1} \frac 1k - \log n} = 0.5772157....
\ee
\end{definition}

\begin{remark}
The product under consideration represents an analytic function of $z$ for all values of $z$. Let $N$ be an integer such that $\abs{z}\leq \frac N2$. Then for any $n>N$, we can take the principal value\footnote{details needed.} of $\log\bb{1+\frac zn}$ and have
\beast
\abs{\log\bb{1+\frac zn} - \frac zn} & = & \abs{-\frac 12 \frac{z^2}{n^2} + \frac 13 \frac{z^3}{n^3} - \dots} \leq \frac{\abs{z}^2}{n^2}\bb{1 +\abs{\frac zn} + \abs{\frac{z^2}{n^2}} + \dots} \\
& \leq & \frac 14 \frac{N^2}{n^2} \bb{1+\frac 12 + \frac 1{2^2} + \dots} \leq \frac {N^2}{2n^2}.
\eeast

Since the series $\sum^\infty_{n=N+1} N^2/(2n^2)$ converges, it follows that, when $\abs{z}\leq \frac N2$,
\be
\sum^\infty_{n=N+1} \bb{\log\bb{1+\frac zn} -\frac zn}
\ee
is an absolutely and uniformly convergent series of analytic functions, and so it is an analytic function\footnote{details needed.}. Consequently its exponential
\be
\prod^\infty_{n=N+1} \bb{\bb{1+\frac zn}e^{-\frac zn}}
\ee
is an analytic function and so is $\Gamma(z)$ is an analytic function when $\abs{z}\leq \frac N2$ where $N$ is any integer. That is to say, the product $\Gamma(z)$ is analytic for all finite values of $z$.

So $\Gamma(z)$ is well-defined and analytic except at the points $z=0,-1,-2,\dots$ where it has simple poles.
\end{remark}

\begin{center}
\psset{yunit=0.5cm,algebraic,labelsep=5pt,
  linewidth=0.4pt,arrowsize=3pt 2,arrowinset=0.25}
\begin{pspicture}(-5.75,-5.75)(5.75,6.75)%
\psaxes[labelFontSize=\scriptstyle,Dy=2,ticksize=-2pt 0,
   subticks=0]{->}(0,0)(-5.2,-6)(4.5,6.5)%
\rput[lb](-5.2,-5.5){%
  \begin{pspicture*}(-5.2,-5.5)(5.75,6.2)
  \psplot[plotpoints=5000,yMaxValue=6,linewidth=1.5pt,
    linecolor=blue]{-5.2}{6}{GAMMA(x)}%
  \multido{\iA=-1+-1}{5}{\psline[linestyle=dashed](\iA,-6)(\iA,6)}%
  \psdots[dotsize=2pt 0,dotstyle=*](!1 1 GAMMA)\uput[90](!1 1 GAMMA){0!}
  \psdots[dotsize=2pt 0,dotstyle=*](!2 2 GAMMA)\uput[90](!2 2 GAMMA){1!}
  \psdots[dotsize=2pt 0,dotstyle=*](!3 3 GAMMA)\uput[110](!3 3 GAMMA){2!}
  \psdots[dotsize=2pt 0,dotstyle=*](!4 4 GAMMA)\uput[200](!4 4 GAMMA){3!}
  \end{pspicture*}}%
 \end{pspicture}
 \end{center}





\begin{proposition}
Let $\Gamma(\cdot)$ be gamma function. Then for $m\in \Z^+$,
\be
\Gamma(m) = (m-1)!,\qquad \Gamma'(1) = -\gamma%\qquad \Gamma(2) = 1,
\ee
where $\gamma$ is Euler's constant.
\end{proposition}

\begin{proof}[\bf Proof]
Taking the logarithm of the product in the definition of gamma function at $z=m$, we have
%\beast
%\gamma + \sum^\infty_{n=1}\bb{\log\bb{1+\frac 1n}-\frac 1n} & = & \gamma + \lim_{n\to \infty}\bb{\log\bb{n+1} - \sum^n_{k=1}\frac 1k} \\
%& = & \gamma + \lim_{n\to \infty}\bb{\log n - \sum^n_{k=1}\frac 1k} + \lim_{n\to \infty} \log\bb{\frac{n+1}n} \\
%& = & \lim_{n\to \infty} \log\bb{\frac{n+1}n} = 0
%\eeast
%Similarly, for $z=2$, we have
\beast
& & \log m + m\gamma + \sum^\infty_{n=1}\bb{\log\bb{1+\frac mn}-\frac mn} \\
& = & \log m + m\gamma + \lim_{n\to \infty}\bb{\log\bb{\frac{(n+1)\dots (n+m)}{1\cdot 2\cdot \dots \cdot m}} - m  \sum^n_{k=1}\frac 1k} \\
& = & m\gamma + m\lim_{n\to \infty}\bb{\log n - \sum^n_{k=1}\frac 1k} + \lim_{n\to \infty} \log\bb{\frac{(n+1)\dots(n+m)}{n^m}} - \log((m-1)!) \\
& = & m\gamma - m\gamma + \lim_{n\to \infty} \log\bb{\frac{(n+1)\dots(n+m)}{n^m}} - \log((m-1)!) = - \log((m-1)!)
\eeast
by definition of $\gamma$. Then we have
\be
1/\Gamma(m) = \exp\bb{- \log((m-1)!)}  \ \ra\ \Gamma(m)=(m-1)!.
\ee

Applying the logarithm again and taking differentiation with respect to $z$, we have
\be
-\frac{\Gamma'(z)}{\Gamma(z)} = \bb{-\log\Gamma(z)}' = \bb{\ln z + \gamma z + \sum^\infty_{n=1}\bb{\log\bb{1+\frac zn}-\frac zn}}'  = \bb{\frac 1z + \gamma + \sum^\infty_{n=1}\bb{\frac{1}{n\bb{1+\frac zn}}-\frac 1n}}
\ee

Thus,
\be
-\frac{\Gamma'(1)}{\Gamma(1)} = \bb{1 + \gamma + \sum^\infty_{n=1}\bb{\frac{1}{n+1}-\frac 1n}} = \bb{1 + \gamma -1 + \lim_{n\to\infty}\frac{1}{n+1}} = \gamma.
\ee

Therefore,
\be
\Gamma'(1) = -\gamma \Gamma(1) = -\gamma.
\ee
\end{proof}

%\begin{proposition}\label{pro:gamma_function_induction}
%For $z\in \C$ and $\Re z\in \Z^+$ and $n\in \Z^+$%\notin \Z^-\cup \bra{0}$,
%\be \Gamma(z+1)=z \Gamma(z),\qquad \Gamma(n) = (n-1)!.
%\ee
%\end{proposition}

%\begin{proof}[\bf Proof]
%\footnote{proof needed.}
%\end{proof}



\begin{theorem}[Euler formula for gamma function]\label{thm:euler_formula_for_gamma_function}
For any $z\in \C\bs \bra{0,-1,-2,-3,\dots}$, gamma function is
\be
\Gamma(z) = \frac 1z \prod^\infty_{n=1} \bb{\bb{1+\frac 1n}^z\bb{1+\frac zn}^{-1}}
\ee
\end{theorem}

\begin{remark}
This formula was given by Euler in 1729 in a letter to Goldbach, printed in Fuss' Corresp. Math.
\end{remark}

\begin{proof}[\bf Proof]
By the definition of an infinite product (see Definition \ref{def:gamma_function_weierstrass_canonical_form}) we have
\beast
\frac 1{\Gamma(z)} & = & z\bb{\lim_{n\to\infty}e^{\bb{1+\frac 12 + \dots + \frac 1n - \log n}z}}\bb{\lim_{n\to \infty}\prod^n_{k=1}\bb{\bb{1+\frac zk}e^{-\frac zk}}} \\
& = & z\lim_{n\to\infty}\bb{e^{\bb{1+\frac 12 + \dots + \frac 1n - \log n}z}\prod^n_{k=1}\bb{\bb{1+\frac zk}e^{-\frac zk}}} = z\lim_{n\to\infty}\bb{n^{-z} \prod^n_{k=1}\bb{1+\frac zk}} \\
& = & z\lim_{n\to\infty}\bb{\prod^{n-1}_{k=1} \bb{1+\frac 1k}^{-z}\prod^n_{k=1}\bb{1+\frac zk}} = z\lim_{n\to\infty}\bb{\bb{1+\frac 1n}^{z} \prod^{n}_{k=1} \bb{1+\frac 1k}^{-z}\bb{1+\frac zk}} \\
& = & z\lim_{n\to\infty}\bb{\prod^{n}_{k=1} \bb{1+\frac 1k}^{-z}\bb{1+\frac zk}}
\eeast
as required.
\end{proof}


\begin{proposition}[Gauss limit for Gamma function]\label{pro:gauss_limit_gamma_function}%{pro:gamma_function_product_ratio}
For any $z\in \C\bs \bra{0,-1,-2,-3,\dots}$,
\be
\Gamma(z) = \lim_{n\to \infty} \frac{1\cdot 2\cdot \dots \cdot (n-1)\cdot n^z}{z\cdot (z+1)\cdot \dots \cdot (z+n-1)} .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Using the result in Theorem \ref{thm:euler_formula_for_gamma_function}, we have
\beast
\Gamma(z) & = & \lim_{n\to \infty}\bb{\frac 1z \prod^{n-1}_{k=1} \bb{\bb{1+\frac 1k}^z\bb{1+\frac zk}^{-1}}} = \lim_{n\to \infty}\bb{\frac 1z \prod^{n-1}_{k=1} \bb{\bb{\frac {k+1}k}^z\bb{\frac{z+k}k}^{-1}}} \\
& = & \lim_{n\to \infty}\bb{\frac {n^z}z \prod^{n-1}_{k=1}\bb{\frac{z+k}k}^{-1}} = \lim_{n\to \infty}\bb{\frac {n^z}z \frac{1\cdot 2 \cdot \dots \cdot (n-1)}{(z+1)\cdot (z+2) \cdot \dots \cdot (z+n-1)}}
\eeast
as required.
\end{proof}



\subsection{The difference equation satisfied by gamma function}

\begin{proposition}\label{pro:gamma_function_product_z_z_plus_1}
For any $z\in \C\bs \bra{0,-1,-2,-3,\dots}$,
\be
\Gamma(z+1) = z\Gamma(z).
\ee

In particular, for $n\in \Z^+$, $\Gamma(n) = (n-1)!$.
\end{proposition}

\begin{remark}
This is one the most important properties of gamma function.
\end{remark}

\begin{proof}[\bf Proof]
By Euler formula (Theorem \ref{thm:euler_formula_for_gamma_function}), if $z$ is not a negative integer,
\beast
\frac{\Gamma(z+1)}{\Gamma(z)} & = & \left.\frac 1{z+1} \lim_{n\to \infty}\bb{\prod^n_{k=1}\frac{\bb{1+\frac 1k}^{z+1}}{1+\frac{z+1}k}}  \right/ \frac 1{z} \lim_{n\to \infty}\bb{\prod^n_{k=1}\frac{\bb{1+\frac 1k}^{z}}{1+\frac{z}k}} \\
& = & \frac z{z+1} \lim_{n\to \infty}\bb{\prod^n_{k=1}\frac{\bb{1+\frac 1k}\bb{z+k}}{z+k+1}} = z \lim_{n\to \infty} \frac{n+1}{z+n+1} = z.
\eeast
\end{proof}
%
%\begin{example}
%
%\end{example}

\subsection{Connection between gamma function and trigonometric function}

\begin{proposition}\label{pro:gamma_function_z_1_minus_z}
For any $z\in \C\bs \Z$,
\be
\Gamma(z) \Gamma(1-z) = \frac{\pi}{\sin (\pi z)}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
By definition of gamma function (Weierstrass canonical form)
\be
\Gamma(z) \Gamma(-z) = -\frac 1{z^2}\prod^\infty_{n=1}\bb{\bb{1+\frac zn}e^{-\frac zn}}^{-1}\prod^\infty_{n=1}\bb{\bb{1-\frac zn}e^{\frac zn}}^{-1} = -\frac 1{z^2}\prod^\infty_{n=1}\bb{1-\frac {z^2}{n^2}}^{-1} = \frac{-\pi}{z\sin (\pi z)}
\ee
by Theorem \ref{thm:trigonometric_function_infinite_product}. Then we use proposition \ref{pro:gamma_function_product_z_z_plus_1}, $\Gamma(1-z) = -z\Gamma(-z)$ and get the required result.
\end{proof}


\begin{proposition}\label{pro:gamma_half_values}
\beast
\Gamma\bb{\frac{1}{2}} & = &\sqrt{\pi},\\
\Gamma\bb{\frac{1}{2}+n} & = & {(2n)! \over 4^n n!} \sqrt{\pi} = \frac{(2n-1)!!}{2^n}\sqrt{\pi} = \sqrt{\pi} \cdot \left[ {n-\frac{1}{2}\choose n} n! \right] \\
\Gamma\bb{\frac{1}{2}-n} & = & {(-4)^n n! \over (2n)!} \sqrt{\pi} = \frac{(-2)^n}{(2n-1)!!} \sqrt{\pi} = \sqrt{\pi} \left/ \left[ {-\frac{1}{2} \choose n} n! \right]\right.
\eeast%\be\Gamma\bb{\frac 12} = \sqrt{\pi}.\ee
\end{proposition}

\begin{proof}[\bf Proof]
Using Proposition \ref{pro:gamma_function_z_1_minus_z} with $z= \frac 12$, we have
\be
\bb{\Gamma\bb{\frac 12}}^{2} = \frac{\pi}{\sin (\pi/2)} = \pi \ \ra\ \Gamma\bb{\frac 12} = \sqrt{\pi}
\ee
since $\Gamma\bb{\frac 12}>0$ by Weierstrass canonical form.

For the other equations, we can simply apply Proposition \ref{pro:gamma_function_product_z_z_plus_1}.
\end{proof}


\begin{proposition}[multiplication theorem]
For any $z\in \C\bs \bra{0,-1,-2,-3,\dots}$ and $n\in \Z^+$,
\be
\Gamma(z)\Gamma\bb{z + \frac 1n}\Gamma\bb{z + \frac 2n}\dots \Gamma\bb{z + \frac {n-1}n} = (2\pi)^{\frac 12(n-1)}n^{\frac 12 - nz}\Gamma(nz).
\ee
\end{proposition}

\begin{remark}
The case in which $n=2$ was given by Legendre. That is,
\be
\Gamma(2z) = \frac{2^{2z-1}}{\sqrt{\pi}}\Gamma(z) \Gamma\bb{z+\frac 12}.
\ee
\end{remark}

\begin{proof}[\bf Proof]
Let
\be
f(z) = \frac{n^{nz}\Gamma(z)\Gamma\bb{z + \frac 1n}\Gamma\bb{z + \frac 2n}\dots \Gamma\bb{z + \frac {n-1}n} }{n\Gamma(nz)}.
\ee

Then by Euler formula (Proposition \ref{pro:gauss_limit_gamma_function})%\ref{thm:euler_formula_for_gamma_function})
\beast
f(z) & = & \frac{n^{nz} \prod^{n-1}_{r=0} \lim_{m\to \infty} \frac{1\cdot 2\cdot \dots \cdot (m-1)\cdot m^{z+r/n}}{\bb{z+\frac rn}\cdot \bb{z + \frac rn +1}\cdot \dots \cdot \bb{z+\frac rn +m-1}} }{n\lim_{m\to \infty} \frac{1\cdot 2\cdot \dots \cdot (mn-1)\cdot (mn)^{nz}}{nz\cdot (nz+1)\cdot \dots \cdot (nz+mn-1)} } = n^{nz-1}\lim_{m\to\infty} \frac{\bb{(m-1)!}^nm^{nz + \frac 12 (n-1)}n^{mn}}{(mn-1)!(mn)^{nz}} \\
& = & \lim_{m\to \infty} \frac{\bb{(m-1)!}^nm^{\frac 12 (n-1)}n^{mn-1}}{(mn-1)!}.
\eeast

It is evident from this last equation that $f(z)$ is independent of $z$. Thus $f(z)$ is equal to the value which it has when $z = \frac 1n$ and so
\be
f(z) = \frac{n^1\Gamma\bb{\frac 1n}\Gamma\bb{\frac 2n} \dots \Gamma\bb{\frac {n-1}n}\Gamma\bb{1}}{n\Gamma(1)} = \Gamma\bb{\frac 1n}\Gamma\bb{\frac 2n} \dots \Gamma\bb{\frac {n-1}n}.
\ee

Therefore, by Proposition \ref{pro:gamma_function_z_1_minus_z},
\be
f^2(z) = \prod^{n-1}_{k=1}\bb{\Gamma\bb{\frac kn}\Gamma\bb{\frac {n-k}n}} = \frac{\pi^{n-1}}{\sin\bb{\frac {\pi}n}\sin\bb{\frac {2\pi}n}\dots \sin\bb{\frac {(n-1)\pi}n}} = \frac{(2\pi)^{n-1}}{n}
\ee
by Proposition \ref{pro:trigonometric_function_multiangle_finite_product}. Since $f(1/n)$ is positive,
\be
f(z) = (2\pi)^{\frac 12(n-1)}n^{-\frac 12}
\ee
which implies the required result.
\end{proof}


%\begin{proposition}
%For $z\in \C$ and $\Re z\in \Z^+$, \be \Gamma(z)\Gamma(1-z)= \frac{\pi}{\sin(\pi z)}.\ee
%\end{proposition}

%\begin{proof}[\bf Proof]
%\footnote{proof needed.}
%\end{proof}


%\begin{proposition}
%For $z\in \C$ and $\Re z\in \Z^+$, \be \Gamma(2z) = \frac{2^{2z-1}}{\sqrt{\pi}}\Gamma(z)\Gamma\bb{z+\frac 12}.\ee
%\end{proposition}
%\begin{proof}[\bf Proof]
%\footnote{proof needed.}
%\end{proof}



%\subsection{Gamma function with postive real part}

\subsection{Gamma function as an infinite integral for positive real part}

%\begin{definition}[gamma function\index{gamma function}]\label{def:gamma_function_positive_real_part}
%The gamma function (represented by the capital Greek letter $\Gamma$) is an extension of the factorial function, with its argument shifted down by 1, to real and complex numbers. That is, if $n$ is a positive integer, $\Gamma(n) = (n-1)!$.

%The gamma function is defined for all complex numbers except the non-positive integers. For complex numbers with a positive real part ($\Re z >0$), it is defined via an improper integral that converges:

%\end{definition}

\begin{theorem}[infinite integral of gamma function for positive values]\label{thm:infinite_integral_of_gamma_function_for_positive_values}
When the real part of $z\in \C$ is positive ($\Re z >0$), we have
\be
\Gamma(z) = \int_0^\infty e^{-t} t^{z-1} dt .
\ee
\end{theorem}

\begin{remark}
It is also known as the Euler integral of the second kind (the Euler integral of the first kind defines the beta function).
\end{remark}

\begin{proof}[\bf Proof]%\footnote{proof needed.}
First, we can see that for $z\in \C$ such that $\Re z >0$,
\be
\Gamma_1(z) := \int^\infty_0 e^{-t} t^{z-1}dt \quad \text{is well-defined and an analytic function of $z$.}
\ee

This is direct result of Theorem \ref{thm:complex_exponential_function_f_integral_exists} as the function $f(t)= t^{z-1}$. That is,
\be
\abs{f(t)} = \abs{t^{z-1}} = \abs{e^{(z-1)\log t}} = \abs{t}^{\Re z -1} = \bb{t^{\Re z}}^{\frac{\Re z -1}{\Re z}} < \bb{\bb{\Re z}! e^t}^{\frac{\Re z -1}{\Re z}}  = \bb{(\Re z)!}^{\frac{\Re z -1}{\Re z}} e^{\bb{\frac{\Re z -1}{\Re z}}t}
\ee%for $t>1$. For $t<1$, we have that
with $1>  \frac{\Re z -1}{\Re z}$. %denote the real part of $z$ by $x$ with $x>0$. Then we

Now we define
\be
\Pi(z,n) := \int^n_0 \bb{1-\frac tn}^n t^{z-1} dt = n^z \int^1_0 (1-\tau)^n \tau^{z-1} d\tau.
\ee

It is easily shown by repeated integrations by parts\footnote{details needed.}, when $\Re z>0$ and $n$ is a positive integer,
\beast
\int^1_0 (1-\tau)^n \tau^{z-1} d\tau & = & \bsb{\frac 1z \tau^z (1-\tau)^n}^1_0 + \frac nz \int^1_0 (1-\tau)^{n-1}\tau^z d\tau \\
& = & \dots = \frac {n(n-1)\dots 1}{z(z+1)\dots (z+n-1)} \int^1_0 \tau^{z+n-1}d\tau.
\eeast

Therefore, we have
\be
\Pi(z,n) = \frac {n(n-1)\dots 1}{z(z+1)\dots (z+n-1)} n^z  \ \ra\ \Pi(z,n) \to \Gamma(z)
\ee
as $n\to \infty$ by Proposition \ref{pro:gauss_limit_gamma_function}. Consequently,
\be
\Gamma(z) = \lim_{n\to \infty}\int^n_0 \bb{1 - \frac tn}^n t^{z-1}dt.
\ee

Therefore,
\beast
\Gamma_1(z) - \Gamma(z) & = & \lim_{n\to \infty}\bsb{\int^n_0 \bb{e^{-t} - \bb{1 - \frac tn}^n}t^{z-1}dt + \int^\infty_n e^{-t}z^{z-1}dt} \\
& = & \lim_{n\to \infty} \int^n_0 \bb{e^{-t} - \bb{1 - \frac tn}^n}t^{z-1}dt \qquad\qquad  (*)
\eeast
since $\lim_{n\to\infty} \int^\infty_n e^{-t}t^{z-1}dt = 0$ ($\int^\infty_0 e^{-t}t^{z-1}dt$ converges). %To show that zero is the limit of the

Also, by Proposition \ref{pro:exponential_1_plus_x_inequalities} we have that
\be
\bb{1 + \frac tn}^{-n} \geq e^{-t} \geq \bb{1-\frac tn}^n.
\ee

Thus, we have
\be
0 \leq e^{-t} - \bb{1-\frac tn}^n = e^{-t}\bb{1-e^t\bb{1-\frac tn}^n} \leq e^{-t}\bb{1- \bb{1-\frac {t^2}{n^2}}^n}.
\ee

By Bernoulli's inequality (Theorem \ref{thm:bernoulli_inequality_one_plus_x_power_n}) we have
\be%Proposition \ref{pro:one_minus_x_power_n_greater_than_one_minus_nx}
\bb{1 - \frac{t^2}{n^2}}^n \geq 1 - n\frac{t^2}{n^2}\ \ra\ 1 - \bb{1 - \frac{t^2}{n^2}}^n \leq \frac {t^2}{n}\ \ra\ e^{-t} - \bb{1-\frac tn}^n \leq \frac{e^{-t}t^2}n.
\ee

From the inequalities, it follows at once that
\be
\abs{\int^n_0 \bb{ e^{-t} - \bb{1-\frac tn}^n }t^{z-1}dt } \leq \int^n_0 \frac{e^{-t}t^{\Re z+1}}{n} dt < \frac 1n\int^\infty_0 e^{-t}t^{\Re z + 1}dt \to 0
\ee
as $n\to \infty$. Hence, $\Gamma_1(z) = \Gamma(z)$ since ($*$) converges.
\end{proof}

\begin{remark}
This definition of gamma function is a component in various probability-distribution functions, and as such it is applicable in the fields of probability and statistics, as well as combinatorics.
\end{remark}%This integral function is extended by analytic continuation to all complex numbers except the non-positive integers (where the function has simple poles), yielding the meromorphic function we call the gamma function.

\begin{proposition}
For $z\in \C$ and $\Re z\in \Z^+$ \be \frac 1{\Gamma(z)} \approx z\quad \text{as }z\to 0.\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}\label{pro:gamma_function_positive_real_part_half}
For $n\in \N$,
\beast
\Gamma\bb{\frac{1}{2}} & = &\sqrt{\pi},\\
\Gamma\bb{\frac{1}{2}+n} & = & {(2n)! \over 4^n n!} \sqrt{\pi} = \frac{(2n-1)!!}{2^n}\sqrt{\pi} = \sqrt{\pi} \cdot \left[ {n-\frac{1}{2}\choose n} n! \right] .%\Gamma\bb{\frac{1}{2}-n} & = & {(-4)^n n! \over (2n)!} \sqrt{\pi} = \frac{(-2)^n}{(2n-1)!!} \sqrt{\pi} = \sqrt{\pi} \left/ \left[ {-\frac{1}{2} \choose n} n! \right]\right.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
By definition of gamma function,
\be
\Gamma\bb{\frac 12} =  \int_0^\infty \frac 1{\sqrt{t}}e^{-t}  dt = 2\int_0^\infty e^{-t}  d\sqrt{t}  = 2\int_0^\infty e^{-t^2}  dt = \sqrt{\pi} \erf\bb{\infty} = \sqrt{\pi}
\ee
by definition of error function (Definition \ref{def:error_function}).

By induction, it is easy to see that $\Gamma\bb{\frac 12}$ satisfies the other equation when $n = 0$. We assume that for $n\geq 1$,
\be
\Gamma\bb{\frac{1}{2}+n-1} = {(2n-2)! \over 4^{n-1} (n-1)!} \sqrt{\pi}.
\ee

Then
\beast
\Gamma\bb{\frac{1}{2}+n} & = & \int_0^\infty e^{-t} t^{n-\frac 12}  dt =  \left. t^{n-\frac 12} e^{-t}\right|^0_\infty + \int_0^\infty e^{-t}  d t^{n-\frac 12} =  \bb{n-\frac 12} \int_0^\infty e^{-t}  t^{n-\frac 32}dt \\
& = & \frac 12\bb{2n-1} \Gamma\bb{\frac{1}{2}+n-1} = \frac {2n(2n-1)}{4n} {(2n-2)! \over 4^{n-1} (n-1)!} \sqrt{\pi} = {(2n)! \over 4^n n!} \sqrt{\pi}
\eeast
as required. %Similarly, we get $\Gamma\bb{\frac{1}{2}-n}$.
\end{proof}

\begin{proposition}
For $z\in \C$ with $\Re z\in \Z^+$ and $a>0$, \be \Gamma(az+b) \approx \sqrt{2\pi} e^{-az} (az)^{az+b-1/2}\quad\text{as }z\to \infty.\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\subsection{Gamma function as an infinite integral for negative real part}

\begin{theorem}[inifinite integral of gamma function for negative values]
For $z\in \C\bs \bra{0,-1,-2,\dots}$ with $\Re(z)<-1$, we have
\be
\Gamma(z) = \int^\infty_0 t^{z-1}\bb{e^{-t} - 1 + t - \frac{t^2}{2!} -+ \dots +(-1)^{k+1} \frac{t^k}{k!}}dt
\ee
where $k = \floor{-\Re(z)}$.
\end{theorem}

\begin{remark}
This proof is proposed by Cauchy\footnote{Exercises de Math. II. (1827), pp. 91-92.} and Saalsh\"utz\footnote{Zeitschrift f\"ur Math. und Phyz. XXXII. (1887), XXXIII (1888).}
\end{remark}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\subsection{Hankel's expression of gamma funciton as a contour integral}

\begin{theorem}[Hankel's formula]\label{thm:hankel_formula_gamma_function}
Let $z\in \C\bs \Z$ and $C$ be a contour which starts from a large enough point $x$ on real axis, encircles the orgin once counter-clockwise and returns to $x$. Then
\be
\Gamma(z) = -\frac 1{2i\sin (\pi z)} \int_C (-t)^{z-1} e^{-t}dt.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{corollary}
Let $z\in \C\bs \Z$ and $C$ be a contour which starts from a large enough point $x$ on real axis, encircles the orgin once counter-clockwise and returns to $x$. Then
\be
\frac 1{\Gamma(z)} = \frac i{2\pi} \int_C (-t)^{-z} e^{-t} dt.
\ee
\end{corollary}

\begin{proof}[\bf Proof]
Direct result of applying Theorem \ref{thm:hankel_formula_gamma_function} and Proposition \ref{pro:gamma_function_z_1_minus_z}.
\end{proof}

\subsection{Digamma function}

\begin{definition}[digamma function]
The digamma function is defined by
\be
\Psi(z) = \frac{d}{dz}\log \bb{\Gamma(z)} = \frac{\Gamma'(z)}{\Gamma(z)}
\ee
where $\Gamma(\cdot)$ is the gamma function.
\end{definition}


\begin{proposition}\label{pro:digamma_function_properties}
Let $\Psi(z)$ be the digamma function. Then for $z\in \C\bs\bra{0,-1,-2,\dots}$ and $n=0,1,2,\dots$,
\beast
\text{(i)}\ \Psi(z+1) = \frac 1z + \Psi(z) ,\qquad
\text{(ii)}\ \Psi(n+1) = -\gamma + \sum^n_{k=1}\frac 1k ,\qquad
\text{(iii)} \ \Psi(z) = -\gamma - \sum^\infty_{k=0}\bb{\frac 1{z+k}-\frac 1{k+1} }.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed. see notes psifun\_11.pdf}
\end{proof}

\subsection{Derivatives of gamma function}

\begin{proposition}\label{pro:derivatives_of_gamma_1234}
For $z\in \C\bs\bra{0,-1,-2,\dots}$, we have
\be
\text{(i)} \ \Gamma'(z) = \Gamma(z) \Psi(z) = -\Gamma(z) \bb{\gamma + \sum^\infty_{k=0}\bb{\frac 1{z+k}-\frac 1{k+1} }},
\ee

\be
\text{(ii)} \ \Gamma''(z) = \frac{\bb{\Gamma'(z)}^2}{\Gamma(z)} + \Gamma(z) \sum^\infty_{k=0}\frac 1{(z+k)^2}  ,
\ee

\be
\text{(iii)} \ \Gamma'''(z) = \frac{\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^2} + 3\Gamma'(z)\sum^\infty_{k=0}\frac 1{(z+k)^2} - 2\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} ,
\ee

\be
\text{(iv)}\ \Gamma''''(z) = \frac{\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + \frac{6\bb{\Gamma'(z)}^2}{\Gamma(z)}\sum^\infty_{k=0}\frac 1{(z+k)^2}  + 3\Gamma(z)\bb{\sum^\infty_{k=0}\frac 1{(z+k)^2} }^2 - 8\Gamma'(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} + 6\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^4}\nonumber
\ee
\end{proposition}

\begin{remark}
In particular, if $z=1$ we have
\be
\Gamma'(1) = -\gamma,\quad \Gamma''(1) = \gamma^2 + \frac {\pi^2}6,\quad \Gamma'''(1) = -\gamma^3 - \frac{\gamma\pi^2}2 - 2\zeta(3),\quad \Gamma''''(1) = \gamma^4 + \gamma^2 \pi^2 + 8\gamma \zeta(3) + \frac{3\pi^4}{20}.
\ee
\end{remark}

\begin{proof}[\bf Proof]
Since $\Psi(z) = -\gamma - \sum^\infty_{k=0}\bb{\frac 1{z+k}-\frac 1{k+1} }$ for $z\in \C\bs\bra{0,-1,-2,\dots}$ (see Proposition \ref{pro:digamma_function_properties}), we can get (i). Then take the differentiation of $\Psi(z)$ and get
\be
\sum^\infty_{k=0}\frac 1{(z+k)^2} = \bb{\frac{\Gamma'(z)}{\Gamma(z)}}' = \frac{\Gamma''(z)\Gamma(z) - \bb{\Gamma'(z)}^2}{\bb{\Gamma(z)}^2} \ \ra\ \Gamma''(z) = \frac{\bb{\Gamma'(z)}^2}{\Gamma(z)} + \Gamma(z) \sum^\infty_{k=0}\frac 1{(z+k)^2}
\ee

Taking the differentiation again, we have
\beast
-2\sum^\infty_{k=0}\frac 1{(z+k)^3} & = & \bb{\frac{\Gamma'(z)}{\Gamma(z)}}'' = \bb{\frac{\Gamma''(z)\Gamma(z) - \bb{\Gamma'(z)}^2}{\bb{\Gamma(z)}^2} }' \\
& = & \frac{\Gamma'''(z)\Gamma(z) - \Gamma''(z)\Gamma'(z)}{\bb{\Gamma(z)}^2} - \frac{2\Gamma''(z)\Gamma'(z)\Gamma(z) - 2\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^3} \\
& = & \frac{\Gamma'''(z)}{\Gamma(z)} - \frac{3\Gamma''(z)\Gamma'(z)}{\bb{\Gamma(z)}^2} +\frac{2\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^3}.
\eeast

Therefore, the third derivative is given by
\beast
\Gamma'''(z) & = & \frac{3\Gamma''(z)\Gamma'(z)}{\Gamma(z)} - \frac{2\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^2} - 2\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} \\
& = & \frac{\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^2} + 3\Gamma'(z)\sum^\infty_{k=0}\frac 1{(z+k)^2} - 2\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} .
\eeast

Furthermore, we take the differentiation again,
\beast
6\sum^\infty_{k=0}\frac 1{(z+k)^4} & = & \bb{\frac{\Gamma'(z)}{\Gamma(z)}}''' = \bb{\frac{\Gamma''(z)\Gamma(z) - \bb{\Gamma'(z)}^2}{\bb{\Gamma(z)}^2} }'' =\bb{ \frac{\Gamma'''(z)}{\Gamma(z)} - \frac{3\Gamma''(z)\Gamma'(z)}{\bb{\Gamma(z)}^2} +\frac{2\bb{\Gamma'(z)}^3}{\bb{\Gamma(z)}^3}}'\\
& = & \frac{\Gamma''''(z)\Gamma(z) - \Gamma'''(z)\Gamma'(z)}{\bb{\Gamma(z)}^2} - \frac{3\Gamma'''(z)\Gamma'(z)\bb{\Gamma(z)}^2 + 3\bb{\Gamma''(z)}^2\bb{\Gamma(z)}^2 - 6\Gamma''(z)\bb{\Gamma'(z)}^2\Gamma(z)}{\bb{\Gamma(z)}^4} \\
& & \qquad\qquad + \frac{6\Gamma''(z)\bb{\Gamma'(z)}^2\bb{\Gamma(z)}^3 - 6\bb{\Gamma'(z)}^4\bb{\Gamma(z)}^2}{\bb{\Gamma(z)}^6} \\
& = & \frac{\Gamma''''(z)}{\Gamma(z)}  - \frac{4\Gamma'''(z)\Gamma'(z)}{\bb{\Gamma(z)}^2} - \frac{3\bb{\Gamma''(z)}^2}{\bb{\Gamma(z)}^2} + \frac{12\Gamma''(z)\bb{\Gamma'(z)}^2}{\bb{\Gamma(z)}^3} - \frac{6\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^4} .
\eeast

Therefore, the fourth derivative is given by
\beast
\Gamma''''(z) & = & \frac{4\Gamma'''(z)\Gamma'(z)}{\Gamma(z)} + \frac{3\bb{\Gamma''(z)}^2}{\Gamma(z)} - \frac{12\Gamma''(z)\bb{\Gamma'(z)}^2}{\bb{\Gamma(z)}^2} + \frac{6\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + 6\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^4} \\
& = & \frac{4\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + \frac{12\bb{\Gamma'(z)}^2}{\Gamma(z)}\sum^\infty_{k=0}\frac 1{(z+k)^2} - 8\Gamma'(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} + \frac{3\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + \frac{6\bb{\Gamma'(z)}^2}{\Gamma(z)}\sum^\infty_{k=0}\frac 1{(z+k)^2} \\
& & \qquad + 3\Gamma(z)\bb{\sum^\infty_{k=0}\frac 1{(z+k)^2} }^2 - \frac{12\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} - \frac{12\bb{\Gamma'(z)}^2}{\Gamma(z)}\sum^\infty_{k=0}\frac 1{(z+k)^2}  + \frac{6\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + 6\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^4} \\
& = & \frac{\bb{\Gamma'(z)}^4}{\bb{\Gamma(z)}^3} + \frac{6\bb{\Gamma'(z)}^2}{\Gamma(z)}\sum^\infty_{k=0}\frac 1{(z+k)^2}  + 3\Gamma(z)\bb{\sum^\infty_{k=0}\frac 1{(z+k)^2} }^2 - 8\Gamma'(z)\sum^\infty_{k=0}\frac 1{(z+k)^3} + 6\Gamma(z)\sum^\infty_{k=0}\frac 1{(z+k)^4}.
\eeast
\end{proof}

\begin{proposition}\label{pro:derivatives_of_gamma_function_integral}
For $\Re(z)>0$, the $n$th derivative of the gamma function is\footnote{see wiki, gamma function}
\be
\frac{d^n}{dz^n}\Gamma(z) = \int^\infty_0 x^{z-1} e^{-x}\bb{\log x}^n dx.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed. see wiki, gamma function. This can be derived by differentiating the integral form of the gamma function with respect to x, and using the technique of differentiation under the integral sign.)}
\end{proof}



\subsection{Pochhammer symbol}

\begin{definition}[Pochhammer symbol\index{Pochhammer symbol}]\label{def:pochhammer_symbol}
The Pochhammer symbol $(\cdot)_n$ is defined by
\be
(z)_n := \frac{\Gamma(z+n)}{\Gamma(z)} = z(z+1)\dots (z+n-1),\qquad z\notin \Z^- = \bra{\dots,-3,-2,-1}.
\ee

In closed form $(z)_n$ can be written as
\be
(z)_n = \sum^n_{k=0}(-1)^{n-k} s(n,k)z^k
\ee
where $s(n,k)$ is a Stirling number of the first kind\footnote{definition needed.}.
\end{definition}

\begin{remark}
\beast
(z)_0 & = & 1, \\
(z)_1 & = & z, \\
(z)_2 & = & z^2 + z, \\
(z)_3 & = & z^3 + 3z^2 + 2z, \\
(z)_4 & = & z^4 + 6z^3 + 11z^2 + 6z.
\eeast

\be
(1)_n = n!,\quad \bb{\frac 12}_n = \frac{(2n-1)!!}{2^n}.
\ee
\end{remark}

\footnote{add more properties of Pochhammer symbol. See wolfram mathworld}




\section{Beta function}

\begin{definition}[beta function\index{beta function}]\label{def:beta_function}
In mathematics, the beta function, also called the Euler integral of the first kind, is a special function defined by
\be
B(a,b) = \int_0^1 x^{a-1}(1-x)^{b-1} dx,\qquad \Re a, \Re b > 0.
\ee
%The beta function was studied by Euler and Legendre and was given its name by Jacques Binet; its symbol  is a Greek capital  rather than the similar Latin capital B.
\end{definition}

\begin{remark}
$B(a,b)$ is well-defined as the integrand is non-negative.
\end{remark}

\begin{proposition}\label{pro:beta_gamma_relation}
\be
B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First, write the product of two factorials as
\be
\Gamma(a)\Gamma(b) = \int_0^\infty e^{-u} u^{a-1}du \int_0^\infty e^{-v} v^{b-1}dv =\int_0^\infty\int_0^\infty\ e^{-u-v} u^{a-1}v^{b-1}du dv.
\ee

Changing variables by putting $u=zt$, $v=z(1-t)$ shows that this is
\be
\int_{0}^\infty\int_{0}^1 e^{-z} (zt)^{a-1}(z(1-t))^{b-1}z dtdz =\int_{0}^\infty \ e^{-z}z^{a+b-1} \,dz\int_{0}^1t^{a-1}(1-t)^{b-1}dt.
\ee
Hence $\Gamma(a)\Gamma(b)=\Gamma(a+b)B(a,b)$.
\end{proof}

%\section{Bessel function}
\subsection{Incomplete beta function}

Incomplete beta function is first given by Pearson's (1934) (see \cite{Pearson_1934}).

\begin{definition}[incomplete beta function\index{beta function!incomplete}]\label{def:incomplete_beta_function}
The incomplete beta function, a generalization of the beta function, is defined as
\be
B_x(a,b) = \int_0^x t^{a-1}(1-t)^{b-1} dt,\qquad \Re a, \Re b > 0.
\ee
\end{definition}

\begin{definition}[regularized incomplete beta function\index{regularized incomplete beta function}]\label{def:regularized_incomplete_beta_function}
The regularized incomplete beta function (or regularized beta function for short) is defined in terms of the incomplete beta function and the complete beta function:
\be
I_x(a,b) = \frac{B_x(a,b)}{B(a,b)}.
\ee
\end{definition}

\begin{remark}%\footnote{need to check}
The regularized incomplete beta function is the cumulative distribution function of the Beta distribution, and is related to the cumulative distribution function of a random variable $X$ from a binomial distribution, where
the "probability of success" is p and the sample size is $n$:
\be
F(k;n,p) = \pro(X \le k) = I_{1-p}(n-k, k+1) = 1 - I_p(k+1,n-k).
\ee
%Working out the integral (one can use integration by parts) for integer values of $a$ and $b$, one finds:
%\be
%I_x(a,b) = \sum_{j=a}^{a+b-1} \binom{a+b-1}{j} x^j (1-x)^{a+b-1-j}.
%\ee
\end{remark}

\begin{lemma}\label{lem:incomplete_beta_function_integral}
For $p\in (0,1)$ and $n\in \Z^+$,
\be
\sum^n_{k=i}\binom{n}{k} p^k(1-p)^{n-k} = \int^p_0 \frac{n!}{(i-1)!(n-i)!} t^{i-1} (1-t)^{n-i}dt.
\ee
\end{lemma}

\begin{proof}[\bf Proof]
This can be proved by repeated integration by parts,
\beast
& & \int^p_0 \frac{n!}{(i-1)!(n-i)!} t^{i-1} (1-t)^{n-i}dt \\
& = & \int^p_0 \frac{n!}{i!(n-i)!}  (1-t)^{n-i}dt^i = \frac{n!}{i!(n-i)!} p^i(1-p)^{n-i} + \int^p_0 \frac{n!}{i!(n-i-1)!}  t^i (1-t)^{n-i-1} dt = \dots \\
& = & \frac{n!}{i!(n-i)!} p^i(1-p)^{n-i} + \frac{n!}{(i+1)!(n-i-1)!} p^{i+1}(1-p)^{n-i-1} + \dots + \int^p_0 \frac{n!}{(n-1)!}  t^{n-1} dt \\
& = & \frac{n!}{i!(n-i)!} p^i(1-p)^{n-i} + \frac{n!}{(i+1)!(n-i-1)!} p^{i+1}(1-p)^{n-i-1} + \dots + p^n \\
& = & \sum^n_{k=i}\binom{n}{k} p^k(1-p)^{n-k}.
\eeast
\end{proof}

\begin{proposition}\label{pro:regularized_incomplete_beta_function}
\be
\text{(i)}\ I_0(a,b) = 0,\quad \text{(ii)} \ I_1(a,b) = 1,\quad \quad \text{(ii)} \ I_x(a,1) = x^a,\quad \text{(iv)} \ I_x(1,b) = 1-(1-x)^b, \nonumber
\ee
\be
\text{(v)}\ I_x(a,b) = 1 - I_{1-x}(b,a), \quad \text{(vi)}\ I_x(a+1,b) = I_x(a,b)-\frac{x^a(1-x)^b}{a B(a,b)},\quad \text{(vii)}\ I_x(a,b+1) = I_x(a,b)+\frac{x^a(1-x)^b}{b B(a,b)}.\nonumber
\ee
\end{proposition}

\begin{proof}[\bf Proof]
(i), (ii) and (iii) are obvious. For (iv), we have $\Re a,\Re b>0$,%\footnote{need to check (iv)}
\beast
I_x(a+1,b) & = & \frac{B_x(a+1,b)}{B(a+1,b)} = \frac{\Gamma(a+b+1)}{\Gamma(a+1)\Gamma(b)}\int_0^x t^{a}(1-t)^{b-1} dt = - \frac{(a+b)\Gamma(a+b)}{ab\Gamma(a)\Gamma(b)}\int_0^x t^{a}d(1-t)^{b}\qquad \text{(Proposition \ref{pro:gamma_function_induction})}\\
& = & \frac{(a+b)}{ab B(a,b)}\bb{\int_0^x (1-t)^{b} dt^a -x^{a}(1-x)^{b}} = \frac{(a+b)}{b B(a,b)}\int_0^x t^{a-1}(1-t)^{b} dt - \frac{a+b}{ab B(a,b)} x^{a}(1-x)^{b}\\
& = & \frac{(a+b)}{b B(a,b)}\int_0^x t^{a-1}(1-t)^{b-1} dt - \frac{(a+b)}{b B(a,b)}\int_0^x t^{a}(1-t)^{b} dt - \frac{a+b}{ab B(a,b)} x^{a}(1-x)^{b}\\
& = & \frac{(a+b)}{b} I_x (a,b) - \frac{a}{b }I_x(a+1,b) - \frac{a+b}{ab B(a,b)} x^{a}(1-x)^{b}
\eeast

Rebalancing the equation, we have the required result.
\end{proof}


\section{Binomial Coefficients and Binomial Series}

\subsection{Binomial coefficients}

%\subsection{Binomial coefficients}

\begin{definition}[binomial coefficients\index{binomial coefficients!positive integers}]\label{def:binomial_coefficients}
Given two positive integers $m\geq n>0$, the binomial coefficient is defined to be
\be
\binom{m}{n} =\frac{m!}{n!(m-n)!}.
\ee
\end{definition}

%Explicitly, for $z\in \C$,
%\be
%(1+z)^m = \sum^m_{n=1} \binom{m}{n} z^n.
%\ee

\begin{lemma}\label{lem:prime_power_divides_factorial}
Let $p$ be a prime and $n$ be a positive integer. The largest $a$ such that $p^a$ divides $n!$ can be expressed as
\be
a = \sum^\infty_{k=1} \floor{\frac{n}{p^k}}.
\ee
\end{lemma}

\begin{proof}[\bf Proof]
For each $k\geq 0$, let $a_k$ be the size of the set
\be
A_k := \bra{m\in \Z: 1\leq m\leq n, p^k\mid m, p^{k+1}\nmid m}.
\ee

Then each number in the $A_k$ has exact power $k$ dividing $n!$. Therefore, it is easy to see that $A_k \cap A_r = \emptyset$ if $k\neq r$. So
\be
a = \sum^\infty_{k=0} ka_k,\qquad \text{with }a_k = \floor{\frac{n}{p^k}} - \floor{\frac{n}{p^{k+1}}}.
\ee

So
\be
a = \sum^\infty_{k=0} k\bb{\floor{\frac{n}{p^k}} - \floor{\frac{n}{p^{k+1}}}} = \sum^\infty_{k=0} (k+1)\floor{\frac{n}{p^{k+1}}} -\sum^\infty_{k=0} k\floor{\frac{n}{p^{k+1}}}= \sum^\infty_{k=0} \floor{\frac{n}{p^{k+1}}} =  \sum^\infty_{k=1} \floor{\frac{n}{p^k}}.
\ee
\end{proof}

\begin{theorem}
For all $m\geq n>0$, $\binom{m}{n}$ is a positive integer.
\end{theorem}

\begin{proof}[\bf Proof]
Let $p$ be a prime number. If $p\mid n!(m-n)!$, then $p\mid n!$ or $p\mid (m-n!)$. Since $n,m-n<m$, we have $p\mid m!$. By Lemma \ref{lem:prime_power_divides_factorial}, if $a_i, i=1,2,3$ are the largest integers such that
\be
p^{a_1} \mid n!,\quad p^{a_2} \mid (m-n)!,\quad p^{a_3} \mid m!,
\ee
then
\be
a_1 = \sum^\infty_{k=1} \floor{\frac{n}{p^k}},\quad a_2 = \sum^\infty_{k=1} \floor{\frac{m-n}{p^k}},\quad ,a_3 = \sum^\infty_{k=1} \floor{\frac{m}{p^k}}.
\ee

For each $k\geq 0$, we have
\be
\floor{\frac{n}{p^k}} + \floor{\frac{m-n}{p^k}} \leq \floor{\frac{m}{p^k}}
\ee
and so $a_1 + a_2 \leq a_3$. This shows that if $p^k\mid n!(n-m)!$ then $p^k\mid m!$ for any prime $p$ and so by fundamental theorem of arithmetic (Theorem \ref{thm:fundamental_theorem_arithmetic}), $\binom{m}{n}$ is an integer.
\end{proof}


\subsection{Binomial theorem}


\begin{theorem}[Pascal's rule]\label{thm:Pascal_rule_binomial_coefficients}
For $1\leq k\leq n$,
\be
\binom{n-1}{k} + \binom{n-1}{k-1} = \binom{n}{k}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
By definition of binomial coefficients,
\beast
\binom{n-1}{k} + \binom{n-1}{k-1}  & = & \frac{\bb{n-1}!}{k!(n-k-1)!} + \frac{\bb{n-1}!}{\bb{k-1}!(n-k)!} = \frac{n!}{k!(n-k)!} \frac{n-k}{n}+ \frac{n!}{k!(n-k)!}\frac{k}{n} \\
& = & \frac{n!}{k!(n-k)!} = \binom{n}{k}.
\eeast
\end{proof}

\begin{theorem}[binomial theorem]\label{thm:binomial_non_negative_integer_power}
Let $x,y\in \C$ and $n\in \N$. Then
\be
(x+y)^n = \sum^n_{k=0} \binom{n}{k}x^ky^{n-k}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
We prove this theorem with inductive method. For $n=0$,
\be
(x+y)^0 = 1 = \binom{0}{0}x^0y^0 = \sum^n_{k=0} \binom{n}{k}x^k y^{n-k}.
\ee

For $n=1$, we have
\be
(x+y)^1 = x+y = \binom{1}{1}x^1y^0 + \binom{1}{0}x^0y^1 = \sum^n_{k=0} \binom{n}{k}x^k y^{n-k}.
\ee

Now let the equation hold for $n$, that is
\be
(x+y)^n = \sum^n_{k=0} \binom{n}{k}x^ky^{n-k}.
\ee

Then by Pascal's rule (Theorem \ref{thm:Pascal_rule_binomial_coefficients})
\beast
(x+y)^{n+1} & = & (x+y)\sum^n_{k=0} \binom{n}{k}x^ky^{n-k} = \sum^n_{k=0} \binom{n}{k} \bb{x^{k+1}y^{n-k} + x^k y^{n-k+1}} \\
& = & \sum^{n+1}_{k=1} \binom{n}{k-1} x^{k}y^{n+1-k} + \sum^n_{k=0} \binom{n}{k} x^{k}y^{n+1-k} = x^{n+1} + \sum^n_{k=1} \bb{\binom{n}{k-1} + \binom{n}{k}}x^{k}y^{n-k+1}  + y^{n+1}\\
& = & \binom{n+1}{n+1}x^{n+1} + \sum^n_{k=1} \binom{n+1}{k}x^{k}y^{n-k+1}  + \binom{n+1}{0} y^{n+1} = \sum^{n+1}_{k=0} \binom{n+1}{k}x^ky^{n+1-k},
\eeast
as required.
\end{proof}

\subsection{Properties of binomial coefficients}


\begin{lemma}\label{lem:binomial_inequality}
For $r,n\in \Z^+$,
\be
\binom{n}{r} \leq n(n-1)\binom{n-2}{r-2},\quad 2\leq r\leq n.
\ee
\end{lemma}

\begin{proof}[\bf Proof]
\be
\frac{\binom{n}{r}}{\binom{n-2}{r-2}} = \frac{n!}{r!(n-r)!}\cdot \frac{(r-2)!(n-r)!}{(n-2)!} = \frac{n(n-1)}{r(r-1)} \leq n(n-1).
\ee
\end{proof}

%\begin{lemma}
%If $\alpha$ is a non-negative integer $n$, then the $(n + 1)$th term and all later terms in the series are 0, since each contains a factor $(n - n)$; thus in this case the series is finite and gives the algebraic binomial formula.

%The following variant holds for arbitrary complex $\beta$, but is especially useful for handling negative integer exponents in (*) in Definition \ref{def:binomial_series}:
%\be
%\frac{1}{(1-z)^{\beta+1}} = \sum_{k=0}^{\infty}{k+\beta \choose k}z^k.
%\ee
%\end{lemma}

%To prove it, substitute x = z in (1) and apply a binomial coefficient identity.
%\begin{proof}[\bf Proof]
%\footnote{need proof.}
%\end{proof}

%\section{Partial sums}



\begin{proposition}\label{pro:binomial_double_choice}
\be
\sum^n_{k=0}\binom{k}{m} \binom{n}{k} = \binom{n}{m} 2^{n-m}.
\ee
\end{proposition}

\begin{remark}
In particular,
\beast
\sum^n_{k=0}\binom{n}{k} = 2^n,\qquad \sum^n_{k=0}k \binom{n}{k} & = & n2^{n-1},\qquad \sum^n_{k=0}k(k-1) \binom{n}{k} = n(n-1)2^{n-1}.
\eeast
\end{remark}

\begin{proof}[\bf Proof]
\beast
\sum^n_{k=0} \binom{k}{m}\binom{n}{k} & = & \sum^n_{k=0} \frac{k!}{(k-m)!m!}\frac{n!}{k!(n-k)!} = \frac{n!}{m!(n-m)!} \sum^n_{k=0} \frac{(n-m)!}{(k-m)!(n-k)!} \\
& = & \frac{n!}{m!(n-m)!} \sum^n_{k=0} \frac{(n-m)!}{(k-m)!(n-m-(k-m))!} = \binom{n}{m} \sum^{n-m}_{k=0} \frac{(n-m)!}{k!(n-m-k)!} = \binom{n}{m} 2^{n-m}.
\eeast
\end{proof}

\begin{proposition}
\be
\sum^{\floor{n/2}}_{k=0} \binom{n}{2k}  = \sum^{\floor{(n-1)/2}}_{k=0} \binom{n}{2k+1} = 2^{n-1}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
By definition, we have
\beast
2 ^n & = & (1+1)^n = \sum^n_{k=0} \binom{n}{k} = \sum^{\floor{n/2}}_{k=0}\binom{n}{2k} + \sum^{\floor{(n-1)/2}}_{k=0}\binom{n}{2k+1}, \\
0 & = & (1-1)^n = \sum^n_{k=0} (-1)^k\binom{n}{k} = \sum^{\floor{n/2}}_{k=0}\binom{n}{2k} - \sum^{\floor{(n-1)/2}}_{k=0}\binom{n}{2k+1},
\eeast
which implies that
\be
2^n = 2\sum^{\floor{n/2}}_{k=0}\binom{n}{2k} = 2\sum^{\floor{(n-1)/2}}_{k=0}\binom{n}{2k+1}
\ee
as required.
\end{proof}

\begin{example}
For $n=4$,
\beast
\sum^n_{k=0} \binom{n}{2k} & = & \binom{4}{0} + \binom{4}{2} + \binom{4}{4} = 1 + 6 + 1 = 8 = 2^3 = 2^{n-1}, \\
\sum^n_{k=0} \binom{n}{2k+1} & = & \binom{4}{1} + \binom{4}{3} = 4 + 4 = 8 = 2^3 = 2^{n-1}.
\eeast

For $n=5$,
\beast
\sum^n_{k=0} \binom{n}{2k} & = & \binom{5}{0} + \binom{5}{2} + \binom{5}{4} = 1 + 10 + 5 = 16 = 2^4 = 2^{n-1}, \\
\sum^n_{k=0} \binom{n}{2k+1} & = & \binom{5}{1} + \binom{5}{3} + \binom{5}{5} = 5 + 10 + 1 = 16 = 2^4 = 2^{n-1}.
\eeast
\end{example}




\subsection{Binomial series}

\begin{definition}[binomial series]\label{def:binomial_series}
The binomial series is the Taylor series at $x = 0$ of the function $f(z)$ (for $z\in \C$) given by $f(z) = (1 + z)^\alpha$, where $\alpha \in \C$ is an arbitrary complex number. Explicitly,
\be
(1 + z)^\alpha =\sum_{k=0}^{\infty}  \binom{\alpha}{k}  z^k  = 1 + \alpha z + \frac{\alpha(\alpha-1)}{2!} z^2 + \cdots, \quad(*)
\ee
and the binomial series\index{binomial series} is the power series on the right hand side, expressed in terms of the (generalized) binomial coefficients
\be
\binom{\alpha}{k} := \frac{\alpha (\alpha-1) (\alpha-2) \cdots (\alpha-k+1)}{k!}.
\ee
\end{definition}

\begin{remark}
For any complex number $\alpha$,
\be
\binom{\alpha}{0} = 1,\qquad \binom{\alpha}{k+1} = \binom{\alpha}{k} \frac{\alpha - k}{k+1}.
\ee
\end{remark}



\begin{proposition}\label{pro:binomial_addition_split}
For any $\alpha \in \C$ and $k\in \N$,
\be
\binom{\alpha +1}{k+1} = \binom{\alpha}{k+1} + \binom{\alpha}{k}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\beast
\binom{\alpha}{k+1} + \binom{\alpha}{k} & = & \frac{\alpha!}{(k+1)!(\alpha-k-1)!} + \frac{\alpha!}{k!(\alpha-k)!} = \frac{(\alpha+1)!}{(k+1)!(\alpha-k)!} \frac{\alpha-k}{\alpha+1} + \frac{(\alpha+1)!}{(k+1)!(\alpha-k)!}\frac{k+1}{\alpha+1} \\
& = &  \frac{(\alpha+1)!}{(k+1)!(\alpha-k)!} \bb{\frac{\alpha-k}{\alpha+1} + \frac{k+1}{\alpha+1}} = \frac{(\alpha+1)!}{(k+1)!(\alpha-k)!} = \binom{\alpha+1}{k+1}.
\eeast
\end{proof}

\subsection{Convergence of binomial series}


\begin{lemma}[Landau notation]\label{lem:binomial_coefficients_landau_notation}
Let $\alpha \in \C \bs\bra{0,1,2,\dots}$. Then binomial coefficient
\be
\binom{\alpha}{k} = \frac{(-1)^k}{\Gamma(-\alpha) k^{1+\alpha}}\bb{1 + o(1)},\quad \text{as }k\to \infty.
\ee
\end{lemma}

\begin{proof}[\bf Proof]
By Proposition \ref{pro:gauss_limit_gamma_function}, we have
\beast
\Gamma(-\alpha) & = & \lim_{k\to \infty} \frac{k!k^{-\alpha}}{(-\alpha)(-\alpha + 1)\dots (-\alpha + k) } =  \lim_{k\to \infty} \frac{k!k^{-1-\alpha}}{(-\alpha)(-\alpha + 1)\dots (-\alpha + k-1) }  \\
& = & \lim_{k\to \infty} \frac{k!k^{-1-\alpha}}{(-1)^{k}\alpha(\alpha - 1)\dots (\alpha - k+1)} = \lim_{k\to \infty} \frac{(-1)^{k} }{ \binom{\alpha}{k} k^{1+\alpha}}
\eeast
as required.
\end{proof}

Note that the radius of convergence $R$ is proposed by the following theorem.

\begin{theorem}\label{thm:convergence_binomial_series}
Consider the binomial series for $\alpha\in \C$ %\bs\bra{0,1,2,\dot} = \C\bs\N$\footnote{Otherwise, the coefficients will be zero eventually and thus the series is finite.},
\be
\sum^\infty_{k=0} \binom{\alpha}{k}z^k.
\ee

Its radius of convergence is $R=1$. In particular,
\ben
\item [(i)] If $\abs{z}<1$, the series converges absolutely for all complex number $\alpha$.
\item [(ii)] If $\abs{z}>1$, the series only converges for non-negative integer $\alpha$.
\item [(iii)] Consider $\abs{z} =1$.
\ben
\item [(a)] The series converges absolutely if and only if either $\Re(\alpha)>0$ or $\alpha =0$.
\item [(b)] If $z\neq -1$, the series converges if and only if $\Re(\alpha) > -1$.
\een
\een
\end{theorem}

\begin{proof}[\bf Proof]
First, if $\alpha$ is non-negative integer, the coefficients will be zero eventually and thus the series is finite.

Note that $a_n = \binom{\alpha}{n}$ and thus
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{\binom{\alpha}{n+1}}{\binom{\alpha}{n}}} = \abs{\frac{\alpha (\alpha-1) (\alpha-2) \cdots (\alpha-n)n!}{\alpha (\alpha-1) (\alpha-2) \cdots (\alpha-n+1)(n+1)!}} = \abs{\frac{\alpha-n}{n+1}} \to  1\ \text{ as }n\to \infty.
\ee

Therefore, the radius of convergence is $1$ by Proposition \ref{pro:ratio_convergence_radius} and (i) and (ii) are obvious.

Now consider $\abs{z} =1$. By Lemma \ref{lem:binomial_coefficients_landau_notation}, we have there exist $m,M>0$ such that
\be
\frac{m}{k^{1+\Re \alpha}} = \abs{\frac{(-1)^k m}{k^{1+\alpha}}} \leq\abs{\binom{\alpha}{k} z^k} \leq \abs{\frac{(-1)^k M}{k^{1+\alpha}}} = \frac{M}{k^{1+\Re \alpha}} .\quad(*)
\ee

Thus, the binomial series converges absolutely if and only if $\Re \alpha +1>1 \ \lra\ \Re\alpha >0$ by Corollary \ref{cor:riemann_zeta_function_real}.

By Proposition \ref{pro:binomial_addition_split}, we have
\beast
(1+z)\sum^n_{k=0}\binom{\alpha}{k} z^k & = & \sum^n_{k=0}\binom{\alpha}{k} z^k + \sum^{n}_{k=0}\binom{\alpha}{k} z^{k+1}  = \sum^n_{k=0}\binom{\alpha}{k} z^k + \sum^{n}_{k=1}\binom{\alpha}{k-1} z^k + \binom{\alpha}{n+1} z^{n+1} \\
& = & \sum^n_{k=0}\binom{\alpha+1}{k} z^k + \binom{\alpha}{n} z^{n+1}. \qquad\qquad (\dag)
\eeast

Then with the similar argument we can have that the right hand converges when $\Re \alpha > -1$. The first term is $\alpha+1$ for previous case and the second term converges as
\be
\lim_{n\to \infty}\abs{\binom{\alpha}{n}z^{n+1}} = \lim_{n\to \infty}\abs{\frac{1}{\Gamma(-\alpha) k^{1+\Re \alpha}}} \to 0
\ee
by Lemma \ref{lem:binomial_coefficients_landau_notation}. So if $z\neq -1$, the series converges for $\Re \alpha >-1$. On the other hand, the series does not converge if $\abs{z}=1$ and $\Re\alpha \leq -1$ ($-\alpha \geq 1$) as for all $k$,
\be
\abs{\binom{\alpha}{k}z^k} = \abs{\frac{-\alpha (-\alpha + 1)\dots(-\alpha +k-1)}{k!}} \geq 1.
\ee

If $z = -1$, we plug it into ($\dag$) and replace $\alpha$ with $\alpha -1$,
\be
\sum^n_{k=0}\binom{\alpha}{k} (-1)^k = -\binom{\alpha -1}{n}(-1)^{n+1} = \binom{\alpha -1}{n}(-1)^{n}.
\ee

Thus, by ($*$) again, the binomial series converges if and only if $1 + \Re(\alpha-1)>0$ for $z=-1$. That is, $\Re \alpha >0$.
\end{proof}

\begin{example}
Isaac Newton considered the following function for binomial series.

For any $\abs{z}\leq 1$,
\beast
(1+z)^{1/2} = 1 + \alpha z + \frac{\alpha (\alpha-1)}{2!}z^2 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}z^3 + \dots =  1 + \frac z2 - \frac{z^2}8 + \frac {z^3}{16} - \frac{5z^4}{128} + \frac{7z^5}{256}-\dots
\eeast

For $\abs{z}<1$,
\beast
(1+z)^{-1} = 1 + \alpha z + \frac{\alpha (\alpha-1)}{2!}z^2 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}z^3 + \dots =  1 - z + z^2 - z^3 + z^4 - z^5 + \dots
\eeast

For $\abs{z}\leq 1$ with $z\neq -1$,
\beast
(1+z)^{-1/2} = 1 + \alpha z + \frac{\alpha (\alpha-1)}{2!}z^2 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}z^3 + \dots =  1 - \frac{z}2 + \frac{3z^2}8 - \frac{5z^3}{16} + \frac{35z^4}{128} - \frac{63z^5}{256} + \dots
\eeast

The binomial series of following functions are given by John Wallis when he considered the expressions of the form $y = (1-x^2)^m$ where $m$ is a fraction.

For $\abs{z}\leq 1$,
\beast
(1-z^2)^{1/2} = 1 + \alpha (-z^2) + \frac{\alpha (\alpha-1)}{2!}z^4 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}(-z^2)^3 + \dots =  1 - \frac{z^2}2 - \frac{z^4}8 - \frac{z^6}{16}-\dots
\eeast
\beast
(1-z^2)^{3/2} = 1 + \alpha (-z^2) + \frac{\alpha (\alpha-1)}{2!}z^4 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}(-z^2)^3 + \dots =  1 - \frac{3z^2}2 + \frac{3z^4}8 + \frac{z^6}{16}+\dots
\eeast
\beast
(1-z^2)^{1/3} = 1 + \alpha (-z^2) + \frac{\alpha (\alpha-1)}{2!}z^4 + \frac{\alpha (\alpha-1)(\alpha -2)}{3!}(-z^2)^3 + \dots =  1 - \frac{z^2}3 - \frac{z^4}9 - \frac{5z^6}{81} - \dots
\eeast
\end{example}




\subsection{Properties of binomial series}


\begin{theorem}[Chu-Vandermonde identity]
Let $r,s\in \R$ and $n\in \Z^+$. Then
\be
\sum^n_{k=0} \binom{r}{k}\binom{s}{n-k} = \binom{r+s}{n}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
By definition of binomial series, for any $\abs{z}<1$,
\beast
\sum^\infty_{n=0} \binom{r+s}{n}z^n & = & (1+z)^{r+s} = (1+z)^r (1+z)^s = \sum^\infty_{k=0}\binom{r}{k}z^k \cdot \sum^\infty_{m=0}\binom{s}{m}z^m\\
& = &  \sum^\infty_{k=0}\binom{r}{k}z^k \cdot \sum^\infty_{n=k}\binom{s}{n-k}z^{n-k} = \sum^\infty_{n=0}\bb{\sum^n_{k=0} \binom{r}{k}\binom{s}{n-k}}z^{n}
\eeast
by Mertens' theorem (Theorem \ref{thm:mertens_cauchy_product}) since $\abs{z}<1$ implies the absolute convergence (Theorem \ref{thm:convergence_binomial_series}). Then we have the required result by comparing the coefficients.
\end{proof}%by properties of power function\footnote{proposition needed. $x^{r+s} = z^rz^s$}.

\begin{proposition}\label{pro:negative_binomial_pmf} 
For $r\in \R^+$ and $z\in \C$ with $\abs{z}<1$,
\be
\sum^\infty_{k=0}{k+r-1 \choose k}\cdot z^k = \bb{1-z}^{-r} .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\beast
 {k+r-1 \choose k} & = & \frac{(k+r-1)!}{k!\,(r-1)!} = \frac{(k+r-1)(k+r-2)\cdots(r)}{k!} \\
& = & \frac{(k+r-1)\cdots(r)}{k!} = (-1)^k \frac{(-r)(-r-1)(-r-2)\cdots(-r-k+1)}{k!} = (-1)^k{-r \choose k} \qquad (*).
\eeast

Then by Definition \ref{def:binomial_series} and $(*)$,
\be
(1-z)^{-r}= (1+(-z))^{-r} = \sum_{k=0}^\infty{-r \choose k}(-z)^k =\sum_{k=0}^\infty{k+r-1\choose k} z^k
\ee
as required.
\end{proof}

\subsection{Binomial coefficients by complex integral}


%We can get binomial coefficients by complex integral

\begin{proposition}\label{pro:binomial_complex_integral_representation}
For $m,n\in \Z$ with $0\leq m\leq n$,
\be
\binom{n}{m} = \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{1}{z^{m+1}}(1+z)^n dz
\ee
\end{proposition}

\begin{remark}
This is the coefficient of $z^{-1}$ of the integrand.
\end{remark}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{example}
Consider
\beast
 \sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n} \binom{n}{k} \binom{k}{m} & = & \sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n} \frac{n!}{(n-k)!m!(k-m)!}\\
 & = & \sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n} \binom{n}{m} \frac{(n-m)!}{(n-k)!(k-m)!} \\
& = & \binom{n}{m} \sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n}  \binom{n-m}{k-m}.
\eeast

We introduce
\be
\binom{2n-2k}{n} =  \binom{2n-2k}{n-2k} = \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{1}{z^{n-2k+1}}(1+z)^{2n-2k} dz.
\ee

Note that this vanishes when $2k>n$ so we may raise $k$ to end at $n$, getting that
\beast
\sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n}  \binom{n-m}{k-m} & = & \sum^{n}_{k=m}(-1)^k  \binom{n-m}{k-m} \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{1}{z^{n-2k+1}}(1+z)^{2n-2k} dz \\
& = & \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{(1+z)^{2n}}{z^{n+1}}  \sum^{n}_{k=m}(-1)^k  \binom{n-m}{k-m}  \frac{z^{2k}}{(1+z)^{2k}} dz %\\ & = & \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{(1+z)^{2n}}{z^{2n+1}}  \sum^{n}_{k=m}(-1)^k  \binom{n-m}{k-m}  \frac{z^{2k}}{(1+z)^{2k}} dz \\
\eeast

Then replace $k-m$ with $k$,
\beast
\sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n}  \binom{n-m}{k-m} & = &  \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{(1+z)^{2n}}{z^{n+1}} \frac{(-1)^mz^{2m}}{(1+z)^{2m}} \sum^{n-m}_{k=0}(-1)^k  \binom{n-m}{k}  \frac{z^{2k}}{(1+z)^{2k}} dz \\
& = &  \frac 1{2\pi i}\int_{\abs{z} =\ve} (-1)^m \frac{(1+z)^{2n-2m}}{z^{n-2m+1}} \bb{1- \frac{z^{2}}{(1+z)^{2}}}^{n-m} dz \\
& = &   (-1)^m \frac 1{2\pi i}\int_{\abs{z} =\ve} \frac{\bb{1+2z}^{n-m}}{z^{n-2m+1}} dz = (-1)^m 2^{n-2m} \frac 1{2\pi i}\int_{\abs{z} =\ve} \frac{\bb{1+2z}^{n-m}}{(2z)^{n-2m+1}}d(2z) \\
& = & (-1)^m 2^{n-2m} \binom{n-m}{n-2m}
\eeast

Thus,
\beast
 \sum^{\floor{n/2}}_{k=m}(-1)^k \binom{2n-2k}{n} \binom{n}{k} \binom{k}{m} & = &  \binom{n}{m} (-1)^m 2^{n-2m} \binom{n-m}{n-2m} = (-1)^m 2^{n-2m} \binom{n}{m} \binom{n-m}{m} .
\eeast
\end{example}




%\begin{proof}[\bf Proof]
%Note that this vanishes when $2k+1>n$ so we may raise $k$ to end at $n-1$, getting that
%\be
%\sum_{k=m}^{\floor{(n-1)/2}} \binom{k}{m}\binom{n}{2k+1} = \sum_{k=0}^{\floor{(n-1)/2}} \binom{k}{m}\binom{n}{2k+1} .%= \sum_{k=m}^{n} \binom{k}{m}\binom{n}{n-2k-1}
%\ee
%
%We introduce
%\be
%\binom{k}{m}  = \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{1}{z^{m+1}}(1+z)^{k} dz.
%\ee
%
%
%
%\beast
%\sum_{k=m}^{\floor{(n-1)/2}} \binom{k}{m}\binom{n}{2k+1} & = & \sum_{k=0}^{\floor{(n-1)/2}} \binom{n}{2k+1} \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{1}{z^{m+1}}(1+z)^{k} dz \\
%& = & \frac 1{2\pi i}\int_{\abs{z} =\ve} \frac{1}{z^{m+1}} \bb{\sum_{k=0}^{\floor{(n-1)/2}} \binom{n}{2k+1} (1+z)^k } dz.
%\eeast
%
%In particular,
%\be
%\sum_{k=0}^{\floor{(n-1)/2}} \binom{n}{2k+1} (1+z)^k =
%\ee
%%
%%\beast
%%\sum_{k=m}^{\floor{(n-1)/2}} \binom{k}{m}\binom{n}{2k+1} & = & \sum_{k=m}^{n} \binom{k}{m} \frac 1{2\pi i}\int_{\abs{z} =\ve}\frac{1}{z^{n-2k}}(1+z)^{n} dz = \frac 1{2\pi i}\int_{\abs{z} =\ve} \frac{(1+z)^n}{z^n} \bb{\sum_{k=0}^{n} \binom{k}{m} z^{2k}} dz\\
%%\eeast
%
%\end{proof}


\begin{proposition}\label{pro:binomial_odd_even_choice}
For $n,m\in \Z$ with $n\geq m$,
\beast
\sum_{k=m}^{\floor{n/2}}\binom{n}{2k} \binom{k}{m} & = &  2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg],\qquad 0\leq m\leq \frac n2, \\
\sum_{k=m}^{\floor{(n-1)/2}}\binom{n}{2k+1}\binom{k}{m} & = &  2^{n-2m-1}\binom{n-m-1}{m},\qquad\qquad\qquad 0\leq m \leq \frac {n-1}2.
\eeast%\be
%\sum^{\floor{(n-1)/2}}_{m=k} \binom{m}{k}\binom{n}{2m+1} = \binom{n-k-1}{k} 2^{n-2k-1}.
%\ee
\end{proposition}

\begin{remark}
In other form
\be
\sum_{k=m}^{\floor{n/2}}\binom{n}{2k} \binom{k}{m}= 2^{n-2m-1}\frac{n}{n-m}\binom{n-m}{m},\qquad 0\leq m\leq \frac n2.
\ee
\end{remark}

\begin{proof}[\bf Proof]
{\bf Approach 1.} Indeed, we can write the equation in general form since the terms will vanish when $k<m$ and $2k+1>n$ or $2k>n$%.\sum_{k=m}\binom{n}{2k}\binom{k}{m}=2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg]
\beast
\sum_{k=0}^{n}\binom{n}{2k} \binom{k}{m} & = &  2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg],\qquad 0\leq m\leq \frac n2, \\
\sum_{k=0}^{n}\binom{n}{2k+1} \binom{k}{m}& = &  2^{n-2m-1}\binom{n-m-1}{m},\qquad\qquad \qquad 0\leq m \leq \frac {n-1}2.
\eeast

We will use induction to prove the identity. First assume $n=1$ and $m=0$. Then both equations hold.
\beast
\sum_{k=0}^{n}\binom{n}{2k} \binom{k}{m} & = & \binom{1}{0}\binom{0}{0} + \binom{1}{2}\binom{2}{0} = 1+0 = 1 = 2^{1-0-1}\bigg[\underbrace{\binom{1-0}{0}}_{=1}+\underbrace{\binom{1-0-1}{0-1}}_{=0} \bigg] \\
\sum_{k=0}^{n}\binom{n}{2k+1}\binom{k}{m} & = & \binom{1}{1}\binom{0}{0} + \binom{1}{3}\binom{1}{0} = 1+0 = 1 = 2^{1-0-1}\underbrace{\binom{1-0-1}{0}}_{=1}
\eeast

So assume that both equation are valid for some $n\in\N$. Then \footnote{for $k<0$, $\binom{n}{k} = 0$}
\beast
\sum_{k=0}^{n+1} \binom{k}{m} \binom{n+1}{2k}  & = &  \sum_{k=0}^{n+1}\binom{k}{m}\bb{\binom{n}{2k-1} + \binom{n}{2k} } = \sum_{k=0}^{n+1}\binom{k}{m}\binom{n}{2k-1} + \sum_{k=0}^{n+1}\binom{k}{m}\binom{n}{2k} \\
& = & \sum_{k=0}^{n}\binom{k+1}{m}\binom{n}{2k+1} + \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k} = \sum_{k=0}^{n}\bb{\binom{k}{m-1}+\binom{k}{m}}\binom{n}{2k+1} + \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k} \\
& = & 2^{n-2m+1}\binom{n-m}{m-1} + 2^{n-2m-1}\binom{n-m-1}{m} + 2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg] \\
& = & 2^{n-2m-1}\bsb{4\binom{n-m}{m-1}+ \binom{n-m-1}{m} +\binom{n-m}{m}+\binom{n-m-1}{m-1} } \\
& = & 2^{n-2m-1}\bsb{4\binom{n-m}{m-1}+ 2\binom{n-m}{m}} = 2^{(n+1)-2m-1}\bsb{\binom{(n+1)-m}{m}+\binom{(n+1)-m-1}{m-1}}
\eeast

We also need to consider $m+1$ case when $n$ is an odd number ($m =\frac{n-1}{2}$). Thus, we consider
\be
\sum_{k=0}^{n+1}\binom{k}{m+1} \binom{n+1}{2k}
\ee

However, to pick non-zero term, we have
\be
\ba{l}
k\geq m+1\\
n+1 \geq 2k
\ea \ \ra\  m+1 \geq k\geq m+1\ \ra\ k = m+1 .
\ee
%which is a contradiction so we have
%\beast
%\sum_{k=0}^{n+1}\binom{k}{m+1} \binom{n+1}{2k} = \sum_{k=0}^{n}\binom{n+1}{2k+2} \binom{k}{m} = \sum_{k=0}^{n}\bsb{\binom{n}{2k+2} + \binom{n}{2k+1}} \binom{k}{m}.
%\eeast
%
%
%\beast
%& & \sum_{k=0}^{n+1} \binom{k}{m} \binom{n+1}{2k} = \sum_{k=0}^{n+1}\binom{k}{m}\bb{\binom{n}{2k-1} + \binom{n}{2k} } = \sum_{k=0}^{n+1}\binom{k}{m}\binom{n}{2k-1} + \sum_{k=0}^{n+1}\binom{k}{m}\binom{n}{2k} \\
%& = & \sum_{k=0}^{n}\binom{k+1}{m}\binom{n}{2k+1} + \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k} = \sum_{k=0}^{n}\bb{\binom{k}{m-1}+\binom{k}{m}}\binom{n}{2k+1} + \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k} \\
%& = & 2^{n-2m+1}\binom{n-m}{m-1} + 2^{n-2m-1}\binom{n-m-1}{m} + 2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg] \\
%& = & 2^{n-2m-1}\bsb{4\binom{n-m}{m-1}+ \binom{n-m-1}{m} +\binom{n-m}{m}+\binom{n-m-1}{m-1} } \\
%& = & 2^{n-2m-1}\bsb{4\binom{n-m}{m-1}+ 2\binom{n-m}{m}} = 2^{n-2m}\bsb{\binom{n-m+1}{m}+\binom{n-m}{m-1}}
%\eeast

Therefore, since $n = 2m+1$,
\be
\sum_{k=0}^{n+1}\binom{k}{m+1} \binom{n+1}{2k}  = \binom{m+1}{m+1} \binom{n+1}{2m+2}= 1
\ee
which is consistent with
\be
2^{n+1-2(m+1)-1}\bsb{\binom{n+1-(m+1)}{m+1}+\binom{n+1-(m+1)-1}{m+1-1}} = 2^{-1}\bb{\binom{m+1}{m+1} + \binom{m}{m}} = 2^{-1}\cdot 2 = 1.
\ee

Similarly,
\beast
\sum_{k=0}^{n+1}\binom{k}{m}\binom{n+1}{2k+1}  & = & \sum_{k=0}^{n+1}\binom{k}{m}\bb{\binom{n}{2k+1} + \binom{n}{2k} } = \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k+1} + \sum_{k=0}^{n}\binom{k}{m}\binom{n}{2k} \\
& = & 2^{n-2m-1}\binom{n-m-1}{m} + 2^{n-2m-1}\bsb{\binom{n-m}{m}+\binom{n-m-1}{m-1}} \\
& = & 2^{(n+1)-2m-1}\binom{(n+1)-m-1}{m}
\eeast

We also need to consider $m+1$ case when $n$ is an even number ($m =\frac{n}{2}-1$). Thus, we consider
\be
\sum_{k=0}^{n+1}\binom{k}{m+1} \binom{n+1}{2k+1}.
\ee

However, to pick non-zero term, we have
\be
\ba{l}
k\geq m+1\\
n+1 \geq 2k+1
\ea \ \ra\  m+1 \geq k\geq m+1\ \ra\ k = m+1 .
\ee

Therefore, since $n = 2m+2$,
\be
\sum_{k=0}^{n+1}\binom{k}{m+1} \binom{n+1}{2k+1}  = \binom{m+1}{m+1} \binom{2m+3}{2m+3}= 1
\ee
which is consistent with
\be
2^{n+1-2(m+1)-1}\binom{n+1-(m+1)-1}{m+1} = 2^{0}\binom{m+1}{m+1} = 2^{0}\cdot 1 = 1.
\ee

{\bf Approach 2.} Indeed, we can write the equation in general form since the terms will vanish when $k<m$ and $2k+1>n$ or $2k>n$%.\sum_{k=m}\binom{n}{2k}\binom{k}{m}=2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg]
\beast
\sum_{k=0}^{\infty}\binom{n}{2k} \binom{k}{m} & = &  2^{n-2m-1}\bigg[\binom{n-m}{m}+\binom{n-m-1}{m-1}\bigg],\qquad 0\leq m\leq \frac n2, \\
\sum_{k=0}^{\infty}\binom{n}{2k+1} \binom{k}{m}& = &  2^{n-2m-1}\binom{n-m-1}{m},\qquad\qquad \qquad 0\leq m \leq \frac {n-1}2.
\eeast

By Proposition \ref{pro:binomial_complex_integral_representation},
\be
\binom{n}{2k+1} = \binom{n}{n-2k-1}  = \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{1}{z^{n-2k}}(1+z)^n dz = \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n}}  z^{2k} dz
\ee
which implies that
\beast
\sum_{k=0}^{\infty}\binom{n}{2k+1} \binom{k}{m} & = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n}} \bb{\sum_{k=m}^{\infty}\binom{k}{m} z^{2k}} dz \\
& = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n}} \bb{\sum_{k=0}^{\infty}\binom{k+m}{m} z^{2k+2m}} dz \\
& = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n-2m}} \bb{\sum_{k=0}^{\infty}\binom{k+m}{k} z^{2k}} dz
\eeast

By Proposition \ref{pro:negative_binomial_pmf}
\be
\sum_{k=0}^{\infty}\binom{k+m}{k} z^{2k} = (1-z^2)^{-(m+1)}.
\ee

So,
\beast
\sum_{k=0}^{\infty}\binom{n}{2k+1} \binom{k}{m} & = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n-2m}} (1-z^2)^{-(m+1)}  dz \\
& = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^{n-m-1}(1-z)^{-(m+1)}}{z^{n-2m}}   dz
\eeast

By Proposition \ref{pro:negative_binomial_pmf} again,
\beast
(1-z)^{-(m+1)} & = & \sum_{k=0}^{\infty}\binom{k+m}{k} z^{k} = \sum_{k=0}^{\infty}\binom{k+m}{m} z^{k} \\
(1+z)^{n-m-1} & = & \sum_{l=0}^{n-m-1}\binom{n-m-1}{l} z^{l} .
\eeast

So the coefficient of $z^{n-2m-1}$ in $(1+z)^{n-m-1}(1-z)^{-(m+1)}$ is
\beast
\sum^{n-2m-1}_{p=0}  \binom{n-m-1}{p} \binom{(n-2m-1-p)+m}{m} &  = & \sum^{n-2m-1}_{p=0}  \binom{n-m-1}{n-m-1-p} \binom{n-m-1-p}{m} \\
& = & \sum^{n-m-1}_{p=m}  \binom{n-m-1}{p} \binom{p}{m} = 2^{n-2m-1}\binom{n-m-1}{m}
\eeast
by Proposition \ref{pro:binomial_double_choice}. Similarly,
\be
\binom{n}{2k} = \binom{n}{n-2k}  = \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{1}{z^{n-2k+1}}(1+z)^n dz = \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n+1}}  z^{2k} dz.
\ee
which implies that
\beast
\sum_{k=0}^{\infty}\binom{n}{2k} \binom{k}{m} & = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^n}{z^{n-2m+1}} \bb{\sum_{k=0}^{\infty}\binom{k+m}{k} z^{2k}} dz \\
& = & \frac 1{2\pi i} \int_{\abs{z}=\ve} \frac{(1+z)^{n-m-1}(1-z)^{-(m+1)}}{z^{n-2m+1}}   dz
\eeast

So the coefficient of $z^{n-2m}$ in $(1+z)^{n-m-1}(1-z)^{-(m+1)}$ is%\footnote{more details needed.}
\beast
\sum^{n-2m}_{p=0}  \binom{n-m-1}{p} \binom{(n-2m-p)+m}{m} & = &
\sum^{n-2m}_{p=0}  \binom{n-m-1}{n-m-1-p} \binom{n-m-p}{m} = \sum^{n-m-1}_{p=m-1}  \binom{n-m-1}{p} \binom{p+1}{m}  \\ %& = & \sum^{n-m-1}_{p=m-1}  \binom{n-m-1}{p} \binom{p}{m} = 2^{n-2m-1}\binom{n-m-1}{m}
&  = & \sum^{n-m-1}_{p=m-1}  \binom{n-m-1}{p} \bsb{\binom{p}{m} + \binom{p}{m-1}  }
\eeast
by Proposition \ref{pro:binomial_addition_split}. Then
\beast
\sum_{k=0}^{\infty}\binom{n}{2k} \binom{k}{m}  & = & \sum^{n-m-1}_{p=m}  \binom{n-m-1}{p} \binom{p}{m} + \sum^{n-m-1}_{p=m-1}  \binom{n-m-1}{p}\binom{p}{m-1}  \\
& = & 2^{n-2m-1}\binom{n-m-1}{m} + 2^{n-2m}\binom{n-m-1}{m-1} \\
& = & 2^{n-2m-1}\bsb{\binom{n-m}{m} - \binom{n-m-1}{m-1} + 2\binom{n-m-1}{m-1} } \\
& = & 2^{n-2m-1}\bsb{\binom{n-m}{m} + \binom{n-m-1}{m-1}}
\eeast
by Proposition \ref{pro:binomial_double_choice}. So we can have the required result.
\end{proof}

\begin{example}
For $n=11$ and $m=3$, we have $k=3,4,5$. Then
\beast
\sum^{\floor{(n-1)/2}}_{k=m} \binom{k}{m}\binom{n}{2k+1} & = & \binom{3}{3} \binom{11}{7} + \binom{4}{3}\binom{11}{9} + \binom{5}{3}\binom{11}{11} = 1\cdot 330 + 4 \cdot 55 + 10 \cdot 1 \\
& = & 560 = 35 \cdot 16 =  2^4 \cdot \binom{7}{3} = 2^{n-2m-1}\binom{n-m-1}{m} .
\eeast
\beast
\sum^{\floor{(n-1)/2}}_{k=m} \binom{k}{m}\binom{n}{2k} & = & \binom{3}{3} \binom{11}{6} + \binom{4}{3}\binom{11}{8} + \binom{5}{3}\binom{11}{10} = 1\cdot 924 + 4 \cdot 165 + 10 \cdot 11 \\
& = & 1232 = 16\cdot 77 =  2^4 \cdot \bb{56 + 21 } = 2^4 \cdot \bsb{\binom{8}{3} + \binom{7}{2}}  = 2^{n-2m-1} \bsb{\binom{n-m}{m} + \binom{n-m-1}{m-1}}.
\eeast

For $n=12$ and $m=3$, we have $k=3,4,5$. Then
\beast
\sum^{\floor{(n-1)/2}}_{k=m} \binom{k}{m}\binom{n}{2k+1} & = & \binom{3}{3} \binom{12}{7} + \binom{4}{3}\binom{12}{9} + \binom{5}{3}\binom{12}{11} = 1\cdot 792 + 4 \cdot 220 + 10 \cdot 12 \\
& = & 1792 =  32 \cdot 56 =  2^5\cdot \binom{8}{3} = 2^{n-2m-1}\binom{n-m-1}{m} .
\eeast
\beast
\sum^{\floor{(n-1)/2}}_{k=m} \binom{k}{m}\binom{n}{2k} & = & \binom{3}{3} \binom{12}{6} + \binom{4}{3}\binom{12}{8} + \binom{5}{3}\binom{12}{10} + \binom{6}{3}\binom{12}{12} =  1\cdot 924 + 4 \cdot 495 + 10 \cdot 66 + 20 \cdot 1 \\
& = & 3584 = 32 \cdot 112  = 2^5 \bsb{84 + 28} = 2^5 \bsb{\binom{9}{3} + \binom{8}{2}} = 2^{n-2m-1} \bsb{\binom{n-m}{m} + \binom{n-m-1}{m-1}}.
\eeast
\end{example}

\subsection{Elementary boundary of binomial coefficients}

\begin{theorem}[elementary boundary of binomial coefficients]
For any $\alpha \in \C$, there exist $M>0$ independent of $k$ as follows such that
\be
\abs{\binom{\alpha}{k}} \leq \frac{M}{k^{1+\Re\alpha}},\qquad \forall k\in\Z^+.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
By arithmetic-geometric mean inequality (Theorem \ref{thm:arithmetic_geometric_mean_inequality}),
\be
\abs{\binom{\alpha}{k}} = \abs{\frac{\alpha (\alpha -1)\dots (\alpha-k+1)}{k!}}^2 = \prod^k_{n=1}\abs{\frac{\alpha-n+1}{n}}^2 = \prod^k_{n=1}\abs{1 -\frac{\alpha+1}{n}}^2 \leq \bb{\frac 1k \sum^k_{n=1}\abs{1 -\frac{\alpha+1}{n}}^2  }^k.
\ee

Using the expansion,
\be
\abs{1-z}^2 = \bb{1-z}\bb{1-\ol{z}} = 1 - 2\Re z + \abs{z}^2,
\ee
we have
\beast
\frac 1k \sum^k_{n=1}\abs{1 -\frac{\alpha+1}{n}}^2 & = & \frac 1k \sum^k_{n=1} \bb{1 - 2\Re\bb{\frac{\alpha+1}{n}} + \frac{\abs{\alpha+1}^2}{n^2}} \\
& = & 1 + \frac 1k \bb{-2(1+\Re\alpha)\sum^k_{n=1}\frac 1n  + \abs{1+\alpha}^2 \sum^k_{n=1}\frac 1{n^2}}.
\eeast

\be
-2(1+\Re\alpha)\sum^k_{n=1}\frac 1n  + \abs{1+\alpha}^2 \sum^k_{n=1}\frac 1{n^2} > \abs{1+\alpha}^2 -2\abs{1+\Re\alpha}\bb{1+\log k} \geq -2\abs{1+\Re\alpha}\bb{1+\log k}
\ee
since
\be
\log k < \sum^k_{n=1}\frac 1n <  1+\log k,\qquad 1\leq \sum^k_{n=1} \frac 1{n^2} = \frac{\pi^2}{6} \leq 2
\ee%Proposition \ref{pro:one_plus_one_over_n_power_n_strictly_increasing}
by Theorem \ref{thm:log_bound_of_summation_natural_inverse} and Theorem \footnote{zeta function $\zeta(2)$ needed.}. By Corollary \ref{cor:one_plus_x_over_n_power_n_smaller_than_exp_x}, we have for any $x\geq -k$,
\be
\bb{1+\frac xk}^k \leq e^x.
\ee

So we can pick large enough $k$ such that $-2\abs{1+\Re\alpha}\bb{1+\log k} \geq -k$, and get
\be
\abs{\binom{\alpha}{k}}^2 \leq \exp\bb{-2(1+\Re\alpha)\sum^k_{n=1}\frac 1n  + \abs{1+\alpha}^2 \sum^k_{n=1}\frac 1{n^2}} \leq \exp\bb{-2(1+\Re\alpha)\sum^k_{n=1}\frac 1n  + 2\abs{1+\alpha}^2 }
\ee

When $\Re\alpha \leq -1$,
\beast
\abs{\binom{\alpha}{k}}^2 & \leq & \exp\bb{-2(1+\Re\alpha)\bb{1+\log k} + 2\abs{1+\alpha}^2 } \\
& = & \exp\bb{-2(1+\Re\alpha)\log k}\exp\bb{-2(1+\Re\alpha) + 2\abs{1+\alpha}^2 } \\
& = & \frac 1{k^{2(1+\Re\alpha)}}\exp\bb{-2(1+\Re\alpha) + 2\abs{1+\alpha}^2 } .
\eeast

When $\Re\alpha \geq -1$,
\beast
\abs{\binom{\alpha}{k}}^2 & \leq & \exp\bb{-2(1+\Re\alpha)\log k + 2\abs{1+\alpha}^2 } \\
& = & \exp\bb{-2(1+\Re\alpha)\log k}\exp\bb{2\abs{1+\alpha}^2 } = \frac 1{k^{2(1+\Re\alpha)}}\exp\bb{ 2\abs{1+\alpha}^2 }.
\eeast


Therefore, we can always find $M>0$ such that
\be
\abs{\binom{\alpha}{k}}^2 \leq \frac{M^2}{k^{2(1+\Re\alpha)}}  \ \ra\ \abs{\binom{\alpha}{k}} \leq \frac{M}{k^{1+\Re\alpha}}
\ee
as required.
\end{proof}


\section{Riemann Zeta Function}

\subsection{Definition}

\begin{definition}[Riemann zeta function\index{Riemann zeta function}]\label{def:riemann_zeta_function}
The Riemann zeta function $\zeta(s)$ is a function of a complex variable $s = \sigma + it$. The following infinite series converges for all complex numbers $s$ with real part greater than 1, and defines $\zeta(s)$ in this
case:
\be
\zeta(s) = \sum_{n=1}^\infty n^{-s} = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots, \qquad \sigma = \Re s  > 1.
\ee
\end{definition}

\subsection{Properties}

\begin{theorem}
For positive even integer $k$,
\be
\zeta(2k) = \sum^\infty_{n=1}\frac{1}{n^{2k}} = \frac{(-1)^{k-1}B_{2k}(2\pi)^{2k}}{2(2k)!}
\ee
where $B$ is Bernoulli number\footnote{definition needed}.
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
\be \zeta(3) = \frac 43 \sum^\infty_{n=0}\frac{(-1)^n}{(n+1)^3} \approx 1.202.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\subsection{Euler product}

\begin{definition}[Euler product]
An Euler product is an expansion of a Dirichlet series into an infinite product indexed by prime numbers.
\end{definition}

\begin{remark}
Euler product arose from the case of the Riemann zeta function, where such a product representation was proved by Leonhard Euler.
\end{remark}

\begin{theorem}[Euler product attached to Riemann zeta function]\label{thm:euler_product_riemann_zeta_function}
For $s\in \C$ with $\Re(s)>1$ and all prime numbers $p$,
\be
\prod_p \frac 1{1-p^{-s}} = \prod_p \bb{\sum^\infty_{n=0} p^{-ns}} = \sum^\infty_{n=1}\frac 1{n^s} = \zeta(s).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\section{Constants}

\subsection{Euler-Mascheroni constant}

\begin{definition}[Euler constant]\label{def:euler_mascheroni_constant}
The Euler constant (also called Euler-Mascheroni constant) is defined by
\be
\gamma := \lim_{n\to \infty} \bb{\sum^n_{k=1}\frac 1k - \ln n} = \lim_{n\to \infty} \bb{H_n - \log n} = \int^\infty_{1} \bb{\frac 1{\floor{x}}-\frac 1x}dx
\ee
where $\floor{x}$ represents the floor function.
\end{definition}


%\begin{corollary}[Euler's constant\index{Euler's constant}]\label{cor:euler_constant_definition}
%\be
%1+\frac 12 + \frac 13 + \cdots + \frac 1n - \log n\to \gamma \text{ as } n\to \infty, \quad 0\leq \gamma \leq 1.
%\ee
%\end{corollary}


\begin{remark}
\ben
\item [(i)] The existence is implied by applying $f(x)=1/x$ in integral test (Theorem \ref{thm:integral_test_real}) with $0\leq \gamma \leq 1 = f(1)$.
\item [(ii)] Still unknown if $\gamma$ is rational/irrational;
\item [(iii)] $\gamma \sim 0.577$;
\een
\end{remark}

\begin{proposition}
For Euler constant $\gamma$, we have $\frac 12 < \gamma < 1$.
\end{proposition}

\begin{proof}[{\bf Proof}]
\be
a_n := \int^1_0 \frac{t}{n(n-t)dt},\quad n\geq 2.
\ee

We will derive an estimate for $a_n$. Let $g(t) = t$, $f(t) = 1/(n-t)$, $\exists c\in (0,1)$,
\be
a_n = \frac 1n \frac 1{n-c}\int^1_0 tdt = \frac 1{2n(n-c)} < \frac 1{2n(n-1)}\ \ra \ 0 < a_n < \frac 1{2n(n-1)}
\ee
Thus,
\be
0 < \sum^N_{n=2}a_n < \sum^N_{n=2}\frac 1{2n(n-1)} = \frac 12 \sum^N_{n=2}\lob\frac 1{n-1} -\frac 1n\rob = \frac 12 \lob 1 -\frac 1N\rob\to \frac 12.
\ee

But $a_n$ can be easily computed integrating by parts. If you do the calculation, you can get
\be
a_n = \log\lob\frac n{n-1}\rob - \frac 1n
\ee
\be
\sum^N_{n=2}a_n = -\sum^N_{n=2}\frac 1n + \lob \log 2 - \log 1\rob + \lob \log 3 - \log 2\rob + \dots + \lob \log N - \log (N-1)\rob  = -\sum^N_{n=2}\frac 1n + \log N \to 1 -\gamma.
\ee
\end{proof}




\begin{proposition}[de la Vall\'ee-Pousin's formula]
\be
\gamma = \lim_{n\to \infty} \frac 1n \sum^n_{k=1}\bb{\ceil{\frac{n}{k}}- \frac{n}{k}}
\ee
where $\ceil{\cdot}$ is the ceiling function.
\end{proposition}


\begin{proposition}
Let $\Gamma(z)$ be gamma function and $\Psi(x)$ be the digamma function. Then the Euler constant is
\be
\gamma = -\Gamma'(1) = -\Psi(1).
\ee

Also,
\be
\gamma = -\lim_{z\to 0} \bb{\Gamma(z) - \frac 1z} = -\lim_{z\to 0} \bb{\Psi(z) +\frac 1z}
\ee
and\footnote{see Kr\"amer, Stefan (2005) Die Eulersche Konstante $\gamma$ und verwandte Zahlen, Ph.D. Thesis,Unversity of G\"ottingen, Germany.}
\beast
\lim_{z\to 0} \frac 1z \bb{\frac 1{\Gamma(1+z)} - \frac 1{\Gamma(1-z)}}  & = & 2\gamma, \\
\lim_{z\to 0} \frac 1z \bb{\frac 1{\Psi(1-z)} - \frac 1{\Psi(1+z)}}  & = & \frac{\pi^2}{3\gamma^2}.
\eeast

Furthermore,
\be
\gamma =\lim_{n\to \infty} \bb{\frac{\Gamma\bb{\frac 1n}\Gamma(n+1)n^{1+\frac 1n}}{\Gamma\bb{2+n+\frac 1n}} - \frac{n^2}{n+1}} = \lim_{n\to\infty} \sum^m_{k=1}\binom{m}{k} \frac{(-1)^k}{k} \ln\bb{\Gamma(k+1)}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Let $\zeta(\cdot)$ be the Riemann zeta function. Then
\be
\gamma = \sum^\infty_{k=2} (-1)^k \frac{\zeta(k)}{k} = \ln \frac{4}{\pi} + \sum^\infty_{k=2} (-1)^k \frac{\zeta(k)}{2^{k-1}k}
\ee
and for $s\in \R$,
\be
\gamma = \lim_{s\to 1^+} \sum^\infty_{n=1} \bb{\frac 1{n^s} - \frac 1{s^n}} = \lim_{s\to 1}\bb{\zeta(s) - \frac{1}{s-1}} = \lim_{s\to 0} \frac{\zeta(1+s) +\zeta(1-s)}2
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}[Catalan's 1875 integral (see Sondow and Zudilin\footnote{Sondow, Jonathan and Zudilin, Wadim, Euler's constant, $q$-logarithms, and formulas of Ramanujan and Gosper, Ramanujan Journal 12, 225-244})]
\be
\gamma = \int^1_0 \bb{\frac 1{1+x}\sum^\infty_{n=1}x^{2^n-1}}dx.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\subsection{Series expansions of Euler constant}

\begin{proposition}
Euler showed that the following infinite series approaches $\gamma$,
\be
\gamma = \sum^\infty_{k=1} \bb{\frac 1k - \ln \bb{1+\frac 1k}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}
Nielsen and Vacca (1910) showed that
\be
\gamma = 1 - \sum^\infty_{k=2} (-1)^k\frac{\floor{\log_2 k}}{k+1} = \sum^\infty_{k=2} (-1)^k\frac{\floor{\log_2 k}}{k} .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}
Vacca (1926) showed that
\be
\gamma + \zeta(2) = \sum^\infty_{k=2} \bb{\frac{1}{\floor{\sqrt{k}}^2} - \frac 1k} = \sum^\infty_{k=2}\frac{k- \floor{\sqrt{k}}^2}{k\floor{\sqrt{k}}^2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
From the Malmsten-Kummer expansion for the logarithm of the gamma function we get
\be
\gamma = \ln \pi - 4\ln\bb{\Gamma\bb{\frac 34}} + \frac 4{\pi} \sum^\infty_{k=1} (-1)^{k+1} \frac{\ln (2k+1)}{2k+1} .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}
\be
\gamma = \sum^\infty_{n=1} \frac{\abs{G_n}}{n} = \frac 12 + \frac 1{24} + \frac 1{72} + \frac{19}{2880} +\frac{3}{800}+\dots
\ee
where $G_n$ are Gregory coefficients.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
For prime number $p$,
\be
\gamma = \lim_{n\to\infty} \bb{\ln n - \sum_{p\leq n}\frac{\ln p}{p-1}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}
\be
\gamma = \lim_{n\to\infty} \bb{\sum^n_{k=1}\frac 1k - \ln\sqrt{\sum^n_{k=1}k}} - \frac{\ln 2}2.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Let $p_n$ be the $n$th prime number. Then
\be
e^\gamma = \lim_{n\to\infty} \frac 1{\ln p_n} \prod^n_{k=1} \frac{p_k}{1-p_k}.
\ee
\end{proposition}

\begin{remark}
The constant $e^\gamma$ is important in number theory.
\end{remark}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\begin{proposition}
\be
\frac{e^{1+\frac{\gamma}2}}{\sqrt{2\pi}} = \prod^\infty_{k=1} e^{-1+\frac 1{2k}}\bb{1+\frac 1k}^k,\qquad \frac{e^{3+2\gamma}}{2\pi} = \prod^\infty_{k=1} e^{-2+\frac 2{k}}\bb{1+\frac 2k}^k.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
\be
e^\gamma = \sqrt{\frac 21}\cdot \sqrt[3]{\frac{2^2}{1\cdot 3}}\cdot \sqrt[4]{\frac{2^3\cdot 4}{1\cdot 3^3}}\cdot \sqrt[5]{\frac{2^4\cdot 4^4}{1\cdot 3^6\cdot 5}} \dots
\ee
where the $n$th factor is the $(n+1)$th root of
\be
\prod^n_{k=0} (k+1)^{(-1)^{k+1}\binom{n}{k}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed. First discovered by Ser in 1926, was rediscovered by Sondow (2003) using hypergeometric functions.}
\end{proof}

\subsection{Euler's generalized constants}

\begin{definition}
Euler's generalized constants are given by
\be
\gamma_\alpha = \lim_{n\to\infty}\bb{\sum^n_{k=1}\frac 1{k^\alpha} - \int^n_1 \frac 1{x^\alpha} dx},
\ee
for $0<\alpha <1$, with $\gamma$ as the special case $\alpha =1$.
\end{definition}

\begin{remark}
The can be further generalized to
\be
c_f := \lim_{n\to \infty} \bb{\sum^n_{k=1}f(k) - \int^n_1 f(x)dx}
\ee
for some positive decreasing function $f$ (see Theorem \ref{thm:integral_test_real}). Note that Stieltjes constants are also of this kind.
\end{remark}


%\item %Stieltjes constants

\begin{definition}[Stieltjes constants]
For function $f_n(x) = \bb{\ln x}^n/x$, Stieltjes constants is defined by
\be
\gamma_n := \lim_{m\to \infty} \bb{\sum^m_{k=1}f_n(k) - \int^m_1 f_n(x)dx} = \lim_{m\to \infty} \bb{\sum^m_{k=1} \frac{\bb{\ln k}^n}k - \int^m_1 \frac{\bb{\ln x}^n}x dx}.
\ee

Note that the limit exists by Theorem \ref{thm:integral_test_real}.
\end{definition}

\begin{remark}
If $n=0$, Stieltjes constant is actually Euler constant.
\end{remark}

\begin{theorem}
The Riemann zeta function about $z=1$ is
\be
\zeta(z) = \frac{1}{z-1} + \sum^\infty_{n=0}\frac{(-1)^n}{n!}\gamma_n (z-1)^n
\ee
where $\gamma_n$ are the Stieltjes constants.
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed. See Havil 2003, p118, Havil, J. , Gamma: Exploring Euler's Constant, Princeton, NJ: Princeton University Press, 2003}
\end{proof}


\begin{definition}
For function $f_a(x) = x^{-a}$ with $a>0$,
\be
\gamma_{f_a} := \lim_{n\to \infty} \bb{\sum^n_{k=1}f_a(k) - \int^n_1 f_a(x)dx} = \lim_{n\to \infty} \bb{\sum^n_{k=1} \frac 1{k^{a}}- \int^n_1 x^{-a}  dx}.
\ee

Note that the limit exists by Theorem \ref{thm:integral_test_real}.
\end{definition}

\begin{proposition}
\be
\gamma_{f_a} = \frac{(a-1)\zeta(a)-1}{a-1}.
\ee

Then we have
\be
\gamma = \lim_{a\to 1} \bb{\zeta(a) - \frac 1{a-1}}
\ee
where $\gamma$ is the Euler constant.
\end{proposition}

\section{Partial Sums}

\subsection{Faulhaber's formula}

\begin{theorem}[Faulhaber's formula\footnote{named after Johann Faulhaber}]
Let $p\in \N$. Then the sum of the $p$th powers of the first $n$ positive integers can be expressed as a $(p+1)$ degree polynomial function of $n$, the coefficients involving Bernoulli number (of first kind) $B_k$ (see Definition \ref{def:bernoulli_numbers_first_kind}). That is,
\be
\sum^n_{k=1} k^p = \frac 1{p+1} \sum^p_{k=0}(-1)^k\binom{p+1}{k} B_k n^{p+1-k}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Let $z\in \C$ and
\be
S_p(n) = \sum^n_{k=1}k^p \leq n^{p+1}.
\ee

Then define the exponential generating function with indeterminate $z$,
\be
G(z,n) = \sum^\infty_{p=0}S_p(n) \frac 1{p!}z^p \leq n \sum^\infty_{p=0}\frac 1{p!}(nz)^p = ne^{nz}
\ee
which is bounded. Then by Fubini theorem we have
\be
G(z,n) = \sum^\infty_{p=0} \sum^n_{k=1} \frac 1{p!}(kz)^p = \sum^n_{k=1} e^{kz} = e^z\cdot \frac{1-e^{nz}}{1-e^z} = \frac{1-e^{nz}}{e^{-z}-1}.
\ee

Using definition of Bernoulli numbers (see Definition \ref{def:bernoulli_numbers})
\be
\frac{z}{e^z -1} = \sum^\infty_{m=0}B_m \frac{z^m}{m!} \ \ra\ \frac{-z}{e^{-z} -1} = \sum^\infty_{m=0}B_m \frac{(-z)^m}{m!}
\ee
and
\be
-\frac{1- e^{nz}}{z} = - \frac 1z\bb{-\sum^\infty_{k=1}\frac{(nz)^k}{k!}}
\ee

Therefore,
\beast
G(z,n) & = & \sum^\infty_{m=0}B_m \frac{(-z)^{m-1}}{m!} \bb{-\sum^\infty_{k=1}\frac{(nz)^k}{k!}} = \sum^\infty_{p=0} z^p \sum^p_{m=0} (-1)^m \frac{1}{m!(p+1-m)!} B_m n^{p+1-m} \\
& = & \sum^\infty_{p=0} \frac{z^p}{p!} \frac 1{p+1}\sum^p_{m=0} (-1)^m \binom{p+1}{m} B_m n^{p+1-m}.
\eeast

This gives the required result as we can differentiate the sum and let $z=0$ repeatedly.
\end{proof}

\begin{example}
For the case $p=1$, since $B_0 =1$ and $B_1 = -1/2$,
\beast
1 + 2 + \dots + n & = & \frac 12 \sum^1_{k=0}(-1)^k\binom{2}{k} B_k n^{2-k} =\frac 12 \bb{B_0 n^2 - 2B_1 n } \\
& = & \frac 12 \bb{n^2 + n} = \frac 12n(n+1).
\eeast

For the case $p=2$, since $B_2 = 1/6$,
\beast
1^2 + 2^2 + \dots + n^2 & = & \frac 13 \sum^1_{k=0}(-1)^k\binom{3}{k} B_k n^{3-k} = \frac 13 \bb{B_0 n^3 - 3B_1 n^2 + 3B_2 n } \\
& = & \frac 13 \bb{n^3 + \frac 32 n^2 + \frac 12 n} = \frac 16 n(n+1)(2n+1).
\eeast
\end{example}

Then we have the following corollary for the common cases.
\begin{corollary}
For $n\in \Z^+$,
\beast
\sum^n_{k=1} k & = & \frac{n^2+n}2 = \frac{n(n+1)}2, \\
\sum^n_{k=1} k^2 & = & \frac{2n^3+3n^2 + n}6 = \frac{n(n+1)(2n+1)}6, \\
\sum^n_{k=1} k^3 & = & \frac{n^4+2n^3 + n^2}4 = \bsb{\frac{n(n+1)}2}^2, \\
\sum^n_{k=1} k^4 & = & \frac{6n^5 + 15n^4+10n^3 - n}{30} = \frac{n(n+1)(2n+1)(3n^2 + 3n -1)}{30}, \\
\sum^n_{k=1} k^5 & = & \frac{2n^6 + 6n^5 + 5n^4 - n^2}{12} = \frac{n^2(n+1)^2(2n^2 + 2n -1)}{12}, \\
\sum^n_{k=1} k^6 & = & \frac{6n^7 + 21n^6 + 21n^5 - 7n^3 + n}{42} = \frac{n(n+1)(2n+1)(3n^4 + 6n^3 - 3n+1)}{42}.
\eeast
\end{corollary}


\subsection{Pascal's identity}

\begin{theorem}
$\sigma_m(n) := \sum^n_{k=1}k^m$ is a polynomial in $n$ of degree $m+1$.
\end{theorem}

\begin{proof}[\bf Proof]
For $m,n\in \N$, by binomial theorem\footnote{theorem needed.},
\beast
(n+1)^{m+1} -1 & = & \sum^n_{k=1}\bb{(k+1)^{m+1} - k^{m+1}} = \sum^n_{k=1}\bb{\sum^{m+1}_{r=0} \binom{m+1}{r} k^r - k^{m+1}} \\
& = &  \sum^n_{k=1}\sum^{m}_{r=0} \binom{m+1}{r} k^r = \sum^{m}_{r=0} \binom{m+1}{r} \bb{\sum^n_{k=1} k^r} = \sum^{m}_{r=0} \binom{m+1}{r} \sigma_r(n)\qquad (*)
\eeast
from which it follows (by induction) that $\sigma_m(n)$ is a polynomial in $n$ of degree $m+1$. ($*$) is called Pascal's identity\index{Pascal's identity}.
\end{proof}

\begin{remark}
$\sigma_k(z)$ can be considered as a polynomial in a complex variable $z$ and $\sigma_k(0) = 0$.
\end{remark}



\subsection{Faulhaber polynomials}

Faulhaber polynomial was first proposed by \footnote{citation needed. See C.G.J. Jacobi, De usu legitimo formulae summatoriae Maclaurinianae, Journal f\"ur die reine und angewandte Mathematik, Vol 2, 263-272, 1834}.

\begin{theorem}
If $m$ is odd, then
\be
\sum^n_{k=1} k^m = 1^m + 2^m + \dots + n^m
\ee
is a polynomial function of
\be
a = \sum^n_{k=1} k = 1+ 2 + \dots + n = \frac {n(n+1)}2.
\ee

More generally, for $p\in \N$,
\be
\sum^n_{k=1} k^{2p+1}= \frac 1{2^{2p+2}(2p+2)}\sum^p_{k=0}\binom{2p+2}{2k}(2-2^{2k})B_{2k}\bb{(8a+1)^{p+1-k}-1}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}





\section{Hyperbolic functions}

%\subsection{Hyperbolic functions}

%\be
%\cosh z = \frac 12(e^z + e^{-z}), \quad \sinh z = \frac 12(e^z - e^{-z}), \quad z\in\C
%\ee

%From this,
%\be
%\left\{\ba{rcl}
%\cosh z = \cos iz\\
%i\sinh z = \sin iz
%\ea\right.,\quad
%\left\{
%\ba{rcl}
%(\cosh z)' = \sinh z\\
%(\sinh z)' = \cosh z
%\ea\right.,\quad \cosh^2 z - \sinh^2 z =1
%\ee

%\begin{remark}
%\ben
%\item The other trigonometric functions ($\tan, \sec$, etc.) are defined in the usual way.

%\ite
%\een
%\end{remark}



\subsection{Definitions}

\begin{definition}[hyperbolic functions]\label{hyperbolic_function}
The hyperbolic functions are:

Hyperbolic sine:
\be
\sinh x = \frac {e^x - e^{-x}} {2} = \frac {e^{2x} - 1} {2e^x}
\ee

Hyperbolic cosine:
\be
\cosh x = \frac {e^x + e^{-x}} {2} = \frac {e^{2x} + 1} {2e^x}
\ee

Hyperbolic tangent:
\be
\tanh x = \frac{\sinh x}{\cosh x} = \frac {e^x - e^{-x}} {e^x + e^{-x}} = \frac{e^{2x} - 1} {e^{2x} + 1}
\ee

Hyperbolic cotangent:
\be
\coth x = \frac{\cosh x}{\sinh x} = \frac {e^x + e^{-x}} {e^x - e^{-x}} = \frac{e^{2x} + 1} {e^{2x} - 1}
\ee

Hyperbolic secant:
\be
\operatorname{sech}\,x = \left(\cosh x\right)^{-1} = \frac {2} {e^x + e^{-x}} = \frac{2e^x} {e^{2x} + 1}
\ee

Hyperbolic cosecant:
\be
\operatorname{csch}\,x = \left(\sinh x\right)^{-1} = \frac {2} {e^x - e^{-x}} = \frac{2e^x} {e^{2x} - 1}
\ee

Hyperbolic functions can be introduced via imaginary circular angles:

Hyperbolic sine: \be \sinh x = - i \sin \bb{ix} \ee

Hyperbolic cosine: \be \cosh x = \cos \bb{ix} \! \ee

Hyperbolic tangent: \be \tanh x = - i \tan \bb{ix} \! \ee

Hyperbolic cotangent: \be \coth x = i \cot \bb{ix} \! \ee

Hyperbolic secant: \be \operatorname{sech} x = \sec \bb{ix}  \ee

Hyperbolic cosecant: \be \operatorname{csch}x = i \csc\bb{ix} \ee where $i$ is the imaginary unit defined by $i^2 = -1$. The complex forms in the definitions above derive from Euler's formula.
\end{definition}

\begin{proposition}\label{pro:hyperbolic_function_relation}
Odd and even functions:
\be
\sinh(-x) = -\sinh (x),\quad  \cosh(-x) = \cosh (x)
\ee

Hence:
\begin{align}
\tanh(-x) &= -\tanh (x) \\ \coth(-x) &= -\coth (x) \\ \operatorname{sech}(-x) &= \operatorname{sech}(x) \\ \operatorname{csch}(-x) &= -\operatorname{csch}(x) \end{align}

It can be seen that cosh x and sech x are even functions; the others are odd functions.
\begin{align} \operatorname{arsech}(x) &= \operatorname{arcosh} \left(\frac{1}{x}\right) \\ \operatorname{arcsch}(x) &= \operatorname{arsinh} \left(\frac{1}{x}\right) \\ \operatorname{arcoth}(x) &= \operatorname{artanh} \left(\frac{1}{x}\right) \end{align}


Hyperbolic sine and cosine satisfy the identity
\be
\cosh^2 (x) - \sinh^2 (x) = 1\,
\ee
which is similar to the Pythagorean trigonometric identity. One also has
\begin{align} \operatorname{sech} ^{2}(x) &= 1 - \tanh^{2}(x) \\ \coth^{2}(x) &= 1 + \operatorname{csch}^{2}(x) \end{align}
for the other functions.

The hyperbolic tangent is the solution to the nonlinear boundary value problem\footnote{see wiki}:
\be
\frac{1}{2} f'' = f^3 - f ; \quad f(0) = f'(\infty) = 0
\ee

It can be shown that the area under the curve of $\cosh (x)$ is always equal to the arc length:
\be
\text{area} = \int_a^b{ \cosh{(x)} } \ dx = \int_a^b\sqrt{1 + \left(\frac{d}{dx} \cosh{(x)}\right)^2} \ dx = \text{arc length}
\ee

Sums of arguments:
\begin{align} \cosh {(x + y)} &= \sinh{(x)} \cdot \sinh {(y)} + \cosh {(x)} \cdot \cosh {(y)} \\ \sinh {(x + y)} &= \cosh{(x)} \cdot \sinh {(y)} + \sinh {(x)} \cdot \cosh {(y)} \end{align}

Sum and difference of cosh and sinh:
\begin{align} \cosh{(x)} + \sinh{(x)} &= e^x \\ \cosh{(x)} - \sinh{(x)} &= e^{-x} \end{align}
\end{proposition}



\subsection{Euler numbers}

\begin{definition}[Euler numbers\index{Euler numbers}]\label{def:euler_numbers}
The Euler numbers are a sequence En of integers defined by the following Taylor series expansion:
\be
\frac{1}{\cosh t} = \frac{2}{e^{t} + e^ {-t} } = \sum_{n=0}^\infty \frac{E_n}{n!} \cdot t^n
\ee
where $\cosh t$ is the hyperbolic cosine. The Euler numbers appear as a special value of the Euler polynomials.
\end{definition}

The odd-indexed Euler numbers are all zero. The even-indexed ones have alternating signs. Some values are:
\beast
E_0 & = & 1 \\
E_2 & = & -1 \\
E_4 & = & 5 \\
E_6 & = & -61 \\
E_8 & = & 1,385 \\
E_{10} & = & -50,521 \\
E_{12} & = & 2,702,765 \\
E_{14} & = & -199,360,981 \\
E_{16} & = & 19,391,512,145 \\
E_{18} & = & -2,404,879,675,441
\eeast

%%Some authors re-index the sequence in order to omit the odd-numbered Euler numbers with value zero, and/or change all signs to positive. This encyclopedia adheres to the convention adopted above.
%
%The Euler numbers appear in the Taylor series expansions of the secant and hyperbolic secant functions. The latter is the function in the definition. They also occur in combinatorics, specifically
%when counting the number of alternating permutations of a set with an even number of elements.
%
%Contents
%
%    1 Explicit formulas
%        1.1 Iterated sum
%        1.2 Sum over partitions
%        1.3 Determinant
%    2 Asymptotic approximation
%    3 Euler zigzag numbers
%    4 Generalized Euler numbers
%    5 See also
%    6 References
%    7 External links
%                                  Explicit formulas Iterated sum

\begin{proposition}
An explicit formula for Euler numbers is given by:
\be
E_{2n}=i\sum _{k=1}^{2n+1} \sum _{j=0}^k {k\choose j}\frac{(-1)^j(k-2j)^{2n+1}}{2^k i^k k}
\ee
where $i$ denotes the imaginary unit with $i^2= -1$.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{Ross Tang, "An Explicit Formula for the Euler zigzag numbers (Up/down numbers) from power series"}
\end{proof}



%\section{Polynomials}%\subsection{Le polynomials}

\section{Polynomials}

\subsection{Basic properties}


Newton's identities, also known as the Newton-Girard formulae, give relations between two types of symmetric polynomials, namely between power sums and elementary symmetric polynomials.

\begin{proposition}[Newton's identities]\label{pro:newton_identities}

\end{proposition}

\begin{proof}[\bf Proof]
\footnote{see wiki, Newton's identities.}
\end{proof}

\subsection{Chebyshev polynomials}



\section{Taylor Series}

\subsection{Maclaurin series}

\begin{definition}[Maclaurin series]
A Maclaurin series is a Taylor series expansion of a function about 0,
\be
f(z) = \sum^\infty_{n=0} \frac{f^{(n)}(0)}{n!}z^n = f(0) + f'(0)z + \frac{f''(0)}{2!}z^2 + \dots .
\ee
\end{definition}

\subsection{Exponential function}

\begin{proposition}[Maclaurin series of exponential function]
For $z\in \C$, the Maclaurin series of exponential function is
\be
\exp\bb{z} = \sum^\infty_{n=0} \frac{z^n}{n!} = 1 + z + \frac{z^2}{2!} + \frac{z^3}{3!} + \dots.
\ee
\end{proposition}

%\subsection{Logarithm function}


%\begin{proposition}
%For $z\in \C$ with $\abs{z}<1$ and $\arg z \in [0,2\pi)$, the Maclaurin series of (principal value) logarithm function is
%\beast
%\Log(1-z) & = &  -\sum^\infty_{n=1}\frac{z^n}{n} = -z - \frac{z^2}2- \frac{z^3}{3} - \dots , \\
%\Log(1+z) & = & \sum^\infty_{n=1} (-1)^{n+1} \frac{z^n}{n} = z - \frac{z^2}{2} + \frac{z^3}{3}.
%\eeast
%\end{proposition}

\subsection{Geometric series}

%\begin{proposition}
%For $x\in \R$ with $\abs{x}<1$,
%\be
%\sum^\infty_{n=1} nx^{n-1} = \frac 1{(1-x)^2}.
%\ee

%Similarly,
%\be
%\sum^\infty_{n=2} n(n-1) x^{n-2} = \frac 2{(1-x)^3},
%\ee
%\be
%\sum^\infty_{n=3} n(n-1)(n-2) x^{n-3} = \frac 6{(1-x)^4}.
%\ee
%\end{proposition}

\begin{proposition}[Geometric series]
For $z\in \C$ with $\abs{z}<1$,
\be
\frac{1}{1-z} = \sum^\infty_{n=0}z^n ,\quad \frac{1}{(1-z)^2} = \sum^\infty_{n=1}nz^{n-1} ,\quad \frac{2}{(1-z)^3} = \sum^\infty_{n=2}n(n-1)z^{n-2}.
\ee
\end{proposition}

\subsection{Binomial series}

\begin{proposition}
For $z\in \C$ with $\abs{z}<1$ and any $\alpha\in \C$,
\be
(1+z)^\alpha = \sum^\infty_{n=0} \binom{\alpha}{n} z^n
\ee
with general binomial coefficients
\be
\binom{\alpha}{n} = \prod^n_{k=1} \frac{\alpha -k+1}{k} = \frac{\alpha(\alpha-1)\dots (\alpha -n+1)}{n!}.
\ee
\end{proposition}

\begin{example}
\beast
(1+z)^{1/2} & = & 1 + \frac 12 z - \frac{1}{8}z^2 + \frac{1}{16}z^3 - \frac{5}{128}z^4 + \frac{7}{256}z^5 -\dots \\
(1-z)^{-1/2} & = & 1 - \frac 12 z + \frac{3}{8}z^2 - \frac{5}{16}z^3 + \frac{35}{128}z^4 - \frac{63}{256}z^5 -\dots
\eeast
\end{example}

\subsection{trigonometric functions}

\begin{proposition}[trigonometric functions, sine and cosine]
For all $z\in \C$,
\beast
\sin z & = & \sum^\infty_{n=0} \frac{(-1)^n}{(2n+1)!}z^{2n+1} = z - \frac{z^3}{3!} + \frac{z^5}{5!} - \dots \\
\cos z & = & \sum^\infty_{n=0} \frac{(-1)^n}{(2n)!}z^{2n} = 1 - \frac{z^2}{2!} + \frac{z^4}{4!} - \dots
\eeast
\end{proposition}


\begin{proposition}
For all $z\in \C$ with $\abs{z} <\frac {\pi}2$,
\beast
\tan z & = & \sum^\infty_{n=1} \frac{B_{2n}(-4)^n(1-4^n)}{(2n)!}z^{2n-1} = z + \frac{z^3}3 + \frac{2z^5}{15} + \dots ,\\
\sec z & = & \sum^\infty_{n=0} \frac{(-1)^nE_{2n}}{(2n)!}z^{2n}  = 1 + \frac 12z^2 + \frac{5}{24}z^4 + \frac{61}{720}z^6 + \frac{277}{8064}z^8 + \dots.
\eeast
where $B_k$ are Bernoulli numbers and $E_k$ are Euler numbers.
\end{proposition}


\subsection{Maclaurin series of inverse trigonometric functions}%Maclaurin series of i

\begin{proposition}[Maclaurin series of inverse sine and inverse cosine]
For all $z\in \C$ with $\abs{z} \leq 1$,
\beast
\Arcsin z & = & \sum^\infty_{n=0} \frac{(2n)!}{4^n (n!)^2(2n+1)}z^{2n+1} = \sum^\infty_{n=0} \frac{(2n-1)!!}{(2n+1)2^n n!}z^{2n+1} = z + \frac 16 z^3 + \frac{3}{40} z^5 + \frac{5}{112}z^7 +  \frac{35}{1152}z^9 + \dots, \\
\Arccos z & = & \frac {\pi }2 - \arcsin z = \frac {\pi }2 - \sum^\infty_{n=0} \frac{(2n)!}{4^n (n!)^2(2n+1)}z^{2n+1}.
\eeast%Furthermore, for $\abs{z} \leq 1$ with $z\neq \pm i$,
%\be
%\arctan z = \sum^\infty_{n=0} \frac{(-1)^n}{2n+1}z^{2n+1}.
%\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


%\begin{proposition}
%For $x\in [-1,1]$,
%\be
%\arcsin x = \sum^\infty_{n=0} \frac{(2n-1)!!}{(2n+1)2^n n!}x^{2n+1} = x + \frac 16 x^3 + \frac{3}{40} x^5 + \frac{5}{112}x^7 +  \frac{35}{1152}x^9 + \dots
%\ee
%\end{proposition}

\begin{remark}
The radius of convergence of $\arcsin z$ is calculated by
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{\frac{(2n+1)!!}{(2n+3)2^{n+1}(n+1)!}}{\frac{(2n-1)!!}{(2n+1)2^n n!}}} = \frac{\frac{2n+1}{2(2n+3)(n+1)}}{\frac 1{2n+1}} = \abs{\frac{(2n+1)^2}{2(n+1)(2n+3)}} \to 1 \ \ra\ R=1.
\ee

Therefore, for $z=1$,
\be
\pi = \sum^\infty_{n=0} \frac{(2n-1)!!}{(2n+1)2^{n-1} n!} = \underbrace{2 + \frac 13 + \frac 3{20} + \frac{5}{56} + \frac{35}{576}}_{\approx 2.6334} + \dots
\ee

For $z=\frac 12$,
\be
\pi = 6\arcsin\frac 12 = 3 \sum^\infty_{n=0} \frac{(2n-1)!!}{(2n+1)8^n n! } = \underbrace{3 + \frac 1{8} + \frac 9{640} + \frac{15}{7168}}_{\approx 3.1412} + \dots
\ee
which is used to show that $\pi>3.14$.
\end{remark}

\begin{proposition}
For all $z\in \C$ with $\abs{z} \leq 1$,
\be
\bb{\arcsin z}^2 = \frac 12 \sum^\infty_{n=1} \frac{4^{n}(n!)^2}{n^2(2n)!}z^{2n} = z^2 + \frac 13z^4 + \frac{8}{45} z^6 + \frac{4}{35}z^8 + \frac{128}{1575}z^{10} + \dots.
\ee
\end{proposition}


\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{remark}
Therefore, for $z=1$\footnote{The second equation of $\bb{\arcsin x}^2$ has been checked.},
\be
\pi^2 =  2 \sum^\infty_{n=1} \frac{4^{n}(n!)^2}{n^2(2n)!} = \underbrace{4 + \frac 43 + \frac {32}{45} + \frac{16}{35} + \frac{512}{1575}}_{\approx 2.6128^2} + \dots
\ee

For $z=\frac 12$,
\be
\pi^2 = 36\bb{\arcsin\frac 12}^2 = 18 \sum^\infty_{n=1} \frac{(n!)^2}{n^2 (2n)!} = \underbrace{9 + \frac 3{4} + \frac 1{10} + \frac{9}{560}}_{\approx 3.1410^2} + \dots
\ee
\end{remark}

%\begin{proposition}[Maclaurin series of inverse cosine]
%For $x\in [-1,1]$
%\be
%\arccos x = \frac {\pi}2 - \arcsin x=  \frac {\pi}2 - \sum^\infty_{n=0} \frac{(2n-1)!!}{(2n+1)2^n n!}x^{2n+1} =  \frac {\pi}2 - x - \frac 16 x^3 - \frac{3}{40} x^5 - \frac{5}{112}x^7 - \frac{35}{1152}x^9 -\dots
%\ee
%\end{proposition}


\begin{proposition}[Maclaurin series of inverse tangent]
For all $z\in \C$ with $\abs{z} \leq 1$ with $z\neq \pm i$,
\be
\Arctan z = \sum^\infty_{n=0} \frac{(-1)^n}{2n+1}z^{2n+1}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
See Theorem \ref{thm:complex_inverse_tangent_infinite_sum}.%{thm:principal_value_logarithm_expansion}.
\end{proof}


\subsection{Hyperbolic functions}

For hyperbolic functions, we have\footnote{see \cite{Abramowitz_1972}.$P_{85}$}%\begin{proposition}\label{pro:hyperbolic_functions_taylor_expansion}

\begin{proposition}[hyperbolic sine, hyperbolic cosine]
For all $z\in \C$,
\beast
\sinh z & = & \sum^\infty_{n=0} \frac{z^{2n+1}}{(2n+1)!} = z +\frac{z^3}{3!} + \frac{z^5}{5!}+ \frac{z^7}{7!} + \cdots\quad\abs{z} <\infty,\\
\cosh z & = & \sum^\infty_{n=0} \frac{z^{2n}}{(2n)!} = 1 +\frac{z^2}{2!} + \frac{z^4}{4!} + \frac{z^6}{6!} + \cdots\quad \abs{z} <\infty.
\eeast
\end{proposition}

In following propositions, $B_n$ is the $n$th Bernoulli numbers of the first kind\footnote{Actually, Bernoulli numbers of the first and the  second kind are the same except for the index $1$} (see Definition \ref{def:bernoulli_numbers_first_kind}) and $E_n$ is the $n$th Euler numbers (see Definition \ref{def:euler_numbers}).

\begin{proposition}[hyperbolic tangent]
For all $z\in \C$,% with $\abs{z} <\frac {\pi}2$,
\beast%\tanh z = \sum^\infty_{n=1} \frac{B_{2n}4^n(4^n-1)}{(2n)!}z^{2n-1}.
\tanh z & = & \sum^{\infty}_{n=1} \frac{4^n (4^n-1)B_{2n}z^{2n-1}}{(2n)!}  = z-\frac{1}{3}z^3+\frac{2}{15}z^5-\frac{17}{315}z^7+\cdots \quad \abs{z} < \frac{\pi}{2},\\
\coth z & = & \sum^{\infty}_{n=0} \frac{4^n B_{2n} z^{2n-1}}{(2n)!}  = \frac 1z + \frac 13z - \frac{1}{45}z^3 + \frac{2}{945}z^5- \cdots \quad \abs{z} < \pi.
\eeast
\end{proposition}

\begin{proposition}
For all $z\in \C$,
\beast
\sech z & = & \sum^\infty_{n=0} \frac{E_{2n}z^{2n}}{(2n)!} = 1 - \frac 12 z^2 + \frac 5{24} z^4 - \frac {61}{720} z^6 +\cdots \quad \abs{z} < \frac{\pi}{2}, \\
\csch z & = & -\sum^\infty_{n=0} \frac{2\bb{2^{2n-1}-1}B_{2n}z^{2n-1}}{(2n)!} = \frac 1z - \frac 16 z + \frac 7{360} z^3 - \frac {31}{15120} z^5 +\cdots \quad \abs{z} < \pi
\eeast
\end{proposition}

\begin{proposition}
For all $z\in \C$ with $\abs{z} \leq 1$,
\be
\arcsinh z = \sum^\infty_{n=0} \frac{(-1)^n (2n)!}{4^n (n!)^2(2n+1)}z^{2n+1}.
\ee
\end{proposition}

\begin{proposition}
For all $z\in \C$ with $\abs{z} \leq 1$ and $z\neq \pm 1$,
\be
\arctanh z = \sum^\infty_{n=0} \frac{z^{2n+1}}{2n+1}
\ee
\end{proposition}

%\subsection{Taylor expansion of functions}

% \be \sinh z = \sum^{\infty}_{n=0} \frac{z^{2n+1}}{(2n+1)!} = z + \frac{z^3}{3!} + \frac{z^5}{5!} + \frac{z^7}{7!} + \cdots\quad\abs{z} <\infty.
%\ee

%\be \cosh z = \sum^{\infty}_{n=0} \frac{z^{2n}}{(2n)!} = 1 + \frac{z^2}{2!} + \frac{z^4}{4!} + \frac{z^6}{6!} + \cdots\quad \abs{z} <\infty \ee

%\be \tanh z = \sum^{\infty}_{n=1} \frac{4^n (4^n-1)B_{2n}z^{2n-1}}{(2n)!}  = z-\frac{1}{3}z^3+\frac{2}{15}z^5-\frac{17}{315}z^7+\cdots \quad \abs{z} < \frac{\pi}{2} \ee

% \end{proposition}

\section{Convolution of Functions}

\subsection{Convolution of probability density functions}

The red lines are the convolutions of two probability density functions.

\begin{center}
\psset{xunit=1cm,yunit=4cm}
\begin{pspicture}[linewidth=1pt](-5,-.2)(5,0.75)
\psaxes[dx=1cm,Dx=1,Dy=0.5]{->}(0,0)(-5,0)(5,0.75)
%\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs 2 le {0.25}{0} ifelse}
\psplot[linecolor=green,plotpoints=200]{-5}{5}{x abs 1 le {0.5}{0} ifelse}
\psConv[plotpoints=100,Simpson=1000,linecolor=red]{-5}{5}(-10,10){abs 1 le {0.5}{0} ifelse}{abs 1 le {0.5}{0} ifelse}
\rput(4,0.5){$f_1(x) = f_2(x) = \left\{\ba{ll}
0.5 \quad\quad & \abs{x} \leq 1 \\
0 & \abs{x} >1
\ea\right.$}
\end{pspicture}
\end{center}

\begin{center}
\psset{xunit=1cm,yunit=4cm}
\begin{pspicture}[linewidth=1pt](-5,-.2)(5,0.75)
\psaxes[dx=1cm,Dx=1,Dy=0.5]{->}(0,0)(-5,0)(5,0.75)
\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs 2 le {0.25}{0} ifelse}
\psplot[linecolor=green,plotpoints=200]{-5}{5}{x abs 1 le {0.5}{0} ifelse}
\psConv[plotpoints=100,Simpson=1000,linecolor=red]{-5}{5}(-10,10){abs 2 le {0.25}{0} ifelse}{abs 1 le {0.5}{0} ifelse}
\rput(-4,0.5){$f_1(x) = \left\{\ba{ll}
0.5 \quad\quad & \abs{x} \leq 1 \\
0 & \abs{x} >1
\ea\right.$}
\rput(4,0.5){$f_2(x) = \left\{\ba{ll}
0.25 \quad\quad & \abs{x} \leq 2 \\
0 & \abs{x} >2
\ea\right.$}
\end{pspicture}
\end{center}




\begin{center}
\psset{xunit=1cm,yunit=4cm}
\begin{pspicture}[linewidth=1pt](-5,-.2)(5,0.75)
\psaxes[dx=1cm,Dx=1,Dy=0.5]{->}(0,0)(-5,0)(5,0.75)%\psplot[linecolor=blue,plotpoints=200]{-1}{1}{x abs 1 le {0.333}{0} ifelse}%\psplot[linecolor=blue,plotpoints=200]{-1}{1}{x -5 ge -1 le {0.333}{0} ifelse}
\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}
%\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs -3 exp 0.333 mul}
%\psplot[linecolor=blue,plotpoints=1000]{-5}{5}{x abs 1 ge -3 exp 0.333 mul}
\psplot[linecolor=green,plotpoints=200]{-5}{5}{x abs 1 le {0.5}{0} ifelse}
%\psConv[plotpoints=100,Simpson=1000,linecolor=red]{-5}{5}(-10,10){abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}{abs 1 le {0.5}{0} ifelse}
\psConv[plotpoints=100,Simpson=2000,linecolor=red]{-5}{5}(-10,10){abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}{abs 1 le {0.5}{0} ifelse}
\rput(-4,0.5){$f_1(x) = \left\{\ba{ll}
0.5 \quad\quad & \abs{x} \leq 1 \\
0 & \abs{x} >1
\ea\right.$}
\rput(4,0.5){$f_2(x) = \left\{\ba{ll}
\frac 13  & \abs{x} \leq 1 \\
\frac 13\abs{x}^{-3} \quad\quad & \abs{x} >1
\ea\right.$}
\end{pspicture}
\end{center}

\begin{center}
\psset{xunit=1cm,yunit=4cm}
\begin{pspicture}[linewidth=1pt](-5,-.2)(5,1.1)
\psaxes[dx=1cm,Dx=1,Dy=1]{->}(0,0)(-5,0)(5,1.1)%\psplot[linecolor=blue,plotpoints=200]{-1}{1}{x abs 1 le {0.333}{0} ifelse}%\psplot[linecolor=blue,plotpoints=200]{-1}{1}{x -5 ge -1 le {0.333}{0} ifelse}
\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}
%\psplot[linecolor=blue,plotpoints=200]{-5}{5}{x abs -3 exp 0.333 mul}
%\psplot[linecolor=blue,plotpoints=1000]{-5}{5}{x abs 1 ge -3 exp 0.333 mul}
\psplot[linecolor=green,plotpoints=200]{-5}{5}{x abs 0.5 le {1}{0} ifelse}
%\psConv[plotpoints=100,Simpson=1000,linecolor=red]{-5}{5}(-10,10){abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}{abs 1 le {0.5}{0} ifelse}
\psConv[plotpoints=100,Simpson=2000,linecolor=red]{-5}{5}(-10,10){abs 1 ge {x abs -3 exp 0.3333 mul}{0.3333} ifelse}{abs 0.5 le {1}{0} ifelse}
\rput(-4,0.5){$f_1(x) = \left\{\ba{ll}
1 \quad\quad & \abs{x} \leq 0.5 \\
0 & \abs{x} >0.5
\ea\right.$}
\rput(4,0.5){$f_2(x) = \left\{\ba{ll}
\frac 13  & \abs{x} \leq 1 \\
\frac 13\abs{x}^{-3} \quad\quad & \abs{x} >1
\ea\right.$}
\end{pspicture}
\end{center}



\section{Theta Functions}

\footnote{See \cite{Bellman_1961} for the proof.}

\begin{definition}[Jacobi theta function\index{Jacobi theta function}]\label{def:jacobi_theta_function}
Jacobi theta function (named after Carl Gustav Jacob Jacobi) is a function defined\footnote{details needed.} for two complex variables $z$ and $\tau$, where $z$ can be any complex number and $\tau$
is confined to the upper half-plane, which means it has positive imaginary part. It is given by the formula
\be
\vartheta(z, \tau) = \sum_{n=-\infty}^\infty \exp \bb{\pi i n^2 \tau + 2 \pi i n z} = 1 + 2 \sum_{n=1}^\infty \left(e^{\pi i\tau}\right)^{n^2} \cos(2\pi n z) = \sum_{n=-\infty}^\infty q^{n^2}\eta^n
\ee
where $q = \exp(\pi i \tau)$ and $\eta = \exp(2\pi iz)$.
\end{definition}

\begin{remark}
If $\tau$ is fixed, this becomes a Fourier series for a periodic entire function of $z$ with period 1; in this case, the theta function satisfies the identity
\be
\vartheta(z+1, \tau) = \vartheta(z, \tau).
\ee

The function also behaves very regularly with respect to its quasi-period\footnote{explanation needed.} $\tau$ and satisfies the functional equation
\be
\vartheta(z+a+b\tau,\tau) = \exp(-\pi i b^2 \tau -2 \pi i b z)\vartheta(z,\tau)
\ee
where $a$ and $b$ are integers.
\end{remark}

\begin{theorem}\label{thm:jacobi_theta_function_transform}
For Jacobi theta function $\vartheta(z,\tau)$, we have that (see \cite{Bellman_1961}.$P_{4}$)
\be
\vartheta \bb{\frac{z}{\tau}, \frac{-1}{\tau}} = \alpha \vartheta \bb{z, \tau} \ee where \be \alpha = (-i \tau)^{1/2} \exp\bb{\frac{\pi}{\tau} i z^2 }.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed. This is actually $\theta_3$ in \cite{Bellman_1961}.}
\end{proof}

\begin{proposition}
For $s\in \C$ with $\Re s >0$, we have
\be
\frac 1s + 2\sum^\infty_{n=1}\frac 1{n^2 + s} = \frac {\pi}{\sqrt{s}} \frac{1+e^{-2\pi\sqrt{s}}}{1-e^{-2\pi\sqrt{s}}} =   \frac {\pi}{\sqrt{s}}\coth\bb{\pi\sqrt{s}}.
\ee
\end{proposition}

\begin{remark}
This is a general case of equation
\be
\sum^\infty_{n=1} \frac 1{n^2 + a^2} = \frac {\pi a \coth(\pi a) -1}{2a^2},\quad a>0.
\ee%\in \R\backslash\bra{0}.\ee
\end{remark}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\section{Summary}

\begin{figure}[h]%[t]
\begin{center}
\begin{pspicture}(-4,-2)(4,4.5)
%\psaxes[ticks=none,labels=none]{->}(0,0)(-4,-1)(4,4)
\psset{plotpoints=500,linewidth=0.5pt,arrowscale =2}

\pstGeonode[PointSymbol=none,PointName=none](-3.5,4.2){O1}(-5,4){O2}(-2.5,4.2){A1}(-1,4){A2}(1,4){A3}(-2,3.5){B1}(-4,3.5){B2}(-3,3){B3}(3,2.5){C1}(3,2){C2}
\pstGeonode[PointSymbol=none,PointName=none](-3,2.5){D1}(-3,2){D2}(-3,1.5){E1}(-3,1){E2}(-2,0.5){F1}(1,0.5){F2}(0,0){F3}(-2,0){F4}(2,0){F5}(0,-1.5){G1}(-3,-0.5){H1}(3,-0.5){I1}

\psline[linecolor=black]{->}(O1)(A1)
\psline[linecolor=black]{->}(O2)(B2)
\psline[linecolor=black]{->}(A2)(B1)
\psline[linecolor=black]{->}(A3)(C1)
\psline[linecolor=black]{->}(B3)(D1)
\psline[linecolor=black]{->}(D2)(E1)
\psline[linecolor=black]{->}(E2)(F1)
\psline[linecolor=black]{->}(C2)(F2)
\psline[linecolor=black]{->}(F3)(G1)
\psline[linecolor=black]{->}(F4)(H1)
\psline[linecolor=black]{->}(F5)(I1)
%\psline[linestyle=dashed](Z)(Y)


\rput[cb](-5,4.2){infinite summation}
\rput[cb](0,4.2){natural exponential function}

\rput[cb](-3,3.2){trigonometric function}
\rput[cb](3,2.2){real logarithm function}

\rput[cb](-3,2.3){real inverse trigonometric function}
\rput[cb](-3,1.3){argument}

\rput[cb](0,0.3){complex logarithm function}
\rput[cb](0,-1.7){complex inverse trigonometric function}
\rput[cb](-3,-0.7){complex exponential function}
\rput[cb](3,-0.7){complex power function}

\end{pspicture}
\end{center}
\end{figure}


%\be
%\text{natural exponential function} \ra \left\{\ba{l}
%\text{real logarithm function (as inverse)} \\
%\text{trigonometric function}\ \ra \ \text{argument}
%\ea\right. \ \ra\ \text{complex logarithm function}
%\ee

\section{Problems}


\subsection{Logarithm function}

\begin{problem}
For any $x\in [0,1]$,
\be
x - \frac {x^2}2 \leq \log (1+x) \leq x - \frac{x^3}{2(1+x)}.
\ee
\end{problem}

\begin{solution}[\bf Solution.]
\footnote{proof needed.}
\end{solution}



\subsection{Gamma function}


\begin{problem}
Show that
\be
1+\frac 12 + \frac 13 + \dots + \frac 1n = \int^1_0 \frac{1-(1-t)^n}{t} dt
\ee
and hence that Euler's constant is given by\footnote{may also be written by $\int^1_0\bb{1-e^{-t}}\frac{dt}t - \int^\infty_1 \frac{e^{-t}dt}t$.}
\be
\lim_{n\to \infty} \bb{\int^1_0 \bb{1-\bb{1-\frac tn}^n}\frac {dt}t - \int^n_1 \bb{1-\frac tn}^n \frac {dt}t}.
\ee
\end{problem}

\begin{solution}[\bf Solution.]
\footnote{solution needed.}
\end{solution}

\begin{problem}
Show that
\be
\prod^\infty_{n=1} \bb{\bb{1 - \frac x{z+n}}e^{\frac xn}} = \frac{e^{\gamma x}\Gamma(z+1)}{\Gamma(z-x+1)}.
\ee
\end{problem}

\begin{solution}[\bf Solution.]
\footnote{solution needed.}
\end{solution}



\begin{problem}
For any $z\in \C\bs \bra{0,-1,-2,-3,\dots}$,
\be
\frac 1{\Gamma(z+1)} + \frac 1{\Gamma(z+2)} + \frac 1{\Gamma(z+3)} + \dots = \frac e{\Gamma(z)}\bb{\frac 1z - \frac 1{1!}\frac 1{z+1} + \frac 1{2!}\frac 1{z+2} - \dots}
\ee
\end{problem}

\begin{solution}[\bf Solution.]
Consider the expression
\be
\frac 1z + \frac 1{z(z+1)} + \frac 1{z(z+1)(z+2)} + \dots + \frac 1{z(z+1)\dots(z+m)}.
\ee

It can be expressed\footnote{details needed.} in partial fractions in the form $\sum^m_{n=0}\frac{a_n}{z+n}$, where
\be
a_n = \frac{(-1)^n}{n!}\bb{1 +\frac 1{1!} + \frac 1{2!} + \dots + \frac 1{(m-n)!}}  = \frac{(-1)^n}{n!} \bb{e- \sum^\infty_{r=m-n+1}\frac 1{r!}}.
\ee

Noting that
\be
\sum^\infty_{r= m-n+1}\frac 1{r!}< \frac{e}{(m-n+1)!} \ \ra\ \sum^m_{n=0} \frac{(-1)^n}{n!}\frac 1{z+n}\bb{\sum^\infty_{r=m-n+1}\frac 1{r!}} \to 0
\ee
as $m\to \infty$ when $z$ is not a negative integer.
\end{solution}

%\subsection{Gamma function}

\begin{problem}
Show that\footnote{see a course of modern analysis, Whittaker and Watson p35}
\be
\frac{1\cdot 2\cdot \dots \cdot (n-1)n^z}{(z+1)(z+2)\dots (z+n-1)}
\ee
tends to a finite limit as $n\to \infty$, unless $z$ is a negative integer.
\end{problem}

\begin{remark}
This is equal to $z\Gamma(z)$ (see Proposition \ref{pro:gauss_limit_gamma_function}).
\end{remark}

\begin{solution}[\bf Solution.]
When $z$ is a negative integer the expression does not exists because one of the factors in the denominator vanishes. Thus, the expression can be written as %a product of which the $n$th factor is
\beast
\prod^n_{k=1}\frac{k}{z+k}\bb{\frac{k+1}{k}}^z & = &  \prod^n_{k=1} \bb{1+\frac 1k}^z \bb{1+\frac zk}^{-1}= \prod^n_{k=1} \bb{1+\frac{z}{k} + \frac{z(z-1)}{2k^2} + O\bb{\frac 1{k^3}}} \bb{1-\frac{z}{k} + \frac{2z^2}{2k^2} + O\bb{\frac 1{k^3}}} \\
& = & \prod^n_{k=1} \bb{1 +\frac{z}{k}-\frac{z}{k} -\frac{z^2}{k^2} + \frac{z(z-1)}{2k^2} + \frac{2z^2}{2k^2}+O\bb{\frac 1{k^3}} } = \prod^n_{k=1} \bb{1 + \frac{z(z-1)}{2k^2} +O\bb{\frac 1{k^3}} } \\
& = & 1 +  \sum^n_{k=1}\bb{ \frac{z(z-1)}{2k^2} + O\bb{\frac 1{k^3}}}
\eeast

Note that we can expand the power by binomial series in the above steps. Therefore this product is absolute convergent with the convergent series $\sum^\infty_{n=1}\frac 1{n^2}$.
\end{solution}

\subsection{Trigonometric functions}

\begin{problem}
Prove that %for $z\in \Z\bs $
\be
z\bb{1 - \frac z{\pi}}\bb{1 - \frac {z}{2\pi}}\bb{1 + \frac z{\pi}}\bb{1 - \frac {z}{3\pi}}\bb{1 - \frac {z}{4\pi}}\bb{1 + \frac {z}{2\pi}} \dots = e^{-\frac{z}{\pi}\ln 2}\sin z.
\ee
\end{problem}

\begin{proof}[\bf Proof]
For the given product
\beast
& & \lim_{k\to \infty} z\bb{1-\frac z{\pi}}\bb{1-\frac {z}{2\pi}}\bb{1+\frac z{\pi}} \dots \bb{1-\frac z{(2k-1)\pi}}\bb{1-\frac z{2k\pi}}\bb{1+\frac z{k\pi}} \\
& = & \lim_{k\to \infty}e^{\frac{z}{\pi}\bb{-1-\frac 12 + 1  - \dots -\frac 1{2k-1} - \frac 1{2k} + \frac 1k}} z\bb{1-\frac z{\pi}}e^{\frac{z}{\pi}}\bb{1-\frac {z}{2\pi}}e^{\frac{z}{2\pi}}\dots \bb{1-\frac z{2k\pi}}e^{\frac{z}{2k\pi}} \bb{1+\frac z{k\pi}}e^{-\frac{z}{k\pi}} \\
& = & \lim_{k\to \infty}e^{-\frac{z}{\pi}\bb{1-\frac 12 \dots + \frac 1{2k-1} -\frac 1{2k}} } z\bb{1-\frac z{\pi}}e^{\frac{z}{\pi}}\bb{1+\frac {z}{\pi}}e^{-\frac{z}{\pi}} \bb{1-\frac z{2\pi}}e^{\frac{z}{2\pi}}\bb{1+\frac {z}{2\pi}}e^{-\frac{z}{2\pi}} \dots \bb{1-\frac z{k\pi}}e^{\frac{z}{k\pi}} \bb{1+\frac z{k\pi}}e^{-\frac{z}{k\pi}}
\eeast
since the product whose factors
\be
\bb{1-\frac{z}{k\pi}}e^{\frac{z}{k\pi}}
\ee
is absolutely convergent\footnote{details needed.}, and so the order of its factors can be altered. Since
\be
\ln 2 = 1 -\frac 12 + \frac 13 - \frac 14 + \dots,
\ee
this shows that the given product is equal to $e^{-\frac{z}{\pi}\ln 2}\sin z$ by Theorem \ref{thm:trigonometric_function_infinite_product}.
\end{proof}





