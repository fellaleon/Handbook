\chapter{Complex Analysis}

\section{Complex Numbers}

\subsection{Complex numbers}

\begin{definition}[complex number]
A complex number $z$ is defined as an ordered pair
\be
z = (x,y),
\ee
where $x$ and $y$ are both real numbers. Commonly, we write
\be
z = x+ iy,
\ee
where $i$ is a symbol such that $i^2 = -1$. Symbolically, we write
\be
\Re(z) =x,\quad \Im(z) = y
\ee
which are called real part\index{real part} and imaginary part\index{imaginary part} of $z$, respectively. If $y=0$, the complex number is real. If $x= 0$ and $y\neq 0$, the complex number is called purely imaginary.

The set of all complex numbers is denoted by $\C$.
\end{definition}

\begin{figure}[h!]%[t]
\begin{center}
\begin{pspicture}(-4,-0.5)(4,4)
\psaxes[ticks=none,labels=none]{->}(0,0)(-4,-1)(4,4)
\psset{plotpoints=500,linewidth=1pt,arrowscale =2}

\pstGeonode[PointSymbol=none,PointName=none](1,0.1){A1}(1,-0.1){A2}(-0.1,1){B1}(0.1,1){B2}
\pstGeonode[PointSymbol=default,PointName=none](2,0){X}(0,2){Y}(2,2){Z}
%\pstCircleOA[PointSymbol=none,PointName=none,linestyle=dashed,linecolor=green]{O}{A}

\psline[linecolor=blue]{->}(O)(Z)
\psline[linestyle=dashed](Z)(X)
\psline[linestyle=dashed](Z)(Y)

\psset{linewidth=0.5pt}
\psline(A1)(A2)
\psline(B1)(B2)

%\psline[linecolor=red]{->}(B)(Z)
%\psline[linestyle=dashed,linecolor=green](B)(C)
%\psline[linestyle=dashed,linecolor=green](Z)(D)
%
%\pstMarkAngle[MarkAngleRadius=0.2,LabelAngleOffset=-15,LabelSep=1.2]{C}{B}{Z}{$\Arg(z+i)$}
%\pstMarkAngle[MarkAngleRadius=0.2,LabelAngleOffset=-15,LabelSep=0.6]{D}{Z}{A}{$\Arg(i-z)$}
%
%\rput[lb](0.1,3.1){$i$}
%\rput[lb](0.1,-3.4){$-i$}
%
%\rput[lb](0.5,1.8){$i-z$}
%\rput[lb](1.5,-1){$z+i$}
%
%\rput[lb](1.1,0.6){$z$}
%
%\pstGeonode[PointSymbol=o,PointName=none](0,3){AA}(0,-3){BB}
%
\rput[lb](1.7,2.1){$z = x+ iy$}
\rput[lb](1.9,-0.3){$x$}
\rput[lb](-0.4,1.9){$iy$}
\rput[lb](0.85,-0.3){$1$}
\rput[lb](-0.3,0.9){$i$}

\rput[lb](3.5,-0.3){real axis}
\rput[lb]{90}(-0.2,2.3){imaginary axis}
\end{pspicture}
\end{center}
\end{figure}


\begin{remark}
The complex numbers can be visualized as the usual Euclidean plane by the following simple identification: the complex number $z = x+iy \in \C$ is identified with the point $(x,y)\in \R^2$. For example, 0 corresponds to the origin and $i$ corresponds to $(0,1)$. So any complex number $z$ can be treated as a vector in $\R^2$.

Naturally, the $x$ and $y$ axis of $\R^2$ are called the real axis and imaginary axis, which form the complex plane.
\end{remark}

\begin{definition}[equivalence of complex numbers]
For two complex numbers $z_1 = x_1+iy_1$ and $z_2 = x_2+ iy_2$, we say $z_1 =z_2$ if 
\be
x_1=x_2,\quad y_1 = y_2.
\ee
\end{definition}


\subsection{Algebra of complex numbers}

\begin{definition}[algebra of complex numbers]\label{def:algebra_complex}
Let $z_1,z_2\in \C$ with $z_1 = x_1+iy_1$ and $z_2 = x_2 + iy_2$. Then the addition is defined by
\be
z_1 + z_2 := (x_1+x_2) + i(y_1+y_2)
\ee
and substraction is defined bt
\be
z_1 - z_2 :=  (x_1-x_2) + i(y_1-y_2)
\ee

The multiplication is defined by
\beast
z_1z_2 & := & ( x_1+iy_1)(x_2+iy_2) = x_1x_2 + ix_1y_2 + ix_2y_1 + i^2 y_1y_2 \\
& = & (x_1x_2-y_1y_2) + i(x_1y_2 + x_2y_1).
\eeast
and for $z_2 \neq 0$ the division is define by
\beast
\frac{z_1}{z_2} & := & \frac{x_1+ iy_1}{x_2 + iy_2} = \frac{(x_1+ iy_1)(x_2 - iy_2)}{(x_2 + iy_2)(x_2 - iy_2)} = \frac{x_1x_2 + y_1y_2 + i(-x_1y_2 + x_2y_1)}{x_2^2 + y_2^2} \\
& = & \frac{x_1x_2 + y_1y_2 }{x_2^2 + y_2^2} + i\frac{ x_2y_1-x_1y_2 }{x_2^2 + y_2^2} .
\eeast
\end{definition}

\begin{example}
For $z_1 = 3+7i$ and $z_2 = 5 - 6i$,
\beast
z_1+ z_2 & = & (3+5) + i(7+(-6)) =8+ i,\\
z_1- z_2 & = & (3-5) + i(7+6) =-2+ 13i.
\eeast

Also,
\be
z_1z_2 = (3+7i)(5-6i) = (3\cdot 5 - 7 \cdot (-6)) + i(3\cdot (-6) + 7 \cdot 5) = 57 + 17i,
\ee
and
\be
\frac{z_1}{z_2} = \frac{3\cdot 5 + 7\cdot (-6)}{5^2 + 6^2} + \frac{7\cdot 5 - 3\cdot (-6)}{5^2 + 6^2}i = -\frac{27}{61} + \frac{53}{61}i.
\ee
\end{example}

\begin{proposition}
For all $z_i\in \C$, we have
\ben
\item [(i)] Commutativity. $z_1+z_2 = z_2+z_1$ and $z_1z_2 = z_2 z_1$.
\item [(ii)] Associativity. $(z_1+z_2)+ z_3 = z_1 + (z_2+z_3)$ and $(z_1z_2)z_3 = z_1(z_2z_3)$.
\item [(iii)] Distributivity. $z_1(z_2+z_3) = z_1z_2 + z_1z_3$.
\een
\end{proposition}

\begin{proof}[\bf Proof]
Direct result from Definition \ref{def:algebra_complex}.
\end{proof}

\begin{proposition}
The complex domain $\C$ is a field.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed. see \cite{Mathews_Howell_1997}}
\end{proof}

\subsection{Conjugate of complex number}

\begin{definition}[complex conjugate]
The complex conjugate of complex number $z = x+iy$ is defined by
\be
\ol{z} := x - iy,
\ee
and it is obtained by a reflection across the real axis in the plane.

\begin{figure}[h]%[t]
\begin{center}
\begin{pspicture}(-3,-2.5)(3,2.5)
\psaxes[ticks=none,labels=none]{->}(0,0)(-3,-2.5)(3,2.5)
\psset{plotpoints=500,linewidth=1pt,arrowscale =2}

%\pstGeonode[PointSymbol=none,PointName=none](1,0.1){A1}(1,-0.1){A2}(-0.1,1){B1}(0.1,1){B2}
\pstGeonode[PointSymbol=default,PointName=none](2,2){Z}
\pstGeonode[PointSymbol=default,PointName=none](2,-2){ZC}
%\pstCircleOA[PointSymbol=none,PointName=none,linestyle=dashed,linecolor=green]{O}{A}

\psline[linecolor=blue]{->}(O)(Z)
\psline[linecolor=red]{->}(O)(ZC)
\psline[linestyle=dashed](Z)(ZC)


%\psset{linewidth=0.5pt}
%\psline(A1)(A2)
%\psline(B1)(B2)
%
\rput[lb](1.7,2.1){$z = x+ iy$}
\rput[lb](1.6,-2.4){$\ol{z} = x- iy$}
\end{pspicture}
\end{center}
\end{figure}%In fact, a complex number $z$ is real if and only if $z = \ol{z}$, and it is purely imaginary if and only if $z = -\ol{z}$.
\end{definition}

\begin{remark}
Obviously, $z = \ol{z}$ if and only if $z$ is a real number.
\end{remark}

\begin{proposition}
For any $z\in \C$,
\be
\ol{\ol{z}} = z,\qquad \Re(z) = \frac{z+\ol{z}}2,\qquad \Im(z) = \frac{z - \ol{z}}{2i}.%,\qquad \abs{z}^2 = z\ol{z}.
\ee

Furthermore, for any $z_1,z_2\in \C$,
\be
\ol{z_1+z_2} = \ol{z_1} + \ol{z_2},\qquad \ol{z_1-z_2} = \ol{z_1} - \ol{z_2},\qquad\ol{z_1z_2} = \ol{z_1}\cdot \ol{z_2}.
\ee

In addition, for $z_2\neq 0$,
\be
\ol{\bb{\frac {z_1}{z_2}}} = \ol{z_1}/\ol{z_2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
The first three equations are the direct result from the definitions. For $z_1 = x_1 + iy_1$ and $z_2 = x_2 + iy_2$,
\beast
\ol{z_1+z_2} & = & \ol{(x_1+x_2) + i(y_1+y_2)} = (x_1+x_2) - i(y_1+y_2) = (x_1-iy_1) + (x_2-iy_2) = \ol{z_1} + \ol{z_2},\\
\ol{z_1-z_2}  & = & \ol{(x_1-x_2) + i(y_1-y_2)} = (x_1-x_2) - i(y_1-y_2) = (x_1-iy_1) - (x_2-iy_2) = \ol{z_1} - \ol{z_2}.
\eeast

Also,
\beast
\ol{z_1z_2} & = & \ol{(x_1x_2-y_1y_2) + i(x_1y_2+x_2y_1)} = (x_1x_2-y_1y_2) - i(x_1y_2+x_2y_1) \\
& = & (x_1-iy_1)(x_2-iy_2) = \ol{z_1}\cdot \ol{z_2},
\eeast
\beast
\ol{\bb{\frac{z_1}{z_2}}} & = & \ol{\bb{\frac{x_1x_2 + y_1y_2 + i(-x_1y_2 + x_2y_1)}{x_2^2 + y_2^2} }} = \frac{x_1x_2 + y_1y_2 - i(-x_1y_2 + x_2y_1)}{x_2^2 + y_2^2}\\
& = & \frac{x_1x_2 + (-y_1)(-y_2) + i(-x_1(-y_2) + x_2(-y_1))}{x_2^2 + y_2^2} = \frac{x_1-iy_1}{x_2-iy_2} = \ol{z_1} / \ol{z_2}
\eeast
as required.
\end{proof}



\subsection{Modulus of complex numbers}

\begin{definition}[modulus]\label{def:modulus_complex_number}
Let $z=x+iy$ with $x,y\in\R$. Then the modulus (or absolute value) of $z$ is defined by
\be
\abs{z} := \sqrt{x^2 + y^2}.
\ee
\end{definition}

\begin{remark}
The modulus $\abs{z}$ is the distance between the origin and the point $(x,y)$ in $\R^2$-plane.

Obviously, we have $\abs{z} = \abs{-z}$, $\abs{z} = \abs{\ol{z}}$ and $\abs{z}^2 = z\ol{z}$ for any $z\in \C$.

In addition, $\Re(z) \leq \abs{z}$ and $\Im(z) \leq \abs{z}$.
\end{remark}

\begin{proposition}\label{pro:modulus_multiplication_division_complex}
For all $z_1,z_2,z_3\in \C$,
\be
\abs{z_1z_2} = \abs{z_1}\abs{z_2},\qquad \abs{\frac{z_1}{z_3}}= \frac{\abs{z_1}}{\abs{z_3}},\quad z_3 \neq 0.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
For $z_1 =x_1+iy_1$ and $z_2 = x_2 + iy_2$,
\be
\abs{z_1z_2}^2 = z_1z_2\ol{z_1z_2} = z_1z_2 \ol{z_1}\ol{z_2} = z_1\ol{z_1}z_2 \ol{z_2} = \abs{z_1}^2 \abs{z_2}^2.
\ee
%\beast
%\abs{z_1z_2}^2 & = &  \abs{(x_1x_2 - y_1y_2)+ i(x_1y_2 + x_2y_1)}^2 = (x_1x_2 - y_1y_2)^2 + (x_1y_2 + x_2y_1)^2 \\
%& = & x_1^2 x_2^2 + y_1^2y_2^2 + x_1^2y_2^2 + x_2^2 y_1^2 = \bb{x_1^2 + y_1^2}\bb{x_2^2 + y_2^2} = \abs{z_1}^2\abs{z_2}^2
%\eeast

For $z_3 \neq 0$,
\beast
\abs{\frac{z_1}{z_3}}^2 = \frac{z_1}{z_3}\ol{\bb{\frac{z_1}{z_3}}} = \frac{z_1}{z_3}\frac{\ol{z_1}}{\ol{z_3}} = \frac{z_1\ol{z_1}}{z_3\ol{z_3}} = \frac{\abs{z_1}^2}{\abs{z_3}^2}.
\eeast
\end{proof}

\begin{proposition}[parallelogram law]\label{pro:complex_modulus_parallelogram_law}
For all $z_1,z_2\in \C$,
\beast
\abs{z_1+z_2}^2 = \abs{z_1}^2 + 2\Re \bb{z_1\ol{z_2}} + \abs{z_2}^2,\\
\abs{z_1-z_2}^2 = \abs{z_1}^2 - 2\Re \bb{z_1\ol{z_2}} + \abs{z_2}^2.
\eeast

Thus, we have
\be
\abs{z_1+z_2}^2 + \abs{z_1- z_2}^2 = 2\bb{\abs{z_1}^2 + \abs{z_2}^2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
By definition of modulus, we have
\beast
\abs{z_1+z_2}^2 & = & \bb{z_1 + z_2} \ol{ \bb{z_1 + z_2}} = \bb{z_1 + z_2} \bb{\ol{ z_1} + \ol{z_2}} = z_1 \ol{z_1} + z_1\ol{z_2} + z_2 \ol{z_1} + z_2\ol{z_2} \\
& = &  z_1 \ol{z_1} + z_1\ol{z_2} + \ol{z_1 \ol{z_2}} + z_2\ol{z_2} =  \abs{z_1}^2 + 2\Re\bb{z_1\ol{z_2}} + \abs{z_2}^2 
\eeast
and 
\beast
\abs{z_1-z_2}^2 & = & \bb{z_1 - z_2} \ol{ \bb{z_1 - z_2}} = \bb{z_1 - z_2} \bb{\ol{ z_1} - \ol{z_2}} = z_1 \ol{z_1} - z_1\ol{z_2} - z_2 \ol{z_1} + z_2\ol{z_2} \\
& = &  z_1 \ol{z_1} - z_1\ol{z_2} - \ol{z_1 \ol{z_2}} + z_2\ol{z_2} =  \abs{z_1}^2 - 2\Re\bb{z_1\ol{z_2}} + \abs{z_2}^2 
\eeast

Then we get the required result by adding the above two.
\end{proof}



\begin{proposition}[triangle inequality]\label{pro:triangle_inequality_complex}
For all $z_1,z_2\in \C$,
\ben
\item [(i)] $\abs{z_1+z_2} \leq \abs{z_1} + \abs{z_2}$,
\item [(ii)] $\abs{\abs{z_1} -\abs{z_2}} \leq \abs{z_1-z_2} $
\een
where $\abs{\cdot}$ is the modulus of complex numbers.
\end{proposition}

\begin{remark}
\ben
\item [(i)] If we treat $z_1$ and $z_2$ as two vectors, this inequality is actually the triangle inequality.

\item [(ii)] Let $z = x + iy$. Then
\be
\abs{z} = \abs{x+iy} \leq \abs{x} + \abs{iy} = \abs{x} + \abs{y} = \abs{\Re z} + \abs{\Im z}.
\ee
\een
\end{remark}

\begin{proof}[\bf Proof]
\ben
\item [(i)] {\bf Approach 1.} Let $z_1 = x_1+iy_1$ and $z_2 = x_2 + iy_2$. Since $ab \leq \frac{a^2+b^2}2$ for any $a,b\in \R$, we have
\beast
2x_1x_2y_1y_2 \leq x_1^2 y_2^2 + x_2^2 y_1^2 \ \ra\ \bb{x_1x_2 + y_1y_2}^2 \leq \bb{x_1^2+ y_1^2}\bb{x_2^2 + y_2^2} \ \ra\ x_1x_2 + y_1y_2 \leq \sqrt{x_1^2+ y_1^2}\sqrt{x_2^2 + y_2^2}.
\eeast

Therefore,
\beast
\abs{z_1+z_2}^2 & = & (x_1+x_2)^2+ (y_1+y_2)^2 = x_1^2+ x_2^2 + y_1^2+ y_2^2 + 2x_1x_2 + 2y_1y_2 \\
&\leq & x_1^2+ x_2^2 + y_1^2+ y_2^2 + 2\sqrt{x_1^2+ y_1^2}\sqrt{x_2^2 + y_2^2} = \bb{\sqrt{x_1^2+ y_1^2} + \sqrt{x_2^2 + y_2^2}}^2\\
& = & \bb{\abs{z_1} + \abs{z_2}}^2
\eeast
which implies the required result.

{\bf Approach 2.} Apply basic properties of modulus, we have
\beast
\abs{z_1+z_2}^2 & = &  \abs{z_1}^2 + 2\Re\bb{z_1\ol{z_2}} + \abs{z_2}^2 \leq \abs{z_1}^2 + 2\abs{\Re\bb{z_1\ol{z_2}}} + \abs{z_2}^2 \\
& \leq & \abs{z_1}^2 + 2\abs{z_1\ol{z_2}} + \abs{z_2}^2 = \abs{z_1}^2 + 2\abs{z_1}\abs{z_2} + \abs{z_2}^2 = \bb{\abs{z_1}+\abs{z_2}}^2
\eeast

\item [(ii)] By (i), we have
\be
\abs{z_1} = \abs{(z_1-z_2) + z_2} \leq \abs{z_1-z_2} + \abs{z_2} \ \ra\ \abs{z_1} - \abs{z_2} \leq \abs{z_1-z_2}.
\ee

Then switching $z_1$ and $z_2$ we have
\be
\abs{z_2} - \abs{z_1} \leq \abs{z_2-z_1} = \abs{z_1-z_2} \ \ra\ \abs{z_1} - \abs{z_2} \geq -\abs{z_1-z_2}.
\ee

Therefore,
\be
-\abs{z_1-z_2} \leq \abs{z_1} - \abs{z_2} \leq \abs{z_1-z_2} \ \ra\ \abs{\abs{z_1} - \abs{z_2}} \leq \abs{z_1-z_2}
\ee
as required.
\een
\end{proof}


\subsection{The extended plane and its spherical representation}

\footnote{See \cite{Conway_1978_a}.$P_{8}$}




\section{Complex Sequences and Convergence}

%\subsection{Convergence and limits on complex domain}

\subsection{Convergence and limits on complex sequence}%\section{Convergence and limits of complex sequences}

\begin{definition}[convergence, limit]\label{def:convergence_limit_complex}
Let $(z_n)$ be a complex sequence. Then we say that $(z_n)$ converges\index{convergence!complex sequence} to a complex number $z$ if for any $\ve>0$ there exists $N>0$ such that for all $n\geq N$,
\be
\abs{z_n - z} < \ve
\ee
where $\abs{\cdot}$ is the modulus function. It can also written as
\be
\lim_{n\to \infty} z_n = z.
\ee

In addition, $z$ is called the limit\index{limit!complex sequence} of $(z_n)$.

Otherwise, $(z_n)$ is divergent.
\end{definition}

\begin{definition}
Let $(z_n)$ be a complex sequence. Then we write
\be
\lim_{n\to \infty}z_n = \infty
\ee
if for any $M>0$ there exists $N>0$ such that for all $n\geq N$, $\abs{z_n} > M$. Note that $\abs{\cdot}$ is the modulus function.
\end{definition}

%\begin{definition}
%We say $a_n\to a\in\C$ as $n\to \infty$, if $a_n,a\in \C$ for any $n$ and given $\ve>0,\exists N$ s.t.
%\be
%|a_n-a|<\ve,\ \forall n\geq N.
%\ee
%where $|\cdot|$ stands for the modulus of a complex number.
%\end{definition}

%If we were considering instead subsequences of complex numbers, $a_n\in\C$, we can give essentially the same definition of limit.


\begin{theorem}\label{thm:convergence_of_complex_iff_convergence_of_real_imaginary}
Let $(z_n)$ be a complex sequence with $z_n = x_n + iy_n$ for $n\in \N$ and $z = x+iy \in \C$. Then
\be
\lim_{n\to \infty} z_n = z \quad \lra \quad \lim_{n\to \infty} x_n = x,\quad \lim_{n\to \infty} y_n = y.
\ee
\end{theorem}

\begin{remark}
Note that the theorem enables us to write
\be
\lim_{n\to \infty} (x_n + iy_n) = \lim_{n\to \infty} x_n + i \lim_{n\to \infty} y_n
\ee
whenever we know that both limits on the right exist or that the one on the left exists.
\end{remark}

\begin{proof}[\bf Proof]
($\ra$). Assume $\lim_{n\to \infty} z_n = z$. Given any $\ve>0$, there exists $N\in\N$ such that for all $n\geq N$,
\be
\abs{x_n + iy_n - x- iy} = \abs{z_n - z} < \ve.
\ee

Thus, we have
\beast
\abs{x_n - x} & = & \abs{\Re (z_n-z)} \leq \abs{z_n-z} < \ve \\
\abs{y_n - y} & = & \abs{\Im (z_n-z)} \leq \abs{z_n-z} < \ve.
\eeast
which implies that $\lim_{n\to \infty} x_n = x$ and $\lim_{n\to \infty} y_n = y$.

($\la$). Assume $\lim_{n\to \infty} x_n = x$ and $\lim_{n\to \infty} y_n = y$. Then given any $\ve>0$, we can find $N_1,N_2\in \N$ such that
\be
\abs{x_n - x} < \ve/2\qquad \forall n\geq N_1,\qquad \abs{y_n - y} < \ve/2\qquad \forall n\geq N_2.
\ee

Then we take $N = \max \bra{N_1,N_2}$, we can have for all $n\geq N$,
\be
\abs{z_n - z} = \abs{x_n + iy_n - x- iy} \leq  \abs{x_n - x} +  \abs{y_n - y} < \ve/2 + \ve/2 = \ve
\ee
which implies that $\lim_{n\to \infty} z_n = z$.
\end{proof}

\begin{example}
The sequence
\be
z_n = \frac 1{n^3} + i
\ee
converges to $i$ since
\be
\lim_{n\to \infty} \bb{\frac 1{n^3} + i} = \lim_{n\to \infty} \frac 1{n^3} + i \lim_{n\to \infty} 1 = 0 + i\cdot 1 = i.
\ee
\end{example}



\subsection{Convergence properties of complex sequence}

\begin{lemma}\label{lem:basic_convergence_complex}
For complex domain and sequence $(z_n)$ and $(w_n)$ and complex constants $z,w,c$,
\ben
\item [(i)] The limit is unique. That is, if $z_n \to z$ and $z_n \to w$ as $n \to \infty$ then $z=w$.
\item [(ii)] If $z_n \to z$ as $n \to \infty$ and $n_1 < n_2 < n_3 \ldots$ then $z_{n_i} \to a$ as $i \to \infty$. (Any subsequence converges to the same limit).
\item [(iii)]  If $z_n = c$ for all $n$ then $z_n \to c$ as $n \to \infty$.
\item [(iv)] If $z_n \to z$ and $w_n \to w$ as $n \to \infty$ then $z_n + w_n \to z + w$.
\item [(v)] If $z_n \to z$ and $w_n \to w$ as $n \to \infty$ then $z_n w_n \to zw$.
\item [(vi)] If $z_n \to z$ as $n \to \infty$, $z_n \neq 0$ for each $n$ and $z \neq 0$, then $z_n^{-1} \to  z^{-1}$.
\item [(vii)] If $z_n\to z$, then $\abs{z_n} \to \abs{z}$.
\een
\end{lemma}

\begin{remark}
The converse of (vii) is not true. Let $z_n = (-1)^n$, Then $\lim_{n\to \infty}\abs{z_n}= 1$ but $\lim_{n\to \infty} z_n$ does not exist.

It is also obvious that $\lim_{n\to\infty} z_n = 0$ iff $\lim_{n\to\infty}\abs{z_n} = 0$.
\end{remark}


\begin{proof}[\bf Proof]
\ben
\item [(i)] $z_n\to z$ means given $\ve>0$, $\exists N_1$ for all $n\geq N_1$ we have $\abs{z_n-z}<\ve$. Similarly, $z_n\to w$ means given $\varepsilon>0$, $\exists N_2$ for all $n\geq N_2$ we have $|z_n-w|<\ve$. Thus, by triangle inequality (Proposition \ref{pro:triangle_inequality_complex}) we have
\be
\abs{z-w} \leq \abs{z-z_n} + \abs{w-z_n} < 2\ve \text{ for }n\geq \max\bra{N_1,N_2}
\ee

Hence we have $|z-w|<2\ve$. If $z\neq w$, just take $\ve=\frac{|z-w|}{3}$, then $|z-w|<\frac{2|z-w|}{3}$ which is assurd. Thus, $z=w$.

\item [(ii)] $z_n\to z$ means given $\ve >0$, $\exists N$ s.t. $|z_n-z|<\ve, \forall n\geq N$. $z_{n_i}$, $n_i\geq i$, thus we have
\be
|z_{n_i}-z| < \varepsilon,\ \forall j\geq N \ \ra \ z_{n_i}\to z\ \text{ as }i\to\infty.
\ee

\item [(iii)] If $z_n = c$ then given $\ve > 0$ set $N(\ve) = 1$. Then
\be
|z_n - c| = |c-c| = 0 < \ve, \ \forall n \geq N(\ve).
\ee

%\item [(iv)] We know that given $\ve > 0$, $\exists N_1(\ve),N_2(\ve)$ such that $|a_n - a| < \ve\ \forall n \geq N_1(\ve),\ |b_n - b| < \ve\ \forall n \geq N_2(\ve)$. Thus if $n \geq N(\ve) = \max\bra{N_1\bb{\frac{\ve}2}, N_2\bb{\frac{\ve}2}}$, we have
%\be
%|(a_n + b_n) - (a - b)| = |(a_n - a) + (b_n - b)| \leq |a_n - a| + |b_n -b| < \frac{\ve}{2} + \frac{\ve}{2}
%\ee
%for any $n \geq N(\ve)$.

\item [(iv)] For given $\ve>0$, we can find $n$ such that $\abs{z_n -z}<\ve/2$ and $\abs{w_n -w}<\ve/2$. Thus, by Proposition \ref{pro:triangle_inequality_complex},
\be
\abs{z_n+w_n - (z+w)} = \abs{(z_n -z) + (w_n-w)} \leq \abs{z_n -z} + \abs{w_n -w} < \ve/2+\ve/2 = \ve.
\ee

\item [(v)] $z_n\to z$, given $\ve>0$, $\exists N_1$ s.t. $|z_n-z|<\ve, \ \forall n\geq N_1$. $w_n\to w$, given $\varepsilon>0$, $\exists N_2$ s.t. $|w_n-w|<\varepsilon, \forall n\geq N_2$. Then by triangle inequality (Proposition \ref{pro:triangle_inequality_complex})
\be
\abs{z_nw_n-zw} \leq |z_nw_n-z_nw| + |z_nw-zw| = |z_n||w_n-b| + |w||z_n-z|
\ee

We have $|z_n|\leq |z_n-z|+|z|\leq 1+|z|,\forall n\geq N_1(1) \ (\ve=1)$. Thus, we have
\be
|z_nw_n-zw| \leq (1+|z|)\ve + |w|\ve = \ve(|z|+|w|+1), \ \forall n\geq \max\{N_1(1),N_1(\ve), N_2(\ve)\}.
\ee

\item [(vi)] Again, given $\ve > 0$, $\exists N_1(\ve)$ such that $|z_n - z| < \ve$. Thus if $n \geq N(\ve) = \max\bra{N_1\bb{\frac{|z|}{2}}, N_1\bb{\frac{\ve|z|^2}{2}}}$, then
\be
\abs{\frac{1}{z_n} - \frac{1}{z}} = \abs{\frac{z - z_n}{zz_n}} = \frac{|z-z_n|}{|z||z_n|} <\frac{2|z_n - z|}{|z|^2} <\frac{\ve |z|^2}{2} \cdot \frac{2}{|z|^2} = \ve.
\ee

If $n \geq N(\ve)$ then $|z_n - z| < \frac{|z|}{2}$ so $|z_n| > \frac{|z|}{2}$.

\item [(vii)] By Proposition \ref{pro:triangle_inequality_complex}, we have given $\ve>0$, there exists $N$ such that $\forall n\geq N$,
\be
\abs{\abs{z_n} -\abs{z}} \leq \abs{z_n - z} <\ve
\ee
which implies that $\lim_{n\to \infty}\abs{z_n} = \abs{z}$.
\een
\end{proof}

\begin{proposition}\label{pro:convergence_of_complex_power_function}
Let $z$ be a complex number. Then
\ben
\item [(i)] $\lim_{n\to \infty} z^n = 0$ for $\abs{z} <1$.
\item [(ii)] $\lim_{n\to \infty} z^n = \infty$ for $\abs{z}>1$.
\item [(iii)] $\lim_{n\to \infty} z^n$ does not exist for $\abs{z}=1$ with $z\neq 1$.
\een
\end{proposition}

\begin{remark}
Obviously, $\lim_{n\to \infty} 1^n = 1$ by definition.
\end{remark}

\begin{proof}[\bf Proof]
\ben
\item [(i)] By definition of convergence, for any $1>\ve>0$ and $\abs{z} = \frac 1{1+\delta}$ with $\delta>0$
\be
\abs{z^n-0} = \abs{z^n} = \abs{z}^n = \frac 1{(1+\delta)^n} < \frac 1{1+n\delta}.
\ee

Therefore, we can find $n\geq \frac {1-\ve}{\delta\ve}$ such that $\abs{z^n-0}<\ve$. Thus, $\lim_{n\to\infty} z^n = 0$.

%If $\abs{z}\geq 1$, clearly $\lim_{n\to \infty} \abs{z^n} \neq 0$. Hence $\lim_{n\to \infty} z^n \neq 0$.

\item [(ii)] If $\abs{z} >1$, we assume $\abs{z} = 1+\delta$ with $\delta >0$. Then
\be
\abs{z^n} = \abs{z}^n = \bb{1+\delta}^n > 1+ n\delta.
\ee

So for any $M>1$ we can find $n \geq \frac{M-1}{\delta}$ such that $\abs{z^n} > M$. This implies that $\lim_{n\to \infty}z^n = \infty$.

\item [(iii)] Now let $\abs{z=1}$. If $z=1$, it is obvious that $z^n = 1$ for any $n\in \N$ which implies that $\lim_{n\to \infty}z^n = 1$. Assume $w$ is the limit of $z^n$. Then given $\ve>0$, we can find $N$ such that $\forall n\geq N$ we have
\be
\abs{z^n - w} < \ve.
\ee

Then we have for any $n\geq N$,
\be
\abs{z^{n+1} - zw} = \abs{z\bb{z^n -w}} = \abs{z}\abs{z^n-w} < \abs{z}\ve = \ve .
\ee

This means $zw$ is also the limit of $z^n$. Since the limit is unique, we have $w =0$. By Lemma \ref{lem:basic_convergence_complex}, %{lem:sequence_limit_implies_absolute_sequence_absolute_limit_complex}, %But $w\neq zw$ since $z\neq 1$
\be
\lim_{n\to\infty} z^n = w \ \ra\ \lim_{n\to\infty} \abs{z^n} = \abs{w} = 0.
\ee

However, we have $\abs{z^n} = \abs{z}^n = 1$ for any $n$ which implies the contradiction. Thus, $\lim_{n\to\infty} z^n $ does not exist for $\abs{z}=1$ with $z\neq 1$.
\een
\end{proof}


\subsection{Cauchy sequence}

\begin{definition}[Cauchy sequence\index{Cauchy sequence!complex}]
A complex sequence $(z_n)$ is said to be a Cauchy sequence if
\be
\abs{z_n - z_m} \to 0,\qquad \text{as }n,m\to \infty.
\ee

In other words, given $\ve>0$ there exists an integer $N>0$ so that $\abs{z_n-z_m}<\ve$ whenever $n,m>N$.
\end{definition}

\begin{theorem}\label{thm:complex_plane_is_complete}%[$\C$ is complete]
The complex domain $\C$ is complete\index{complete space!complex}. That is, every Cauchy sequence in $\C$ has a limit in $\C$.
\end{theorem}

\begin{proof}[\bf Proof]
Let $(z_n)$ be a Cauchy sequence in $\C$ with $z_n = x_n + iy_n$. Since
\be
\abs{z_n - z_m} = \abs{(x_n-x_m) + i(y_n - y_m)} ,
\ee
we have
\be
\abs{z_n - z_m} \to 0 \ \lra\ (x_n-x_m)^2 + (y_n - y_m)^2 \to 0 \ \lra\ \abs{x_n-x_m} \to 0,\ \abs{y_n - y_m} \to 0.
\ee

This means that the complex sequence $(z_n)$ is Cauchy sequence if an only if the sequences of real and imaginary parts of $z_n$ are Cauchy. Therefore, we have that $(x_n)$ and $(y_n)$ are real Cauchy sequences. Since $\R$ is complete, every real Cauchy sequence converges in $\R$\footnote{theorem needed.}, there exist $x,y\in \R$ such that
\be
\abs{x_n -x} \to 0,\quad \abs{y_n - y}\to 0,\qquad\text{as }n\to \infty.
\ee

Then for $z = x+iy \in \C$, we have
\be
\abs{z_n - z} = \abs{(x_n-x) + i(y_n - y)} = \sqrt{(x_n-x)^2 + (y_n - y)^2} \to 0
\ee
as $n\to \infty$. This implies that $z_n$ converges to $z$ so $\C$ is complete.
\end{proof}

\subsection{Bolzano-Weierstrass theorem}

\begin{definition}[bounded sequence\index{bounded sequence!complex}]
Let $(z_n)$ be a complex sequence. We say that $(x_n)$ is bounded if there exists $M>0$ such that for any $n$, $\abs{z_n}\leq M$.
\end{definition}

\begin{theorem}[Bolzano-Weierstrass theorem]\label{thm:bolzano_weierstrass_complex}
If a complex sequence $(z_n)$ is bounded, then there exists a subsequence of $(z_n)$ which converges.
\end{theorem}

\begin{proof}[\bf Proof]
Since $(z_n)$ is bounded, there is a disk centered at the origin containing all $z_n$. Then by possibly shrinking and translating this disc we can assume that it is contained in the square $S$ with vertices 0,1,$1+i$ and $i$. Note that the shrinking and translating do not change the convergence behavior of the sequence.

Now consider the following recursive procedure. Using a vertical segment and a horizontal segment divide $S$ into four squares of the same size $S_1$ with vertices 0, 1/2, $1/2+i/2$, $i/2$, $S_2$ with vertices 1/2, 1, $1+i/2$, $1/2+i/2$, $S_3$ with vertices $1/2+i/2$, $1+i/2$, $1+i$, $1/2+i$ and $S_4$ with vertices $i/2$, $1/2+i/2$, $1/2+i$, $i$.

Since the sequence $(z_n)$ is infinite, there must be one of the these squares with an infinite number of points. If $S_i$ is such square, pick an arbitrary point in it and call it $w_1$. Then only consider those points in the sequence $(z_n)$ with indices $n$ larger than the index of $w_1$ in $(z_n)$. Then repeat the same procedure using $S_i$ instead of $S$ and proceed recursively. In this way we construct a sequence $(w_k)$ (in other form, $(z_{n_k})$) where the indices of the $w_k$'s in the sequence $(z_n)$ are in order and moreover each $w_k$ is contained in a square of side $1/2^k$ with all $w_j$ with $j\geq k$. Therefore,
\be
\abs{w_j - w_k} < \frac 1{2^k},\qquad \forall j\geq k
\ee
which means that the sequence $(w_k)$ (or the subsequence $(z_{n_k})$) is a Cauchy sequence and therefore it is convergent (Theorem \ref{thm:complex_plane_is_complete}).
\end{proof}



\subsection{Function sequences}

\begin{definition}[uniform convergence\index{uniform convergence!complex function}]\label{def:uniform_convergence_complex}
Let $f,(f_n)_{n\in\N}$ be complex-valued functions defined on $A\subseteq \C$. If for any $\ve>0$, there exists $N\in\N$ such that for all $z\in A$ and all $n\geq N$ we have
\be
\abs{f_n(z) - f(z)} < \ve.
\ee
then we say the function sequence $(f_n)$ converges to $f$ uniformly on $A$.

Equivalently, $(f_n)_{n\in\N}$ converges uniformly to $f$ on $A$ if and only if for any $\ve>0$, there exists $N\in \N$ such that for all $m,n\geq N$ and all $z\in A$,
\be
\abs{f_n(z)-f_m(z)} < \ve.
\ee

Note that Cauchy sequence is convergent in complex case. This is the Cauchy criterion for uniform convergence.

Equivalently, we say $f_n$ converges to $f$ uniformly if and only if $a_n\to 0$ as $n\to \infty$ where $a_n$ is defined by
\be
a_n := \sup_{z\in A}\abs{f_n(z) - f(z)}.
\ee
\end{definition}


\section{Complex Sets}

\subsection{Bounded set}

%\begin{definition}[bounded set\index{bounded set!complex}]
%Let $X$ be a complex set. We say that $X$ is bounded if there exists $M>0$ such that for any $z\in X$, $\abs{z}\leq M$.
%\end{definition}


\begin{definition}[bounded set\index{bounded set!complex}]
A set $A\subseteq \C$ is bounded if there exists $M>0$ such that $\abs{z}< M$ whenever $z\in A$. In other words, the set $A$ is contained in some large disc.
\end{definition}

\subsection{Open set and closed set}

\begin{definition}[open disc, closed disc, circle]
If $z_0\in \C$ and $r>0$, we define the open disc $D_r(z_0)$ of radius $r$ centered at $z_0$ to be the set of all complex numbers that are at absolute value strictly less than $r$ from $z_0$. In other words,
\be
D_r(z_0) = \bra{z\in \C: \abs{z-z_0}<r},
\ee
and this is precisely the usual disc in the plane of radius $r$ centered at $z_0$.

The closed disc $\ol{D}_r(z_0)$ of radius $r$ centered at $z_0$ is the set of all complex numbers that are at absolute value no more than $r$ from $z_0$. In other words,
\be
\ol{D}_r(z_0) = \bra{z\in \C: \abs{z-z_0}\leq r}.
\ee

The boundary of either the open or closed disc is the circle
\be
C_r(z_0) = \bra{z\in \C: \abs{z-z_0}=r}.
\ee%In particular, the unit disc (the open disc centered at the origin and of radius 1) is denoted by%\be
%\sD = \bra{z\in \C: \abs{z}<1}.
%\ee
\end{definition}


\begin{definition}[interior point]
Given a set $A\subseteq X$ where $X \subseteq \C$, a point $z$ is an interior point of $A$ if there exists $r>0$ such that
\be
D_r(z) \subseteq A.
\ee

The interior of $A$, denoted by $\inter{A}$, consists of all its interior points.
\end{definition}

\begin{definition}[open set]
A set $A\subseteq X$ where $X\subseteq \C$ is said to be open in $X$ if every point in that set is an interior point of $A$. That is, for any $z\in A$, there exists $r>0$ such that $D_r(z)\subseteq A$. 
\end{definition}

\begin{remark}
The definition of open set in complex plane coincides with the definition of an open set in $\R^2$.\footnote{details needed.}

Note that the open set might have several open discs.
\end{remark}


\begin{definition}[closed set]
A set $A\subseteq X$ where $X\subseteq \C$ is closed in $X$ if its complement $A^c = X\bs A$ is open.
\end{definition}

\begin{example}
Consider the closed disc $A: = \ol{D}_r(z_0) = \bra{z\in \C:\abs{z-z_0} \leq r}$ with $z_0\in\C$ and $r>0$. If it is not closed then $X\bs A$ is not open, thus, for any $\ve>0$ and any $w\in X\bs A$, we can find $D_\ve(w) \cap A \neq \emptyset$. Thus, we can find a sequence $(w_n)\in A$ (such that $\abs{w_n- z_0} \leq r$) converging to $w$. But $\abs{w-z_0} > r$ so there exists $\delta>0$ such that $\abs{w-z_0} = r+ \delta$. Thus, by triangle inequality,
\be
\abs{w_n - w} \geq \abs{\abs{w-z_0}-\abs{w_n - z_0}} = \abs{w-z_0}-\abs{w_n - z_0} \geq r + \delta - r = \delta
\ee
which contradicts the statement that $(w_n)$ converges to $w$. Thus, we have that $A$ is closed.
\end{example}


\begin{definition}[limit point]
A point $z\in X$ where $X\subseteq \C$ is said to be a limit point of the set $A\subseteq X$ if there exists a sequence of points $z_n\in A$ such that $z_n\neq z$ and
\be
\lim_{n\to \infty} z_n = z.
\ee
\end{definition}

\begin{definition}[closure]
The closure of any set $A\subseteq X \subseteq \C$ is the union of $A$ and its limit points in $X$, often denoted by $\ol{A}$.
\end{definition}

\begin{theorem}\label{thm:closed_complex_set_contains_all_limit_points_equals_closure}
Let $A$ be a set in $X\subseteq \C$. Then the following three statements are equivalent:
\ben
\item [(i)] $A$ is closed in $X$.
\item [(ii)] $A$ contains all its limit points.
\item [(iii)] $\ol{A} = A$.
\een
\end{theorem}

\begin{proof}[\bf Proof]
(i) $\ra$ (ii). Suppose $A$ is closed and $B:= X\bs A = A^c$ is open. For any sequence $(z_n)$ in $A$ with $z_n \to z$. If $z\in B$ then we can find a $\delta>0$ such that $D_\delta(z) \subseteq B$. Therefore, $\abs{z_n - z} \geq \delta$ for all $n$ which contradicts to the assumption. Thus, $z\in A$.

(ii) $\ra$ (i). Suppose $A$ contains all its limit points and $B:= X \bs A = A^c$. If $A$ is not closed then $B$ is not open. Thus, we can find $z\in A$ such that
\be
D_\delta(z) \cap B \neq \emptyset,\qquad \text{for all }\delta >0.
\ee

In particular, we can find $z_n \in A$ such that $\abs{z_n - z} < 1/n$ for each $n\in \Z^+$. Therefore, $z_n \to z$ and $z\in B$ is a limit point which is absurd. So $A$ is closed in $X$.

(i) $\ra$ (iii). Suppose $A$ is closed in $X$. We shall show that no point of its complement is in $\ol{A}$. By definition $A^c$ is open so for any $z\in A^c$ there exists $\delta >0$ such that $D_\delta(z) \subseteq A^c$. Therefore, $D_\delta(z) \cap A = \emptyset$. This shows that $z\not\in \ol{A}$. Hence, $\ol{A} \subseteq A$ which implies $\ol{A} = A$.

(iii) $\ra$ (i). Conversely, if $\ol{A} = A$ then for any $z\in A^c = \ol{A}^c$ we have $z\not\in \ol{A}$. Therefore, for some $\ve>0$ we have $D_\ve(z)\cap A = \emptyset$ and so $D_\ve(z)\subseteq A^c$. This implies that $A^c$ is open and thus $A$ is closed in $X$.
\end{proof}


\begin{definition}[boundary]
The boundary of a set $A\subseteq X$ where $X\subseteq \C$ is equal to its closure minus its interior, often denoted by $\partial A$.
\end{definition}




\subsection{Functions of set}

\begin{definition}[diameter]
Let $A$ be a subset of $\C$. Then its diameter by
\be
\diam\bb{A} := \sup_{z,w\in A}\abs{z-w}.
\ee
\end{definition}


\begin{theorem}\label{thm:cantor_theorem_complex_version}
For any sequence $(A_n)_{n\in \N}$ of non-empty closed sets in $\C$ with $A_1 \supseteq A_2 \supseteq \dots $ and $\diam A_n \to 0$, $\bigcap^\infty_{n=1}A_n$ consists of a single point.
\end{theorem}

\begin{remark}
This is actually the complex version of Cantor's theorem.
\end{remark}

\begin{proof}[\bf Proof]
For each $n$, let $z_n$ be an arbitrary point in $A_n$. If $n,m\geq N$, then $z_n,z_m\in A_N$ so that by definition
\be
\abs{z_n - z_m} \leq \diam A_N \to 0
\ee
by assumption. This shows that $(z_n)$ is a Cauchy sequence. Therefore, $(z_n)$ is convergent sequence since $\C$ is complete. Thus, we have
\be
\lim_{n\to \infty}z_n = z.
\ee

Also, $z\in A_N$ for all $n\geq N$ since $A_N$ is closed and $A_n\subseteq A_N$. Thus, we have
\be
z \in \bigcap^\infty_{n=1}A_n : = A.
\ee

So $A$ contains at least one point. If $w$ is also in $A$ then $z,w\in A_n$ for each $n$ and this gives $\abs{z-w} \leq \diam A_n \to 0$. Therefore
\be
\abs{z-w} = 0\ \ra\ z= w.
\ee
\end{proof}




\subsection{Connected sets}

Recalling the definition of disconnectedness and partition in topology\footnote{definition and proposition needed.}, we have the following definition.

\begin{definition}[connected set\index{connected set!complex space}]\label{def:connected_set_complex_space}
A set $X\subseteq \C$ is called disconnected if it is the union of two disjoint non-empty open sets $X_1,X_2$ in $X$. Otherwise, $X$ is called connected.
\end{definition}

\begin{remark}
Equivalently, $X$ is connected if the only subsets of $X$ which are both open and closed are $\emptyset$ and $X$.

If there exists non-empty proper subset $A\subset X$ which is both open and closed, we can have that $A$ and $X \bs A$ are both non-empty open (since $A$ is also closed). Thus, $X$ is disconnected by definition. Conversely, we can use the similar argument.

%Sometimes the connected set is called region. The open connected set is sometimes called domain or region.

A non-empty open connected set is called domain (though sometimes it is called region as in Conway's book\cite{Conway_1978_a}). Note that any neighbourhood is a domain. A domain together with some, none, or all of its boundary points is referred to as a region.
\end{remark}

\begin{remark}
Connectedness in complex space is similar with interval in real space.
\end{remark}


\begin{example}
A disc $D_\ve(z)$ is connected set.
\end{example}





%\begin{definition}[compact set]
%A set $A\subseteq \C$ is said to be compact if it is closed and bounded.
%\end{definition}


\subsection{Compact sets} %{Compactness of Complex domain}

\begin{definition}[cover]
An cover of the set $A$ is a family of sets $\bra{U_{\alpha}}_{\alpha\in\sA}$ (not necessarily countable) such that
\be
A \subseteq \bigcup_{\alpha\in \sA} U_{\alpha}.
\ee
\end{definition}

\begin{definition}[open cover]
An open cover of the set $A$ is a family of open sets $\bra{U_{\alpha}}_{\alpha\in\sA}$ (not necessarily countable) such that
\be
A \subseteq \bigcup_{\alpha\in \sA} U_{\alpha}.
\ee
\end{definition}


\begin{definition}[compact set]
A complex set $A\subseteq \C$ is compact if every open cover of $A$ has a finite subcover.
\end{definition}

\begin{example}
An example of a non-compact set is $D = \bra{z\in \C :\abs{z} < 1}$. If
\be
U_n = \bra{z:\abs{z} < 1 - \frac 1n},\qquad n\in \Z^+,
\ee
then $\bra{U_1,U_2,\dots}$ is an open cover of $D$ for which there is no finite subcover.
\end{example}

%\begin{definition}[compact, complex domain]
%A complex set $X\subseteq \C$ is called compact if it is closed and bounded.
%\end{definition}

%\begin{remark}
%sufficient and necessary condition for compactness
%real :
%complex: closed and bounded.
%\end{remark}

%\begin{theorem}
%The complex set $X\subseteq \C$ is compact if and only if every sequence $\bb{z_n}\subseteq X$ has a subsequence that converges to a point in $X$.
%\end{theorem}

%\begin{proof}[\bf Proof]
%\footnote{proof needed.}
%\end{proof}

In analogy with the situation in $\R$, we have the following equivalent formulation of compactness.


\begin{theorem}\label{thm:complex_set_is_compact_iff_bounded_and_closed}
The following conditions are equivalent for a subset $X$ of $\C$:
\ben
\item [(i)] $X$ is closed and bounded.
\item [(ii)] Every sequence of points in $X$ has subsequence which converges to some point in $X$.
\item [(iii)] $X$ is compact.
\een
\end{theorem}

\begin{remark}
Actually this is the complex version of Heine-Borel theorem.
\end{remark}


\begin{proof}[\bf Proof]
\ben
\item [(i)] $\ra$ (ii). Suppose $X$ is closed and bounded and consider any sequence $(z_n)$ in $X$. Since $X$ is bounded, we have that $(z_n)$ has a convergent subsequence by Bolzano-Weierstrass theorem (Theorem \ref{thm:bolzano_weierstrass_complex}). Since $X$ is closed, we have that the limit of this sequence is in $X$.

\item [(ii)] $\ra$ (iii). Suppose that every sequence in $X$ contains a convergent subsequence with limit in $X$. 

Consider an open cover $\bra{U_\alpha}_{\alpha\in \sA}$ of $X$ such that $X\subseteq \bigcup_{\alpha\in\sA} U_{\alpha}$. For any $z\in X$, we want to show that there exists $\ve>0$ such that $D_\ve(z) \subseteq U_\alpha$ for some $\alpha\in \sA$.

Suppose not, then for every $\ve>0$, in particular for $\ve = \frac 1n$ with $n\in \Z^+$, there is a point $z_n\in X$ such that for every $\alpha\in \sA$ we have that $D_{\frac 1n}(z_n) \not\subseteq U_\alpha$. Consider the sequence $(z_n)$, by the assumption there is a convergent subsequence $(z_{n_k})$ converging to $z^*$. Since $\bra{U_{\alpha}}_{\alpha\in \sA}$ is a cover we know that there is $\alpha^* \in \sA$ such that $z^* \in U_{\alpha^*}$. Since $U_{\alpha^*}$ is open then there is $\delta >0$ such that $D_{\delta}(z^*) \subseteq U_{\alpha^*}$. But since $(z_{n_k})\to z^*$ there is $N\in \N$ such that $\abs{z^* - z_{n_k}} < \delta/2$ whenever $n_k\geq N$.
    
Then pick $n_k\geq N$ and $n_k > 2/\delta$. Then for any $w\in D_{\delta/2}(z_{n_k})$ we have
\be
\abs{z^* - w} = \abs{z^* - z_{n_k} + z_{n_k} - w} \leq \abs{z^* - z_{n_k}} + \abs{z_{n_k} - w} < \frac {\delta}2 + \frac{\delta}2 = \delta.
\ee
    
Therefore,
\be
D_{1/n_k}(z_{n_k}) \subseteq D_{\delta/2} (z_{n_k}) \subseteq D_\delta(z^*) \subseteq U_{\alpha^*}
\ee 
which contradicts the fact that $D_{1/n}(z_n) \not\subseteq U_{\alpha}$ for every $\alpha\in \sA$. 
    
Now for any $z\in X$ we can find $\ve= \ve(z)>0$ such that $D_z := D_\ve(z) \subseteq U_{\alpha}$ for some $\alpha\in \sA$. Obviously, $\bra{D_z}_{z\in X}$ is an open cover of $X$. Suppose we know how to extract a finite subcover $\bra{D_{z_1},\dots,D_{z_M}}$ of $X$, then since each $D_{z_i}$ is contained in some $U_{\alpha_i}$ we can conclude that $\bra{U_{\alpha_1},\dots,U_{\alpha_M}}$ is also a finite subcover. So it is enough to show that $\bra{D_{z}}_{z\in X}$ has a finite subcover of $X$.
    
For any $z_0\in X$. If $D_{z_0}$ covers $X$ we are done, otherwise there is $z_1\in X\bs D_{z_0}$. If $\bra{D_{z_0},D_{z_1}}$ covers $X$ we are done, otherwise there is $z_2\in X\bs\bb{D_{z_0}\cup D_{z_1}}$. If we continue this process we either obtain a finite subcover or a sequence $(z_i)_{i\in \N}$. Observe that for any $i\in \N$, there exists $\ve = \ve(z_i)>0$ such that $\abs{z_i - z_j}>\ve$ for any $j>i$. So the sequence $(z_i)$ cannot have a convergent subsequence which is a contraction to the assumption. Therefore, the process must end at some point and we should have a finite subcover of $X$.
    
\item [(iii)] $\ra$ (i). Suppose $X$ is compact. Consider the collection
\be
\sC = \bra{D_n(0),n\in \N}.
\ee

Clearly $\sC$ is an open cover of $X$ (in fact of whole $\C$). Therefore, since $X$ is compact, there is a finite subcover
\be
\sC_f= \bra{D_{n_1}(0),\dots,D_{n_M}(0)} 
\ee
of $X$. Without loss of generality, we may assume that $n_1<n_2 < \dots < n_M$ then clearly $X \subseteq D_{n_M}(0)$, i.e., $X$ is bounded.

Now we want to prove that $X$ is closed we can prove instead that $\C\bs X$ is open. Given any $z\in \C\bs X$ and any $w\in X$ consider the disk
\be
D_w := D_{\frac 12 \abs{w-z}}(w)
\ee
and the collection 
\be
\sC := \bra{D_w : w\in X}.
\ee

Clearly, $\sC$ is an open cover of $X$ since every point $w$ in $X$ has a disk centered at it in $\sC$. Since $X$ is compact, there is a finite subcover $\sC_f = \bra{D_{w_1},\dots,D_{w_M}}$. Define
\be
\ve := \min_{1\leq i\leq M}\bra{\frac 12\abs{z-w_i}}.
\ee

Then we observe that since $\frac 12 \abs{z - w_i} \geq \ve$, $z$ is at least farther apart than $\ve$ from every point in $D_{w_i}$. Thus, for any $w\in D_{w_i}$ ($\abs{w-w_i} < \frac 12 \abs{z-w_i}$),
\be
\abs{z-w} = \abs{z-w_i + w_i - w} \geq \abs{z - w_i} - \abs{w -w_i} > \abs{z - w_i} - \frac 12 \abs{z-w_i} = \frac 12 \abs{z-w_i} \geq \ve.
\ee

Therefore, $D_{\ve}(z) \cap D_{w_i}= \emptyset$ and 
\be
D_{\ve}(z) \subseteq \C\left\bs \bigcup_{i=1}^M D_{w_i}\right. \subseteq \C \bs X
\ee
which proves that $\C\bs X$ is open (since $z\in \C\bs X$), i.e., $X$ is closed.
\een
\end{proof}

\begin{proposition}
Every closed subset of a compact set in $\C$ is also compact.
\end{proposition}

\begin{proof}[\bf Proof]
Let $A$ and $B$ be sets of complex numbers such that $A\subseteq B$ and let $A$ be closed and $B$ be compact.

Let $\sC = \bra{U_{\alpha}:\alpha \in \sA}$ be any open cover of $A$. Since $A$ is closed, $\C\bs A$ is open. Observe that since $A\subseteq B$ we have that $\sC \cup \bra{\C\bs A}$ is a open cover of $B$. Since $B$ is compact, there exists a finite open subcover $\sC \cup \bra{\C\bs A}$, say
\be
\bra{U_1,U_2,\dots, U_n, \C\bs A}
\ee
with 
\be
A \subseteq B\subseteq \bra{\C\bs A} \cup \bigcup^n_{i=1}U_i  \ \ra\ A \subseteq \bigcup^n_{i=1}U_i.
\ee

This means $\bra{U_1,U_2,\dots, U_n}$ is a finite subcover of $A$. Therefore, $A$ is compact.
\end{proof}

\section{Complex-valued Functions}

\subsection{Complex function of bounded variation}

\begin{definition}[function of bounded variation, total variation]\label{def:function_of_bounded_variation_total_variation_complex}
A function $f:[a,b]\to \C$ with $[a,b]\subseteq \R$ is of bounded variation if there is a constant $M>0$ such that for any partition
\be
P := \bra{a=t_0 < t_1< \dots < t_n =b}
\ee
of $[a,b]$, the function
\be
v_f(P) := \sum^n_{k=1}\abs{f(t_k) - f(t_{k-1})} \leq M.
\ee

The total variation of $f$ for $[a,b]$, is defined by
\be
V_f[a,b] := \sup\bra{v_f(P): P\text{ is a partition of }[a,b]}.
\ee

Clearly, $V_f[a,b] \leq M < \infty$.
\end{definition}

\begin{proposition}
Let $f : [a,b]\to \C$ be of bounded variation. Then
\ben
\item [(i)] If $P$ and $Q$ are partitions of $[a,b]$ and $P\subseteq Q$, then $v_f(P) \leq v_f(Q)$.
\item [(ii)] If $g:[a,b]\to \C$ is also of bounded variation and $\alpha,\beta\in \C$, then $\alpha f+ \beta g$ is of bounded variation and
\be
V_{\alpha f + \beta g} [a,b] \leq \abs{\alpha} \cdot V_f[a,b] + \abs{\beta} \cdot V_g[a,b].
\ee
\een
\end{proposition}

\begin{proof}[\bf Proof]
The result is straight forward by apply triangle inequality.
\end{proof}



\section{Complex Series}

\subsection{Series and partial sum}

\begin{definition}[complex series\index{series!complex}]\label{def:series_complex}
Complex series is the sum of the terms of an infinite sequence $\bb{a_n}_{n\in \N}$ where $a_n\in \C$. It is denoted by 
\be
\sum^\infty_{n=1}a_n.
\ee 
\end{definition}


\begin{definition}[partial sum of complex series\index{partial sum!complex series}]\label{def:partial_sum_convergence_divergence_complex}
Let $\bb{a_n}_{n\in\N}\in \C$ be a sequence. We define the partial sum of this sequence by
\be
\sum^N_{n=1}a_n.
\ee

We say that $\sum^\infty_{n=1}a_n$ converges to $S$\index{convergence!complex series} if the sequence of partial sum
\be
\lim_{N\to \infty}S_N := \lim_{N\to \infty} \sum^N_{n=1}a_n = S.
\ee

In that case we write
\be
\sum^\infty_{n=1}a_n = S.
\ee

If $S_N$ does not converge, we say that $\sum^\infty_{n=1}a_n$ diverges\index{divergence!complex series}.
\end{definition}


\begin{lemma}[term test\index{term test!complex}]\label{lem:complex_series_sum_convergence_imples_sequence_zero}%{lem:sum_convergence_imples_sequence_zero}
Let $(a_n) \in \C$. If the series $\sum^\infty_{n=1}a_n$ converges, then 
\be
\lim_{n\to\infty}a_n=0.
\ee
\end{lemma}

\begin{proof}[\bf Proof]%\ref{lem:basic_convergence_complex}.
$S_n=S_{n-1}+a_n$. If $S_n=\sum^n_{k=1}a_k$ converges, $S_n\to S$. Therefore,
\be
a_n = S_n - S_{n-1} \to S-S = 0
\ee
by Lemma \ref{lem:basic_convergence_complex}.
\end{proof}


\subsection{Absolute convergence of complex series}

\begin{definition}[absolute convergence\index{absolute convergence!complex sequence}]
Take $a_n\in\C$. If $\sum_n\abs{a_n}$ is convergent, then the series is called absolutely convergent.
\end{definition}

\begin{theorem}\label{thm:absolutely_convergence_implies_convergence_complex}
For complex sequence $(a_n)$, if $\sum_{n=1}^{\infty} a_n$ is absolutely convergent, then it is convergent.
\end{theorem}

\begin{proof}[{\bf Proof}]
Suppose that $\sum \abs{a_{k}}$, $a_{k}\in \C$ is convergent. Then equivalently, $\sum \bb{\Re(a_{k})^{2}+\Im(a_{k})^{2}}^{1/2}$ is convergent, which implies that $\sum \abs{\Re (a_{k})} $ and $\sum \abs{\Im (a_{k})}$ converge by termwise comparison of non-negative terms. 

It suffices to show that the convergence of these series implies the convergence of $\sum \Re(a_{k})$ and $\sum \Im(a_{k})$, for then, the convergence of $\sum a_{k}=\sum \Re(a_{k})+i\sum \Im (a_{k})$ would follow, by the definition of the convergence of complex-valued series. Thus, it suffices to show that we need only prove that convergence of $\sum |a_{k}|$, $a_{k}\in \R$ implies the convergence of $\sum a_{k}$. This is due to Theorem \ref{thm:absolutely_convergence_implies_convergence_real}.
\end{proof}

%\footnote{proof needed. Suppose first $a_n\in\mathbb{R}$. Introduce
%\be
%u_n=\frac{|a_n|+a_n}{2},\quad v_n = \frac{|a_n|-a_n}{2}
%\ee
%where $u_n,v_n\geq 0$ and $a_n = u_n - v_n, |a_n| = u_n + v_n\geq u_n,v_n$. By the comparison test and Lemma \ref{lem:basic_convergence_real} (iv), we have
%\be
%\sum|a_n| \text{ converges } \ \Rightarrow \ \sum u_n,\ \sum v_n \text{ converges } \ \Rightarrow \ \sum a_n \text{ converges }.
%\ee

%If $a_n\in\mathbb{C}$, we set $a_n=x_n+iy_n$ where $x_n,y_n\in\mathbb{R}$. By comparision test, we have
%\be
%\left\{\ba{l}
%|x_n|,|y_n| \leq |a_n| = \sqrt{x_n^2+y_n^2} \\
%\sum|a_n| \text{ converges } \ea \right.\ \ra \ \sum|x_n|,\ \sum|y_n| \text{ converges } \ \xlongrightarrow{x_n,y_n\in\mathbb{R}} \ \sum x_n,\ \sum y_n \text{ converges.}
%\ee

%Since $a_n=x_n+iy_n$, we have $\sum a_n $ converges by Lemma \ref{lem:basic_convergence_real}.(iv).}
%


\begin{proof}[\bf Alternative proof]
With $S_n = \sum^n_{k=1}a_k$, $T_n = \sum^n_{k=1}\abs{a_k}$ and $m\geq 0$, there exists $N\in \N$ such that by Proposition \ref{pro:triangle_inequality_complex}
\be
\abs{S_{n+m}-S_n} = \abs{\sum^{n+m}_{i=n+1}a_i} \leq \sum^{n+m}_{i=n+1}|a_n| = T_{n+m} - T_n < \ve,\ \forall n\geq N
\ee
since $T_n$ is Cauchy sequence $\lra$ $T_n$ converges. Hence, $S_n$ is Cauchy, which implies that $S_n$ converges.
\end{proof}


%Alternative proof of Theorem \ref{thm:absolutely_convergenct_implies_convergence}]%\footnote{proof needed. There is an alternative `quick' proof of this using Cauchy sequences. 

%\begin{proof}[\bf Alternative proof]
%With $S_n = \sum^n_{i=1}a_i,\ T_n = \sum^n_{i=1}\abs{a_i}$ and $m\geq 0$, we have $\exists N$ such that by Proposition \ref{pro:triangle_inequality_complex}
%\be
%\abs{S_{n+m}-S_n} = |\sum^{n+m}_{i=n+1}a_i| \leq \sum^{n+m}_{i=n+1}|a_n| = T_{n+m} - T_n < \varepsilon,\ \forall n\geq N
%\ee
%since $T_n$ is Cauchy sequence $\Leftrightarrow\ T_n$ converges. Hence, $S_n$ is Cauchy, which implies that $S_n$ converges.
%\end{proof}

\begin{definition}[conditional convergence]
Let $a_n\in \C$. If $\sum_n a_n$ converges, but $\sum_n\abs{a_n}$ does not converge. We say that the series is conditionally convergent.
\end{definition}

\begin{theorem}\label{thm:absolute_convergence_change_term_order_same_sum_complex}
Let $a_n\in \C$. If $\sum a_n$ is absolutely convergent, then any series consisting of the same terms in any order (a rearrangement) has the same sum.
\end{theorem}

\begin{proof}[{\bf Proof}]
Let $\sum_n b_n$ be a rearrangement of $\sum_n a_n$. Then given any $\ve>0$, we can choose $n\in \N$ such that
\be
\sum^\infty_{k=n+1} \abs{a_k} < \ve
\ee
by Lemma \ref{lem:real_series_sum_convergence_imples_sequence_zero} since $\sum_n a_n$ is absolutely convergent. Then we can choose $N\in \N$ such that
\be
\bra{a_1,\dots, a_n} \subseteq \bra{b_1,\dots,b_N}.
\ee

Then for any $m\geq N$, we have
\be
\sum^\infty_{k=0}a_k - \sum^m_{k=0} b_k = \sum_{k\in A_m}a_k
\ee
where $A_m = \bra{n+1,n+2,\dots }\bs\bra{\text{finitely many points}}$. Hence, for any $m\geq N$, it follows that
\be
\abs{\sum^\infty_{k=0}a_k - \sum^m_{k=0} b_k} = \abs{\sum_{k\in A_m}a_k} \leq  \sum_{k\in A_m}\abs{a_k} \leq \sum^\infty_{k=n+1}\abs{a_k} < \ve.
\ee

Thus, we have that $\sum^m_{k=0} b_k$ converges and furthermore
\be
\sum^\infty_{n=0}a_n = \sum^\infty_{n=0}b_n.
\ee
\end{proof}

%Let $\sum_n a_n'$ be a rearrangement of $\sum_n a_n$ and
%\be
%S_n = \sum^n_{k=1}a_k,\qquad T_n = \sum^n_{k=1}a'_k,\qquad S = \sum^\infty_{k=1}a_k
%\ee
%by Theorem \ref{thm:absolutely_convergence_implies_convergence_complex}. Suppose $a_n\geq 0$, then given $n$, there exists $m\geq 0$ such that $S_m$ contains every term in $T_n$, thus $T_n \leq S_m \leq S$ since $a_n\geq 0$. By the fundamental axiom of analysis (Theorem \ref{thm:fundamental_axiom_of_analysis}), $T_n\to T\leq S$. By symmetry, we have $S\leq T$ and thus $S=T$.
%
%If $a_n$ can have any sign, consider
%\be
%u_n = \abs{a_n} + a_n,\quad v_n = \abs{a_n}  -a_n, \quad u'_n = \abs{a'_n} + a'_n ,\quad v'_n = \abs{a'_n} - a'_n ,\qquad n\in \N.
%\ee
%
%Since $0\leq u_n,v_n \leq 2\abs{a_n}$, we have that $\sum_n u_n$ converges since $\sum^n_{k=1} u_k$ is bounded increasing sequence of partial sums. Thus, $\sum_n u_n$ converges. Similarly, we have that $\sum_n v_n$ converges. With the fact that $u_n,u'_n\geq 0$, we have $\sum u_n$ and $\sum u_n'$ converge to the same limit and $\sum v_n$ and $\sum v_n'$ converge to the same limit.
%
%Hence $a_n = u_n - v_n$ and $a_n' = u_n' - v_n'$ converge to the same limit.


%\footnote{proof needed. We will prove it for $a_n\in\mathbb{R}$ and leave the extension to $\mathbb{C}$ as an exercise.

%Let $\sum a_n'$ be a rearrangement of $\sum a_n$ and $S_n = \sum^n_{i=1}a_i$, $S = \sum^\infty_{i=1}a_i$, $T_n = \sum^n_{i=1}a_i'$. Suppose fixed $a_n\geq 0$, then given $n$, $\exists m$ s.t. $S_m$ contains every term in $T_n$, thus $T_n\leq S_m \leq S,\ (a_n\geq 0)$. By the fundamental axiom, $T_n\to T\leq S$. By symmetry, we have $S\leq T \ \Rightarrow\ S=T$.

%If $a_n$ has any sign, consider $u_n$ and $v_n$ from the proof of Theorem \ref{thm:absolutely_convergenct_implies_convergence} and $\sum a_n'$, $\sum u_n'$, $\sum v_n'$. Since $\sum |a_n|$ converges, both $\sum u_n$ and $\sum v_n$ converge. With the fact that $u_n,v_n\geq 0$, we have $\sum u_n$ ($\sum v_n$) and $\sum u_n'$ ($\sum v_n'$) converge to the same limit.

%Hence $a_n = u_n - v_n$ and $a_n' = u_n' - v_n'$ converge to the same limit.}


\subsection{Basic tests for complex series}

\begin{theorem}[root test\index{root test}]\label{thm:root_test_complex}
Let the sequence $(a_n)\in \R$. Suppose $\abs{a_n}^{\frac 1n}\to \ell \in \R$ as $n\to\infty$, then
\be
\left\{\ba{ll}
\sum_n a_n \text{ converges } \quad & \ell <1\\
\sum_n a_n \text{ diverges } \quad & \ell >1
\ea\right.
\ee
\end{theorem}

%\begin{remark}
%If $x=1$, the test does not give any information. In fact later on, we will see examples with $x=1$ which convergent and divergent.
%\end{remark}

\begin{proof}[{\bf Proof}]
Suppose $\abs{a_n}^{\frac 1n}\to \ell$ with $\ell <1$. Take $r$ such that $\ell <r<1$. By the definition of convergence, given $\ve>0$, then there exists $N\in\N$ such that $\forall n\geq N$,
\be
\abs{\abs{a_n}^{\frac 1n}-\ell}< \ve \ \ra \ \ell-\ve< \abs{a_n}^{\frac 1n} < \ell +\ve.
\ee

Taking $\ve =r-\ell$, we have
\be
\abs{a_n}^{\frac 1n} < r,\ \forall n\geq N \ \ra \ \abs{a_n} < r^n, \ \forall n\geq N \ \ra \ \sum_n \abs{a_n} < \sum_n r^n.
\ee

Since the geometric series $\sum_n r^n$ converges for $r<1$ by Proposition \ref{pro:geometric_series_sum}, the comparison test (Theorem \ref{thm:comparison_test}) gives us right away that $\sum_n \abs{a_n}$ converges. Then we have that $\sum_n a_n$ converges by Theorem \ref{thm:absolutely_convergence_implies_convergence_complex}.

Suppose now $\abs{a_n}^{\frac 1n}\to \ell$ with $\ell >1$. By the definition of limit, there exists $N\in \N$ such that $\abs{a_n}^{\frac 1n}> 1$, $\forall n\geq N$. Thus, $\abs{a_n} >1$ $\forall n\geq N$, in particular $a_n$ does not tend to zero. By Lemma \ref{lem:complex_series_sum_convergence_imples_sequence_zero}, $\sum_n a_n$ diverges.
\end{proof}



\begin{theorem}[ratio test\index{ratio test}]\label{thm:ratio_test_complex}
Suppose $a_n \neq 0$, and $\abs{\frac{a_{n+1}}{a_n}}\to \ell$ as $n\to\infty$. Then
\be
\left\{\ba{ll}
\sum_n a_n \text{ converges } \quad & \ell<1,\\
\sum_n a_n \text{ diverges } \quad & \ell >1.
\ea\right.
\ee
\end{theorem}

\begin{proof}[{\bf Proof}]
Suppose $\abs{\frac{a_{n+1}}{a_n}}\to \ell$ with $\ell<1$. Take $r\in \R$ such that $\ell<r<1$. By the definition of convergence, given $\ve>0$, $\exists N$ such that $\forall n\geq N$,
\be
\abs{\abs{\frac{a_{n+1}}{a_n}} -\ell}<\ve \ \ra \ \ell -\ve < \abs{\frac{a_{n+1}}{a_n}} < \ell+\ve.
\ee

Take $\ve=r-\ell$, thus $\forall n\geq N$, $\abs{\frac{a_{n+1}}{a_n}} < r$ and thus
\be
\abs{a_n} = \abs{\frac{a_n}{a_{n-1}}}\cdot\abs{\frac{a_{n-1}}{a_{n-2}}}\cdot \cdots \cdot \abs{\frac{a_{N+1}}{a_N}} \cdot \abs{a_N}\ \ra \ \abs{a_n} < \abs{a_N} r^{n-N}
\ee

In other words, there is a constant $K$ (independent of $n$) such that $\abs{a_n} < K r^{n-N}$,  $\forall n\geq N$. Since $r<1$, the series $\sum_n K r^n$ converges by Proposition \ref{pro:geometric_series_sum} and $\sum_n a_n$ also converges by the comparison test (Theorem \ref{thm:comparison_test}).

Suppose now $\abs{\frac{a_{n+1}}{a_n}}\to \ell$ with $\ell>1$. By the definition of limit, there exists $N\in \N$ such that $\abs{\frac{a_{n+1}}{a_n}} >1$, $\forall n\geq N$. This is saying that sequence $\abs{a_n}$ increases after $N$. In particular, $\abs{a_n}>\abs{a_N}$, $\forall n\geq N$, which is saying $a_n$ does not tend to zero. By Lemma \ref{lem:complex_series_sum_convergence_imples_sequence_zero}, $\sum_n a_n$ diverges.
\end{proof}




\subsection{Uniformly convergent series}

\begin{definition}[uniformly convergent series]
Consider the functions $(f_n(z))$ defined on $A\subseteq \C$ and
\be
S_n(z) := \sum^n_{k=1} f_k(z).
\ee

If the function $S_n(z)$ converges uniformly in $A$, then we say $\sum^\infty_{k=1} f_k(z)$ is a uniformly convergent series.
\end{definition}

\footnote{example needed.}

%\subsection{Weierstrass M-test}

\begin{theorem}[Weierstrass M-test\index{Weierstrass M-test}]\label{thm:weierstrass_m_test}
Suppose that $(f_n)$ is a sequence of complex functions defined on a set $A\subseteq \C$ and there is a sequence of positive number $(M_n)$ satisfying for any $n\in \N$ and $\forall x\in A$,
\be
\abs{f_n(z)} \leq M_n,\qquad \sum^\infty_{n=0} M_n \ \text{converges}.
\ee

Then series
\be
\sum^\infty_{n=0} f_n(z) \quad\text{converges absolutely and uniformly on }A.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Let
\be
S_n(z) = \sum^n_{k=1} f_k(z).
\ee

Since the series $\sum^\infty_{n=0} M_n$ converges and thus it is Cauchy sequences, we have for any $\ve>0$ there exist $N\in \N$ for all $n>m>N$
\be
\abs{\sum^n_{k=m+1} M_k} = \abs{\sum^n_{k=1} M_k - \sum^m_{k=1} M_k} < \ve.
\ee

Thus, for the chosen $N$ and all $x\in A$ and all $n>m>N$,
\be
\abs{S_n(z)- S_m(z)} = \abs{\sum^n_{k=m+1} f_k(z)} \leq \sum^n_{k=m+1} \abs{f_k(z)} \leq  \sum^n_{k=m+1} M_k < \ve
\ee
by triangle inequality. Therefore, the sequence of partial sums of series is Cauchy sequence. Since Cauchy sequences are convergent\footnote{theorem needed.} in complex plane, we have that $S_n(z) = \sum^n_{k=1} f_k(z)$ converges absolutely and uniformly on $A$.
\end{proof}


\subsection{Dirichlet's test}

\begin{theorem}[Dirichlet test\index{Dirichlet test}]\label{thm:dirichlet_test}
Let $(a_n)$ be a sequence of real numbers and $(b_n)$ be a sequence of complex numbers satisfying
\ben
\item [(i)] $0<a_{n+1} \leq a_n$ and $\lim_{n\to \infty} a_n = 0$.
\item [(ii)] $\abs{\sum^N_{n=1}b_n} \leq M$ for every integer $N$ where $M$ is some constant.
\een

Then we have that the series
\be
\sum^\infty_{n=1} a_nb_n \ \text{ converges.}
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Let
\be
S_n = \sum^n_{k=1} a_kb_k,\qquad B_n = \sum^n_{k=1} b_k.
\ee

Then from summation by parts, we have
\beast
S_n & = & \sum^n_{k=1} a_kb_k = a_{n+1}\sum^n_{k=1}b_k + \sum^n_{i=1}b_i\bb{a_i-a_{n+1}} = a_{n+1}B_n + \sum^n_{i=1}b_i\sum^n_{k=i}\bb{a_k-a_{k+1}} \\
& = & a_{n+1}B_n + \sum^n_{k=1}\bb{a_k-a_{k+1}} \sum^k_{i=1} b_i = a_{n+1}B_n + \sum^n_{k=1}B_k\bb{a_k-a_{k+1}}  .
\eeast

Since $B_n$ is bounded by $M$ and $a_n\to 0$, the first of these terms approaches to zero, $a_{n+1}B_n \to 0$ as $n\to \infty$.

On the other hand, since the sequence $a_n$ is decreasing, $a_k-a_{k+1}$ is non-negative for all $k$, so
\be
\abs{B_k\bb{a_k-a_{k+1}}} \leq M(a_k-a_{k+1}).
\ee

But
\be
\sum^n_{k=1}M\bb{a_k-a_{k+1}} = M\sum^n_{k=1}\bb{a_k-a_{k+1}}
\ee
is a telescoping series that equals $M\bb{a_1 - a_{n+1}}$ ana therefore approaches $Ma_1$ as $n\to\infty$. Thus,
\be
\sum^\infty M\bb{a_1 - a_{n+1}} \quad \text{converges.}
\ee

Thus, by the comparison test (Theorem \ref{thm:comparison_test}),
\be
\sum^{\infty}_{k=1}\abs{B_k\bb{a_k-a_{k+1}}} \quad \text{converges} \quad \ra \quad \sum^{\infty}_{k=1}B_k\bb{a_k-a_{k+1}} \quad \text{converges}
\ee
by Theorem \ref{thm:absolutely_convergence_implies_convergence_complex}. Thus, $S_n$ converges.
\end{proof}

\begin{example}
A particular case of Dirichlet's test is the more commonly used alternating series test (Theorem \ref{thm:alternating_series_test}) for the case
\be
b_n = (-1)^n \ \ra\ \abs{\sum^N_{n=1}b_n} \leq 1.
\ee
\end{example}

\begin{example}
If $a_n = \frac 1n$, $b_n = z^n$ where $z = re^{ix}$ with $x\in \R$, $\abs{z}\leq 1$ and $z\neq 1$, then (i) and (ii) are obvious. In addition,
\be
\abs{\sum^N_{n=1} b_n} = \abs{\sum^N_{n=1} \bb{re^{ix}}^n} =  \abs{\frac{1 - \bb{re^{ix}}^{n+1}}{1 - re^{ix}}} \leq \frac{1 +\abs{ \bb{re^{ix}}^{n+1}}}{\abs{1 - re^{ix}}} \leq \frac{2}{\abs{1 - re^{ix}}} := M.
\ee

Therefore,
\be
\sum^\infty_{n=1} \frac {r^n}n e^{inx} = \sum^\infty_{n=1} \frac {r^n}n  \cos nx + i \sum^\infty_{n=1} \frac {r^n}n \sin nx
\ee
converges.
\end{example}

\subsection{Cauchy product and Mertens' theorem}


\begin{definition}[Cauchy product]\label{def:cauchy_product}
Let $\sum_{n=0}^\infty a_n$ and $\sum_{n=0}^\infty b_n$ be two infinite series with complex terms. The Cauchy product of these two infinite series is defined by a discrete convolution as follows:
\be
\sum_{n=0}^\infty c_n,\qquad c_n =\sum_{k=0}^n a_k b_{n-k}.
\ee
\end{definition}

Then we have the following important thoerem proved by Franz Mertens.

\begin{theorem}[Mertens' theorem]\label{thm:mertens_cauchy_product}
Let $(a_n)$ and $(b_n)$ be complex (or real) sequences. If the series $\sum _{{n=0}}^{\infty }a_{n}$ converges to $A$ and $\sum _{{n=0}}^{\infty }b_{n}$ converges to $B$, and at least one of them converges absolutely, then their Cauchy product $\sum_{n=0}^\infty c_n$ converges to $AB$.
\end{theorem}

\begin{proof}[\bf Proof]
Assume without loss of generality that the series $\sum _{{n=0}}^{\infty }a_{n}$ converges absolutely. Define the partial sums
\be
A_{n}=\sum _{{i=0}}^{n}a_{i},\quad B_{n}=\sum _{{i=0}}^{n}b_{i}\quad {\text{and}}\quad C_{n}=\sum _{{i=0}}^{n}c_{i}
\ee
with
\be
c_{i}=\sum _{{k=0}}^{i}a_{k}b_{{i-k}}.
\ee

Then
\be
C_{n} = \sum _{{i=0}}^{n} \sum _{{k=0}}^{i}a_{k}b_{{i-k}} =\sum _{{k=0}}^{n} \sum _{{i=k}}^{n}  a_{k}b_{{i-k}} = \sum _{{k=0}}^{n} a_{k} \sum _{{i=k}}^{n}  b_{{i-k}} = \sum _{{k=0}}^{n} a_{k} B_{n-k} = \sum _{{k=0}}^{n}a_{{n-k}}B_{k}
\ee
by rearrangement, hence
\be
C_{n}=\sum _{{k=0}}^{n}a_{{n-k}}(B_{i}-B)+A_{n}B.\qquad (*)
\ee

Then given any $\ve > 0$. Since 
\be
\sum _{{k\in {{\mathbb N}}}}|a_{k}|<\infty 
\ee
by absolute convergence, and since $B_n$ converges to $B$ as $n \to \infty$, there exists an integer $N$ such that, for all integers $n \geq N$,
\be
|B_{n}-B|\leq {\frac {\varepsilon /3}{\sum _{{k\in {{\mathbb N}}}}|a_{k}|+1}}\qquad (\dag)
\ee
(this is the only place where the absolute convergence is used). Since the series of the $(a_n)$ converges, the individual an must converge to 0 by the term test. Hence there exists an integer $M$ such that, for all integers $n \geq M$,
\be
|a_{n}|\leq {\frac {\varepsilon }{3N(\sup _{{k\in \{0,\dots ,N-1\}}}|B_{k}-B|+1)}}.\qquad (\dag\dag)
\ee        

Also, since $A_n$ converges to $A$ as $n \to \infty$, there exists an integer $L$ such that, for all integers $n \geq L$,
\be
|A_{n}-A|\leq {\frac {\varepsilon /3}{|B|+1}}.\qquad (\dag\dag\dag)
\ee

Then, for all integers $n \geq \max\bra{L, M + N}$, use the representation ($*$) for $C_n$, split the sum in two parts, use the triangle inequality for the absolute value, and finally use the three estimates ($\dag$), ($\dag\dag$) and ($\dag\dag\dag$) to show that
\be
{\begin{aligned}|C_{n}-AB|&={\biggl |}\sum _{{k=0}}^{n}a_{{n-k}}(B_{k}-B)+(A_{n}-A)B{\biggr |}\\&\leq \sum _{{k=0}}^{{N-1}}|a_{{\underbrace {\scriptstyle n-k}_{{\scriptscriptstyle \geq M}}}}|\,|B_{k}-B|+\sum _{{k=N}}^{n}|a_{{n-k}}|\,|B_{k}-B|+|A_{n}-A|\,|B|<\frac{\ve}3 + \frac{\ve}3 + \frac{\ve}3=  \varepsilon .\end{aligned}}
\ee

By the definition of convergence of a series, $C_n \to AB$ as required.
\end{proof}

\begin{remark}
It is not sufficient for both series to be convergent; if both sequences are conditionally convergent, the Cauchy product does not have to converge towards the product of the two series, as the following example shows.

Consider the two alternating series with
\be
a_{n}=b_{n}={\frac {(-1)^{n}}{{\sqrt {n+1}}}},
\ee
which are only conditionally convergent (the divergence of the series of the absolute values follows from the direct comparison test and the divergence of the harmonic series). The terms of their Cauchy product are given by
\be
c_{n}=\sum _{{k=0}}^{n}{\frac {(-1)^{k}}{{\sqrt {k+1}}}}\cdot {\frac {(-1)^{{n-k}}}{{\sqrt {n-k+1}}}}=(-1)^{n}\sum _{{k=0}}^{n}{\frac {1}{{\sqrt {(k+1)(n-k+1)}}}}
\ee
for every integer $n \geq 0$. Since for every $k \in \bra{0, 1, \dots, n}$ we have the inequalities 
\be
k + 1 \leq n + 1,\qquad n - k + 1 \leq n + 1,
\ee
it follows for the square root in the denominator that $\sqrt{(k + 1)(n -k + 1)} \leq n +1$, hence, because there are $n + 1$ summands,
\be
\abs{c_{n}}\geq \sum _{k=0}^{n}{\frac {1}{n+1}}=1
\ee
for every integer $n \geq 0$. Therefore, $c_n$ does not converge to zero as $n \to \infty$, hence the series of the $(c_n)$ diverges by the term test (Lemma \ref{lem:complex_series_sum_convergence_imples_sequence_zero}).
\end{remark}



\section{Continuous Functions}

\subsection{Continuous function}

\begin{definition}[continuous function\index{continuous function!complex}]\label{def:continuous_function_complex}
Let $f:A\to \C$ be a complex function defined on a set $A\subseteq \C$.

Then $f$ is said continuous at $z_0\in A$ if given any $\ve>0$ there exists $\delta>0$ such that whenever $z\in A$ and $\abs{z-z_0}<\delta$ then
\be
\abs{f(z)-f(z_0)} <\ve.
\ee

Equivalently, we say $f$ is continuous at $z_0\in A$ if for any sequence $\bra{z_1,z_2,\dots}\in A$ such that $\lim_{n\to \infty}z_n = z_0$ then
\be
\lim_{n\to \infty}f(z_n) = f(z_0).
\ee
\end{definition}

\begin{remark}
These two definitions are equivalent. See the similar argument in real case (remark of Definition \ref{def:continuous_function_real}).
\end{remark}


\begin{proposition}\label{pro:complex_real_imaginary_conjugate_modulus_continuous}
Let $z\in \C$. Then $\Re z$, $\Im z$, $\ol{z}$ and $\abs{z}$ are continuous at any point $z_0\in \C$.
\end{proposition}

\begin{proof}[\bf Proof]
Let any $z_0 \in\C$ and $z_n \to z_0$. Then
\beast
\abs{\Re z_n - \Re z_0} & = & \abs{\Re\bb{z_n - z_0}} \leq \abs{z_n - z_0} \to 0,\\
\abs{\Im z_n - \Im z_0} & = & \abs{\Im\bb{z_n - z_0}} \leq \abs{z_n - z_0} \to 0.
\eeast

Also, $\abs{\ol{z_n} - \ol{z_0}} = \abs{\ol{z_n - z_0}} = \abs{z_n - z_0} \to 0$. Furthermore, by Proposition\footnote{triangle inequality}
\be
\abs{\abs{z_n} - \abs{z_0}} \leq \abs{z_n - z_0} \to 0.
\ee
\end{proof}

\begin{proposition}\label{pro:complex_continuous_iff_real_imaginary_parts_continuous}
A complex function $f= u+ iv$ is continuous at a point $z_0$ if and only if both its real and imaginary parts are continuous.
\end{proposition}

\begin{proof}[\bf Proof]
($\la$). If the real and imaginary parts are continuous, we have that for any $z_0$ with $\abs{z_n - z_0} \to 0$,
\be
\abs{u(z_n) - u(z_0)} \to 0,\qquad \abs{v(z_n) - v(z_0)} \to 0.
\ee

Then by triangle inequality, 
\be
\abs{f(z_n) - f(z_0)} = \abs{u(z_n) - u(z_0) + i\bb{v(z_n) - v(z_0)}} \leq \abs{u(z_n) - u(z_0)} + \abs{v(z_n) - v(z_0)} \to 0
\ee
which implies that $f$ is continuous at point $z_0$.

($\ra$). If $f$ is continuous at $z_0$, then we can find $(z_n)$ such that $\abs{z_n - z_0} \to 0$, $\abs{f(z_n) - f(z_0)} \to 0$. Then for real part
\be
\abs{u(z_n) - u(z_0)} = \abs{\Re\bb{f(z_n) - f(z)}} \leq \abs{f(z_n) - f(z_0)} \to 0
\ee
which implies that $u$ is continuous at point $z_0$. Similar for $v$.
\end{proof}

\subsection{Bounded function}

\begin{definition}[bounded function\index{bounded function!complex}]
Let $f$ be a complex function on the set $X\subseteq \C$. Then $f$ is bounded if there exists $M>0$ such that
\be
\abs{f(z)} < M,\qquad z\in X.
\ee
\end{definition}

\subsection{Properties of continuous function}

\begin{proposition}\label{pro:basic_continuous_complex_property}
Let $f,g$ be continuous at $z\in \C$. Then the following functions
\be
f+g,\qquad f-g,\qquad \lm f\quad(\lm\in \C),\qquad fg,\qquad \frac{f}{g}\quad(g(x)\neq 0), \qquad f\circ g
\ee
are continuous at $z$.
\end{proposition}


\begin{proof}[\bf Proof]
Direct result from Definition \ref{def:continuous_function_complex} and Lemma \ref{lem:basic_convergence_complex}. Note that we have $g(z_n)\neq 0$ when we assume $g(z_n) \to g(z)\neq 0$. This sequence $(z_n)$ can be found since $g$ is continuous.
\end{proof}

\begin{example}
$f(z)=z$ is clearly continuous. By Proposition \ref{pro:basic_continuous_complex_property}, any ploynomial is continuous at every point of $\C$.
\end{example}


\begin{proposition}\label{pro:absolute_value_of_continuous_function_complex}
Let $f(z)$ be a continuous complex-valued function. Then $\abs{f(z)}$ is also continuous.
\end{proposition}

\begin{proof}[\bf Proof]
Direct result of definition of continuity and triangle inequality. In particular,
\be
\abs{\abs{f(z_n)} - \abs{f(z)}} \leq \abs{f(z_n) - f(z)}.
\ee
\end{proof}



\begin{theorem}\label{thm:complex_continuous_function_reserves_boundedness_and_closeness}
Let $X$ be a closed and bounded complex set and $f$ be a complex-valued continuous function defined on $X$. Then $f(X)$, the image of function $f$ is also closed and bounded.
\end{theorem}

\begin{proof}[\bf Proof]
Let $y$ be any limit point of $f(X)$ and let $(z_n)$ be sequence in $X$ such that $\lim_{n\to \infty}f(z_n) = y$. Since $X$ is bounded, $(z_n)$ has a convergent subsequence $(z_{n_k})$ by Bolzano-Weierstrass theorem (Theorem \ref{thm:bolzano_weierstrass_complex}). Since $X$ is closed, we have that limit of $(z_{n_k})$, say $z$ must be in $X$, i.e., $\lim_{k\to \infty} z_{n_k} = z$ by Theorem \ref{thm:closed_complex_set_contains_all_limit_points_equals_closure}. Then by continuity of function $f$,
\be
\lim_{k\to \infty} f(z_{n_k}) = f(z).
\ee

Since $f(z_{n_k})$ must have the same limit as $f(z_n)$, we have that $y = f(z) \in f(X)$. Then we have that $f(X)$ is closed.

Now suppose $f(X)$ is not bounded on $X$. Then for any $n\in \N$, there exists $z_n\in X$ such that $\abs{f(z_n)} > n$. Thus, we can construct the sequence $(z_n)$ in $X$. Note that $(z_n)$ is bounded as $X$ is bounded. Then by Bolzano-Weierstrass theorem (Theorem \ref{thm:bolzano_weierstrass_complex}), $(z_n)$ has a limit point $z$ such that there exists a subsequence $(z_{n_k})$ converges to $z$. Moreover, $z\in X$ since $X$ is closed by Theorem \ref{thm:closed_complex_set_contains_all_limit_points_equals_closure}.

This implies that $\lim_{k\to \infty}f(z_{n_k}) = f(z)$ and $\lim_{k\to \infty}\abs{f(z_{n_k})} = \abs{f(z)}$ by Proposition \ref{pro:absolute_value_of_continuous_function_complex}. This contradicts to the assumption. Thus $f(X)$ is bounded.
\end{proof}


\begin{corollary}
The image of continuous function on a compact set is also compact.
\end{corollary}

\begin{proof}[\bf Proof]
Direct result from Theorem \ref{thm:complex_continuous_function_reserves_boundedness_and_closeness} and Theorem \ref{thm:complex_set_is_compact_iff_bounded_and_closed}.
\end{proof}

\begin{remark}
This is actually the complex version of the fact that the continuity reserves the compactness.\footnote{see more general version in topology.}
\end{remark}


\subsection{Uniformly continuous funciton}

\begin{definition}[uniform continuity]\label{def:uniformly_continuous_function_complex}
Let $X,Y\subseteq \C$ be two subsets. Then a function $f:X\to Y$ is uniformly continuous if for any $\ve>0$ and any $x,y\in X$ there exists $\delta>0$ (depending only on $\ve$) such that $\abs{f(x) - f(y)} < \ve$ whenever $\abs{x - y} < \delta$.
\end{definition}




\subsection{Uniform convergence theorem}


\begin{theorem}[uniform convergence theorem\index{uniform convergence theorem!complex function}]\label{thm:uniform_convergence_continuous_complex}
If $f_n:X\to \C$ is a sequence of continuous functions all of which are defined on the disc $X\subseteq \C$ which converges uniformly to the function $f$ on the disc $X$, then $f$ is continuous on $X$ as well.
\end{theorem}

\begin{proof}[\bf Proof]
For any $\ve>0$ and any $z_0\in X$, we have there exists $\delta >0$ such that $\abs{z-z_0}<\delta$ and
\be
\abs{f_n(z) - f_n(z_0)} < \frac{\ve}{3}
\ee
since $f_n$ is continuous at $z_0$. Also, there exists $n$ such that for all $z\in X$,
\be
\abs{f_n(z) - f(z)} < \frac{\ve}3
\ee
since $f_n$ uniformly converges to $f$ on $X$. In particular, we must have
\be
\abs{f_n(z_0) - f(z_0)} < \frac{\ve}3.
\ee

Therefore,
\beast
\abs{f(z) - f(z_0)} & = & \abs{f(z) - f_n(z)+f_n(z) - f_n(z_0) + f_n(z_0) - f(z_0)} \\
& \leq &  \abs{f(z) - f_n(z)} + \abs{f_n(z) - f_n(z_0)} + \abs{f_n(z_0) - f(z_0)} < \frac{\ve}3 + \frac{\ve}3+ \frac{\ve}3 = \ve.
\eeast
which implies that $f$ is continuous on $X$.
\end{proof}


\begin{example}
The natural exponential $\exp:\C\to \C$ is continuous at every point $z\in \C$ (see Proposition \ref{pro:natural_exponential_complex_continuous}).
\end{example}



\section{Differentiable Functions}

\subsection{Differentiable functions}

%\begin{definition}[neighbourhood\index{neighbourhood}]\label{def:neighbourhood_complex}
%The set of points $z\in \C$ such that $\abs{z-z_0} <\ve$ where $z_0\in \C$ and $\ve \in \R$, contains points that are inside the circle centered at $z_0$ and with radius $\ve$. We call it a neighbourhood of $z_0$ and denote it by $N_\ve(z_0)$.

%A deleted neighbourhood\index{deleted neighbourhood} of $z_0$ is the point set $N_\ve(z_0)\bs\bra{z_0}$. We write it as $\wh{N}_\ve(z_0)$.
%\end{definition}

\begin{definition}[differentiable function\index{differentiable function!complex}]\label{def:differentiable_function_complex}
Let $f$ be a complex function that is defined at all points in some open disc of complex point $z_0$. Then the function $f$ is differentiable at $z_0$ if the limit
\be
\lim_{z\to z_0} \frac{f(z)-f(z_0)}{z-z_0}
\ee
exists. Also, the derivative of $f$ at $z_0$ is written $f'(z_0)$ (or $\fd{}{z}f(z_0)$) and is defined by the equation
\be
f'(z_0) = \lim_{z\to z_0} \frac{f(z)-f(z_0)}{z-z_0}.
\ee%provided that the limit exists.  

If we write $\Delta z = z-z_0$, then the definition can be expressed in the form
\be
f'(z_0) = \lim_{\Delta z\to 0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z} = \lim_{\Delta z\to 0} \frac{\Delta f}{\Delta z}.
\ee

Note that the value of the limit must be independent of the manner in which $\Delta z\to 0$. If we can find two paths that end at $z_0$ along which $\Delta f/\Delta z$ approaches distinct values, then $\Delta f/\Delta z$ does not have a limit as $\Delta z\to 0$ and $f$ does not have a derivative at $z_0$.
\end{definition}

\begin{remark}
The definition of derivative for complex functions is formally the same as the real functions and is the natural extension from real variables to complex variables (see Definition \ref{def:differentiable_function_real}). 
\end{remark}

\begin{example}
If $f(z) = z^3$, show we can get for any $z_0\in \C$,
\be
f'(z_0) = \lim_{z\to z_0} \frac{z^3 - z_0^3}{z-z_0} = \lim_{z\to z_0} \frac{(z-z_0)(z^2 + zz_0 + z_0^2)}{z -z_0} = \lim_{z\to z_0} z^2 + zz_0 + z_0^2 = 3z_0^2.
\ee

The subscript on $z_0$ can be dropped to obtain the general formula $f'(z) = 3z^2$.
\end{example}

%\begin{example}%The function $1/z$ is holomorphic on any open set in $\C$ that does not contain the origin, and $f'(z) = -1/z^2$.
%\end{example}

\begin{example}
For $z_0 \neq 0$ and function $f(z) = 1/z$ we have $f'(z) = -1/z^2$.
\beast
\lim_{z\to z_0}\frac{f(z) - f(z_0)}{z - z_0} & = & \lim_{z\to z_0}\frac{1/z - 1/z_0}{z-z_0} = -\lim_{z\to z_0}\frac{\frac{z - z_0}{zz_0}}{z-z_0} \\
& = & -\lim_{z\to z_0}\frac{1}{zz_0} = - \frac 1{z_0^2}.
\eeast
\end{example}

\begin{example}
However, the function $f(z) = \ol{z} = x - iy$ is nowhere differentiable.

To show this, we choose two approaches to the point $z_0 = x_0 + iy_0$ and compute limits of the difference quotients. First, we approach $z_0 = x_0 + iy_0$ along a line parallel to the $x$ axis by forcing $z$ to be the form $z = x+iy_0$,
\beast
\lim_{z\to z_0} \frac{f(z)-f(z_0)}{z-z_0} & = & \lim_{(x,iy_0)\to (x_0,iy_0)}\frac{f(x+iy_0)-f(x_0+iy_0)}{x+iy_0-(x_0+iy_0)} = \lim_{(x,iy_0)\to (x_0,iy_0)}\frac{x-iy_0-(x_0-iy_0)}{x+iy_0-(x_0+iy_0)} \\
& = & \lim_{(x,iy_0)\to (x_0,iy_0)}\frac{x-x_0}{x-x_0} = 1. 
\eeast

Second, we approach $z_0$ along a line parallel to the $y$ axis by forcing $z$ to be of the form $z = x_0 + iy$,
\beast
\lim_{z\to z_0} \frac{f(z)-f(z_0)}{z-z_0} & = & \lim_{(x_0,iy)\to (x_0,iy_0)}\frac{f(x_0+iy)-f(x_0+iy_0)}{x_0+iy-(x_0+iy_0)} = \lim_{(x_0,iy)\to (x_0,iy_0)}\frac{x_0-iy-(x_0-iy_0)}{x_0+iy-(x_0+iy_0)} \\
& = & \lim_{(x_0,iy)\to (x_0,iy_0)}\frac{-i(y-y_0)}{i(y-y_0)} = -1. 
\eeast

Since the limits along the two approaches are different, there is no computable limit for the right side of the definition of derivative. Therefore, $f(z) = \ol{z}$ is not differentiable at the point $z_0$. Since $z_0$ was arbitrary, $f(z)$ is nowhere differentiable.
\end{example}

\begin{example}
The function $f(z) = \abs{z}^2$ is differentiable at 0 but nowhere else.
\beast
\frac{f(z) - f(z_0)}{z - z_0} & = & \frac{\abs{z}^2 - \abs{z_0}^2}{z-z_0} = \frac{z\ol{z} - z_0\ol{z_0}}{z-z_0} = \frac{z\ol{z} - z_0 \ol{z} + z_0\ol{z} - z_0\ol{z_0}}{z-z_0} \\
& = & \frac{\ol{z}\bb{z-z_0} + z_0\bb{\ol{z} - \ol{z_0}}}{z-z_0} = \ol{z} + z_0 \frac{\ol{z} - \ol{z_0}}{z-z_0}
\eeast

Obviously, if $z_0 = 0$ we have
\be
\lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0} = \lim_{z\to z_0}\ol{z} = \ol{z_0} = 0.
\ee

Otherwise,
\be
\lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0} = \lim_{z\to z_0}\ol{z} + z_0 \lim_{z\to z_0}\frac{\ol{z} - \ol{z_0}}{z-z_0} = \left\{\ba{ll}
\ol{z_0} + z_0 \quad\quad & \text{horizontally}\\
\ol{z_0} - z_0 \quad\quad & \text{vertically}\\
\ea\right. 
\ee
by the same argument as for $z\mapsto \ol{z}$.
\end{example}


\begin{example}\label{exa:derivative_of_exponential_complex}
For $f(z) = e^z$ with any $z\in \C$, we have $f'(z) = e^z$.
\beast
\lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0} & = & \lim_{z\to z_0} \frac{e^z - e^{z_0}}{z - z_0} = e^{z_0} \lim_{z\to z_0} \frac{e^{z-z_0}-1}{z-z_0} = e^{z_0} \lim_{z\to 0} \frac{e^{z}-1}{z}
\eeast

Write $z =x + iy$ and by Proposition \ref{pro:exponential_of_sum_is_product_of_exponential_complex} and Euler's formula (Theorem \ref{thm:euler_formula_exponential}), we have $e^z = e^x \bb{\cos y + i\sin y}$. Then
\beast
\frac{e^{z}-1}{z} & = & \frac{e^x\cos y - 1 + ie^x \sin y}{x+ iy} = \frac{\bb{e^x\cos y - 1 + ie^x \sin y}\bb{x- iy}}{x^2+ y^2}\\
& = & \frac{x\bb{e^x\cos y - 1} + y e^x \sin y}{x^2+ y^2} + i\frac{x e^x\sin y - y\bb{e^x\cos y - 1}}{x^2+ y^2}
\eeast

Now let $x,y\to 0$. By the definitions of $e^x$, $\sin y$ and $\cos y$ (Definition \ref{def:exponential_function_natural_complex}, Definition \ref{def:sine_cosine_function}), we have
\beast
e^x & = & 1 + x + \frac 12 x^2 + o\bb{x^2} \\
\sin y & = & y - \frac 16 y^3 + o\bb{y^3} \\
\cos y & = & 1 - \frac 12 y^2+ o\bb{y^2}
\eeast

Thus,
\beast
\lim_{z\to 0} \frac{e^{z}-1}{z} & = & \lim_{x,y\to 0} \frac{x\bb{\bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{1 - \frac 12 y^2+ o\bb{y^2}}-1 } + y  \bb{1+x+ \frac 12 x^2 + o\bb{x^2}} \bb{y - \frac 16 y^3 + o\bb{y^3}}}{x^2+ y^2} \\
& & + i\lim_{x,y\to 0} \frac{x \bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{y - \frac 16 y^3 + o\bb{y^3}} - y\bb{\bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{1 - \frac 12 y^2+ o\bb{y^2}}-1}}{x^2+ y^2}.
\eeast

For the real part,
\beast
& & \lim_{x,y\to 0} \frac{x\bb{\bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{1 - \frac 12 y^2+ o\bb{y^2}}-1 } + y  \bb{1+x+ \frac 12 x^2 + o\bb{x^2}} \bb{y - \frac 16 y^3 + o\bb{y^3}}}{x^2+ y^2}  \\
& = & \lim_{x,y\to 0} \frac{x\bb{\bb{1+x+ \frac 12 x^2}\bb{1 - \frac 12 y^2}-1 } + y  \bb{1+x+ \frac 12 x^2} \bb{y - \frac 16 y^3}}{x^2+ y^2}  \\
& = & \lim_{x,y\to 0} \frac{x\bb{x+ \frac 12 x^2 - \frac 12 y^2 - \frac 12 xy^2 - \frac 14 x^2y^2 } + y  \bb{y+xy+ \frac 12 yx^2  - \frac 16 y^3 - \frac 16 xy^3 - \frac 1{12}x^2y^3}}{x^2+ y^2}  \\
& = & \lim_{x,y\to 0} \frac{x\bb{x- \frac 12 y^2 - \frac 12 xy^2 } + y  \bb{y+xy+ \frac 12 yx^2}}{x^2+ y^2} = \lim_{x,y\to 0} \frac{x^2 + y^2 - \frac 12 xy^2  +xy^2 }{x^2+ y^2} = 1.
\eeast
For the imaginary part,
\beast
& & \lim_{x,y\to 0} \frac{x \bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{y - \frac 16 y^3 + o\bb{y^3}} - y\bb{\bb{1+x+ \frac 12 x^2 + o\bb{x^2}}\bb{1 - \frac 12 y^2+ o\bb{y^2}}-1}}{x^2+ y^2} \\
& = & \lim_{x,y\to 0} \frac{x \bb{1+x+ \frac 12 x^2}\bb{y - \frac 16 y^3 } - y\bb{\bb{1+x+ \frac 12 x^2 }\bb{1 - \frac 12 y^2}-1}}{x^2+ y^2} \\
& = & \lim_{x,y\to 0} \frac{xy + x^2y + \frac 12 x^3y  - y\bb{x+ \frac 12 x^2 }}{x^2+ y^2} = \lim_{x,y\to 0} \frac{xy + x^2y   - xy - \frac 12 x^2y }{x^2+ y^2} = 0.
\eeast

Thus, 
\be
\lim_{z\to 0} \frac{e^{z}-1}{z} = 1 \ \ra\ \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0} = e^{z_0} \lim_{z\to 0} \frac{e^{z}-1}{z} = e^{z_0}.
\ee
\end{example}

\subsection{Properties of differentiable function}

%Then we have the following similar property for complex differentiable function.

\begin{proposition}[differentiability implies continuity]\label{pro:differentiability_implies_continuity_complex_function}
If complex function $f$ is differentiable at $z_0$, then $f$ is continuous at $z_0$.
\end{proposition}

\begin{proof}[\bf Proof]
Given $\ve > 0$,  there exists $\delta(\ve) > 0$ such that 
\be
\abs{\frac{f(z) - f(z_0)}{z-z_0} - f'(z_0)} < \ve
\ee
for $|z - x_0| < \delta(\ve)$, so 
\be
\abs{f(z) - f(z_0) - f'(z_0)(z-z_0)} < \ve\abs{z-z_0}.
\ee
 
Thus,
\be
\abs{f(z) - f(z_0)} < \ve |z-z_0| + \abs{f'(z_0) (z-z_0)} = \ve |z-z_0| + \abs{f'(z_0)}\abs{z-z_0}.
\ee

All of the terms in the last expression are small except $\abs{f'(z_0)}$ which is fixed. So if we set 
\be
\delta_1(\ve) = \min\bra{\delta(1), \frac{\ve}{2}, \frac{\ve}{2(\abs{f'(z_0) + 1})}}
\ee
for $\ve < 1$. Then if $0 < |z-z_0| < \delta_1(\ve)$,
\be
\abs{f(z) - f(z_0)} < 1 \cdot |z-z_0| + \abs{f'(z_0)}|z-z_0| < \frac{\ve}{2} + \frac{\ve}{2} = \ve.
\ee
\end{proof}

The basic differentiation formulas follow identically as in the case of real functions, and we obtain the same rules of differentiating powers, sums, products, quotients, and compositions of functions. The proof of the differentiation formulas are easily established by using the limit theorems.

\begin{proposition}[properties of differentiable functions]\label{pro:properties_differentiable_function_complex}
Let $C$ be a complex constant and $n$ is positive integer. $f(z)$ and $g(z)$ are differentiable complex functions. Then the following functions are differentiable at any point $z\in \C$ and
\beast
& \text{(i)} & \frac{d}{dz}C = 0, \\
& \text{(ii)} & \fd{}{z} z^n = nz^{n-1},\ n\in \N, \\
& \text{(iii)} & \frac{d}{dz}\bb{f(z)+g(z)} = f'(z) + g'(z), \\
& \text{(iv)} & \frac{d}{dz}\bb{f(z)g(z)} = f'(z)g(z) + f(z)g'(z), \\
& \text{(v)} & \frac{d}{dz}\bb{\frac{f(z)}{g(z)}} = \frac{f'(z)g(z) - f(z)g'(z)}{(g(z))^2}, \quad g(z) \neq 0\\
& \text{(vi)} & \frac{d}{dz}\bb{f\circ g(z)} =  \frac{d}{dz}\bb{f(g(z))} = f'(g(z))g'(z).\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad
\eeast
\end{proposition}

\begin{remark}
We know that from (v) and (vi), for positive integer $n$,
\beast
\frac{d}{dz} z^{-n} & = & -n z^{-(n+1)},\\
\frac{d}{dz}\bb{f(z)}^n & = & n\bb{f(z)}^{n-1} f'(z).
\eeast
\end{remark}

\begin{proof}[\bf Proof]%Let $z = z_0 + h$. 
Since $f$ and $g$ are differentiable, they are continuous.
\ben
\item [(i)]
\be
\frac{d}{dz}C =\lim_{h\to 0}\frac{f(z+h)-f(z)}{h} = \lim_{h\to 0}\frac{C-C}{h} = 0.
\ee

\item [(ii)] For $n\in \N$,
\beast
\frac{d}{dz} z^n & = & \lim_{h\to 0}\frac{(z+h)^n - z^n}{h} = \lim_{h\to 0}\frac{\sum^n_{k=0}\binom{n}{k}h^k z^{n-k} - z^n}{h} \\
& = &  \lim_{h\to 0}\frac{z^n + nz^{n-1}h + o(h)- z^n}{h} =  \lim_{h\to 0}\frac{nz^{n-1}h + o(h)}{h} = nz^{n-1}.
\eeast

\item [(iii)]
\beast
\frac{d}{dz}\bb{f(z)+g(z)}  & = & \lim_{h\to 0}\frac{f(z+h)+g(z+h)-f(z)-g(z)}{h} \\
& = & \lim_{h\to 0}\frac{f(z+h)-f(z)}{h} + \lim_{h\to 0}\frac{g(z+h)-g(z)}{h} =  f'(z)+g'(z).
\eeast

\item [(iv)] 
\beast
\frac{d}{dz}\bb{f(z)g(z)}  & = &  \lim_{h\to 0}\frac{f(z+h)g(z+h)-f(z)g(z)}{h} \\
& = & \lim_{h\to 0}\frac{(f(z+h)-f(z))g(z+h)}{h} + \lim_{h\to 0}\frac{f(z)(g(z+h)-g(z))}{h}  = f'(z)g(z)+f(z)g'(z).
\eeast


\item [(v)] First for function $\phi(z) = 1/f(z)$ with $z\neq 0$, we have
\beast
\frac{d}{dz}\bb{\frac 1{f(z)}} & = & \lim_{h\to 0}\frac{\phi(z+h)-\phi(z)}{h} = \lim_{h\to 0}\frac{1/f(z+h)-1/f(z)}{h} = \lim_{h\to 0}\frac{f(z)-f(z+h)}{hf(z+h)f(z)} = -\frac{f'(z)}{f^2(z)}
\eeast%\item [(v)] \footnote{need proof}
since $f$ is continuous at $z$. Then we have the required result by (iv).

\item [(vi)] If $f'(z) \neq 0$ then $f(z+h) - f(z) \neq 0$ for $h$ small and thus
\be
\frac{g(f(z+h)) - g(f(z))}{h} = \frac{g(f(z+h)) - g(f(z))}{f(z+h) - f(z)} \cdot \frac{f(z+h) - f(z)}{h}  = g'(f(z))\cdot f'(z).
\ee
since $f$ is continuous at $z$, $f(z+h) \rightarrow f(z)$.
\een
\end{proof}

\begin{example}
If we use Proposition \ref{pro:properties_differentiable_function_complex} and get for $f(z) = z^2 + 2iz + 3$, $f'(z) = 2z + 2i$. Then
\be
\frac{d}{dz}\bb{z^2 + 2iz + 3}^4 = 4\bb{z^2 + 2iz + 3}^3 \frac{d}{dz}\bb{z^2 + 2iz + 3} = 8(z^2 + 2iz + 3)^3(z+i).
\ee
\end{example}

Similar with Corollary \ref{cor:derivative_greater_equal_to_zero} in real analysis, we have the following theorem.

\begin{theorem}\label{thm:holomorphic_derivative_zero_on_open_connected_set_implies_constant}
If $X$ is an open connected set in $\C$ and $f:X\to \C$ is differentiable with $f'(z)=0$ for all $z\in X$, then $f$ is constant in $X$.
\end{theorem}

\begin{remark}
See alternative proof in Corollary \ref{cor:holomorphic_derivative_zero_on_open_connected_set_implies_constant}.
\end{remark}

\begin{proof}[\bf Proof]
Fix $z_0$ in $X$ and let $f(z_0) = w_0$. Put
\be
A := \bra{z\in X:f(z) = w_0}.
\ee

For any convergent sequence $(z_n)_{n\in\N}\subseteq A$ such that $\lim_{n\to \infty}z_n = z$. Since $f(z_n) = w_0$ for each $n\in \N$ and $f$ is continuous, we have that $f(z) = w_0$. Thus, we have that $z\in A$ which implies that $A$ is closed in $X$.

Now fix $a\in A$, we can find $\ve>0$ such that $D_\ve(a)\subseteq X$ since $X$ is open. Then for any $z\in D_\ve(a)$, set
\be
g(t) = f(tz + (1-t)a),\qquad t\in [0,1].
\ee

Then for any $s\in [0,1]$,
\beast
\frac{g(t)-g(s)}{t-s} & = & \frac{g(t)-g(s)}{(t-s)z + (s-t)a} \frac{(t-s)z + (s-t)a}{t-s} \\
& = & \frac{f(tz + (1-t)a)-f(sz + (1-s)a)}{tz + (1-t)a - (sz + (1-s)a)} \frac{(t-s)z + (s-t)a}{t-s}
\eeast

Therefore,
\be
\lim_{t\to s}\frac{g(t)-g(s)}{t-s} = f'(tz + (1-t)a)-f(sz + (1-s)a)\cdot(z-a) = 0\cdot (z-a) = 0.
\ee

That is, $g'(s) =0$ for $s\in [0,1]$, implying that $g$ is a constant (by Corollary \ref{cor:derivative_greater_equal_to_zero}). Hence,
\be
f(z) = g(1) = g(0) = f(a) = w_0 \ \ra\ D_\ve(a)\subseteq A \ \ra\ A \text{ is open.}
\ee

Since $X$ is connected and $A$ is both closed and open, we have that $X = A$, as required.
\end{proof}

\subsection{Cauchy-Riemann equations}

This section discusses the necessary and sufficient conditions for the existence of the derivative of a complex function
\be
f(z) = u(x,y) + iv(x,y),\qquad z = x+ iy.
\ee

The necessary conditions are given by the Cauchy-Riemann equations. The sufficient conditions require, additionally, the continuity of all first-order partial derivatives of $u$ and $v$.

\begin{theorem}[necessary conditions for differentiability of complex function]\label{thm:cauchy_riemann_equation}
Suppose $f(z) = u(x,y) + iv(x,y)$ is differentiable at a point $z_0 = x_0 + iy_0$. Then at that point, all partial derivatives of $u(x,y)$ and $v(x,y)$ exist and 
\be
f'(z_0) = u_x(x_0,y_0) + iv_x(x_0,y_0) = v_y(x_0,y_0) - iu_y(x_0,y_0).
\ee

Accordingly, we have
\be
u_x(x_0,y_0) = v_y(x_0,y_0),\qquad v_x(x_0,y_0) = -u_y(x_0,y_0)
\ee
or
\be
\fp{u}{x} = \fp{v}{y},\qquad \fp{v}{x} = -\fp{u}{y}.\qquad (*)
\ee

($*$) is called Cauchy-Riemann equations\index{Cauchy-Riemann equations}.
\end{theorem}

\begin{remark}
These equations were discovered independently by the French mathematician Augutin Louis Cauchy (1789-1857) and the German mathematician Georg Friedrich Bernhard Riemann (1826-1866).
\end{remark}

\begin{proof}[\bf Proof]
We know that by definition of derivative, the limit is independent of the direction along which $z$ approaches $z_0$.

First, we take $z\to z_0$ in the direction parallel to the $x$-axis, that is, $z-z_0 = x-x_0$. Then
\beast
f'(z_0) & = & \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z-z_0} = \lim_{z\to z_0}\frac{u(x,y_0) + iv(x,y_0) - u(x_0,y_0) - iv(x_0,y_0)}{x-x_0}  \\
& = & \lim_{z\to z_0}\frac{u(x,y_0) - u(x_0,y_0)}{x-x_0} + i\lim_{z\to z_0}\frac{v(x,y_0) - v(x_0,y_0)}{x-x_0}
\eeast

So partial derivatives must exist and
\be
f'(z_0) = \fp{u(x_0,y_0)}{x} + i\fp{v(x_0,y_0)}{x}.
\ee

Similarly, we let $z-z_0 = i(y-y_0)$ and have
\beast
f'(z_0) & = & \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z-z_0} = -i \lim_{z\to z_0}\frac{u(x_0,y) + iv(x_0,y) - u(x_0,y_0) - iv(x_0,y_0)}{y-y_0}  \\
& = & -i\lim_{z\to z_0}\frac{u(x_0,y) - u(x_0,y_0)}{y-y_0} + \lim_{z\to z_0}\frac{v(x_0,y) - v(x_0,y_0)}{y-y_0} \\
& = & \fp{v(x_0,y_0)}{y} - i\fp{u(x_0,y_0)}{y}.
\eeast

Therefore, we have
\be
f'(z_0) = \fp{u(x_0,y_0)}{x} + i\fp{v(x_0,y_0)}{x} = \fp{v(x_0,y_0)}{y} - i\fp{u(x_0,y_0)}{y}
\ee
which implies the Cauchy-Riemann equations.
\end{proof}

To give more specific result, we give the following two differential operators

\begin{definition}
For $z = x+ iy\in \C$,
\be
\fp{}{z} = \frac 12 \bb{\fp{}{x} + \frac 1i \fp{}{y}},\qquad \fp{}{\ol{z}} = \frac 12 \bb{\fp{}{x} - \frac 1i\fp{}{y}}.
\ee
\end{definition}

\begin{proposition}
Let $f(z)= u + iv$ be differentiable at $z_0 = x_0+iy_0$ with real valued $u,v$, then
\be
\fp{f}{\ol{z}} = 0,\qquad f'(z_0) = \fp{f}{z}(z_0) = 2\fp{u}{z}(z_0).
\ee

Also, if we write $F(x,y) = \bb{\Re(f(z)),\Im(f(z))}^T$, then $F:\R^2\to \R^2$ is differentiable in the sense of real variables and
\be
\det J_F(x_0,y_0) = \abs{f'(z_0)}^2.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\be
\fp{f}{\ol{z}}(z_0) = \frac 12\bb{\fp{f}{x}(z_0) + i\fp{f}{y}(z_0)} = \frac 12\bb{\fp{u}{x}(z_0) + i \fp{v}{x}(z_0) + i\fp{u}{y}(z_0)- \fp{v}{y}(z_0)} =0
\ee
by Cauchy-Riemann equations (Theorem \ref{thm:cauchy_riemann_equation}). Similarly, by Cauchy-Riemann equations again,
\beast
\fp{f}{z}(z_0) & = & \frac 12\bb{\fp{f}{x}(z_0) - i\fp{f}{y}(z_0)} = \frac 12\bb{\fp{u}{x}(z_0) + i \fp{v}{x}(z_0) - i\fp{u}{y}(z_0) + \fp{v}{y}(z_0)} \\
& = & \fp{u}{x}(z_0) + i \fp{v}{x}(z_0) = f'(z_0)
\eeast
\beast
\fp{u}{z}(z_0) & = & \frac 12\bb{\fp{u}{x}(z_0) - i\fp{u}{y}(z_0)} = \frac 12\bb{\fp{u}{x}(z_0) + i\fp{v}{x}(z_0)} = \frac 12 f'(z_0)
\eeast
as required.

Since $F(x,y) = \bb{\Re(f(z)),\Im(f(z))}^T = \bb{u(x,y),v(x,y)}^T$ we have $f(z) = (1,i)\cdot F(x,y)$. Now let $h = (h_1,h_2)$ and $\delta = h_1+ih_2$, we have
\beast
J(x_0,y_0)\cdot h & = & \bepm \fp{u}{x}(x_0,y_0)\cdot h_1 + \fp{u}{y}(x_0,y_0)\cdot h_2  \\ \fp{v}{x}(x_0,y_0)\cdot h_1 + \fp{v}{y}(x_0,y_0)\cdot h_2\eepm = \bepm \fp{u}{x}(x_0,y_0)\cdot h_1 - \fp{v}{x}(x_0,y_0)\cdot h_2  \\ \fp{v}{x}(x_0,y_0)\cdot h_1 + \fp{u}{x}(x_0,y_0)\cdot h_2\eepm \\
& = & \bepm \Re\bb{\bb{\fp{u}{x}(x_0,y_0) + i\fp{v}{x}(x_0,y_0)}\cdot (h_1+ih_2)} \\
\Im\bb{\bb{\fp{u}{x}(x_0,y_0) + i\fp{v}{x}(x_0,y_0)}\cdot (h_1+ih_2)}\eepm = \bepm \Re\bb{f'(z_0)\cdot \delta } \\
\Im\bb{f'(z_0)\cdot \delta } \eepm
\eeast

%\beast
%F(x_0 + h_1,y_0 + h_2) - F(x_0,y_0) - J(x_0,y_0)\cdot h  = \bepm u(x_0+h_1,y_0+h_2) - u(x_0,y_0) - \fp{u}{x}(x_0,y_0)\cdot h_1 - \fp{u}{y}(x_0,y_0)\cdot h_2  \\ v(x_0+h_1,y_0+h_2) - v(x_0,y_0) - \fp{v}{x}(x_0,y_0)\cdot h_1 - \fp{v}{y}(x_0,y_0)\cdot h_2\eepm.
%\eeast

Then $\dabs{h} = \abs{\delta}$,
\be
\dabs{F(x_0 + h_1,y_0 + h_2) - F(x_0,y_0) - J(x_0,y_0)\cdot h} = \abs{f(z_0 + \delta) - f(z_0) - f'(z_0)\cdot \delta}
\ee
and thus
\be
\frac{\dabs{F(x_0 + h_1,y_0 + h_2) - F(x_0,y_0) - J(x_0,y_0)\cdot h}}{\dabs{h}} = \frac{\abs{f(z_0 + \delta) - f(z_0) - f'(z_0)\cdot \delta}}{\abs{\delta}}
\ee

This implies that
\be
\lim_{h\to 0}\frac{\dabs{F(x_0 + h_1,y_0 + h_2) - F(x_0,y_0) - J(x_0,y_0)\cdot h}}{\dabs{h}} = \lim_{\delta \to 0}\frac{\abs{f(z_0 + \delta) - f(z_0) - f'(z_0)\cdot \delta}}{\abs{\delta}} = 0
\ee
since $f$ is differentiable at $z_0$. Thus, $F$ is differentiable at $(x_0,y_0)$. By Cauchy-Riemann equations again,
\beast
\det J_F(x_0,y_0) & = & \det\bepm \fp{u}{x}(x_0,y_0) & & \fp{u}{y}(x_0,y_0) \\ \fp{v}{x}(x_0,y_0) & & \fp{v}{y}(x_0,y_0) \eepm = \fp{u}{x}(x_0,y_0) \fp{v}{y}(x_0,y_0) - \fp{u}{y}(x_0,y_0)\fp{v}{x}(x_0,y_0) \\
& = & \bb{\fp{u}{x}(x_0,y_0)}^2 + \bb{\fp{u}{y}(x_0,y_0)}^2 = \abs{2\fp{u}{z}(z_0)}^2 = \abs{f'(z_0)}^2
\eeast
as required.
\end{proof}

\begin{remark}
Note that the Cauchy-Riemann equations cannot guarantee the existence of derivative of $f(z)$. Actually, the Cauchy-Riemann equations are necessary but not sufficient for differentiability. However, a partial converse can be salvaged by adding some extra assumptions.
\end{remark}



\begin{theorem}[sufficient and necessary conditions for differentiability of complex function]\label{thm:sufficient_necessary_conditions_differentiable_complex}%{thm:sufficient_conditions_differentiable_complex}
Given $f(z) = u(x,y) + iv(x,y)$ for $z = x+ iy$ defined on an open disc of $z_0 = x_0 + iy_0$. Then $f$ is differentiable at $z_0$ if and only if the multi-variate functions $u$ and $v$ are differentiable at $(x_0,y_0)$ and the Cauchy-Riemann equations hold at the point $(x_0,y_0)$.

If this holds then the derivative $f'(z_0)$ exists and it is given by
\be
f'(z_0) = u_x(x_0,y_0) + iv_x(x_0,y_0) = v_y(x_0,y_0) - iu_y(x_0,y_0).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
($\ra$). Assume $f$ is differentiable at $z_0$. it suffices to show that $u,v$ are differentiable at $(x_0,y_0)$ as the Cauchy-Riemann equations hold by Theorem \ref{thm:cauchy_riemann_equation}. By the Cauchy-Riemann equations, we have $f'(z_0) = u_x(x_0,y_0) - iu_y(x_0,y_0) = v_y(x_0,y_0) +  iv_x(x_0,y_0)$, thus
\beast
f'(z_0)(z-z_0) & = & \ul{u_x(x_0,y_0)(x-x_0) + u_y(x_0,y_0)(y-y_0)} + i \bb{u_x(x_0,y_0)(y-y_0) - u_y(x_0,y_0)(x-x_0)} \\
& = & v_y(x_0,y_0)(x-x_0) - v_x(x_0,y_0)(y-y_0) + i\ul{\bb{v_y(x_0,y_0)(y-y_0) + v_x(x_0,y_0)(x-x_0)}}.
\eeast

By the differentiability of $f(z)$, we have that%
\beast
\frac{f(z) - f(z_0) - f'(z_0)(z-z_0)}{z-z_0}\to 0  \ \ra\ \abs{\frac{f(z) - f(z_0) - f'(z_0)(z-z_0)}{z-z_0}}\to 0%\\& \leq & \lim_{x\to x_0,y\to y_0}\abs{\frac{u(x,y) - u(x_0,y_0) - \fp{u}{x}(x_0,y_0)(x-x_0)-\fp{u}{y}(x_0,y_0)(y-y_0)}{\sqrt{(x-x_0)^2 + (y - y_0)^2}}}
\eeast
by Lemma \ref{lem:basic_convergence_complex}. Also,
\beast
\abs{\frac{u(x,y) - u(x_0,y_0) - \fp{u}{x}(x_0,y_0)(x-x_0)-\fp{u}{y}(x_0,y_0)(y-y_0)}{\sqrt{(x-x_0)^2 + (y- y_0)^2}}} & \leq & \abs{\frac{f(z) - f(z_0) - f'(z_0)(z-z_0)}{\abs{z-z_0}}} \\
\abs{\frac{v(x,y) - v(x_0,y_0) - \fp{v}{x}(x_0,y_0)(x-x_0)-\fp{v}{y}(x_0,y_0)(y-y_0)}{\sqrt{(x-x_0)^2 + (y- y_0)^2}}} & \leq & \abs{\frac{f(z) - f(z_0) - f'(z_0)(z-z_0)}{\abs{z-z_0}}} 
\eeast
implies that the convergence of real and imaginary parts with
\beast
& & \lim_{x\to x_0,y\to y_0}\frac{u(x,y) - u(x_0,y_0) - \fp{u}{x}(x_0,y_0)(x-x_0)-\fp{u}{y}(x_0,y_0)(y-y_0)}{\sqrt{(x-x_0)^2 + (y - y_0)^2}} = 0, \\
& & \lim_{x\to x_0,y\to y_0}\frac{v(x,y) - v(x_0,y_0) - \fp{v}{x}(x_0,y_0)(x-x_0)-\fp{v}{y}(x_0,y_0)(y-y_0)}{\sqrt{(x-x_0)^2 + (y - y_0)^2}} = 0 .
\eeast

Hence, $u(x,y)$ and $v(x,y)$ are differentiable by Definition \ref{def:differentiable_multi_dimensional_real_function}.


($\la$). Now assume $u$ and $v$ are differentiable at $(x_0,y_0)$ (so their partial derviatives exist) and the Cauchy-Riemann equations hold. Combining the Cauchy-Riemann equations at the same point, we have that for sufficiently close point $(x,y)$ to $(x_0,y_0)$ all partial derivatives of $u$ and $v$ exist and
\beast%& = & u(x,y) - u(x_0,y) + u(x_0,y) - u(x_0,y_0) \\
u(x,y) - u(x_0,y_0) & = & u_x(x_0,y_0)(x-x_0) + u_y(x_0,y_0)(y-y_0) + o\bb{\abs{\Delta z}}, \\
& = & u_x(x_0,y_0)(x-x_0) - v_x(x_0,y_0)(y-y_0) +  o\bb{\abs{\Delta z}}.\qquad (*)
\eeast
and
\beast
v(x,y) - v(x_0,y_0) & = & v_x(x_0,y_0)(x-x_0) + v_y(x_0,y_0)(y-y_0) +o\bb{\abs{\Delta z}}, \\
& = & v_x(x_0,y_0)(x-x_0) + u_x(x_0,y_0)(y-y_0) + o\bb{\abs{\Delta z}}. \qquad (\dag)
\eeast
where
\be
\abs{\Delta z} = \sqrt{(x-x_0)^2 + (y-y_0)^2}.
\ee

Then $(*)+ i\cdot (\dag)$ gives that
\beast
f(z) -f(z_0) & = & \bb{u_x(x_0,y_0) + i v_x(x_0,y_0)}(x-x_0) + i\bb{u_x(x_0,y_0) + iv_x(x_0,y_0)}(y-y_0) + (1+i)o\bb{\abs{\Delta z}}  \\
& = & \bb{u_x(x_0,y_0) + i v_x(x_0,y_0)}(z-z_0) + (1+i) o\bb{\abs{\Delta z}}
\eeast

Thus,
\be
\frac{f(z) -f(z_0)}{z-z_0} = u_x(x_0,y_0) + i v_x(x_0,y_0) + (1+i) \frac{o\bb{\abs{\Delta z}}} {z-z_0}
\ee

Obviously,
\be
\lim_{z\to z_0}\abs{\frac{o\bb{\abs{\Delta z}}}{z-z_0}} = \lim_{z\to z_0}\frac{o\bb{\abs{\Delta z}}}{\abs{z-z_0}} = \lim_{\Delta z\to 0}\frac{o\bb{\abs{\Delta z}}}{\abs{\Delta z}} = 0
\ee

Therefore, $f$ is differentiable at $z_0$ and
\be
f'(z_0) = \lim_{z\to z_0}\frac{f(z) -f(z_0)}{z-z_0} = u_x(x_0,y_0) + i v_x(x_0,y_0) = v_y(x_0,y_0) - i u_y(x_0,y_0).
\ee
\end{proof}

\begin{corollary}[sufficient conditions for differentiability of complex function]\label{cor:sufficient_conditions_differentiable_complex}%{thm:sufficient_conditions_differentiable_complex}
Given $f(z) = u(x,y) + iv(x,y)$ for $z = x+ iy$ defined on an open disc of $z_0 = x_0 + iy_0$. Also,
\ben
\item [(i)] $u_x$, $u_y$, $v_x$ and $v_y$ exist in an open disc of $(x_0,y_0)$,
\item [(ii)] $u_x$, $u_y$, $v_x$ and $v_y$ are all continuous at the point $(x_0,y_0)$,
\item [(iii)] the Cauchy-Riemann equations hold at the point $(x_0,y_0)$.
\een

%\ben
%\item [(i)] the Cauchy-Riemann equations hold at a point $z_0 = x_0 + iy_0$.
%\item [(ii)] $u_x$, $u_y$, $v_x$ and $v_y$ are all continuous at the point $(x_0,y_0)$.
%\een

Then the derivative $f'(z_0)$ exists and it is given by
\be
f'(z_0) = u_x(x_0,y_0) + iv_x(x_0,y_0) = v_y(x_0,y_0) - iu_y(x_0,y_0).
\ee
\end{corollary}

\begin{remark}
Condition (i) and (ii) implies the differentiability of real functions $u(x,y)$ and $v(x,y)$. %In particular, a function of real variables $f:\R^2\to\R$ is said to be differentiable at $(x_0,y_0)$ if
%\be
%\lim_{x\to x_0,y\to y_0} \frac{\abs{f(x,y)-f(x_0,y_0) - \bb{\fp{f}{x}(x_0,y_0)(x-x_0) +\fp{f}{y}(x_0,y_0)(y-y_0)}}}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} = 0.
%\ee
\end{remark}

\begin{proof}[\bf Proof]%Since $u(x,y)$ and $v(x,y)$ have continuous first-order partial derivatives at $(x_0,y_0)$ (thus
Since $u_x$, $u_y$, $v_x$ and $v_y$ exist in an open disc of $(x_0,y_0)$ and they are all continuous at the point $(x_0,y_0)$, we can have that $u$ and $v$ are differentiable at $(x_0,y_0)$ by Theorem \ref{thm:continuous_partial_derivatives_implies_real_differentiability}. Then we have the required result by Theorem \ref{thm:sufficient_necessary_conditions_differentiable_complex}.
\end{proof}


\begin{example}\label{exa:counter_example_cauchy_riemann_equations_not_sufficient_for_differentiability}
\ben
\item [(i)] Consider the function
\be
f(z) = f(x+ iy) = \sqrt{\abs{xy}}
\ee
at $z_0=0$. Obviously,
\be
u(x,y) = \sqrt{\abs{xy}},\quad v(x,y) = 0.
\ee

Since $u(x,0)$ and $u(0,y)$ are identically equal to zero, we have
\be
u_x(0,0) = u_y(0,0) = 0.
\ee

Also, since $v(x,y)$ is identically zero, it is obvious that
\be
v_x(0,0) = v_y(0,0) = 0.
\ee

Hence, the Cauchy-Riemann equations are satisfied at the point $(0,0)$.

However, suppose $z$ approaches the origin along the ray $x=at$ and $y=bt$, $t>0$ and $a,b\in \R$, assuming $a$ and $b$ cannot be zero simultaneously. Then for $z=at+ ibt$, we have
\be
\lim_{z\to 0}\frac{f(z) - f(0)}{z-0} = \frac{f(z)}{z} = \frac{\sqrt{\abs{ab}}}{a + ib}.
\ee

The limit depends on the values of $a$ and $b$ as $z\to 0$. So the limit is not unique. Therefore, $f(z)$ is not differentiable at $z=0$, though the Cauchy-Riemann equations are satisfied at $z=0$.% in Example \ref{exa:counter_example_1_cauchy_riemann_equations_not_sufficient_for_differentiability}

Let us check the continuity of $u_x$ at $(0,0)$. Since
\be
\fp{u}{x} = \sqrt{\abs{y}} \frac{d}{dx}\sqrt{\abs{x}},
\ee
$u_x$ fails to be continuous at $(0,0)$.

\item [(ii)] Consider the function defined by
\be
f(z) = \left\{\ba{ll}
\frac{\ol{z}^2}{z} = \frac{x^3 - 3xy^2}{x^2+y^2} + i\frac{y^3 - 3x^2y}{x^2 + y^2}\quad\quad & z\neq 0\\
0 & z = 0
\ea\right.
\ee

This function is not differentiable at the point $z = 0$ even though the Cauchy-Riemann equations are satisfied at the point $(0,0)$. Indeed,
\beast
u_x(0,0) = \lim_{x\to 0}\frac{u(x,0) - u(0,0)}{x} = \lim_{x\to 0}\frac{x^3/x^2}{x} = 1,\\
v_x(0,0) = \lim_{x\to 0}\frac{v(x,0) - v(0,0)}{x} = \lim_{x\to 0}\frac{0/x^2}{x} = 0,\\
u_y(0,0) = \lim_{y\to 0}\frac{u(0,y) - u(0,0)}{y} = \lim_{y\to 0}\frac{0/y^2}{y} = 0,\\
v_y(0,0) = \lim_{y\to 0}\frac{v(0,y) - v(0,0)}{y} = \lim_{y\to 0}\frac{y^3/y^2}{y} = 1
\eeast
which implies the Cauchy-Riemann equations. However,
\be
\lim_{z\to 0} \frac{\ol{z}^2/z}{z} = \lim_{z\to 0} \frac{\ol{z}^2}{z^2}
\ee
has different limits. If we approach 0 along $z = x$,
\be
\lim_{z\to 0} \frac{\ol{z}^2/z}{z} =  \lim_{x\to 0} \frac{x^2}{x^2} = 1.
\ee

If we approach 0 along $z= x + ix$,
\be
\lim_{z\to 0} \frac{\ol{z}^2/z}{z} =  \lim_{x\to 0} \frac{(1-i)^2x^2}{(1+i)^2x^2} = \bb{\frac{1-i}{1+i}}^2 = -1.
\ee
\een
\end{example}

\begin{example}
Consider function $f(z) = z^3$ with $z =x+iy$, we have
\be
f(z) = (x+iy)^3 = x^3 - 3xy^2 + i\bb{3x^2y - y^3} \ \ra\ u(x,y) = x^3 - 3xy^2,\ v(x,y) = 3x^2y - y^3.
\ee

Then we have
\be
u_x(x,y) = 3x^2 - 3y^2 = v_y(x,y),\quad u_y(x,y) = -6xy = - v_x(x,y)
\ee
where all the first-order partial derivatives are continuous, we have by Corollary \ref{cor:sufficient_conditions_differentiable_complex},
\be
f'(z) = u_x(x,y) + iv_x(x,y) = 3x^2 - 3y^2 + 6i xy = 3\bb{x^2 - y^2 + 2i xy} = 3\bb{x+iy}^2 = 3z^2.
\ee
\end{example}



\subsection{Taylor series of complex function}

The Taylor series of a function is the limit of that function's Taylor polynomials as the degree increases, provided that the limit exists. A function may not be equal to its Taylor series, even if its Taylor series converges at every point.

A function that is equal to its Taylor series in an open interval in $\R$ (or disc in the complex plane) is known as an analytic function in that interval.\footnote{definition needed.}

%\section{Holomorphic Functions and Harmonic Functions}

\subsection{Holomorphic functions}

\begin{definition}[holomorphic function\index{holomorphic function}]\label{def:holomorphic_function}%label{def:differentiable_function_complex}
Let $f$ be a complex function. We say that $f$ is holomorphic at the point $z_0$ if it is differentiable on an open disc of $z_0$.

If $f$ is complex differentiable at every point $z_0$ in an open set $U$, then we say that $f$ is holomorphic on $U$.\footnote{Note that by definition, any open set must contain one of oepn discs of its own points.}

We say $f$ is holomorphic on non-open set $A$ if it is holomorphic in an open set $U$ containing $A$.
\end{definition}

\begin{example}
The function $1/z$ is holomorphic on any open set in $\C$ that does not contain the origin, and $f'(z) = -1/z^2$.
\end{example}

%\begin{definition}[analytic function\index{analytic function}]\label{def:analytic_function_complex}
%\footnote{relation between holomorphic function and analytic function.}

\begin{remark}
Holomorphic function is sometimes called analytic function, in the sense that it has a power series expansion near every point.\footnote{details need. see p9 of Princeton lectures in analysis II, complex analysis.}
\end{remark}

%\begin{definition}[analytic function\index{analytic function}]%\label{def:analytic_function_complex}
%The function $f$ is said to be analytic at point $z_0$ if its derivatives exists at each point $z$ in some neighbourhood of $z_0$. If $f$ is analytic at each point in the region $R$, then we say that $f$ is analytic on $R$.
%\end{definition}

\begin{remark}
Points of non-holomorphism are called singular points which are important for certain applications in physics and engineering.
\end{remark}

\begin{example}
The function $f(z) = x^2 + y^2 + 2ixy$ is nowhere holomorphic (or analytic) for $z = x+ iy$.

We identify the functions $u(x,y) = x^2 + y^2$ and $v(x,y) = 2xy$. The equation $u_x = v_y$ becomes $2x = 2x$, which holds everywhere. But the equation $u_y = -v_x$, becomes $2y = -2y$, which holds only when $y=0$. Thus $f(x)$ is differentiable only at points that lie on the $x$ axis (by Corollary \ref{cor:sufficient_conditions_differentiable_complex} as all the partial derivatives are continuous). However, for any point $z_0 = x_0 + 0i = x_0$ on the $x$ axis and any $\delta$-open disc of $z_0$, the point $z = x_0 + i\delta/2$ is a point where $f$ is not differentiable. 

Therefore $f$ is not differentiable in any open disc of $z_0$, and consequently it is not analytic at $z_0$.
\end{example}

\begin{definition}[entire function\index{entire function}]
If $f$ is holomorphic on the whole complex plane, then $f$ is said to be entire. $f$ is then called entire function.
\end{definition}

%\begin{remark}
%\end{remark}

%\begin{proposition}\label{pro:holomorphic_derivative_zero_implies_constant}
%Let $f$ be a holomorphic function on a set $A$ (or an open set $U$ containing $A$). Then if $f'(z)=0$ for any $z\in A$, we have $f(z)$ is a complex constant in set $A$.
%\end{proposition}

%\begin{proof}[\bf Proof]
%Since $f$ is holomorphic on a set $A$, it is differenitable at any point $z = x+iy\in A$. Assume that $f(z) = u(x,y) + iv(x,y)$. Thus, by Theorem \ref{thm:cauchy_riemann_equation}, we have 
%\be
%0 = f'(z)= u_x(x,y) + iv_x(x,y) = v_y(x,y) - iu_y(x,y) \ \ra\ u_x(x,y) = v_x(x,y) = u_y(x,y) = v_y(x,y) = 0.
%\ee

%Then by Corollary \ref{cor:derivative_greater_equal_to_zero}, we have $u$ and $v$ are constants.\footnote{Note that we get $u(x,y) = u(y)$ by considering $x$ as the single variable.} So $f(z) = u+iv$ is a complex constant, as required.
%\end{proof}


\subsection{Analytic function}

\begin{definition}[analytic function]
Let $f$ be a complex function. Then $f$ is analytic at the point $z_0$ if it is continuously differentiable on an open disc of $z_0$.

If $f$ is analytic at every point $z_0$ in an open set $U$, then we say that $f$ is analytic on $U$.

We say $f$ is analytic on non-open set $A$ if it is analytic in an open set $U$ containing $A$.
\end{definition}

\begin{remark}
Clearly, every analytic function is holomorphic function. Indeed, we will show later that analytic function is equivalent to holomorphic function in complex sense.
\end{remark}

\footnote{example needed.}

\subsection{Inverse function theorem}

\begin{theorem}[inverse function theorem]
Let $X,Y$ be two open subsets of $\C$. Suppose $f:X\to \C$ and $g:Y\to \C$ are continuous functions that $g(Y)\subseteq X$ and $f(g(z)) = z$ for all $z\in Y$.

If $g$ is differentiable and $f'(z) \neq 0$, $f$ is differentiable on $X$ and
\be
g'(z) = \frac 1{f'(g(z))}.
\ee

If $f$ is analytic on $X$, then $g$ is analytic on $Y$.
\end{theorem}

\begin{proof}[\bf Proof]
Fix $z\in Y$, we can find $h\in \C$ such that $h\neq 0$ and $z+h\in Y$ since $Y$ is open. Hence, $f(g(z)) = z$ and $f(g(z+h)) = z+h$ implies that $g(z)\neq g(z+h)$. Also,
\be
1 = \frac{z+h - z}{h}= \frac{f(g(z+h)) - f(g(z))}{h} =  \frac{f(g(z+h)) - f(g(z))}{g(z+h) - g(z)}\cdot \frac{g(z+h) - g(z)}{h}.
\ee

Now the limit of the left hand side as $h\to 0$ is, of course, 1. So the limit of the right hand side exists. Since $g$ is continuous, we have
\be
\lim_{h\to 0} g(z+h) - g(z) = 0 \ \ra\ \lim_{h\to 0} \frac{f(g(z+h)) - f(g(z))}{g(z+h) - g(z)} = f'(g(z)).
\ee

Hence we get that
\be
\lim_{h\to 0} \frac{g(z+h) - g(z)}{h}
\ee
exists since $f'(g(z)) \neq 0$, and $1 = f'(g(z)) g'(z)$. This means that $g'(z) = [f'(g(z))]^{-1}$.

If $f$ is analytic function on $X$, $f'$ is continuous on $X$. Thus, $g'$ is continuous on $Y$ since $g'$ is composition of continuous function $1/z$, $f'$ and $g$.
\end{proof}

\begin{example}
Let $f(z) = \exp(z)$ for $z\in \C$ and $g(z) = \Log(z)$ for $z\in \C\bs\bra{0}$ (principal value of logarithm function) with $\exp(z)$ continuous on $\C$ and $\Log(z)$ continuous on $\Arg z \in (-\pi,\pi)$. Also, $\Log(z) \subseteq \C$ and $\exp\bb{\Log(z)} = z$ (Proposition \ref{pro:exp_logarithm_composition}) for any $z\in \C\bs\bra{0}$. Furthermore, $\exp(z) \neq 0$ and $\exp(z)$ is differential on $\C$. Thus,
\be
\bb{\Log(z)}' = \frac{1}{\exp'(\Log(z))} =  \frac{1}{\exp(\Log(z))} = \frac 1z.
\ee
\end{example}





\section{Power Series}

\subsection{Power series and basic properties}

\begin{definition}[power series]
A power series (of one complex variable $z$) centered at $z_0\in \C$ is an infinite series of the form
\be
\sum^\infty_{n=0} a_n(z-z_0)^n = a_0 + a_1(z-z_0) + a_2 \bb{z-z_0}^2 + \dots
\ee
where $a_n\in \C$ represents the coefficient of the $n$th term and $z_0$ is a constant. $a_n$ is independent of $z$ and may be expressed as a function of $n$ (e.g. $a_n = \frac 1{n!}$). If $z_0 = 0$, we call 
\be
\sum^\infty_{n=0} a_n z^n = a_0 + a_1z + a_2 z^2 + \dots
\ee
the power series centered at origin.
\end{definition}

\begin{example}
\ben
\item [(i)] The geometric function
\be
\sum^\infty_{n=0}z^n,\qquad a_n = 1.
\ee
\item [(ii)] The natural exponential function 
\be
\exp(z) = \sum^\infty_{n=0} \frac{z^n}{n!},\qquad a_n = \frac 1{n!}.
\ee

\item [(iii)] The sine and cosine function
\be
\cos z = \sum^\infty_{n=0}(-1)^n \frac{z^{2n}}{(2n)!}, \qquad a_n = \left\{\ba{ll} \frac 1{n!} \quad\quad & n = 4k \\ -\frac 1{n!} & n=4k+2\\ 0 & n \text{ is odd}\ea\right.\quad k\in \N,
\ee
\be
\sin z = \sum^\infty_{n=0}(-1)^n \frac{z^{2n+1}}{(2n+1)!}, \qquad a_n = \left\{\ba{ll} \frac 1{n!} \quad\quad & n = 4k+1 \\ -\frac 1{n!} & n=4k+3\\ 0 & n \text{ is even}\ea\right.\quad k\in \N.
\ee
\een
\end{example}


%Look at $\sum^\infty_{n=0}a_nz^n, \ a_n\in \C,\ z\in\C$.

%\subsection{Basic properties of power series}

\begin{lemma}\label{lem:com}
Let $(a_n),w,z\in \C$. For $\abs{z}<\abs{w}$, 
\be
 \sum^\infty_{n=0}a_n w^n\text{ converges} \ \ra\  \sum^\infty_{n=0}a_n z^n\text{ converges absolutely.}
\ee
\end{lemma}

\begin{proof}[{\bf Proof}]
We have
\be
\sum^\infty_{n=0}a_n w^n\text{ converges }\ \ra \ a_n w^n\to 0
\ee
as $n\to\infty$. In particular, there is a constant $K$ s.t. $\abs{a_n w^n}\leq K$ for $n$. Thus,
\be
\abs{a_n z^n}= \abs{a_n z^n \frac{w^n}{w^n}} = \abs{a_n w^n \frac{z^n}{w^n}}  = \abs{a_n w^n }\abs{\frac{z^n}{w^n}} \leq K\abs{\frac{z}{w}}^n.
\ee

Since $|z|<|w|$, the geometric series 
\be
\sum\abs{\frac{z}{w}}^n\text{ converges. }
\ee

By comparison, $\sum^\infty_{n=0}\abs{a_nz^n}$ converges, i.e. $\sum^\infty_{n=0}a_nz^n$ converges absolutely.
\end{proof}

%\begin{theorem}
%A power series either
%(i) converges absolutely for all $z$, or
%(ii) converges absolutely for all $z$ inside a circle $|z|=R$, and diverges for all $z$ outside it, or
%(iii) converges for $z=0$, only.
%\end{theorem}

%\begin{definition}
%The circle $|z|=R$ is called the circle of convergence and $R$ the radius of convergence. In case (i), we agree that $R=\infty$ and in case (iii), we agree that $R=0$.
%\end{definition}

%\begin{proof}[{\bf Proof}]
%Let $S=\{x\in \R: x\geq 0 \text{ and }\sum a_n x^n \text{ converges}\}$, $0\in S\neq\emptyset$.
%If $x_1 \in S$, then by Lemma \ref{lem:com}, $[0,x_1]\subset S$.
%If $S$ is unbounded, then $S=\R^+\{x\in \R: x\geq 0\}$ and we have case (i).
%If $S$ is bounded, there exists a finite supremum for $S$, we call it $R$.
%If $R>0$, we will prove that if $|z_1|<R$, then $\sum a_n z_1^n$ converges absolutely: Choose $R_0$ s.t. $|z_1|<R_0<R$, then $R_0\in S$ implies that $\sum a_n R_0^n$ converges and by Lemma \ref{lem:com}, $\sum a_n z_1^n$ converges absolutely.

%Finally, we show that if $|z_2|>R>0$, then $\sum a_n z_2^n$ diverges. Take $R_0$ s.t. $R<R_0<|z_0|$. If $\sum a_n z_2^n$ converges, again by Lemma \ref{lem:com}, $\sum a_n R_0^n$ converges. But this contradicts the definition of $R$ as supremum of $S$. Thus, $\sum a_n z_2^n$ diverges.
%\end{proof}

\subsection{Radius of convergence}

Here we give the theorem of radius of convergence of single complex variable.

\begin{theorem}[Cauchy-Hadamard theorem]\label{thm:cauchy_hadamard_radius_of_convergence}%[radius of convergence of single complex variable]
Consider the power series of complex variable $z$ of the form
\be
f(z) = \sum^\infty_{n=0} a_n z^n
\ee
where $a_n\in \C$. Then there exists $R\in [0,\infty]$ such that
\ben
\item [(i)] $\abs{z} < R$, the series converges absolutely. In particular, for any $r$ such that $0<r<R$, the series converges absolutely and uniformly on closed disc $\bra{z:\abs{z}\leq r}$.
\item [(ii)] $\abs{z} > R$, the series diverges.
\een

Moreover, if we use the convention that $1/0=\infty$ and $1/\infty = 0$, then $R$ is given by Hadamard's formula\index{Hadamard's formula}
\be
1/R = \limsup_n \abs{a_n}^{1/n}.
\ee

The number $R$ is called the radius of convergence\index{radius of convergence} of the power series.
\end{theorem}

\begin{remark}
In general, nothing can be said at $|z|=R$.
\end{remark}

\begin{proof}[\bf Proof]%Without loss of generality we assume that $a=0$.
\ben
\item [(i)] Suppose that $\abs{z}< R$. First let $t = 1/R$ not be 0. Then for any $\ve>0$, there exists only a finite number of $n$ such that $\abs{a_n}^{1/n}  > t +\ve$ (see remark of Definition limsup\footnote{definition needed.}). Now
\be
\abs{a_n} \leq (t+\ve)^n\qquad (*)
\ee
for all but a finite number of $n$. If $\abs{z} < 1/(t+\ve)$, we have that $(t+\ve)\abs{z} = r<1$. Therefore the series
\be
\sum^\infty_{n=0} \abs{a_n z^n} \leq \sum^\infty_{n=0} r^n = \frac{1}{1-r} < \infty
\ee
which gives that the series converges absolutely.

If $R = \infty$ and $t = 0$, then for any $\ve > 0$, there exists $N$ such that $n\geq N$, $\abs{a_n}^{1/n} \leq \ve \ \ra\ \abs{a_n} \leq \ve^n$
\be
\sum^\infty_{n=0} \abs{a_n z^n} \leq \sum^{N-1}_{n=0} \abs{a_n z^n} + \sum^\infty_{n=N} \abs{a_n z^n} \leq \sum^{N-1}_{n=0} \abs{a_n z^n} + \sum^\infty_{n=N} \abs{\ve z}^n <\infty
\ee
for any $\ve <1/\abs{z}$ (if $z = 0$, it is obvious the conclusion holds). Thus, the series converges absolutely.


For any $r$ such that $0<r<R$, we can find $\ve>0$ such that $r < 1/(t+\ve)$. Then for this $\ve$ there exists $N\in\N$ such that for all $n\geq N$, $\abs{a_n} \leq (t+\ve)^n$ (by Proposition \ref{pro:limsup_liminf_arbitrary_ve_with_finite_infinite_terms}). Therefore, for any $\abs{z} \leq r$, there exists $N\in \N$ such that for all $n\geq N$,
\be
\abs{a_n z^n} \leq \bb{t+\ve}^n r^n = \rho^n
\ee
where $\rho < 1$. Thus, we have that $\sum^\infty_{n=1} \rho^n$ converges to $\frac 1{1-\rho}$. Apply Weierstrass M-test (Theorem \ref{thm:weierstrass_m_test}), we have that 
\be
\sum^\infty_{n=1} a_n z^n \text{ converges absolutely and uniformly on }\abs{z} \leq r.
\ee


\item [(ii)] Suppose that $\abs{z}> R$. First let $t = 1/R$ not be $\infty$. Then by definition of $\limsup$, we have that there are infinitely many $n$ such that
\be
\abs{a_n} > (t-\ve)^n \qquad (\dag)
\ee
so if $\abs{z} = 1/(t-\ve)> R$, the series cannot converge \footnote{lemma needed.} because its $n$th term $a_nz^n$ does not tend to 0,
\be
\abs{a_n z^n} > \abs{\bb{t-\ve}^n\bb{\frac 1{t-\ve}}^n} = 1 \nrightarrow 0.
\ee
% then there exists $N$ such that $\forall n\geq N$, $(\dag)$ holds and
%\be
%\sum^\infty_{n=0} \abs{a_n z^n} > \sum^{N-1}_{n=0} \abs{a_n z^n} + \sum^\infty_{n=N} 1^n = \infty.
%\ee
%Then by Lemma \footnote{lemma needed.}, we have that the series does not converge.

If $R = 0$ and $t =\infty$, there are infinitely many $n$ such that $\abs{a_n} > \bb{t-\ve}^n $ and $\abs{a_n z^n} > \abs{z\bb{t-\ve}}^n =\infty$. Therefore, the series cannot converge \footnote{lemma needed.} whenever $z$ is not 0 because its $n$th term $a_nz^n$ does not tend to 0.
\een
\end{proof}

%\begin{theorem}[radius of convergence of multiple complex variables]
%Let $n$ be a multi-index (a $d$-tuple of integers) with $n= n_1 + \dots + n_d$ and define the multi-dimensional power series
%\be
%f(z) = \sum_{n\geq 0}a_n z^n := \sum_{n_1\geq 0,\dots,n_d\geq 0}a_{n_1}\cdots a_{n_d} z^{n_1} \dots z^{n_d}.
%\ee
%
%Then $f(z)$ converges with radius of convergence $R$ (which is also a multi-index) if and only if
%\be
%\sum_{n\to \infty}\bb{\abs{a_n}R^n }^{1/n} := \sum_{n\to \infty}\bb{\abs{a_{n_1}\dots a_{n_d}}R_1^{n_1}\dots R_d^{n_d}}^{1/n} = 1.
%\ee
%\end{theorem}
%
%\begin{proof}[\bf Proof]
%\footnote{The proof can be found in the book Introduction to Complex Analysis Part II functions in several Variables by B. Shabat}
%\end{proof}


The next propositions are useful for computing $R$.

\begin{proposition}\label{pro:ratio_test_convergence_radius}%{pro:ratio_convergence_radius}
Consider the power series $\sum^\infty_{n=1}a_n z^n$ with $a_n,z\in \C$. If 
\be
\abs{\frac{a_{n+1}}{a_n}}\to \ell \ \text{ as }n\to \infty,
\ee
then $R=1/\ell$.
\end{proposition}

\begin{proof}[{\bf Proof}]
By the ratio test (Theorem \ref{thm:ratio_test_complex}), we have absolute convergence if
\be
\lim_{n\to \infty} \abs{\frac{a_{n+1}z^{n+1}}{a_nz^n}}<1, \ \text{i.e. } |z|<1/\ell
\ee
and if $|z|>1/\ell$, then
\be
\lim_{n\to \infty} \abs{\frac{a_{n+1}z^{n+1}}{a_nz^n}}>1\ \ra\ \exists N\text{ s.t. }\abs{a_{n+1}z^{n+1}} > \abs{a_nz^n},\ \forall n\geq N
\ee
and $a_nz^n$ does not tend to zero which implies that $R=1/\ell$.
\end{proof}

\begin{proposition}\label{pro:root_test_convergence_radius}
Consider the power series $\sum^\infty_{n=1}a_n z^n$ with $a_n,z\in \C$. If $|a_n|^{1/n}\to \ell$ as $n\to \infty$, then $R=1/\ell$.
\end{proposition}


\begin{proof}[\bf Proof]
The result is implied by the root test (Theorem \ref{thm:root_test_complex}). %if $|a_n|^{1/n}\to \ell$, then $R=1/\ell$.
\end{proof}

By the above propositions, we can work out the radius of convergence. However, nothing can be said at $|z|=R$ by these propositions.

\begin{example}
\ben
\item [(i)] $\sum^\infty_{n=0} z^n$. $R=1$ since $a_n=1$ and $\abs{\frac{a_{n+1}}{a_n}}\to 1$ as $n\to \infty$.

\item [(ii)] $\sum^\infty_{n=1} \frac{z^n}{n}$.
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{n}{n+1}} \to 1 \ \ra \ R=1.
\ee

\item [(iii)] $\sum^\infty_{n=1} n z^n$.
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{n+1}n} \to 1 \ \ra \ R=1.
\ee

\item [(iv)] $\sum^\infty_{n=0}\frac{z^n}{n!}$. We have
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{n!}{(n+1)!}} = \frac {1}{n+1}\to 0\ \ra \ R=\infty.
\ee

\item [(v)] $\sum^\infty_{n=0} n!z^n$. We have
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{(n+1)!}{n!}}= n+1\to \infty\ \ra \ R=0.
\ee

\item [(vi)] $\sum^\infty_{n=1} \frac{z^n}{n^2}$.
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{n^2}{(n+1)^2}} \to 1 \ \ra \ R=1.
\ee

\item [(vii)] $\sum^\infty_{n=0} n^n z^n$.
\be
\abs{\frac{a_{n+1}}{a_n}} = \abs{\frac{(n+1)^{n+1}}{n^n}} = (n+1)\bb{\frac{n+1}{n}}^n = (n+1)\underbrace{\bb{1 + \frac 1n}^n}_{\to e} \to \infty \ \ra \ R=0.
\ee
\een
\end{example}

Nevertheless, we can work out the feature of series on the radius of convergence.
\begin{example}
\ben

\item [(i)] $\sum^\infty_{n=0} z^n$. The series diverges for $\abs{z}=1$ as $\lim_{n\to \infty} z^n$ is not zero.

\item [(ii)] $\sum^\infty_{n=1} n z^n$. The series diverges for $\abs{z}=1$ as $\lim_{n\to \infty} n z^n$ is not zero.


\item [(iii)] $\sum^\infty_{n=1} \frac{z^n}{n^2}$. For $\abs{z}=1$, we have
\be
\sum^\infty_{n=1} \abs{\frac{z^n}{n^2}} = \sum^\infty_{n=1} \frac 1{n^2} = \frac {\pi^2}{6} \ \ra\ \sum^\infty_{n=1} \frac{z^n}{n^2} \ \text{ converges on }\abs{z} =1.
\ee

\item [(iv)] $\sum^\infty_{n=1} \frac{z^n}{n}$. If $z=1$,
\be
\sum^\infty_{n=1}\frac 1n\ \text{ diverges\ \ (actually equals to $\lim_{n\to \infty}\log n$).}
\ee

Then we can rewrite
\be
\sum^\infty_{n=1} \frac{z^n}{n} = \sum^\infty_{n=1} a_n b_n
\ee
where $a_n=1/n$ and $b_n=z^n$. Then for any $z\in \C$ with $\abs{z}= 1$ and $z\neq 1$,
\be
\sum^N_{n=1} b_n = \sum^N_{n=1}z^n = \frac {z-z^{N+1}}{1-z} \ \ra \ \abs{\sum^N_{n=1} b_n}\leq \frac{2}{\abs{1-z}} := M
\ee

Also, $a_{n+1}\leq a_n$ and $a_n\to 0$. Thus, we can apply Dirichlet test\footnote{theorem needed.} and get
\be
\sum^\infty_{n=1} \frac{z^n}{n}\ \text{ converges for all }z\in \C\text{ with }\abs{z}= 1\text{ but } z\neq 1.
\ee

Alternatively, we can have for $m$ and $n$,
\be
B_n := \sum^n_{k=1} b_k = \sum^n_{k=1} z^k = \frac{z-z^{n+1}}{1-z}
\ee
and thus
\beast
\abs{\sum^m_{k=n} \frac{z^k}{k}} & = & \abs{\sum^m_{k=n} a_k b_k} = \abs{a_{m}\sum^m_{k=n}b_k + \sum^{m-1}_{k=n}b_k\bb{a_k-a_{m}}} = \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{k=n}b_k\sum^{m-1}_{i=k}\bb{a_i-a_{i+1}} } \\
& = & \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}\sum^i_{k=n}b_k } =  \abs{a_{m}\bb{B_m - B_{n-1}} + \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}\bb{B_i - B_{n-1}} }\\%\abs{a_mB_m - a_{n}B_{n-1} - \sum^{m-1}_{k=n}B_k(a_{k+1} - a_k)}
& = & \abs{a_{m}\bb{B_m - B_{n-1}} + \bb{a_m- a_n} B_{n-1}+ \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}B_i } = \abs{a_{m}B_m  - a_n B_{n-1}+ \sum^{m-1}_{i=n}\bb{a_i-a_{i+1}}B_i } \\
& \leq & \frac 2{\abs{1-z}}\bb{\frac 1m + \frac 1n + \sum^{m-1}_{i=n}\bb{\frac 1i - \frac 1{i+1}}} = \frac 4{n\abs{1-z}}.
\eeast

Thus, $\sum^m_{n=1} \frac 1n z^n$ is a Cauchy sequence. Then the completeness of the complex plane (Theorem \ref{thm:complex_plane_is_complete}) ensures that
\be
\sum^\infty_{n=1}\frac 1n z^n = \lim_{m\to \infty} \sum^m_{n=1} \frac 1n z^n,\quad \abs{z}=1,\ z\neq 1.
\ee
\een
\end{example}

\subsection{Derivatives of power series}

\begin{lemma}\label{lem:radius}
If $\sum a_n z^n$ has radius of convergence $R$, then so do $\sum na_nz^{n-1}$ and $\sum n(n-1)a_nz^{n-2}$. Furthermore, for any $k\in \N$, we have that
\be
\sum_n \frac{n!}{(n-k)!}a_nz^{n-k} \text{ has radius of convergence }R.
\ee
\end{lemma}

\begin{proof}[{\bf Proof}]
$\sum a_nz^n$ has radius of convergence $R$, and $\sum na_nz^{n-1}$ has radius of convergence $R'$. RTP: $R=R'$.

Take $z$ with $|z|<R$, choose $R_0$ s.t. $|z_0|<R_0<R$. Since $R_0<R$, $a_nR_0^n\to 0$ as $n\to \infty$. In particular, there exists $K$ s.t. $|a_nR_0^n|\leq K,\ \forall n$.
\be
|na_nz^{n-1}| = \frac n{|z|}|a_nz^n|\frac {R_0^n}{R_0^n} \leq \frac K{|z|}n\left|\frac z{R_0}\right|^n
\ee
We see that $\sum n\left|\frac z{R_0}\right|^n$ converges. By comparison, $\sum na_nz^{n-1}$ converges absolutely which implies that $R\leq R'$.

But in fact we have equality because
\be
|a_nz^n|\leq n|a_nz^n| = \frac 1{|z|}n|a_nz^{n-1}|
\ee
by comparison, if $\sum na_nz^{n+1}$ converges absolutely, so does $\sum a_nz^n$. Thus, $R=R'$. What we proved also implies that $\sum n(n-1)a_nz^{n-2}$ has radius of convergence $R$. The similar arguement for $k\in \N$.
\end{proof}



\begin{lemma}\label{lem:power_series_binomial_inequality}
For any $h,z\in \Z$,
\be
\abs{(z+h)^n-z^n-nhz^{n-1}} \leq n(n-1)(|z|+|h|)^{n-2}|h|^2.
\ee
\end{lemma}

\begin{proof}[{\bf Proof}]
By Lemma \ref{lem:binomial_inequality},
\beast
(z+h)^n-z^n-nhz^{n-1} & = & \sum^n_{r=2}\binom{n}{r}z^{n-r}h^r\\
\ \ra \ |(z+h)^n-z^n-nhz^{n-1}| & \leq & \sum^n_{r=2}\binom{n}{r}|z|^{n-r}|h|^r \leq \sum^n_{r=2}n(n-1)\binom{n-2}{r-2}|z|^{n-r}|h|^r \\
 & = & n(n-1)|h|^2 \underbrace{\sum^n_{r=2}\binom{n-2}{r-2}|z|^{n-r}|h|^{r-2}}_{(|z|+|h|)^{n-2}}
\eeast
\end{proof}

\begin{theorem}\label{thm:power_series_differentiation}
The power series 
\be
f(z) = \sum^\infty_{n=0}a_nz^n
\ee
defines a holomorphic function in its (open) disc of convergence $\abs{z}<R$. The derivative of $f$ is also a power series obtained by differentiating term by term the series for $f$, that is,
\be
f'(z)=\sum^\infty_{n=0} n a_nz^{n-1}.
\ee

Moreover, $f'$ has the same radius of convergence as $f$.
\end{theorem}

%Suppose $\sum a_nz^n$ has radius of convergence $R$, so let
%\be
%f(z) = \sum^\infty_{n=0}a_nz^n,\ |z|<R.
%\ee

%Then $f$ is differentiable and $f'(z)=\sum^\infty_{n=1}na_nz^{n-1}$.
%\end{theorem}

\begin{remark}
Iterate this theorem, to get that $f$ can be differentiated infinitely many as if it was a polynomial.
\end{remark}

\begin{proof}[{\bf Proof}]
By Lemma \ref{lem:radius}, since $\sum na_nz^n$ has radius of convergence $R$, it defines a function $g(z)=\sum na_n z^{n-1}$ for $z$ with $|z|<R$. We would like to prove that
\be
\frac{f(z+h)-f(z)-hg(z)}{h} \to 0 \text{ as }h\to 0.
\ee
This implies that $f$ is differentiable with $f'(z)=g(z)$. Note that we can change the order of summation since the power series are uniformly convergent,
\be
\frac{f(z+h)-f(z)-hg(z)}{h} = \frac 1h\lob\sum^\infty_{n=0}a_n(z+h)^n-\sum^\infty_{n=0}a_nz^n - h\sum^\infty_{n=0}na_nz^{n-1}\rob = \frac 1h\sum^\infty_{n=0}a_n\lob(z+h)^n-z^n - nhz^{n-1}\rob
\ee

By Lemma \ref{lem:power_series_binomial_inequality},
\be
\left|a_n\lob(z+h)^n-z^n - nhz^{n-1}\rob\right| \leq |a_n|n(n-1)(|z|+|h|)^{n-2}|h|^2
\ee

Take $r$ s.t. $|z|+r<R$. If $|h|<r$, we get
\be
\left|a_n\lob(z+h)^n-z^n - nhz^{n-1}\rob\right| \leq |a_n|n(n-1)(|z|+r)^{n-2}|h|^2
\ee

By Lemma \ref{lem:radius}, we know that $\sum |a_n|n(n-1)(|z|+r)^{n-2}$ converges to some number $A$. Thus,
\be
\frac{|f(z+h)-f(z)-hg(z)|}{|h|} \leq \frac 1{|h|} A|h|^2 = A|h|\to 0 \text{ as }h\to 0.
\ee
\end{proof}

\begin{proof}[\bf Alternative proof]
Since $\lim n^{1/n}=1$ (see Proposition \ref{pro:limit_n_root_one_over_n}), we have the same convergence radii of the following two function
\be
f(z) = \sum^\infty_{n=0} a_n z^{n},\qquad g(z) := \sum^\infty_{n=0} na_n z^{n-1}
\ee
by Hadamard's formula (Theorem \ref{thm:cauchy_hadamard_radius_of_convergence}). So let $R$ be the radius of convergence of $f$ and $g$ and we want to show that $g(z)$ gives the derivative of $f(z)$ within $R$. Assuming $\abs{z_0} <r<R$, we write
\be
f(z) = S_N(z) + E_N(z),
\ee
where
\be
S_N(z) = \sum^N_{n=0}a_n z^n,\qquad E_N(z) = \sum^\infty_{n=N+1} a_n z^n.
\ee

Then, for any $h$ is chosen so that $\abs{z_0 + h} < r$ we have
\beast
& & \frac{f(z_0 + h) - f(z_0)}{h} - g(z_0) \\
& = & \bb{\frac{S_N(z_0+h)-S_N(z_0)}{h}- S_N'(z_0) } + \bb{S_N'(z_0) - g(z_0)} + \bb{\frac{E_N(z_0+h)- E_N(z_0)}{h}}
\eeast
where $S_N'(z_0)$ is the derivative of $S_N(z_0)$. Since for any $a,b\in \C$,
\be
a^n - b^n = (a-b)\bb{a^{n-1} + a^{n-2}b + \dots + ab^{n-2}+b^{n-1}},
\ee
we can have
\be
\abs{\frac{E_N(z_0+h)- E_N(z_0)}{h}} \leq \sum^\infty_{n=N+1}\abs{a_n}\abs{\frac{(z_0+h)^n - z_0^n}{h}} \leq \sum^\infty_{n=N+1}\abs{a_n}n r^{n-1}
\ee
where we have used the fact that $\abs{z_0+h}<r$ and $\abs{z_0}<r$. So this upper bound converges to zero since it is the tail end of a convergent series ($g$ converges absolutely on $\abs{z} <R$) by \footnote{lemma needed.}. Therefore, given any $\ve>0$, we can find $N_1$ so that $N>N_1$ implies
\be
\abs{\frac{E_N(z_0+h)- E_N(z_0)}{h}} < \ve/3.
\ee

Also, since
\be
S_N'(z_0) = \sum^N_{n=0}na_n z^{n-1}
\ee
by Proposition\footnote{prop needed.} for the summation of finite terms, we have $\lim_{N\to\infty} S_N'(z_0) = g(z_0)$, we can find $N_2$ so that $N>N_2$ implies
\be
\abs{S_N'(z_0) - g(z_0)} < \ve/3.
\ee

If we fix $N$ so that $N>\max\bra{N_1,N_2}$, then we can find $\delta>0$ so that $\abs{h}<\delta$ implies
\be
\abs{\frac{S_N(z_0+h)-S_N(z_0)}{h}- S_N'(z_0) } < \ve/3,
\ee
simply because the derivative of a polynomial is obtained by differentiating it term by term. Therefore,
\be
\abs{\frac{f(z_0 + h) - f(z_0)}{h} - g(z_0) } <\ve
\ee
whenever $\abs{h}< \delta$, thereby concluding the proof.
\end{proof}

\begin{example}
\ben
\item [(i)] Geometric series. See Proposition \ref{pro:geometric_series_sum}.

\item [(ii)] Natural exponential function. $\sum^\infty_{n=0}\frac{z^n}{n!}$ has radius of convergence $R=\infty$. Thus, $\exp: \C\mapsto\C$, $\exp(z) = \sum^\infty_{n=0}\frac{z^n}{n!}$. The theorem tells us right away that $e$ is differentiable and
\be
\bb{e^z}' = \sum^\infty_{n=1}\frac n{n!}z^{n-1} = e^z.
\ee

Of course, $\exp(z)$ and its derivative have the same radius of convergence $R=\infty$.
\een
\end{example}

Then we have the following corollaries.

\begin{corollary}
If the series $\sum^\infty_{n=0} a_n(z-z_0)^n$ has radius of convergence $R>0$ then
\be
f(z) = \sum^\infty_{n=0} a_n(z-z_0)^n\quad\text{is analytic in $D_{R}(z_0)$.}
\ee
\end{corollary}


\begin{corollary}
A power series is infinitely complex differentiable in its disc of convergence, and the higher derivatives are also power series obtained by termwise differentiation. 
\end{corollary}






\section{Polar Form of Complex Numbers}

\subsection{Polar representation of complex number}

\begin{lemma}[polar representation of complex number]\label{lem:polar_representation_complex_number}
Let $z=x+iy$ with $x,y\in\R$. Then there exists a unique real number $\theta\in (-\pi,\pi]$ such that
\be
z = re^{i\theta} = r\cos\theta + ir\sin\theta,\qquad r = \abs{z} = \sqrt{x^2 + y^2}\neq 0.
\ee
\end{lemma}

\begin{proof}[\bf Proof]
Note that we used Euler's formula in the equation.

First, we have that for $z \neq 0$, there exists $\theta\in (-\pi,\pi]$ such that $\cos \theta = \frac{x}{r}$ as $\frac xr \in [0,1]$ since $\cos \theta$ is continuous in $(-\pi,\pi]$ (Proposition \ref{pro:sine_cosine_continuous_differentiable}). Therefore,
\be
\cos\theta = \frac x{\sqrt{x^2+y^2}} \ \ra\ \sin\theta = \pm \frac y{\sqrt{x^2+y^2}}
\ee
by Proposition \ref{pro:basic_properties_of_sine_and_cosine}. If so $\theta$ satisfying 
\be
z = \sqrt{x^2 + y^2}\frac{x}{\sqrt{x^2 + y^2}} + i\sqrt{x^2 + y^2}\frac{y}{\sqrt{x^2 + y^2}} = r\cos\theta \pm i r \sin \theta = r\cos\bb{\pm\theta} + i r \sin \bb{\pm\theta}
\ee

For uniqueness, we can assume $\theta_1,\theta_2\in (-\pi,\pi]$ such that 
\be
z = r\cos \theta_1 + ir\sin\theta_1 = r\cos \theta_2 + ir\sin\theta_2 \ \ra\ \cos \theta_1 = \cos\theta_2,\ \sin \theta_1 = \sin\theta_2.
\ee

Then 
\be
\cos\bb{\theta_1 - \theta_2} = \cos \theta_1 \cos\theta_2 + \sin\theta_1\sin\theta_2 = \cos^2 \theta_1 + \sin^2 \theta_1 = 1 \ \ra\ \theta_1 - \theta_2 = 2k\pi,\ k\in\Z
\ee
by the remark in Corollary \ref{cor:sine_cosine_pi_properties}. But $\theta_1 -\theta_2 \in (-2\pi,2\pi)$ implies that $\theta_1 -\theta_2 = 0$ and thus $\theta_1 =\theta_2$.
\end{proof}

\begin{proposition}
Let $z_1 = r_1\bb{\cos \theta_1 + i\sin \theta_1)}$ and $z_2 = r_2\bb{\cos \theta_2 + i \sin \theta_2)}$ with $r_1,r_2>0$ and $\theta_1,\theta_2 \in \R$. Then, 
\be
z_1z_2  =r_1r_2\bb{\cos(\theta_1+\theta_2) + i\sin (\theta_1+\theta_2)}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Direct result by Proposition \ref{pro:sine_and_cosine_of_summation}.
\end{proof}


\subsection{Argument of complex numbers}

Then we have the following definition.

\begin{definition}[argument\index{argument!complex number}]\label{def:argument_complex_number}
The argument of a complex number $z = x+ iy$, denoted by $\arg z$, is defined by $\theta$ such that
\be
z = r\bb{\cos\theta + i\sin\theta} = re^{i\theta}.
\ee

Geometrically, in the complex plane, the argument of $z$, is the angle $\theta$ from the positive real axis to the vector representing $z$. The numeric value is given by the angle in radians and is positive if measured counterclockwise.
\end{definition}

\begin{remark}
It can be seen that argument of complex number has infinitely many values as if $\theta_0\in \R$ is the argument,
\be
z = re^{i\theta_0} = re^{i\theta_0 + 2k\pi i},\qquad k\in \Z.
\ee

This means that $\theta = \theta_0  + 2k\pi$, $k\in \Z$ is also an argument.
\end{remark}

\begin{definition}[principal value of argument]
The  principal value of argument $\arg z$ for complex number $z$ is defined by $\Arg z \in (-\pi,\pi]$ such that
\be
\Arg z := \bra{\arg z: \arg z \in (-\pi,\pi]}.
\ee

For any complex number $z\bs\bra{0}$, it can be expressed by
\be
z = \abs{z} e^{i\Arg z}.
\ee
\end{definition}

\begin{remark}
Obviously, for any $z\in \C\bs \bra{0}$,
\be
\arg z = \Arg z + 2k\pi,\qquad k\in \Z.
\ee
\end{remark}

\begin{example}
\be
\Arg(1) = 0,\quad \Arg(-1) = \pi,\quad \Arg(i) = \frac{\pi}2,\quad \Arg(-i) = -\frac{\pi}2,
\ee
\be
\Arg(1+i) = \frac {\pi}4,\quad \Arg(1-i) = -\frac {\pi}4,\quad \Arg(-1+i) = \frac {3\pi}4,\quad \Arg(-1-i) = -\frac {3\pi}4. 
\ee
\end{example}



\begin{proposition}
Let $z = x + iy\in \C$. Then the principal value of argument is calculated by
\be
\Arg z = \left\{\ba{ll}
\arctan\bb{y/x} & x>0,\\
\arctan\bb{y/x} + \pi\quad\quad\quad\quad & x<0,y\geq 0,\\
\arctan\bb{y/x} - \pi\quad\quad & x<0,y< 0,\\
\pi/2 & x=0,y> 0,\\
-\pi/2 & x=0,y< 0,\\
\text{undefined} & x=0,y=0
\ea\right.
\ee
where $\arctan:\bb{-\infty,\infty}\to \bb{-\frac{\pi}2,\frac{\pi}2} $ is real inverse tangent function.
\end{proposition}

\begin{remark}
A compact expression with 4 overlapping half-plane is
\be
\Arg z = \left\{\ba{ll}
\arctan\bb{y/x} & x>0,\\
\pi/2 - \arctan\bb{x/y}\quad\quad\quad\quad & y>0,\\
-\pi/2 -\arctan\bb{x/y} \quad\quad & y< 0,\\
\arctan\bb{y/x} \pm \pi & x < 0,\\
\text{undefined} & x=0,y=0
\ea\right.
\ee
\end{remark}


\begin{proof}[\bf Proof]
Clearly, we have that $x = r\cos \theta$ and $y = r\sin \theta$ for $z = x+iy$. Then for $z\in \C\bs\bra{0}$
\be
\frac{y}{x} = \frac{r\sin\theta}{r\cos\theta} = \frac{\sin\theta}{\cos\theta} = \tan\theta = \tan\bb{\arg z} = \tan\bb{\Arg z + 2k\pi} = \tan\bb{\Arg z},\quad k\in \Z.
\ee

Thus, if $\Arg z \in \bb{-\frac{\pi}2,\frac{\pi}2}$, we can have 
\be
\Arg z = \arctan \frac{y}{x}
\ee

If $\theta = \frac {\pi}2$, we have that $z = r\bb{\cos {\pi}2 + i\sin {\pi}2} = r\bb{0+i\cdot 1} = ir$ ($x=0, y>0$) which implies that $z$ is purely imaginary above origin. Thus, we have $\Arg z = \frac {\pi}2$ for this case. Similarly, we have $\Arg z = -\frac {\pi}2$ when $x = 0$ and $y<0$.

If $\Arg z = \theta \in \left(\frac{\pi}{2},\pi\right]$ we have 
\be
x = r\cos\theta < 0,\qquad y = r\sin \theta \geq 0.
\ee
and $\tan\bb{\Arg z} = \tan \bb{\Arg z - \pi}$ since $\tan$ has period $\pi$. Furthermore, $\Arg z - \pi \in \left(-\frac{\pi}{2},0\right]$ and therefore
\be
\Arg z - \pi = \arctan \frac{y}{x} \ \ra\ \Arg z = \arctan \frac{y}{x} + \pi.
\ee

Similarly, we have 
\be
\Arg z = \arctan \frac{y}{x} - \pi
\ee
for $x<0$ and $y<0$.
\end{proof}

\begin{proposition}
For any $z,z_1,z_2\in \C\bs\bra{0}$ and $n\in \Z$,
\ben
\item [(i)] $\Arg(z_1z_2) \equiv \Arg z_1 + \Arg z_2 \lmod{(-\pi,\pi]}$.
\item [(ii)] $\Arg\bb{\frac{z_1}{z_2}} \equiv \Arg z_1 - \Arg z_2 \lmod{(-\pi,\pi]}$.
\item [(iii)] $\Arg(z^n) \equiv n\Arg(z)\lmod{(-\pi,\pi]}$.
\een
\end{proposition}


\begin{proof}[\bf Proof]
Let $z_1 = \abs{z_1}e^{i\Arg z_1}$ and $z_2 = \abs{z_2}e^{i\Arg z_2} \neq 0$. 

For product,
\beast
z_1 z_2 = \abs{z_1z_2}e^{i\bb{\Arg z_1 + \Arg z_2}}  \ \ra\ \Arg\bb{z_1z_2} = \Arg z_1 + \Arg z_2 \lmod{(-\pi,\pi]}.
\eeast

For division,
\beast
\frac{z_1}{z_2} = \frac{\abs{z_1}e^{i\Arg z_1}}{\abs{z_2}e^{i\Arg z_2}} = \abs{\frac{z_1}{z_2}}e^{i\Arg z_1}e^{- i\Arg z_2} = \abs{\frac{z_1}{z_2}}e^{i\bb{\Arg z_1 - \Arg z_2}}  \ \ra\ \Arg\bb{\frac{z_1}{z_2}} = \Arg z_1 - \Arg z_2 \lmod{(-\pi,\pi]}.
\eeast

(iii) is the direct result from (i) and (ii).
\end{proof}

\begin{example}
\be
\operatorname {Arg}{\biggl (}{\frac  {-1-i}{i}}{\biggr )}=\operatorname {Arg}(-1-i)-\operatorname {Arg}(i)=-{\frac  {3\pi }{4}}-{\frac  {\pi }{2}}=-{\frac  {5\pi }{4}}={\frac  {3\pi }{4}}{\pmod  {(-\pi ,\pi ]}}.
\ee
\end{example}



\begin{theorem}\label{thm:principal_value_argument_continuous_discontinuous}
The principal value of argument of $z\in \C\bs\bra{0}$, $\Arg z$, is continuous on $\Arg z\in (-\pi,\pi)$ and discontinuous on $\Arg z = \pi$.
\end{theorem}

\begin{proof}[\bf Proof]
By Proposition\footnote{arg in form of arctan}, we have for $\Arg z\in (-\pi,\pi)$
\be
\Arg z = \left\{\ba{ll}
\arctan\bb{y/x} & x>0,\\
\pi/2 - \arctan\bb{x/y}\quad\quad\quad\quad & y>0,\\
-\pi/2 -\arctan\bb{x/y} \quad\quad & y< 0
\ea\right..
\ee

Since $\arctan$, $x = \Re z$ and $y = \Im z$ are all continuous, we have that $\Arg z$ is continuous as it is the composition of continuous functions.

For any real $z<0$, Let $z_n = e^{i/n}z$ and $w_n = e^{-i/n}z$. It is clear that $z_n,w_n \to z$. That is,
\be
\abs{z_n - z} = \abs{e^{i/n}-1}\abs{z} = \abs{z}\abs{\cos \frac 1n -1 + i\sin \frac 1n} = \abs{z}\sqrt{2 - 2\cos \frac 1n} = 2\abs{z}\sin\bb{\frac 1{2n}} \leq 2\abs{z}\frac 1{2n} = \frac{\abs{z}}{n} \to 0
\ee
since $sin x\leq x$ for $x\in \bsb{0,\frac {\pi}2}$. However, we have that 
\be
\Arg z_n = -\pi + \frac 1n \to -\pi,\qquad \Arg w_n = \pi - \frac 1n \to \pi
\ee
which implies that $\Arg z$ is not continuous on negative real axis ($\Arg z= \pi$).
\end{proof}


\subsection{Convergence of polar form}

One must be careful when adapting Theorem \ref{thm:convergence_of_complex_iff_convergence_of_real_imaginary} to polar coordinates. It means that the relation
\be
\lim_{n\to \infty} z_n = \lim_{n\to \infty} \abs{z_n} \cdot e^{i\lim_{n\to \infty} \Arg z_n}
\ee
might not hold as the following example shows.

\begin{example}
Let
\be
z_n = -2 + i\frac{(-1)^n}{n^2}.
\ee

Then the theorem tells us that
\be
\lim_{n\to \infty} z_n = \lim_{n\to \infty}(-2) + i\lim_{n\to \infty}\frac{(-1)^n}{n^2} = -2 + i\cdot 0 = -2.
\ee

If we use polar coordinates, we have $r_n = \abs{z_n}$ and $\theta_n = \Arg z_n$ with $z_n = r_n \theta_n$. Then we find
\be
\lim_{n\to \infty} r_n = \lim_{n\to \infty} \sqrt{x_n^2 + y_n^2} = \lim_{n\to \infty} \sqrt{4 + \frac 1{n^4}} = 2.
\ee

However,
\be
\lim_{n\to \infty} \theta_{2n} = \pi,\qquad \lim_{n\to \infty} \theta_{2n-1} = -\pi.
\ee

Evidently, the limit of $\theta_n$ does not exist as $n\to \infty$.
\end{example}


\subsection{Cauchy-Riemann equations of polar form}

Also, we have the corresponding theorems for the polar coordinates.

\begin{theorem}[necessary conditions for differentiability of complex function in polar coordinates]\label{thm:cauchy_riemann_equation_polar_form}
Let $f(z) = u(x,y) + iv(x,y) $for $z = x+iy = re^{i\theta}$ with $x,y,r,\theta\in \R$. Then the differentiability of $f(z)$ implies the Cauchy-Riemann equations of polar coordinates,
\be
\fp{u}{r} = \frac 1r \fp{v}{\theta},\qquad \fp{v}{r} = -\frac 1r \fp{u}{\theta}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Consider the polar coordinates $r= \sqrt{x^2 + y^2}$ and $\theta = \arctan \frac yx + k\pi$ with $k\in \Z$. Differentiating $r$ and $\theta$ with respect to both $x$ and $y$, we obtain
\be
\fp{r}{x} = \frac{\frac 12 2x}{\sqrt{x^2 + y^2}} = \frac xr = \cos\theta,\qquad \fp{r}{y} = \frac{\frac 12 2y}{\sqrt{x^2 + y^2}} = \frac yr = \sin\theta
\ee
and
\be
\fp{\theta}{x} = \frac{1}{1+\bb{\frac yx}^2} \bb{-\frac{y}{x^2}} = -\frac{y}{x^2+y^2} = -\frac 1r\sin \theta,\qquad \fp{\theta}{y} = \frac{1}{1+\bb{\frac yx}^2} \bb{\frac{1}{x}} = \frac{x}{x^2+y^2} = \frac 1r\cos\theta.
\ee

Using the chain rule\footnote{theorem needed.}, the first-order partial derivatives of $u$ are given by
\beast
\fp{u}{x} & = & \fp{u}{r} \fp{r}{x} + \fp{u}{\theta}\fp{\theta}{x} = \fp{u}{r} \cos\theta - \frac 1r \fp{u}{\theta} \sin\theta, \\
\fp{u}{y} & = & \fp{u}{r} \fp{r}{y} + \fp{u}{\theta}\fp{\theta}{y} = \fp{u}{r} \sin\theta + \frac 1r \fp{u}{\theta} \cos\theta.
\eeast

Similarly, the first-order partial derivatives of $v$ are given by
\beast
\fp{v}{x} & = & \fp{v}{r} \fp{r}{x} + \fp{v}{\theta}\fp{\theta}{x} = \fp{v}{r} \cos\theta - \frac 1r \fp{v}{\theta} \sin\theta, \\
\fp{v}{y} & = & \fp{v}{r} \fp{r}{y} + \fp{v}{\theta}\fp{\theta}{y} = \fp{v}{r} \sin\theta + \frac 1r \fp{v}{\theta} \cos\theta.
\eeast

Using one of the Cauchy-Riemann equations (Theorem \ref{thm:cauchy_riemann_equation}),
\beast
0 & = & \fp{u}{x} - \fp{v}{y} = \bb{\fp{u}{r}- \frac 1r \fp{v}{\theta} } \cos\theta - \bb{\fp{v}{r} + \frac 1r \fp{u}{\theta} } \sin\theta \\
0 & = & \fp{v}{x} + \fp{u}{y} = \bb{\fp{v}{r}+ \frac 1r \fp{u}{\theta} } \cos\theta + \bb{\fp{u}{r} - \frac 1r \fp{v}{\theta} } \sin\theta
\eeast

Since the above equations are satisfied for all $\theta$, we must have
\be
\fp{u}{r} =  \frac 1r \fp{v}{\theta},\qquad \fp{v}{r} = - \frac 1r \fp{u}{\theta}.
\ee
\end{proof}


\begin{theorem}[sufficient conditions for differentiability of complex function in polar coordinates]\label{thm:sufficient_conditions_differentiable_complex_polar_form}
Given $f(z) = u(r,\theta) + iv(r,\theta)$ for $z = re^{i\theta}$. Assume that
\ben
\item [(i)] the Cauchy-Riemann equations for polar coordinates (see Theorem \ref{thm:cauchy_riemann_equation_polar_form})
\be
\fp{u}{r} = \frac 1r \fp{v}{\theta},\qquad \fp{v}{r} = -\frac 1r \fp{u}{\theta}.
\ee
hold at a point $z_0 = r_0e^{i\theta_0}$.
\item [(ii)] $u_r$, $u_\theta$, $v_r$ and $v_\theta$ are all continuous at the point $(r_0,\theta_0)$.
\een

The derivative $f'(z_0)$ then exists and it is given by
\be
f'(z_0) = e^{-i\theta_0} \bb{u_r(r_0,\theta_0) + iv_r(r_0,\theta_0)} = \frac 1{r_0}e^{-i\theta_0}\bb{ v_\theta(r_0,\theta_0) - iu_\theta(r_0,\theta_0)}.
\ee
\end{theorem}

\begin{remark}
Condition (ii) be relaxed to the differentiability of real functions $u(r,\theta)$ and $v(r,\theta)$. In particular, a function of real variables $f:\R^2\to\R$ is said to be differentiable (Definition \ref{def:differentiable_multi_dimensional_real_function}) if
\be
\lim_{r\to r_0,\theta\to \theta_0} \frac{\abs{f(r,\theta)-f(r_0,\theta_0) - \bb{\fp{f}{r}(r_0,\theta_0)(r-r_0) +\fp{f}{\theta}(r_0,\theta_0)(\theta-\theta_0)}}}{\sqrt{r^2 + r_0^2 - 2rr_0 \cos(\theta-\theta_0)}} = 0.
\ee
\end{remark}

\begin{proof}[\bf Proof]
Since $u(r,\theta)$ and $v(r,\theta)$ have continuous first-order partial derivatives at $(r_0,\theta_0)$ (thus $u$ and $v$ are differentiable by Theorem \ref{thm:continuous_partial_derivatives_implies_real_differentiability}) and satisfy the Cauchy-Riemann equations at the same point, we have that for sufficiently close point $(r,\theta)$ to $(r_0,\theta_0)$
\beast%& = & u(x,y) - u(x_0,y) + u(x_0,y) - u(x_0,y_0) \\
u(r,\theta) - u(r_0,\theta_0) & = & u_r(r_0,\theta_0)(r-r_0) + u_\theta(r_0,\theta_0)(\theta-\theta_0) + o\bb{\abs{\Delta z}}, \\
& = & u_r(r_0,\theta_0)(r-r_0) - r_0 v_r(r_0,\theta_0)(\theta-\theta_0) +  o\bb{\abs{\Delta z}}.\qquad (*)
\eeast
and
\beast
v(r,\theta) - v(r_0,\theta_0) & = & v_r(r_0,\theta_0)(r-r_0) + v_\theta(r_0,\theta_0)(\theta-\theta_0) +o\bb{\abs{\Delta z}}, \\
& = & v_r(r_0,\theta_0)(r-r_0) + r_0 u_r(r_0,\theta_0)(\theta-\theta_0) + o\bb{\abs{\Delta z}}. \qquad (\dag)
\eeast
where
\beast
\abs{\Delta z} & = & \sqrt{r^2 + r_0^2 - 2rr_0\cos(\theta-\theta_0)} \\
& = & \sqrt{(r- r_0)^2 + 2rr_0\bb{1-\cos(\theta-\theta_0)}} \\
& = & \sqrt{(r- r_0)^2 + rr_0(\theta-\theta_0)^2 + o\bb{(\theta-\theta_0)^2}}
\eeast

Then $(*)+ i\cdot (\dag)$ gives that
\beast
& & f(z) -f(z_0)\\
& = & \bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)}(r-r_0) + ir_0 \bb{u_r(r_0,\theta_0) + iv_r(r_0,\theta_0)}(\theta-\theta_0) + (1+i)o\bb{\abs{\Delta z}}  \\
& = & e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)}(re^{i\theta}-r_0e^{i\theta_0}) + \bb{u_r(r_0,\theta_0) + iv_r(r_0,\theta_0)}\bb{r-r e^{i(\theta-\theta_0)} + i r_0(\theta-\theta_0)} + (1+i) o\bb{\abs{\Delta z}} \\
& = & e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)}(z-z_0) + \bb{u_r(r_0,\theta_0) + iv_r(r_0,\theta_0)}\bb{r-r e^{i(\theta-\theta_0)} + i r_0(\theta-\theta_0)} + (1+i) o\bb{\abs{\Delta z}}.
\eeast

Thus,
\beast
\frac{f(z) -f(z_0)}{z-z_0} = e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)} + \bb{u_r(r_0,\theta_0) + iv_r(r_0,\theta_0)}\frac{\bb{r-r e^{i(\theta-\theta_0)} + i r_0(\theta-\theta_0)}}{z-z_0} + (1+i) \frac{o\bb{\abs{\Delta z}}} {z-z_0}
\eeast
%
Obviously,
\be
\lim_{z\to z_0}\abs{\frac{o\bb{\abs{\Delta z}}}{z-z_0}} = \lim_{z\to z_0}\frac{o\bb{\abs{\Delta z}}}{\abs{z-z_0}} = \lim_{\Delta z\to 0}\frac{o\bb{\abs{\Delta z}}}{\abs{\Delta z}} = 0
\ee

\beast
\lim_{z\to z_0}\abs{\frac{\bb{r-r e^{i(\theta-\theta_0)} + i r_0(\theta-\theta_0)}}{z-z_0}} & = & \lim_{z\to z_0}\frac{\abs{\bb{r\bb{-i(\theta-\theta_0) + \frac 12(\theta-\theta_0)^2 + o\bb{(\theta-\theta_0)^2} } + i r_0(\theta-\theta_0)}}}{\abs{\Delta z}} \\
& = & \lim_{z\to z_0}\frac{\abs{\frac 12r(\theta-\theta_0)^2 + r\cdot o\bb{(\theta-\theta_0)^2 } + i (r_0-r)(\theta-\theta_0)}}{\abs{\Delta z}} \\
& \leq  & \lim_{z\to z_0}\frac{\abs{\frac 12r(\theta-\theta_0)^2} + r\abs{o\bb{(\theta-\theta_0)^2}} + \abs{(r_0-r)(\theta-\theta_0)}}{\abs{\Delta z}} \to 0.
\eeast

Therefore,
\be
f'(z) = \lim_{z\to z_0}\frac{f(z) -f(z_0)}{z-z_0} = e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)} = \frac 1{r_0}e^{-i\theta_0}\bb{ v_\theta(r_0,\theta_0) - iu_\theta(r_0,\theta_0)}.
\ee
\end{proof}

\begin{example}
We know that $f(z) = z^2$ is differentiable and that $f'(z) = 2z$. For polar coordinates,
\be
f(z) = f\bb{re^{i\theta}} = \bb{r\cos \theta + ir\sin\theta}^2 = r^2\cos(2\theta) + ir^2 \sin(2\theta) = u(r,\theta) + i v(r,\theta).
\ee

Then it is easy to verify the Cauchy-Riemann equations in polar coordinates,
\beast
u_r(r,\theta) & = & 2r\cos(2\theta) = \frac 1r 2r^2 \cos(2\theta) = \frac 1r v_\theta(r,\theta), \\
v_r(r,\theta) & = & 2r\sin(2\theta) = -\frac 1r \bb{-2r^2\sin(2\theta)} = - \frac 1r u_\theta(r,\theta).
\eeast

Moreover, the partial derivatives $u_r$, $v_r$, $u_\theta$ and $v_\theta$ are continuous. By Theorem \ref{thm:sufficient_conditions_differentiable_complex_polar_form}, $f(z) = r^2\cos(2\theta) + ir^2 \sin(2\theta)$ is differentiable for all $z\neq 0$ as Cauchy-Riemann equation does not hold at $r=0$. Then we have
\be
f'(z_0) = e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)} = e^{-i\theta_0}\bb{2r_0\cos(2\theta_0) + 2ir_0\sin(2\theta_0)} = 2r_0\bb{\cos \theta_0 + i\sin\theta_0} = 2z_0.
\ee
\end{example}

\begin{example}
Let function
\be
f(z) = z^{1/2} = \bb{re^{i\theta}}^{1/2} = r^{1/2}\bb{\cos\frac{\theta}2 + i\sin\frac{\theta}2}.
\ee

Then
\be
f'(z) = \frac 1{2}z^{-1/2} = \frac 12 \bb{re^{i\theta}}^{-1/2}= \frac 12 r^{-1/2} \bb{\cos\frac{\theta}2 - i\sin\frac{\theta}2}
\ee
for every point in the domain $\bra{re^{i\theta}: r>0,\theta\in (-\pi,\pi)}$. Note that
\be
u(r,\theta) = r^{1/2}\cos\frac{\theta}2,\quad v(r,\theta)= r^{1/2}\sin\frac{\theta}2.
\ee

Thus,
\beast
u_r(r,\theta) & = & \frac 12 r^{-1/2} \cos\frac{\theta}2 = \frac 1r \frac 12r^{1/2}\cos\frac{\theta}2 = \frac 1r v_\theta(r,\theta) \\
v_r(r,\theta) & = & \frac 12 r^{-1/2} \sin \frac{\theta}2 = -\frac 1r \bb{-\frac 12r^{1/2}\sin\frac{\theta}2} = -\frac 1r u_\theta(r,\theta).
\eeast

Moreover, the partial derivatives $u_r$, $v_r$, $u_\theta$ and $v_\theta$ are continuous. By Theorem \ref{thm:sufficient_conditions_differentiable_complex_polar_form}, $f(z) = r^{1/2}\bb{\cos\frac{\theta}2 + i\sin\frac{\theta}2}$ is differentiable for all $z\neq 0$ as Cauchy-Riemann equation does not hold at $r=0$. Then we have
\beast
f'(z_0) & = & e^{-i\theta_0}\bb{u_r(r_0,\theta_0) + i v_r(r_0,\theta_0)} = e^{-i\theta_0}\bb{\frac 12 r_0^{-1/2} \cos\frac{\theta_0}2 + \frac 12i r_0^{-1/2} \sin \frac{\theta_0}2} \\
& = & \frac 12 r_0^{-1/2} e^{-i\theta_0} e^{i\theta_0/2} = \bb{r_0e^{i\theta_0}}^{-1/2}  = \frac 12 z_0^{-1/2}.
\eeast

Note that the negative axis is a branch cut\footnote{definition needed.} and the origin is a branch point\footnote{definition needed.} for this function.
\end{example}





%\section{Elementary Functions on Complex Domain}
%\section{Functions on Real Domain}
%\section{Elementary Functions}
%\subsection{Exponential function}


\section{Paths and Connected Sets in Complex Space}


%\section{Curves}
%
%
%
%\subsection{Curves on topological space}
%
%\begin{definition}[curve]
%A curve is defined through a continuous mapping $\gamma: I \to X$ from an interval $I$ of the real numbers into a topological space $X$.
%\end{definition}
%
%\begin{remark}
%Curves are continuous.
%\end{remark}
%
%\subsection{Closed curve}
%
%\begin{definition}[simple closed curve]
%A simple closed curve (also known as Jordan curve) is a closed curve $\gamma:[a,b]\to \R^n$ that does not cross itself and ends at the same point where it begins (that is, the initial and final values of $\gamma(t)$ are the same).
%\end{definition}
%
%\subsection{Directed curves}
%
%\begin{definition}[positive and negative orientation]
%A simple closed curve $C$ has positive orientation if the region $R$ enclosed by the curve stays to the left of $C$ as the curve is traversed. A curve has negative orientation if the region stays to the right of $C$.
%\end{definition}
%
%
%\subsection{Smooth curves}


\subsection{Paths in complex space}

\begin{definition}[path]\label{def:path_complex}%n open connected 
A path in a set $X\subseteq \C$ is a continuous function $\gamma: [a,b]\to X$ for some interval $[a,b]$ in $\R$.

The set $\bra{\gamma(t): t\in [a,b]}$ is called the trace of path $\gamma$, denoted by $\bra{\gamma}$.
\end{definition}

\begin{remark}
Note that the trace of a path is always a compact set.\footnote{theorem in continuity needed.}
\end{remark}

\begin{definition}
A path $\gamma:[a,b]\to X\subseteq \C$ is called closed if $\gamma(a) = \gamma(b)$.
\end{definition}

\begin{definition}[smooth path]\label{def:smooth_path_complex}%n open connected
A smooth path $\gamma$ in a set $X\subseteq \C$ is a path with continuous derivative in the closed interval $t\in [a,b]$.% and non-zero in the open interval $t\in (a,b)$.
\end{definition}

\begin{remark}
Some books assume $\gamma'(t)\neq 0$ except at end points for smooth paths. If $\gamma'(t)$ is allowed to be zero, the path could trace out a path that contains a sharp cusp, despite $z$ being perfectly smooth. The trick is that $\gamma$ has zero velocity at the sharp point so there is no abrupt change in direction. Often books show a few examples like this to explain why they impose such regularity condition.
\end{remark}

\begin{remark}
To say that a function $\gamma:[a,b]\to \C$ has a derivative $\gamma'(t)$ for each point $t\in [a,b]$ means that
\be
\lim_{h\to 0}\frac{\gamma(t+h) - \gamma(t)}{h} = \gamma'(t)
\ee
exists for $t\in(a,b)$ and that the right and left sided limits exist for $t=a$ and $t=b$, respectively. This is, of course, equivalent to saying that $\Re\gamma$ and $\Im\gamma$ have a derivative.
\end{remark}



\begin{definition}[piecewise smooth path]\label{def:piecewise_smooth_path_complex}%n open connected
A piecewise smooth path $\gamma:[a,b]\to X$ in a set $X\subseteq \C$ is a path consisting of a finite number of smooth paths joined end to end. That is there is a partition of $[a,b]$, $a= t_0 < t_1 <\dots < t_{n-1}< t_n = b$, sucht that $\gamma$ is smooth in each subinterval $[t_{i-1},t_{i}]$, $1\leq i \leq n$.
\end{definition}


%\begin{definition}[piecewise smooth curve]\label{def:piecewise_smooth_curve_multiple_real}
%A smooth curve $\gamma:\R\to \R^n$ is a curve consisting of a finite number of smooth curves joined end to end.
%\end{definition}
%
%
%\section{Connected Sets}
%
%\subsection{Connected sets}
%
%%item connected set, move connected set to differential geometry
%
%Recalling the definition of disconnectedness and partition in topology\footnote{definition and proposition needed.}, we have the following definition.
%
%\begin{definition}[connected set\index{connected set!multiple real space}]\label{def:connected_set_multiple_real_space}
%A set $X\subseteq \R^n$ is called disconnected if it is the union of two disjoint non-empty open sets $X_1,X_2$ in $X$. Otherwise, $X$ is called connected.
%\end{definition}
%
%\begin{remark}
%Note that the open set is with respect to $X$. For instance, for $X = [0,1)\cup (1,2]$, $X_1 = [0,1)$ and $X_2 = (1,2]$ are both open.
%\end{remark}
%
%\subsection{Pathwise connected sets}
%
%\begin{definition}[pathwise connected set]
%A set $X\subseteq \R^n$ is said to be pathwise connected if any two points in $X$ can be joined by a (continuous) curve entirely contained in $X$.
%\end{definition}

Recalling the definition of function of bounded variation and total variation (Definition \ref{def:function_of_bounded_variation_total_variation_complex}),
\be
v_f(P) := \sum^n_{k=1}\abs{f(t_k) - f(t_{k-1})} \leq M,\qquad V_f[a,b] := \sup\bra{v_f(P): P\text{ is a partition of }[a,b]}.
\ee
for some constant $M>0$ and partition $P$ of interval $[a,b]$. Then $v_\gamma(P)$ is exactly the sum of lengths of the line segments connecting points on $\bra{\gamma}$, the trace of $\gamma$.

\begin{definition}[rectifiable path]\label{def:rectifiable_path_complex}
A path $\gamma:[a,b]\to \C$ is a rectifiable path if $\gamma$ is a function of bounded variation.
\end{definition}

\begin{remark}
To say that $\gamma$ is rectifiable is to say that $\gamma$ has finite length and its length is $V_\gamma[a,b]$. In particular, if path $\gamma$ is piecewise smooth then $\gamma$ is rectifiable (Proposition \ref{pro:piecewise_smooth_path_is_of_bounded_variation_complex}) and its length is $\int^b_a \abs{\gamma'(t)}dt$. %Clearly, every piecewise smooth path is rectifiable by .
\end{remark}



\begin{proposition}\label{pro:piecewise_smooth_path_is_of_bounded_variation_complex}
If $\gamma : [a,b]\to \C$ is piecewise smooth path, then $\gamma$ is rectifiable path and the total variation
\be
V_\gamma[a,b] = \int^b_a \abs{\gamma'(t)}dt.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Assume that $\gamma$ is smooth on $[c,d]\subseteq [a,b]$. This means that $\gamma'$ and $\abs{\gamma'}$ are continuous on $[c,d]$ (thus $\abs{\gamma'}$ is Riemann integrable). Let $P =\bra{c= t_0 < t_1< \dots < t_m = d}$. Then by definition of integral of continuous function and Corollary \ref{cor:primitive_funtion_equation},
\beast
v_\gamma(P) = \sum^m_{k=1} \abs{\gamma(t_k) - \gamma(t_{k-1})} = \sum^m_{k=1} \abs{\int^{t_k}_{t_{k-1}} \gamma'(t)dt } \leq   \sum^m_{k=1} \int^{t_k}_{t_{k-1}} \abs{\gamma'(t)} dt =  \int^d_c \abs{\gamma'(t)} dt. \qquad (*)
\eeast

%Therefore,
%\be
%V_f[c,d] \leq \int^d_c \abs{\gamma'(t)}dt.\qquad (*)
%\ee


Since $\gamma'$ is continuous on $[c,d]$, it is uniformly continuous on $[c,d]$ by Theorem \ref{thm:continuous_on_closed_interval_implies_uniformly_continuous}. So given any $\ve>0$ we can choose $\delta_1$ such that $\abs{s-t}<\delta_1$ implies that $\abs{\gamma'(s) - \gamma'(t)} < \ve$. Also, by Lemma \ref {lem:finer_partition_smaller_upper_sum_bigger_lower_sum} and Theorem \ref{thm:riemann_integrable_iff_upper_lower_sum_close_enough}, we may choose $\delta_2>0$ such that if $P = \bra{c=t_0 < t_1 < \dots < t_m =b}$ and $\dabs{P} = \max\bra{t_k - t_{k-1}:1\leq k\leq m} < \delta_2$ then
\be
\abs{\int^b_a \abs{\gamma'(t)}dt - \sum^m_{k=1} \abs{\gamma'(\tau_k)}(t_k - t_{k-1})} < \ve
\ee
where $\tau_k$ is any point in $[t_{k-1},t_k]$. Hence by triangle inequality,
\beast
\int^b_a \abs{\gamma'(t)}dt & \leq & \ve + \sum^m_{k=1} \abs{\gamma'(\tau_k)}(t_k - t_{k-1}) = \ve + \sum^m_{k=1} \abs{\gamma'(\tau_k)} \int^{t_k}_{t_{k-1}} dt = \ve + \sum^m_{k=1} \abs{ \int^{t_k}_{t_{k-1}}\gamma'(\tau_k) dt} \\
& = & \ve + \sum^m_{k=1} \abs{ \int^{t_k}_{t_{k-1}}[\gamma'(\tau_k) -\gamma'(t) ]  dt}  +  \sum^m_{k=1} \abs{ \int^{t_k}_{t_{k-1}}\gamma'(t) dt}.
\eeast

If $\dabs{P} < \delta := \min\bra{\delta_1,\delta_2}$ then $\abs{\gamma'(\tau_k) - \gamma'(t)} < \ve$ for $t\in [t_{k-1},t_k]$ and
\beast
\int^d_c \abs{\gamma'(t)}dt \leq \ve + \ve(d-c) + \sum^m_{k=1} \abs{\gamma(t_k) - \gamma(t_{k-1})} = \ve(1 + d-c) + v_\gamma(P).\qquad (\dag)
\eeast

Now assume $\gamma$ is piecewise smooth with smooth paths on $[a_i,b_i]$ for $i=1,\dots,n$ joined end to end. Clearly, let $P = \bigcup^n_{i=1}P_i$ be  a partition where $a_i,b_i \in P_i$. Then we have for any partition $Q = \bigcup^n_{i=1}Q_i$ of $[a,b]$ with $Q_i \subseteq [a_i,b_i]$, $P_i\cup Q_i$ is a partition of $[a_i,b_i]$ and
\be
v_\gamma(Q) \leq v_\gamma(P\cup Q) = \sum^n_{i=1} v_\gamma(P_i\cup Q_i) \leq \sum^n_{i=1} \int^{b_i}_{a_i} \abs{\gamma'(t)} dt = \int^b_a  \abs{\gamma'(t)} dt.
\ee
by ($*$) and Proposition \ref{pro:riemann_integral_elementary_property}.(vii). Therefore, we have
\be
V_\gamma[a,b] \leq \int^b_a  \abs{\gamma'(t)} dt.
\ee
which implies that $\gamma$ is of bounded variation since $\abs{\gamma'(t)}$ is continuous and bounded on closed interval $[a,b]$.

Furthermore, by ($\dag$) and Proposition \ref{pro:riemann_integral_elementary_property}.(vii) we have
\be
\int^b_a \abs{\gamma'(t)}dt \leq \ve(n + b-a) + \sum^n_{i=1} v_\gamma(P_i \cup Q_i) \leq \ve(n + b-a) + V_\gamma[a,b].
\ee

Letting $\ve\to 0$, we have 
\be
\int^b_a \abs{\gamma'(t)}dt \leq V_\gamma[a,b].
\ee

Therefore, we have the required result.
\end{proof}





\subsection{Pathwise connected set}

\begin{definition}[pathwise connected set\index{pathwise connected set!complex space}]\label{def:pathwise_connected_set_complex_space}
A set $X\subseteq \C$ is called pathwise connected if any two points of $X$ can be joined by a (continuous) path lying entirely inside $X$.
\end{definition}

\begin{definition}[smoothly pathwise connected set]
A set $X\subseteq \C$ is said to be smoothly pathwise connected if any two points in $X$ can be joined by a smooth path entirely contained in $X$.
\end{definition}

\begin{definition}[piecewise smoothly pathwise connected set]
A set $X\subseteq \C$ is said to be piecewise smoothly pathwise connected if any two points in $X$ can be joined by a piecewise smooth path entirely contained in $X$.
\end{definition}



Recalling the Proposition\footnote{proposition needed. Sutherland's book, p120}, we have

\begin{proposition}\label{pro:pathwise_connected_implies_connected_complex}
Let $X\subseteq \C$ be pathwise connected. Then $X$ is connected.
\end{proposition}


%Recalling the Proposition\footnote{proposition needed. Sutherland's book, p120}, we have
%
%\begin{proposition}
%Let $X\subseteq \R^n$ be pathwise connected. Then $X$ is connected.
%\end{proposition}

Also, we have the following equivalent description when $X$ is open in $\C$ (see Princeton LN, complex analysis, p25).

\begin{theorem}\label{thm:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_complex}%{pro:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_complex}
An open set $X\subseteq \C$ is piecewise smoothly pathwise connected if and only if $X$ is connected.
\end{theorem}

\begin{remark}
For an open $X$ in $\C$, it is obviously smoothly pathwise connectedness implies piecewise smoothly pathwise connectedness.

Conversely, for piecewise smoothly pathwise connected set, we can have finitely many joint points of the smooth paths. Since $X$ is open, we can always find a small ball about these joint points such that the balls are within $X$. Thus, we can easily twist the joint point into a smooth path in each of these balls such that the whole path is smooth.

Therefore, for an open $X$ in $\C$ we have
\beast
\text{$X$ is connected} & \lra & \text{$X$ is pathwise connected}  \\
& \lra & \text{$X$ is smoothly pathwise connected}  \\
& \lra & \text{$X$ is piecewise smoothly pathwise connected} .
\eeast

See p25, complex analysis of princeton LN for the details.
\end{remark}

\begin{proof}[\bf Proof]
($\ra$). Suppose first that $X$ is open and piecewise smoothly pathwise connected, and that it can be written as $X_1\cup X_2$ where $X_1$ and $X_2$ are disjoint, non-empty open sets. Choose two points $w_1 \in X_1$ and $w_2 \in X_2$ and let $\gamma$ denote a path in $X$ joining $w_1$ to $w_2$.

Consider a Parameterization $z : [0, 1] \to X$ of this path with $z(0) = w_1$ and $z(1) = w_2$, and let
\be
t^* = \sup_{0\leq t\leq 1} \bra{t : z(s) \in X_1 \text{ for all }0 \leq s \leq t}.
\ee

Now consider the point $z(t^*)$.

If $z(t^*)$ is in $X_1$, then because $X_1$ is open, there is an open disc $D$ containing $z(t^*)$. Since $z$ is continuous, it follows that $z^{-1}(D)$ is open as a subset of $[0,1]$ by Theorem \ref{thm:continuity_inverse_image_open_is_open_metric}. Thus (assuming $t^* < 1$) $z^{-1}(X_1)$ contains points to the right of $t^*$, which is impossible. If $t^* = 1$, then there is a sequence of points in $X_1$ that converges to $z(1) \in X_2$, contradicting the assumption that $X_2$ is open.

If we assume instead that $z(t^*) \in X_2$, we recognize that $t \geq t^*$ if $z(t)\in X_2$. Thus, $t^*$ is the infimum of all values of $t$ such that $z(t) \in X_2$, and we can use the same argument as in the previous paragraph to conclude $z(t^*) \not\in X_2$. Since $z(t^*) \in X = X_1 \cup X_2$, this is a contradiction.


($\la$). Conversely, suppose that $X$ is open and connected. Fix a point $w \in X$ and let $X_1 \subseteq X$ denote the set of all points that can be joined to $w$ by a piecewise smooth path contained in $X$. Also, let $X_2 \subseteq X$ denote the set of all points that cannot be joined to $w$ by a piecewise smooth path in $X$.

We want to show that both $X_1$ and $X_2$ are open and disjoint and their union is $X$. Clearly, $X_1 \cup X_2 = X$ and $X_1\cap X_2 = \emptyset$. The only thing that remains to be shown is that both $X_1$ and $X_2$ are open.

Let $w_1 \in X_1$. Because $X_1$ is open, it contains an open disc $d$ centered at $w_1$. It is obvious that for any $w^* \in D$, then there exists a smooth path $z^*$ connecting $w_1$ and $w^*$. Let $z_1$ be a path joining $w$ to $w_1$. Then consider the path defined by
\be
z(t) = \begin{cases}
z_1(2t) & t \in [0, 1/2) \\
z^*(2t - 1) \quad\quad & t\in [1/2,1]
\end{cases}.
\ee

Then $z$ is a continuous, piecewise smooth path that connects $w$ to $w^*$. It follows that $B \subseteq X_1$ and that $X_1$ is open.

Now, for any $w_2 \in X_2$, since $X$ is open, it contains an open disc $D$ centered at $w_2$ so there exists a smooth path connecting $w_2$ and any point in $D$. For any $w^* \in D$, if there were a path $z_2$ that connected $w$ to $w^*$, then we could, as in the previous paragraph, find a path connecting $w$ to $w_2$ by concatenating the path from $w$ to $w^*$ and the path from $w^*$ to $w_2$. Thus $w_2 \in X_1$, which is a contradiction.

Since $X$ is connected, either $X_1 = X$ or $X_2 = X$. But $X_1$ is not empty since $X$ is open. So $X = X_1$.% by the assumption.
\end{proof}

\begin{definition}[polygon]
If $z,w\in \C$, the straight line segment from $z$ to $w$ can be represented by
\be
[z,w] = \bra{tw + (1-t)z:0\leq t\leq 1}.
\ee

For $a,b\in \R$, a polygon from $a$ to $b$ is a set of line segments joined end to end, denoted by
\be
P := \bigcup^n_{k=1} [z_k , w_k]
\ee
where $z_1 = a$ and $w_n = b$ and $w_k = z_{k+1}$ for $1\leq k\leq n-1$. Alternatively, it can be written by
\be
P := [a,z_1,\dots, z_n,b].
\ee
\end{definition}

\begin{remark}
Clearly, ploygon is piecewise smooth path.
\end{remark}


\begin{theorem}
An open subset $X\subseteq \C$ is connected if and only if for any two points $a,b\in X$ there is a polygon from $a$ to $b$ lying entirely inside $X$.
\end{theorem}

\begin{proof}[\bf Proof]
($\la$). Suppose that $X$ satisfies the condition and let us assume that $X$ is disconnected (or not connected). Then there exist disjoint non-empty sets $A,B$ which are both open and closed such that $X = A\cup B$ and $A\cap B = \emptyset$. Let $a\in A$ and $b\in B$. By assumption there is a polygon $P$ from $a$ to $b$ such that $P \subseteq X$. Then one of the line segments making up $P$ will have one point $a'$ in $A$ and another $b'$ in $B$. So we can define this segment as $Q = [a',b']$ and
\be
S = \bra{s\in [0,1] : sb'+ (1-s)a' \in A},\qquad T = \bra{t\in [0,1] : tb'+ (1-t)a' \in B}.
\ee

Then $S\cap T = \emptyset$ (from $A\cap B = \emptyset$) and $S\cup T = [0,1]$ ($S,T$ form the whole segment). Clearly $0\in S$ and $1\in T$.


Since $A$ is open, then for any $s\in S$ there exists $\ve>0$ such that $B_\ve\bb{sb'+ (1-s)a'}\subseteq A$. Thus we can find $\ve_s := \ve/\abs{a'-b'}$ such that $\bb{s+\delta} b'+ (1-s-\delta)a' \in A$ for any $\delta \leq \abs{\ve_s}$ which implies that $(s-\ve_s,s + \ve_s) \subseteq S$. Therefore, we have $S$ is open and so is $T$. This contradicts the connectedness of interval $[0,1]$. Thus, $X$ must be connected.

($\ra$). Now suppose that $X$ is connected and fix a point $a\in X$. To show how to construct a polygon (lying in $X$) from $a$ to a point $b$ in $X$ would be difficult. But we don't have to perform such a construction as we can merely show that one exists. For a fixed $a\in X$, define
\be
A := \bra{b\in X:\text{there is a polygon $P\subseteq X$ from $a$ to $b$}}.
\ee

We want to show that $A$ is simultaneously open and closed in $X$. Since $a\in A$ and $X$ is connected this will give that $A=X$ and the theorem will be proved.

To show that $A$ is open, we pick any $b\in A$ and $P = [a,z_1,\dots z_n,b]$ be a ploygon from $a$ to $b$ with $P\subseteq X$. Since $X$ is open (this was not needed in the first half), there exists $\ve>0$ such that $B_\ve(b)\subseteq X$. But if $z\in B_\ve(b)$ then $[b,z] \subseteq B_\ve(b) \subseteq X$. Hence the polygon $Q = P\cup [b,z]$ is inside $X$ and goes from $a$ to $z$, This shows that $B_\ve(b) \subseteq A$ and so $A$ is open.

To show that $A$ is closed, given any $z\in X\bs A$ we can find $\ve>0$ such that $B_\ve(z)\subseteq X$ since $X$ is open. If there is a point $b$ in $A\cap B_\ve(z)$, then we can construct a polygon from $a$ to $z$ which means $z\in A$. Thus, we must have that $A\cap B_\ve(z) = \emptyset$ or $B_\ve(z) \subseteq X\bs A$. That is, $X\bs A$ is open so that $A$ is closed.
\end{proof}





\begin{corollary}
Let $X\subseteq \C$ be an open connected set and $a,b$ are points in $X$ then there is a polygon from $a$ to $b$ which is made up of line segments parallel to either the real or imaginary axis (with stair-case shape).
\end{corollary}

\begin{proof}
For fixed $a\in X$, define
\be
A := \bra{z\in X:\text{there is a polygon $P\subseteq X$ consisting of horizontal and vertical line segments from $a$ to $z$}}.
\ee

For any $b = s+it \in A$, there exists $\ve>0$ such that $D_\ve(b)\subseteq X$ since $X$ is open. Then for any $z=x+iy \in D_\ve(b)$, then polygon $[b,s+iy]\cup [p+iy,z] \subseteq D_\ve(b)$. Thus, $z\in A$ and $D_{\ve}(b)\in A$. This implies that $A$ is open.

Also, for any $b\in X\bs A$, we can find $\ve>0$ such that $D_\ve(b) \subseteq X$ since $X$ is open. Then if there exists a point $z\in A\cap D_\ve(b)$ then we can construct a polygon from $a$ to $b$ with previous argument. Thus $A\cap D_\ve(b)= \emptyset$ which means $D_\ve(b)\in X\bs A$. Thus, $X\bs A$ is open so $A$ is closed.

Since $X$ is connected, the non-empty open and closed $A$ can only be $X$ which implies that required result.
\end{proof}

\begin{remark}
The alternative proof can be obtained by using compactness as we can modify any polygon in $X$ to a new polygon with desired properties.\footnote{link needed.}
\end{remark}









\section{Complex Integral}

\subsection{Definite integral of complex-valued continuous function of a real variable}


First, we consider the complex integral of continuous function.

\begin{definition}[line integral of complex-valued continuous function of a real variable]
Consider a complex-valued continuous function $f(t)$ of a real variable $t$ on $[a,b]$:
\be
f(t) = u(t) + iv(t).
\ee

Then the line integral of $f$ from $a$ to $b$ is defined by
\be
\int^b_a f(t)dt  = \int^b_a u(t)dt + i\int^b_a v(t)dt.
\ee
\end{definition}


\begin{remark}
Note that $\int^b_a u(t)dt$ and $\int^b_a v(t)dt$ are well-defined (more particularly, Riemann integrable by Theorem \ref{thm:continuous_on_closed_interval_is_riemann_integrable}) since the integrands are continuous by Proposition \ref{pro:complex_continuous_iff_real_imaginary_parts_continuous}.

The line integral of complex-valued continuous function is a special case of Riemann-Stieltjes integral of complex case.
\end{remark}


\begin{example}
For $a\in \R\bs \bra{0}$, we have
\beast
\int^{2\pi}_0 e^{iat}dt & = & \int^{2\pi}_0 \bb{\cos (at) + i\sin(at)} dt = \int^{2\pi}_0 \cos (at) dt + i \int^{2\pi}_0 \sin(at) dt \\
& = & \frac 1{a}\bb{\sin (2\pi a)  - i\bb{\cos(2\pi a)-1} } = \frac 1a\bb{-ie^{i 2\pi a} + i} = \frac 1{ia}\bb{e^{i 2\pi a}-1} = \left.\frac 1{ia}e^{ia t}\right|^{2\pi}_0
\eeast
which is consistent with the result if we treat $ia$ as a real number.
\end{example}

\begin{example}\label{exa:exponential_complex_integral}
If $\alpha\in \C\bs\bra{0}$, we have $\alpha = a+ bi$ with $a,b\in \R$. Then
\beast
\int^{2\pi}_0 e^{\alpha t}dt & = & \int^{2\pi}_0 e^{a t + ibt} dt = \int^{2\pi}_0 e^{a t}\cos(bt) + ie^{at} \sin(bt) dt = \int^{2\pi}_0 e^{a t}\cos(bt)dt + i\int^{2\pi}_0 e^{at} \sin(bt) dt.
\eeast

By Proposition \ref{pro:integral_exponential_trigonometric_function} the real part is
\be
\int^{2\pi}_0 e^{a t}\cos(bt) =\left. \frac 1{a^2 + b^2}\bb{be^{at}\sin(bt) + ae^{at}\cos (bt)}\right|^{2\pi}_0
\ee
and the imaginary part is
\be
\int^{2\pi}_0 e^{a t}\sin(bt) =\left. \frac 1{a^2 + b^2}\bb{-be^{at}\cos(bt) + ae^{at}\sin( bt)}\right|^{2\pi}_0.
\ee

Thus,
\beast
\int^{2\pi}_0 e^{\alpha t}dt = \left.  \frac 1{a^2 + b^2} \bb{ae^{at}e^{ibt} - ib e^{at}e^{ibt}} \right|^{2\pi}_0 = \left. \frac 1{a+bi} e^{(a + ib)t} \right|^{2\pi}_0 = \left. \frac {e^{\alpha t}}{\alpha}  \right|^{2\pi}_0
\eeast
which is consistent with the result if we treat $\alpha$ as a real number.
\end{example}





\begin{proposition}\label{pro:complex_line_integral_properties}
Let $f,g$ be a complex-valued continuous functions of a real variable $t$ on $[a,b]$. Then
\ben
\item [(i)] The real part of line integral
\be
\Re \bb{\int^b_a f(t)dt} = \int^b_a \Re\bb{f(t) }dt  = \int^b_a u(t)dt.
\ee

\item [(ii)] The imaginary part of line integral
\be
\Im \bb{\int^b_a f(t)dt} = \int^b_a \Im\bb{f(t) }dt  = \int^b_a v(t)dt.
\ee

\item [(iii)] For any complex numbers $\alpha$ and $\beta$,
\be
\int^b_a \bb{\alpha f(t) + \beta g(t)}dt = \alpha \int^b_a f(t) dt + \beta \int^b_a g(t) dt.
\ee

\item [(iv)] Let $a = t_0 = t_1 = \dots = t_n = b$. Then
\be
\int^b_a f(t) dt = \int^{t_1}_{t_0} f(t)dt + \dots \int^{t_n}_{t_{n-1}} f(t)dt.
\ee

\item [(v)] The modulus of line integral
\be
\abs{\int^b_a f(t)dt} \leq \int^b_a \abs{f(t)}dt.
\ee
\een
\end{proposition}

\begin{proof}[\bf Proof]
The first three properties are obvious from definition. 

(iv) is direct result from Proposition \ref{pro:riemann_integral_elementary_property}.(vii).

For (v), we consider
\be
\int^b_a f(t)dt = \abs{\int^b_a f(t)dt} e^{i\phi},\qquad \phi = \Arg \bb{\int^b_a f(t)dt}.
\ee

Since $\abs{\int^b_a f(t)dt}$ is real, we deduce that by (iii) and (i)
\beast
\abs{\int^b_a f(t)dt} & = & e^{-i\phi} \int^b_a f(t)dt = \int^b_a e^{-i\phi} f(t)dt = \Re\bb{\int^b_a e^{-i\phi} f(t)dt} \\
& = & \int^b_a \Re\bb{e^{-i\phi} f(t)}dt \leq \int^b_a \abs{e^{-i\phi} f(t)}dt = \int^b_a \abs{f(t)}dt.
\eeast
\end{proof}

\begin{proposition}
Suppose $a$ is real. Then
\be
\abs{e^{2a\pi i}-1} \leq 2\pi \abs{a}.
\ee
\end{proposition}

\begin{remark}
More generally, $\abs{e^{ai} - 1} \leq \abs{a}$ for $a\in \R$. This is actually,
\be
\cos^2 a - 2\cos a + 1 + \sin^2a = 2(1-\cos a) \leq a^2 \ \ra\ \cos a \geq 1 - \frac 12 a^2
\ee
\end{remark}

\begin{proof}[\bf Proof]
Let $f(t) = e^{iat}$, where $a\neq 0$ and $t$ are real. Clearly, $f$ is continuous. Substituting the function into (v) of Proposition \ref{pro:complex_line_integral_properties}, we obtain
\be
\abs{\int^{2\pi}_0 e^{iat}dt} \leq \int^{2\pi}_0 \abs{e^{iat}}dt = \int^{2\pi}_0  dt = 2\pi.
\ee

The left-hand side the above inequality is equal to
\be
\abs{\int^{2\pi}_0 e^{iat }dt} = \abs{\left.\frac 1{ia}e^{ia t}\right|^{2\pi}_0} = \frac{\abs{e^{2a \pi i}-1}}{a}.
\ee

Combining the results, we obtain the required
\be
\abs{e^{2a\pi i}-1} \leq 2\pi \abs{a}
\ee
which also holds for $a=0$.
\end{proof}



\begin{proposition}\label{pro:differentiation_under_integral_of_complex_function_of_two_real_variables}
Let $f:[a,b]\times [c,d]\to \C$ be a continuous function and define function $g:[c,d]\to \C$ by
\be
g(t) = \int^b_a f(s,t)ds.
\ee

Then $g$ is continuous on $[c,d]$. Moreover, if $\fp{f}{t}$ exists and is a continuous function on $[a,b]\times [c,d]$ then $g$ is continuously differentiable and
\be
g'(t) = \int^b_a \fp{f}{t}(s,t)ds.\qquad (*)
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Similar argument with Proposition \ref{pro:differentiation_under_integral_of_real_function_of_two_real_variables}.
\end{proof}

%For any $t_0\in [c,d]$, we want to show that given any $\ve>0$ there exists $\delta>0$ such that $\abs{g(t) - g(t_0)} < \ve$ whenever $\abs{t-t_0}< \delta$. Since $f(s,t)$ is continuous then given any $\ve>0$, there exists $\delta>0$ such that for any $w\in [a,b]$ and $t\in [c,d]$
%\be
%\abs{f(s,t_0) - f(w,t)} < \frac{\ve}{b-a}\qquad \text{whenever }\ \abs{(s-w)^2+ (t-t_0)^2}^{1/2} = d((s,t_0) ,(w,t)) < \delta
%\ee

%Let $w=s$. we have that for $t\in [c,d]$
%\be
%\abs{f(s,t)-f(s,t_0)} < \frac{\ve}{b-a} \qquad \text{whenever }\ \abs{t-t_0 } < \delta.
%\ee

%Therefore,
%\beast
%\abs{g(t)-g(t_0)} & = & \abs{\int^b_a f(s,t)ds - \int^b_a f(s,t_0)ds} = \abs{\int^b_a \bb{f(s,t)-f(s,t_0)}dx} \\
%& \leq & \int^b_a \abs{f(s,t) - f(s,t_0)} ds < \frac{\ve}{b-a}(b-a) = \ve
%\eeast
%which implies that $g(t)$ is continuous on $[c,d]$.

%Note that if we prove that $g$ is differentiable with $g'$ given by ($*$) then it will follow from the first part that $g'$ is continuous since $\fp{f}{t}$ is continuous. Hence we need only verify ($*$).

%Fix a point $t_0\in [c,d]$ and given any $\ve>0$. It follows that $\fp{f}{t}$ must be uniformly continuous on $[a,b]\times [c,d]$ by Theorem\footnote{continuous on compact set} as it is continuous on a compact set. Thus, there exists $\delta>0$ such that
%\be
%\abs{\fp{f}{t}(s',t') - \fp{f}{t}(s,t)} < \ve\qquad \text{whenever }\ (s-s')^2 +(t-t')^2 < \delta^2.
%\ee

%In particular,
%\be
%\abs{\fp{f}{t}(s,t) - \fp{f}{t}(s,t_0)} < \frac{\ve}{b-a}\qquad \text{whenever }\ \abs{t-t_0} < \delta, \ s\in [a,b].
%\ee

%This gives that for $\abs{t-t_0}< \delta$ and $s\in [a,b]$,
%\be
%\abs{\int^t_{t_0} \bb{\fp{f}{t}(s,\tau) - \fp{f}{t}(s,t_0)}d\tau} < \frac{\ve \abs{t-t_0}}{b-a}.
%\ee

%But for a fixed $s\in [a,b]$, $\phi(t) := f(s,t) - t\fp{f}{t}(s,t_0)$ is a primitive function of $\fp{f}{t}(s,t) - \fp{f}{t}(s,t_0)$ on $[c,d]$. Then by Corollary \ref{cor:primitive_funtion_equation}, for any $s\in [a,b]$ when $\abs{t-t_0} < \delta$
%\beast
%\abs{f(s,t) - f(s,t_0) - (t- t_0)\fp{f}{t}(s,t_0)} & = & \abs{f(s,t) - t\fp{f}{t}(s,t_0) - f(s,t_0) + t_0\fp{f}{t}(s,t_0)} = \abs{\phi(t) - \phi(t_0)} \\
%& = & \abs{\int^t_{t_0} \bb{\fp{f}{t}(s,\tau) - \fp{f}{t}(s,t_0)}d\tau} < \frac{\ve \abs{t-t_0}}{b-a}.
%\eeast

%Then we have
%\beast
%& & \abs{\frac{g(t)-g(t_0)}{t-t_0} - \int^b_a \fp{f}{t}(s,t_0) ds} \\
%& = & \abs{\frac{\int^b_a f(s,t)ds - \int^b_a f(s,t_0)ds}{t-t_0} - \int^b_a \fp{f}{t}(s,t_0) ds} = \frac 1{\abs{t-t_0}}\abs{\int^b_a \bb{f(s,t)-f(s,t_0) -(t-t_0) \fp{f}{t}(s,t_0)} ds} \\
%& \leq & \frac 1{\abs{t-t_0}}\int^b_a \abs{\bb{f(s,t)-f(s,t_0) -(t-t_0) \fp{f}{t}(s,t_0)}} ds < \frac 1{\abs{t-t_0}} \frac{\ve \abs{t-t_0}}{b-a} \int^b_a ds = \ve \\
%\eeast%
%when $\abs{t-t_0} < \delta$.
%\end{proof}

%\be
%\abs{\frac{f(s,t) - f(s,t_0)}{t-t_0} - \fp{f}{t}(s,t_0)} \leq \frac{\ve}{b-a}
%\ee

\begin{example}
Consider the integral
\be
\int^{2\pi}_0 \frac{e^{is}}{e^{is}-z}ds,\qquad \abs{z}<1.
\ee

Let $f(s,t) = \frac{e^{is}}{e^{is} - tz}$ for $t\in [0,1]$ and $s\in [0,2\pi]$. Note that $f$ is continuously differentiable because $\abs{z}<1$. Hence
\be
g(t) = \int^{2\pi}_0 f(s,t) ds
\ee
is continuously differentiable by Proposition \ref{pro:derivative_under_complex_integral_of_functions_of_two_real_variables}. Now
\be
g'(t) = \int^{2\pi}_0 \frac{ze^{is}}{(e^{is}-tz)^2}ds.
\ee

For fixed $t\in [0,1]$,
\be
\phi(s) := zi(e^{is} -tz)^{-1} \ \ra\ \phi'(s) := -zi(e^{is} -tz)^{-2}ie^{is} = ze^{is}(e^{is} -tz)^{-2}.
\ee

Thus, $g'(t) = \phi(2\pi) - \phi(0) = zi/(1-tz) - zi/(1-tz) = 0$. Then by Corollary \ref{cor:derivative_greater_equal_to_zero}, $g(t)$ is constant on $[0,1]$. Since $g(0) = \int^{2\pi}_0 dz = 2\pi$, we have that the required integral is equal to $g(1) = g(0) = 2\pi$.
\end{example}


\subsection{Riemann-Stieljes integral}


\begin{theorem}[Riemann-Stieljes integral\index{Riemann-Stieljes integral!complex space}]\label{thm:riemann_stieljes_integral_complex}
Let $\gamma:[a,b]\to \C$ be of bounded variation and suppose that $f:[a,b]\to \C$ is continuous. Then there exists a complex number $I$ such that for every $\ve>0$ there is $\delta>0$ such that when the partition of $[a,b]$, $P = \bra{t_0 < t_1 \dots < t_n}$ satisfies $\dabs{P} := \max\bra{t_{k}- t_{k-1}: 1\leq k\leq n} < \delta$, then
\be
\abs{I - \sum^n_{k=1} f(\tau_k)(\gamma(t_k) - \gamma(t_{k-1}))} < \ve
\ee
for whatever choice of point $\tau_k\in [t_{k-1},t_k]$. This number $I$ is called the Riemann-Stieljes integral of $f$ with respect to $\gamma$ over $[a,b]$ and is denoted by
\be
I = \int^b_a f d\gamma = \int^b_a f(t)d\gamma(t).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Since $f$ is continuous on $[a,b]$ it is uniformly continuous by Theorem \ref{thm:continuous_on_closed_interval_implies_uniformly_continuous}. Thus, we can find (inductively) positive numbers $\delta_1>\delta_2 > \delta_3 > \dots >0$ such that for $\abs{s-t} < \delta_m$,
\be
\abs{f(s) - f(t)} < 1/m.
\ee

Then for each $m\geq 1$, let $\sP_m$ be the collection of all partitions $P = \bra{t_0 <t_1 < \dots < t_n}$ of $[a,b]$ with
\be
\dabs{P} = \max\bra{t_k - t_{k-1}:1\leq k\leq n} < \delta_m.
\ee

This implies that $\sP_1 \supseteq \sP_2 \supseteq \dots$. Then define $A_m$ to be the closure of the set
\be
B_m := \bra{\sum^n_{k=1} f(\tau_k)(\gamma(t_k) - \gamma(t_{k-1})): P =\bra{t_0 <t_1 < \dots < t_n} \in \sP_m,\ \tau_k \in [t_{k-1},t_k] }.
\ee

Clearly, $A_1 \supseteq A_2 \supseteq \dots$ follows trivially from the fact that $\sP_1 \supseteq \sP_2 \supseteq \dots$. Now for any $P = \bra{t_0 <t_1 < \dots < t_n}\in \sP_m$, $Q$ is partition satisfying $P\subseteq Q$ (thus $Q\subseteq \sP_m$), we can write
\be
Q = \bra{t_0 = s_0 < s^1_{1} < \dots < s^1_{l_1} = t_1 =  s^2_{1} < \dots < s^2_{l_2} = t_2 = s^3_{1} < \dots s^{n-1}_{l_{n-1}} = t_{n-1} = s^n_{1} < \dots < s^n_{l_n} = t_n}.
\ee%where $Q$ has $l_1 + \dots + l_n$ points.

Then let $S(P)$ be any sum of the form
\be
\sum^n_{k=1}f(\tau_k) (\gamma(t_k) - \gamma(t_{k-1}))
\ee
where $\tau_k$ is any point within $[t_{k-1},t_k]$. Then
\be
S(Q) = \sum^n_{k=1} \sum^{l_k}_{i=1} f(\sigma^k_i)(\gamma(s^k_{i}) - \gamma(s^k_i)) ,\qquad \sigma^k_i \in [s^{k}_{i-1},s^{k}_i].
\ee

Thus, since $\abs{\tau_k - \sigma^k_i} < \delta_m$ ($P,Q\in \sP_m$ and $\tau_k,\sigma^k_i\in [t_{k-1},t_k]$), we have $\abs{f(\tau_k) - f(\sigma^k_i)} < 1/m$ and
\beast
\abs{S(P) - S(Q)} & = & \abs{\sum^n_{k=1} \sum^{l_k}_{i=1} (f(\tau_k) - f(\sigma^k_i))(\gamma(s^k_{i}) - \gamma(s^k_i)) } \leq \sum^n_{k=1} \sum^{l_k}_{i=1} \abs{f(\tau_k) - f(\sigma^k_i)}\abs{\gamma(s^k_{i}) - \gamma(s^k_i)) } \\
& \leq & \frac 1m \sum^n_{k=1} \sum^{l_k}_{i=1} \abs{\gamma(s^k_{i}) - \gamma(s^k_i)) } = \frac 1m v_\gamma(Q) \leq \frac 1m V_\gamma[a,b].\qquad (*)
\eeast

Therefore, for any $P,R \in \sP_m$, we have that $Q = P\cup R$ is a partition and contains both $P$ and $R$. Then by ($*$) we get
\be
\abs{S(P) - S(R)} \leq \abs{S(P)-S(Q)} + \abs{S(R)-S(Q)} \leq \frac 2m V_\gamma[a,b].\qquad (\dag)
\ee

For any $z\in A_m\bs B_m$ and $w\in B_m$, we have that $z$ is a limit point of $B_m$ and there exists $(z_n)\in B_m$ such that $\lim_{n\to\infty}z_n = z$. Therefore, given $\ve = \frac 1m V_\gamma[a,b]$ we have (by ($\dag$))
\be
\abs{z-w} \leq \abs{z_n - z} + \abs{z_n - w} < \frac 1m V_\gamma[a,b] + \frac 2m V_\gamma[a,b] = \frac 3m V_\gamma[a,b].% \ \ra\
\ee


Finally, for any $z,w\in A_m\bs B_m$, we have that $z,w$ are limit points of $B_m$ and there exists $(z_n),(w_n)\in B_m$ such that $\lim_{n\to\infty}z_n = z$ and $\lim_{n\to\infty}w_n = w$ . Therefore, given $\ve = \frac 1m V_\gamma[a,b]$ we have (by ($\dag$))
\be
\abs{z-w} \leq \abs{z_n - z} + \abs{z_n - w_n} + \abs{w_n - w} < \frac 1m V_\gamma[a,b] + \frac 2m V_\gamma[a,b]+ \frac 1m V_\gamma[a,b] = \frac 4m V_\gamma[a,b].% \ \ra\
\ee

Thus, we have that $\diam A_m \leq \frac 4mV_\gamma[a,b]$ which implies that $\diam A_m \to 0$. %Otherwise, if $\diam A_m > \frac 2mV_\gamma[a,b]$ we have two point $z,w\in A_m$ such that $\abs{z-w} > \frac 2mV_\gamma[a,b]$. Thus, at least one of $z,w$ must be in the boundary of $A_m$.
%
%which implies that
%\be
%\diam A_m \leq \frac 2mV_\gamma[a,b] \ \ra\ \diam A_m \to 0.
%\ee

Then by Cantor's theorem\footnote{theorem needed.}, there is exactly one complex number $I$ such that $I \in A_m$ for every $m\geq 1$. This will complete the proof.
\end{proof}

\begin{proposition}[properties of Riemann-Stieljes integral]\label{pro:riemann_stieljes_integral_properties_complex}
Let $f,g$ be complex-valued continuous functions on $[a,b]$ and let $\gamma$ and $\sigma$ be complex-valued functions of bounded variation on $[a,b]$. Then for any scalars $\alpha,\beta\in \C$:
\beast
\int^b_a (\alpha f(t) + \beta g(t)) d\gamma(t) & = & \alpha \int^b_a f(t)d\gamma(t) + \beta\int^b_a g(t)d\gamma(t), \\
\int^b_a f(t)d(\alpha \gamma(t) + \beta \sigma(t)) & = & \alpha \int^b_a f(t)d\gamma(t) + \beta\int^b_a f(t)d\sigma(t).
\eeast

If $a=t_0 < t_1 <\dots < t_n = b$, then
\be
\int^b_a f(t)d\gamma(t) = \sum^n_{k=1} \int^{t_k}_{t_{k-1}} f(t)d\gamma(t).
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Direct result from Theorem \ref{thm:riemann_stieljes_integral_complex}.
\end{proof}

\begin{theorem}\label{thm:integral_along_piecewise_smooth_path_equals_product_with_derivative}
Let $\gamma:[a,b]\to \C$ be piecewise smooth path and $f:[a,b]\to \C$ be continuous. Then
\be
\int^b_a f(t)d\gamma(t) = \int^b_a f(t)\gamma'(t)dt.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
With Proposition \ref{pro:riemann_stieljes_integral_properties_complex}, we only need to consider the case where $\gamma$ is smooth.
\footnote{proof needed.}

By Theorem \ref{thm:riemann_stieljes_integral_complex}, given any $\ve>0$ we choose $\delta_1 >0$ such that if $P =\bra{a=t_0 < \dots < t_n =b}$ has $\dabs{P} =\max\bra{t_{k}-t_{k-1}:1\leq k\leq n} <\delta_1$ then
\be
\abs{\int^b_a f(t)d\gamma(t) - \sum^n_{k=1} f(\tau_k)(\gamma(t_k) - \gamma(t_{k-1}))} < \frac{\ve}3
\ee
and
\be
\abs{\int^b_a f(t)\gamma'(t) dt - \sum^n_{k=1} f(\tau_k)\gamma'(\tau_k)(t_k - t_{k-1})} < \frac{\ve}3
\ee
for any choice of $\tau_k\in [t_{k-1},t_k]$. Let $\gamma(t) = u(t) + iv(t)$ where $u,v$ are real-valued functions. Then by mean value theorem (Theorem \ref{thm:mean_value}), we have that for some values $\rho_k,\sigma_k\in [t_{k-1},t_k]$,
\be
u(t_k) - u(t_{k-1}) = u'(\rho_k)(t_k - t_{k-1}),\qquad v(t_k) - v(t_{k-1}) = v'(\sigma_k)(t_k - t_{k-1}).
\ee

Therefore,
\beast
\sum^n_{k=1} f(\sigma_k)(\gamma(t_k) - \gamma(t_{k-1})) & = & \sum^n_{k=1} f(\sigma_k)(u(t_k) - u(t_{k-1})) + i\sum^n_{k=1} f(\sigma_k)(v(t_k) - v(t_{k-1})) \\
& = & \sum^n_{k=1} f(\sigma_k)u'(\rho_k)(t_k - t_{k-1})  + i\sum^n_{k=1} f(\sigma_k) v'(\sigma_k)(t_k - t_{k-1}) \\
\eeast

Thus,
\be
\sum^n_{k=1} f(\sigma_k)(\gamma(t_k) - \gamma(t_{k-1})) - \sum^n_{k=1} f(\sigma_k)\gamma'(\sigma_k)(t_k - t_{k-1}) = \sum^n_{k=1} f(\sigma_k)(u'(\rho_k)- u'(\sigma_k))(t_k - t_{k-1}).
\ee

Since $u'$ is continuous on $[a,b]$ it is uniformly continuous on $[a,b]$ by Theorem \ref{thm:continuous_on_closed_interval_implies_uniformly_continuous}, we have that given any $\ve>0$, we can find $\delta_2>0$ such that any $\abs{s-t} < \delta$ implies $\abs{u'(s) - u'(t)} < \ve$. Thus, given $\ve>0$ we can find $\delta_2>0$ so that for $\abs{\rho_k - \sigma_k} < \delta_2$
\be
\abs{u'(\rho_k)- u'(\sigma_k)} < \frac {\ve}{3n\delta M}
\ee
where $M$ is maximum value of $\abs{f}$. Therefore, we can choose $\delta := \min\bra{\delta_1,\delta_2}$ such that $\dabs{P}< \delta$ and get
\beast
& & \abs{\int^b_a f(t)d\gamma(t) - \int^b_a f(t)\gamma'(t) dt} \\
& \leq & \abs{\int^b_a f(t)d\gamma(t) - \sum^n_{k=1} f(\sigma_k)(\gamma(t_k) - \gamma(t_{k-1}))} + \abs{\int^b_a f(t)\gamma'(t) dt - \sum^n_{k=1} f(\sigma_k)\gamma'(\sigma_k)(t_k - t_{k-1})} \\
& & \qquad\qquad + \abs{\sum^n_{k=1} f(\sigma_k)(\gamma(t_k) - \gamma(t_{k-1})) - \sum^n_{k=1} f(\sigma_k)\gamma'(\sigma_k)(t_k - t_{k-1})} \\
& < & \frac {2\ve}3 +  \sum^n_{k=1} \abs{f(\sigma_k)}\abs{u'(\rho_k)- u'(\sigma_k)}\abs{t_k - t_{k-1}} < \frac {2\ve}3 +  \sum^n_{k=1} M \cdot \frac{\ve}{3n\delta M} \cdot \delta = \ve
\eeast
as required.
\end{proof}


\subsection{Line integral of complex function along path}

\begin{definition}[line integral]\label{def:line_integral_of_continuous_function_along_rectifiable_path}
Let $\gamma:[a,b]\to \C$ be rectifiable path with trace $\bra{\gamma}\subseteq E\subseteq \C$ and $f:E\to \C$ be a continuous function. Then the line integral of $f$ along $\gamma$ is
\be
\int^b_a f(\gamma(t))d\gamma(t).
\ee

This line integral is also denoted by
\be
\int_\gamma f = \int_\gamma f(z)dz.
\ee

If the path is closed, we can write the integral as $\oint_\gamma f$.
\end{definition}

\begin{remark}
Note that the integral is well-defined by Theorem \ref{thm:riemann_stieljes_integral_complex} since $f\circ \gamma$ is continuous on $[a,b]$.
\end{remark}

\begin{example}
Since we have that $e^{it} = \cos t + i\sin t$ is differentiable on whole complex plane, we can consider the continuous function $f(z) = 1/z$ on unit circle and the smooth path $\gamma$ be the unit circle about 0, parameterized by $z(t) = e^{it}$ with $t\in [0,2\pi]$. Then by Theorem \ref{thm:integral_along_piecewise_smooth_path_equals_product_with_derivative} we have
\be
\oint_\gamma f(z) dz = \int^{2\pi}_0 f(z(t))z'(t)dt =  \int^{2\pi}_0 \frac 1{e^{it}} ie^{it}dt = i \int^{2\pi}_0 e^{-it}e^{it}dt = i \int^{2\pi}_0 dt = 2\pi i.
\ee
\end{example}




\begin{lemma}\label{lem:integral_of_continuous_function_along_rectifiable_path_in_open_set_has_polygonal_path}
Let $X$ be an open set in $\C$. If $\gamma:[a,b]\to X$ is a rectifiable path in $X$ and $f:X\to \C$ is continuous, then given any $\ve>0$ there exists a polygonal path $\Gamma$ in $X$ such that $\Gamma(a) = \gamma(a)$, $\Gamma(b) = \gamma(b)$ and
\be
\abs{\int_\gamma f(z)dz - \int_\Gamma f(z)dz} < \ve.
\ee
\end{lemma}

\begin{proof}[\bf Proof]% ($\partial X = \ol{X}\bs \inter{X} = \ol{X}\bs X$, see metric space for details)
If $X$ is open, then its complement $X^c = \C\bs X$ is closed. Since $\bra{\gamma}$ is compact by Theorem \ref{thm:image_of_compact_or_connected_reserves_property}, we have that $\inf_{c\in \bra{\gamma},d\in X^c}\abs{c-d} = d(\bra{\gamma},X^c) > 0$ by Theorem \ref{thm:compact_disjoint_sets_real_n_imples_distance_positive}. Thus, there exists $r>0$ such that
\be
d(\bra{\gamma},X^c) > r > 0.
\ee

Also, since $\gamma$ is uniformly continuous on $[a,b]$ by Theorem \ref{thm:continuous_on_compact_set_implies_uniformly_continuous_metric}, we can choose $\delta>0$ such that $\abs{\gamma(s) - \gamma(t)} < r$ whenever $\abs{s-t}< \delta$. If $P:= \bra{t_0<t_1<\dots< t_n}$ is a partition of $[a,b]$ with $\dabs{P} = \max_{1\leq k\leq n}\abs{t_{k} - t_{k-1}} < \delta$ then $\abs{\gamma(t) - \gamma(t_{k-1})} < r$ for $t\in [t_{k-1},t_k]$. That is if $\gamma_k:[t_{k-1},t_k]\to X$ is defined by $\gamma_k(t) = \gamma(t)$ then $\bra{\gamma_k}\subseteq D_r(\gamma(t_{k-1})) $ for $1\leq k\leq n$.

Since $\ol{D}_r(\gamma(t_{k-1})) \subseteq X$ is a closed set, $f$ is uniformly continuous on $\ol{D}_r(\gamma(t_{k-1}))$. Then we can choose $r_k>0$ such that given any $\ve>0$, $\abs{f(z) - f(w)}<\ve$ whenever $\abs{z-w} < r_k$ for $z,w\in \ol{D}_r(\gamma(t_{k-1}))$. Thus, $\gamma_k:[t_{k-1},t_k]\to X$ is uniform continuous so given any $\ve>0$ we there is a partition $P_k := \bra{t_{k-1} = s_0< s_1 < \dots < s_m = t_k}$ of $[t_{k-1},t_k]$ such that $\dabs{P_k} = \max_{1\leq i \leq m} \abs{s_{i} - s_{i-1}} < \delta_k$ and
\be
\abs{\gamma_k(s) - \gamma_k(t)} < r_k/2 \qquad (*)
\ee
for any $s,t\in [s_{i-1},s_i]$ with $1\leq i\leq m$ and such that for any $\sigma_i\in [s_{i-1},s_i]$,
\be
\abs{\int_{\gamma_k}f - \sum^m_{i=1}f(\gamma_k(\sigma_i))[\gamma_k(s_i) - \gamma_k(s_{i-1})]} < \ve.
\ee

Then define $\Gamma_k:[t_{k-1},t_k]\to \C$ by
\be
\Gamma_k(s) = \frac 1{s_i - s_{i-1}} \bsb{(s_i-s)\gamma_k(s_{i-1}) + (s-s_{i-1})\gamma_k(s_i)}
\ee
for $s\in [s_{i-1},s_i]$. So on $[s_{i-1},s_i]$, $\Gamma(s)$ traces out the straight line segment from $\gamma_k(s_{i-1})$ to $\gamma_k(s_i)$. That is, $\Gamma_k$ is a polygonal path in $D_r(\gamma(t_{k-1}))$ with $\Gamma_k(t_{k-1}) = \gamma_k(t_{k-1})$ and $\Gamma_k(t_{k}) = \gamma_k(t_{k})$.

From ($*$), we have for any $s \in [s_{i-1},s_i]$,
\beast
\abs{\Gamma_k(s) - \gamma_k(\sigma_i)} &  = &  \abs{\frac 1{s_i - s_{i-1}} \bb{(s_i-s)(\gamma_k(s_{i-1})-\gamma_k(\sigma_i)) + (s-s_{i-1})(\gamma_k(s_i)-\gamma_k(\sigma_i))}} \\
& \leq &  \abs{\frac {s_i-s}{s_i - s_{i-1}}} \abs{\gamma_k(s_{i-1})-\gamma_k(\sigma_i)} + \abs{\frac{s-s_{i-1}}{s_i - s_{i-1}}} \abs{\gamma_k(s_i)-\gamma_k(\sigma_i)} \\
& \leq &  \abs{\gamma_k(s_{i-1})-\gamma_k(\sigma_i)} + \abs{\gamma_k(s_i)-\gamma_k(\sigma_i)} < r_k/2 + r_k/2 = r_k.
\eeast

Thus, we have
\be
\abs{f(\Gamma_k(s)) - f(\gamma_k(\sigma_i))} < \ve.
\ee

Since polygonal path is piecewise, we have Theorem \ref{thm:integral_along_piecewise_smooth_path_equals_product_with_derivative} and Proposition \ref{pro:riemann_stieljes_integral_properties_complex},
\be
\int_{\Gamma_k}f(z)dz = \int^{t_k}_{t_{k-1}} f(\Gamma_k(s))\Gamma_k'(s)ds = \sum^m_{i=1}  \frac{\gamma_k(s_i) - \gamma_k(s_{i-1})}{s_i - s_{i-1}}\int^{s_i}_{s_{i-1}} f(\Gamma_k(s))ds.
\ee

Therefore,
\beast
& & \abs{\int_{\gamma_k}f(z)dz - \int_{\Gamma_k}f(z)dz} \\
& \leq & \abs{\int_{\gamma_k}f(z)dz - \sum^m_{i=1}f(\gamma_k(\sigma_i))[\gamma_k(s_i) - \gamma_k(s_{i-1})]}  + \abs{ \sum^m_{i=1} f(\gamma_k(\sigma_i)) [\gamma_k(s_i) - \gamma_k(s_{i-1})] - \int_{\Gamma_k}f(z)dz} \\
& < & \ve + \abs{\sum^m_{i=1}f(\gamma_k(\sigma_i))[\gamma_k(s_i) - \gamma_k(s_{i-1})]- \sum^m_{i=1}  \frac{\gamma_k(s_i) - \gamma_k(s_{i-1})}{s_i - s_{i-1}}\int^{s_i}_{s_{i-1}} f(\Gamma_k(s))ds} \\
& = & \ve + \abs{\sum^m_{i=1}  \frac{\gamma_k(s_i) - \gamma_k(s_{i-1})}{s_i - s_{i-1}}\int^{s_i}_{s_{i-1}} \bb{f(\gamma_k(\sigma_i))- f(\Gamma_k(s))}ds} < \ve + \ve \sum^m_{i=1} \abs{\gamma_k(s_i) - \gamma_k(s_{i-1})} \\
& \leq & \ve \bb{1 + V_{\gamma_k}[t_{k-1},t_k]}.
\eeast

Thus, we have that
\be
\int_{\gamma_k}f(z)dz = \int_{\Gamma_k}f(z)dz
\ee

Then since $\gamma = \sum^n_{k=1}\gamma_k$ there exists a polygonal path $\Gamma = \sum^n_{k=1}\Gamma_k$ such that
\be
\int_{\Gamma}f(z)dz = \sum^n_{k=1}\int_{\Gamma_k}f(z)dz = \sum^n_{k=1}\int_{\gamma_k}f(z)dz = \int_{\gamma}f(z)dz
\ee
by Proposition \ref{pro:riemann_stieljes_integral_properties_complex}.
\end{proof}


\begin{theorem}\label{thm:fundamental_theorem_of_calculus_of_complex_function_along_rectifiable_path}
Let $X$ be open in $\C$ and let $\gamma:[a,b]\to \C$ be a rectifiable path in $X$ with initial and end points $\alpha$ and $\beta$ respectively. If $f:X\to \C$ is a continuous function on $X$ with a primitive function $F:X\to \C$, then
\be
\int_\gamma f(z)dz = F(\beta) - F(\alpha).
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Given any $\ve>0$, Lemma \ref{lem:integral_of_continuous_function_along_rectifiable_path_in_open_set_has_polygonal_path} implies that there exists a polygonal path $\Gamma$ from $\alpha$ to $\beta$ such that
\be
\abs{\int_\gamma f(z)dz - \int_\Gamma f(z)dz} < \ve.
\ee

Since polygonal path $\Gamma$ is piecewise smooth, we have
\beast
\int_\Gamma f(z)dz & = & \int^b_a f(\Gamma(t))\Gamma'(t)dt = \int^b_a F'(\Gamma(t))\Gamma'(t)dt = \int^b_a \frac{d F(\Gamma(t))}{dt} dt \\
& = & F(\Gamma(b)) - F(\Gamma(a)) = F(\gamma(b)) - F(\gamma(a))  = F(\beta) - F(\alpha)
\eeast
which implies the required result.
\end{proof}


\subsection{Invariance form of line integral along rectifiable path}



%\begin{definition}[smooth curve]\label{def:smooth_curve_complex}
%A smooth curve $\gamma:\R\to \C$ is a curve $z(t) = x(t) + iy(t)$ with continuous derivative in the closed interval $t\in [a,b]$. and non-zero in the open interval $t\in (a,b)$.
%\end{definition}

%\item curves

First, we will introduce a certain `invariance' result which forms the basis for the definition of a curve.

\begin{proposition}\label{pro:integral_along_continuous_non_decreasing_function_of_paths_of_continuous_function_is_equivalent_to_original_integral}
Let $\gamma:[a,b]\to \C$ be a rectifiable path and $\phi:[c,d] \to [a,b]$ be a continuous non-decreasing function with $\phi(c) = a$ and $\phi(b) =d$. Then $\gamma\circ \phi:[c,d]\to \C$ is a rectifiable path.

Furthermore, for any function $f$ continuous on $\bra{\gamma}$,
\be
\int_\gamma f = \int_{\gamma\circ \phi}f \qquad \bb{\int_\gamma f(z)dz = \int_{\gamma\circ \phi}f(z)dz}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Since $\phi$ is continuous, it must have all the values between $\phi(c) =a$ and $\phi(d) = b$ by Theorem \ref{thm:intermediate_value}. Therefore, $\gamma\circ \phi$ is a path with the same trace as $\gamma$ ($\bra{\gamma\circ\phi} = \bra{\gamma}$). Also, for $c =s_0 <s_1<\dots< s_n=d$ then $a = \phi(s_0) \leq \phi(s) \leq \dots \leq \phi(s_n) =b$ is a partition of $[a,b]$. Therefore,
\be
\sum^n_{k=1} \abs{\gamma\circ\phi(s_k) - \gamma\circ\phi(s_{k-1})} = \sum^n_{k=1} \abs{\gamma(\phi(s_k)) - \gamma(\phi(s_{k-1}))} \leq V_\gamma[a,b]
\ee
since $\gamma$ is of bounded variation (thus rectifiable). Then $V_{\gamma\circ \phi}[c,d] \leq V_\gamma[a,b] < \infty$ which implies that $\gamma \circ \phi$ is rectifiable path. Therefore, the integral $\int_{\gamma\circ \phi}f$ is well-defined.

Given any $\ve>0$ and choose $\delta_1>0$ such that for $Q:= \bra{c=s_0<s_1< \dots < s_n = d}$, the partition of $[c,d]$ with $\dabs{Q} = \max\bra{s_k-s_{k-1}:1\leq k\leq n}< \delta_1$ and $\sigma_k \in [s_{k-1},s_k]$ we have
\be
\abs{\int_{\gamma\circ \phi} f - \sum^n_{k=1} f(\gamma\circ \phi(\sigma_k))[\gamma\circ \phi(s_k) - \gamma\circ \phi(s_{k-1})]} < \ve/2\qquad (*)
\ee
by Theorem \ref{thm:riemann_stieljes_integral_complex}. Similarly, we can choose $\delta_2>0$ such that if $P := \bra{a= t_0<t_1<\dots <t_m}$ is a partition of $[a,b]$ with $\dabs{P} = \max\bra{t_k - t_{k-1}:1\leq k\leq m} < \delta_2$ and $\tau_k \in [t_{k-1},t_k]$, then
\be
\abs{\int_{\gamma} f - \sum^m_{k=1} f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})]} < \ve/2.\qquad (\dag)
\ee

Since $\phi$ is continuous on $[c,d]$ then it is uniformly continuous on $[c,d]$ by Theorem \ref{thm:continuous_on_closed_interval_implies_uniformly_continuous}. Hence, there exists $\delta>0$ such that $\abs{\phi(s) - \phi(s')} < \delta_2$ whenever $\abs{s-s'}< \delta < \delta_1$.

Then let $Q = \bra{c= s_0< s_1<\dots <s_n=d}$ be a partition of $[c,d]$ with $\dabs{Q} < \delta<\delta_1$ and $t_k = \phi(s_k)$ for $1\leq k\leq n$. So $P = \bra{t_0\leq t_1\leq \dots\leq t_n}$ is a partition of $[a,b]$ with $\dabs{P} < \delta_2$. If $\sigma_k \in [s_{k-1},s_k]$ we have $\tau_k :=\phi(\sigma_k) \in [\phi(s_{k-1}),\phi(s_k)] = [t_{k-1},t_k]$. Therefore,
\be
\sum^n_{k=1} f(\gamma\circ \phi(\sigma_k))[\gamma\circ \phi(s_k) - \gamma\circ \phi(s_{k-1})] = \sum^n_{k=1} f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})]
\ee

Thus, combining ($*$) and ($\dag$), we have
\beast
\abs{\int_\gamma f - \int_{\gamma\circ \phi}f} & \leq & \abs{\int_{\gamma\circ \phi} f - \sum^n_{k=1} f(\gamma\circ \phi(\sigma_k))[\gamma\circ \phi(s_k) - \gamma\circ \phi(s_{k-1})]} + \abs{\int_{\gamma} f - \sum^m_{k=1} f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})]} \\
& < & \ve/2 + \ve/2 = \ve
\eeast
which implies the required result.
\end{proof}




\subsection{Curves}

\begin{definition}[equivalent path, curve]
Let $\gamma:[a,b]\to \C$ and $\sigma:[c,d]\to \C$ be rectifiable paths. Then the path $\sigma$ is equivalent to $\gamma$ if there is a function $\phi:[c,d]\to [a,b]$ which is continuous, strictly increasing with $\phi(c) =a$ and $\phi(d) =b$ such that $\sigma = \gamma \circ \phi$. We then call the function $\phi$ a change of parameter.

A curve is an equivalence class of rectifiable paths.
\end{definition}

\begin{remark}
By Proposition \ref{pro:integral_along_continuous_non_decreasing_function_of_paths_of_continuous_function_is_equivalent_to_original_integral}, the trace of the curve is the trace of any one of its member. Also, if $f$ is continuous on the trace of the curve then the integral of $f$ over the curve is the integral of $f$ over any member of the curve.

Note that $\phi$ is continuous and strictly increasing so it has inverse function $\phi^{-1}$ by Theorem \ref{thm:real_strictly_increasing_continuous_bijective_inverse_strictly_increasing_continuous}. Indeed, $\gamma = \sigma\circ \phi^{-1}$.

Henceforward, we will not make this distinction between a curve and its representative.
\end{remark}



\begin{definition}[smooth curve]
A curve is smooth if some one of its representatives is smooth.
\end{definition}

\begin{definition}[piecewise smooth curve]
A curve is piecewise smooth if some one of its representatives is piecewise smooth.
\end{definition}

\begin{definition}[closed curve]
A curve is closed if some one of its representatives is closed.
\end{definition}

\begin{definition}[reverse curve]
Let $\gamma:[a,b]\to \C$ be a (rectifiable) curve. Then the reverse curve of $\gamma$ is denoted by $-\gamma:[-b,-a]\to\C$ defined by
\be
(-\gamma)(t) = \gamma(-t),\quad t\in [-b,-a].
\ee
\end{definition}


\subsection{Properties of curve integral}

\begin{proposition}\label{pro:properties_rectifiable_curve_integral}
Let $\gamma:[a,b]\to \C$ be a (rectifiable) curve and suppose that $f$ is a function continuous on $\bra{\gamma}$.
\ben
\item [(i)] $\int_\gamma f = - \int_{-\gamma}f$ i.e.,
\be
\int^b_a f(\gamma(t))d\gamma(t) = -\int^{-a}_{-b} f(-\gamma(t))d(-\gamma(t)).
\ee

\item [(ii)] (modulus inequality).
\be
\abs{\int_\gamma f(z)dz } \leq \int_\gamma\abs{f}\abs{dz} \leq V_\gamma[a,b]\sup_{z\in\bra{\gamma}}\abs{f(z)}.
\ee

\item [(iii)] If $c\in \C$, then
\be
\int_\gamma f(z)dz = \int_{\gamma+c} f(z-c)dz.
\ee
\een
\end{proposition}

\begin{remark}
Note that $\sup_{z\in\bra{\gamma}}\abs{f(z)}$ can be achieved by $\abs{f(z)}$ for some $z\in \bra{\gamma}$ by Corollary \ref{cor:continuous_function_on_compact_set_reachs_sup_inf}.
\end{remark}

\begin{proof}[\bf Proof]
\ben
\item [(i)] Let $P: = \bra{t_0<t_1<\dots< t_n}$ be a partition of $[a,b]$. Then clearly $Q := \bra{-s_0< \dots < s_n}$ with $s_k = t_{n-k}$ (for $k=1,\dots,n$) is a partition of $[-b,-a]$. Then by Theorem \ref{thm:riemann_stieljes_integral_complex}, given any $\ve>0$ there exists $\delta_1>0$ such that if $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_1$,
\be
\abs{\int_\gamma f - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})]} < \ve/2
\ee
for any $\tau_k \in [t_{k-1}, t_k]$. Also, there exists $\delta_2>0$ such that if
\be
\dabs{Q} := \max_{1\leq k\leq n}\abs{s_k - s_{k-1}} = \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_2
\ee
then for any $\sigma_k \in [s_{k-1},s_k]$ (thus $-\sigma_k \in [t_{n-k},t_{n-k+1}]$ and $-\sigma_{n-k+1} \in [t_{k-1},t_k]$)
    \beast
    & & \abs{\int_{-\gamma} f - \sum^n_{k=1}f((-\gamma)(\sigma_k))[(-\gamma(s_k)) - (-\gamma)(s_{k-1})]} < \ve/2 \\
    & \ra & \abs{\int_{-\gamma} f - \sum^n_{k=1}f(\gamma(-\sigma_k))[\gamma(t_{n-k}) - \gamma(t_{n-k+1})]} < \ve/2 \\
    & \ra & \abs{\int_{-\gamma} f - \sum^1_{k=n}f(\gamma(-\sigma_{n-k+1}))[\gamma(t_{k-1}) - \gamma(t_{k})]} < \ve/2
    \eeast

Let $-\sigma_{n-k+1} = \tau_k$, we have that
\be
\sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})] = - \sum^1_{k=n}f(\gamma(-\sigma_{n-k+1}))[\gamma(t_{k-1}) - \gamma(t_{k})].
\ee

Therefore, for $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta := \min\bra{\delta_1,\delta_2}$,
\beast
\abs{\int_\gamma f + \int_{-\gamma}f} & \leq &  \abs{\int_\gamma f - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_k) - \gamma(t_{k-1})]} + \abs{\int_{-\gamma} f - \sum^1_{k=n}f(\gamma(-\sigma_{n-k+1}))[\gamma(t_{k-1}) - \gamma(t_{k})]} \\
& < & \ve/2 + \ve/2 = \ve
\eeast
which implies that required result.

\item [(ii)] First, by Theorem \ref{thm:riemann_stieljes_integral_complex}, given any $\ve>0$ there exists $\delta_1>0$ such that if $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_1$, then for any $\tau_k\in [t_{k-1},t_k]$,
\beast
\abs{\int_\gamma f(z)dz  - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k} - \gamma(t_{k-1}))] } < \ve \ \ra\ \lim_{\delta_1\to 0}\sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k} - \gamma(t_{k-1}))] = \int_\gamma f(z)dz .
\eeast

Also, by Theorem \ref{thm:riemann_stieljes_integral_complex}, given any $\ve>0$ there exists $\delta_2>0$ such that if $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_2$, then for any $\tau_k\in [t_{k-1},t_k]$,
\beast
\abs{\int_\gamma \abs{f(z)}\abs{dz} - \sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} } < \ve \ \ra\ \lim_{\delta_2\to 0}\sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} = \int_\gamma \abs{f(z)}\abs{dz}
\eeast

Thus by triangle inequality,
\be
\abs{\sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k} - \gamma(t_{k-1}))]} \leq \sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))}
\ee
whcih implies that for $\delta:= \min\bra{\delta_1,\delta_2}$,
\beast
\abs{\int_\gamma f(z)dz} & = & \abs{\lim_{\delta\to 0} \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k} - \gamma(t_{k-1}))]} = \lim_{\delta\to 0}\abs{\sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k} - \gamma(t_{k-1}))]} \\
& \leq & \lim_{\delta\to 0}\sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} = \int_\gamma \abs{f(z)}\abs{dz}
\eeast
by Lemma \ref{lem:basic_convergence_complex}.(vii). Since
\be
\sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} \leq \sup_{z\in\bra{\gamma}}\abs{f(z)} \sum^n_{k=1}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} \leq V_\gamma[a,b]\sup_{z\in\bra{\gamma}}\abs{f(z)},
\ee
we have
\be
\int_\gamma \abs{f(z)}\abs{dz} = \lim_{\delta\to 0}\sum^n_{k=1}\abs{f(\gamma(\tau_k))}\abs{\gamma(t_{k} - \gamma(t_{k-1}))} \leq V_\gamma[a,b]\sup_{z\in\bra{\gamma}}\abs{f(z)}.
\ee

%First, we have
%\be
%\int_\gamma \abs{f(z)}\abs{dz} = \int^b_a \abs{f(\gamma(t))}\abs{d\gamma(t)} .
%\ee

\item [(iii)] First, by Theorem \ref{thm:riemann_stieljes_integral_complex}, given any $\ve>0$ there exists $\delta_1>0$ such that if $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_1$, then for any $\tau_k\in [t_{k-1},t_k]$,
\beast
& & \abs{\int_{\gamma+c} f(z-c)dz  - \sum^n_{k=1}f(\gamma(\tau_k)+c-c)[\gamma(t_{k})+c - (\gamma(t_{k-1})+c)] } < \ve/2 \\
& \ra & \abs{\int_{\gamma+c} f(z-c)dz  - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k})- \gamma(t_{k-1})] } < \ve/2
\eeast

But we can find $\delta_2$ such that $\dabs{P} := \max_{1\leq k\leq n}\abs{t_k - t_{k-1}} < \delta_2$, then for any $\tau_k\in [t_{k-1},t_k]$,
\be
\abs{\int_{\gamma} f(z)dz  - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k})- \gamma(t_{k-1})] } < \ve/2.
\ee

Therefore, given any $\ve>0$, we can choose $\delta := \min\bra{\delta_1,\delta_2}$ such that,
\beast
& & \abs{\int_{\gamma} f(z)dz  - \int_{\gamma+c} f(z-c)dz} \\
& \leq & \abs{\int_{\gamma} f(z)dz  - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k})- \gamma(t_{k-1})] } + \abs{\int_{\gamma+c} f(z-c)dz  - \sum^n_{k=1}f(\gamma(\tau_k))[\gamma(t_{k})- \gamma(t_{k-1})] } \\
& < & \ve/2 + \ve/2 = \ve
\eeast
which implies that required result.
\een
\end{proof}



\begin{proposition}%\label{pro:derivative_under_complex_integral_of_functions_of_two_real_variables}
Let $X\subseteq \C$ be an open set and $f:[a,b]\times X \to \C,(t,z)\mapsto f(t,z)$ be a continuous function of $t$ and $z$ and the continuity of $f$ of $z$ is uniform with respect to the variable $t\in [a,b]$. Define function $g:X\to \C$ by
\be
g(z) = \int^b_a f(t,z)dt.
\ee

Then $g(z)$ is continuous on $X$. Moreover, if $f(t,z)$ is an analytic function of $z$, $\fp{f}{z}$ is a continuous function of $t$ and the continuity of $\fp{f}{z}$ of $z$ is uniform with respect to the variable $t\in [a,b]$, then $g(z)$ is analytic function of $z$ and
\be
g'(z) = \int^b_a \fp{f}{z}(t,z)dt.\qquad (*)
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First, the function $g(z)$ is well-defined since $f(t,z)$ is continuous of $t$. Then for fixed $z\in X$, since the continuity of $f$ of $z$ is uniform with respect to the variable $t\in [a,b]$, we have that given $\ve0$, for any $t\in [a,b]$ and any $w\in X$, there exists $\delta = \delta(z)>0$ such that
\be
\abs{f(t,w)-f(t,z)} < \frac{\ve}{b-a} \qquad \text{whenever }\ \abs{w-z} < \delta.
\ee

Therefore,
\beast
\abs{g(w)-g(z)} & = & \abs{\int^b_a f(t,w)dt - \int^b_a f(t,z)dt} = \abs{\int^b_a \bb{f(t,w)-f(t,z)}dt} \\
& \leq & \int^b_a \abs{f(t,w) - f(t,w)} dt < \frac{\ve}{b-a}(b-a) = \ve
\eeast
which implies that $g(z)$ is continuous on $X$.

Note that if we prove that $g$ is differentiable with $g'$ given by ($*$) then it will follow from the first part that $g'$ is continuous (thus $g$ is analytic function by definition) since $\fp{f}{z}$ is continuous. Hence we need only verify ($*$).

Since the continuity of $\fp{f}{z}$ of $z$ is uniform with respect to the variable $t\in [a,b]$, we have that fixed $z\in X$ and any $\ve>0$ there exists $\delta_1 = \delta(z)>0$,
\be
\abs{\fp{f}{z}(t,w) - \fp{f}{z}(t,z)} < \frac{\ve}{b-a}\qquad \text{whenever }\ \abs{w-z} < \delta_1, \ t\in [a,b].
\ee

Also, since $X$ is open, for $z\in X$ we can find $\delta_2>0$ such that $D_{\delta_2}(z)\in X$. Then we can pick $\delta = \min\bra{\delta_1,\delta_2}$ such that for any $\abs{w-z}<\delta$, there is a line segment $\gamma$ lying in the disc $D_{\delta}(z)$ such that 
\be
\abs{\int_\gamma \bb{\fp{f}{z}(t,\xi) - \fp{f}{z}(t,z)}d\xi} < \frac{\ve }{b-a} \int_\gamma \abs{d\xi} = \frac{\ve \abs{w-z}}{b-a}
\ee
by modulus inequality (Proposition \ref{pro:properties_rectifiable_curve_integral}). But for a fixed $t\in [a,b]$, $\phi(w) := f(t,w) - w\fp{f}{z}(t,z)$ is a primitive function of $\fp{f}{z}(t,w) - \fp{f}{z}(t,z)$ on $D_{\delta}(z)$. Then for any $t\in [a,b]$ when $\abs{w-z} < \delta$, by Theorem \ref{thm:fundamental_theorem_of_calculus_of_complex_function_along_rectifiable_path},
\beast
\abs{f(t,w) - f(t,z) - (w- z)\fp{f}{z}(t,z)} & = & \abs{f(t,w) - w\fp{f}{z}(t,z) - f(t,z) + z\fp{f}{z}(t,z)} = \abs{\phi(w) - \phi(z)} \\
& = & \abs{\int_\gamma \bb{\fp{f}{z}(t,\xi) - \fp{f}{z}(t,z)}d\xi} < \frac{\ve \abs{w-z}}{b-a}.
\eeast

%This gives that for $\abs{w-z}< \delta$ and any $t\in [a,b]$, a piecewise smooth (thus rectifiable) path $\gamma$ can be found from $z$ to $w$ since open connected set is piecewise smoothly pathwise connected by Theorem \ref{thm:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_complex}. Then
%\be
%\abs{\int_\gamma \bb{\fp{f}{z}(t,\xi) - \fp{f}{t}(s,z)}d\xi} < \frac{\ve \abs{w-z}}{b-a}.
%\ee

Then we have
\beast
& & \abs{\frac{g(w)-g(z)}{w-z} - \int^b_a \fp{f}{z}(t,z) dt} \\
& = & \abs{\frac{\int^b_a f(t,w)dt - \int^b_a f(t,z)dt}{w-z} - \int^b_a \fp{f}{z}(t,z) dt} = \frac 1{\abs{w-z}}\abs{\int^b_a \bb{f(t,w)-f(t,z) -(w-z) \fp{f}{z}(t,z)} dt} \\
& \leq & \frac 1{\abs{w-z}}\int^b_a \abs{\bb{f(t,w)-f(t,z) -(w-z) \fp{f}{z}(t,z)}} dt < \frac 1{\abs{w-z}} \frac{\ve \abs{w-z}}{b-a} \int^b_a dt = \ve 
\eeast
when $\abs{w-z} < \delta$.
\end{proof}


%Recalling Proposition \ref{pro:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_multiple_real}, we have its complex version.%{pro:open_set_is_pathwise_connected_iff_connected_multiple_real}

%\begin{proposition}\label{pro:open_set_is_contour_connected_iff_connected_complex}
%An open set $X\subseteq \C$ is connected if and only if any two points in $X$ can be joined by a contour.
%\end{proposition}

\subsection{Simple closed curve, simply connected set and multiply connected set}


\begin{definition}[simple closed curve]
A simple closed curve is a closed curve $z:[a,b]\to \C$ that does not cross itself and ends at the same point where it begins (that is, the initial and final values of $z(t)$ are the same).
\end{definition}

\begin{remark}
Examples are circles, ellipses and polygons.
\end{remark}


%\begin{definition}[continuous arc]
%Let $x(t)$ and $y(t)$ be real continuous function of the real parameter $t$ with $t\in [a,b]$. Then the set of points
%\be
%z(t) = x(t) + iy(t)
%\ee
%defines a continuous arc in the complex plane beginning at $z(a)$ and ending at $z(b)$.
%\end{definition}

%\begin{definition}[multiple point]
%A point $z\in \C$ is called multiple point of curve if the equation $z = x(t) + iy(t)$ is satisfied by more than one value of $t\in [a,b]$.
%\end{definition}

%\begin{definition}[Jordan curve, simple closed Jordan curve]
%A (continuous) curve without multiple points is called a Jordan curve.

%If the arc has only one double point, corresponding to the initial and terminal values $a$ and $b$, i.e., $z(a)=z(b)$, then it is called simple closed Jordan curve.
%\end{definition}

\begin{definition}[simply connected set\index{simply connected set!complex}, multiply connected set\index{multiply connected set!complex}]
An open connected set $X\subseteq \C$ is called simply connected if any closed curve in $X$ can be shrunk to a point continuously in the set (without passing through points not belonging to $X$). That is, every simple closed curve within it encloses only points of $X$.

An open connected set $X\subseteq \C$ is called multiply connected if it is not simply connected.
\end{definition}

\begin{remark}
Note that some books use pathwise connected in definition as an open connected is pathwise connected by Proposition\footnote{equivalence of connected and pathwise connected.}

It is always possible to construct some closed curve inside a multiply connected set in such a manner that one or more points inside the curve do not belong to the set. Intuitively, there are holes contained inside some simple closed curve lying completely in the set.

We have one hole in a doubly connected set and two holes in a triply connected set. For instance, the set $\bra{z:1<\abs{z}<2}$ is doubly connected.
\end{remark}



\begin{center}\psset{yunit=2cm,xunit=2cm}  %%%%%%% this is wrong as t is theta
\begin{pspicture}[algebraic](-0.5,-1.7)(1.1,1.5)
%\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-0.5)(9,5.5)
%\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(1,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-1,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
\pscircle(0.5,0.5){0.6}
\pscircle(-0,-0.3){0.7}
\pscustom[fillstyle=solid,fillcolor=blue!20,linestyle=none]{%fillstyle=crosshatch
%\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(1,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-1,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)(1.5,1)
\pscircle(0.5,0.5){0.6}
\pscircle(-0,-0.3){0.7}}
\rput[cb](0.2,-1.3){disconnected}%{\textcolor{blue}
\end{pspicture}
\begin{pspicture}[algebraic](-1.1,-1.7)(1.1,1.5)
%\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-0.5)(9,5.5)
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(0.7,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-0.7,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
%\pscircle(0,0){0.6}
\pscustom[fillstyle=solid,fillcolor=blue!20,linestyle=none]{%fillstyle=crosshatch
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(0.7,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-0.7,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)(1.5,1)
%\pscircle(0,0){0.6}
}
\rput[cb](0,-1.3){simply connected}
\end{pspicture}
\begin{pspicture}[algebraic](-1.1,-1.7)(1.1,1.5)
%\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-0.5)(9,5.5)
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(1,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-1,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
\pscircle(0,0){0.6}
\pscustom[fillstyle=solid,fillcolor=blue!20,linestyle=none]{%fillstyle=crosshatch
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(1,0.1)(0.5,-0.3)(0.6,-0.9)(0,-1)(-0.6,-0.9)(-0.5,-0.3)(-1,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)(1.5,1)
\pscircle(0,0){0.6}}
\rput[cb](0,-1.3){doubly connected}
\end{pspicture}
\begin{pspicture}[algebraic](-1.1,-1.7)(1.1,1.5)
%\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-0.5)(9,5.5)
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(0.8,0.1)(0.5,-0.3)(0.6,-0.7)(0,-1)(-0.6,-0.7)(-0.5,-0.3)(-0.8,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
\pscircle(0,0.6){0.4}
\pscircle(0,-0.6){0.4}
\pscustom[fillstyle=solid,fillcolor=blue!20,linestyle=none]{%fillstyle=crosshatch
\psccurve[linewidth=1pt](0,1.2)(0.5,0.5)(0.8,0.1)(0.5,-0.3)(0.6,-0.7)(0,-1)(-0.6,-0.7)(-0.5,-0.3)(-0.8,0.1)(-0.5,0.5)%(1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)(1.5,1)
\pscircle(0,0.6){0.4}
\pscircle(0,-0.6){0.4}}
\rput[cb](0,-1.3){triply connected}
\end{pspicture}
\end{center}


%\begin{definition}[simply connected set, multiply connected set]
%A open connected set $X$ (or domain) is said to be simply connected if every simple closed Jordan curve in $X$ can be shrunk to a point in $X$ without passing through points not belonging to $X$.

%A open connected set that is not simply connected is said to be multiply connected.
%\end{definition}

%\subsection{Line integral along curve}


\section{Contour Integral}

\subsection{Contour}

\begin{definition}[contour]% (see Definition \ref{def:smooth_curve_complex})
A contour $z(t) = x(t) + iy(t)$ is defined as a curve consisting of a finite number of smooth curves joined end to end.%A contour is said to be simple closed contour if only the initial and final values of $z(t)$ are the same.
\end{definition}

\begin{remark}
We can also view the contour as the complex verison of piecewise smooth curve.
\end{remark}


\subsection{Contour integral}



Since contour is (rectifiable) curve (Proposition \ref{pro:piecewise_smooth_path_is_of_bounded_variation_complex}), we can define the contour integral as follows.% by Theorem \ref{thm:riemann_stieljes_integral_complex} and Definition \ref{def:line_integral_of_continuous_function_along_rectifiable_path}.

\begin{definition}[contour integral]
Let $f(z)$ be any complex function defined in an open connected set $\sD$ in the complex plane and let $C:[a,b]\to \C$ be any contour contained in $\sD$ with initial point $z_0$ and terminal point $z$. We divide the contour $C$ into $n$ subpaths by the discrete points
\be
z_0,z_1,\dots, z_{n=1},z_n = z
\ee
arranged consecutively along the direction of increasing.

Let $\xi_k$ be an arbitrary point on the subpath $z_{k-1}z_{k}$ and write $\Delta z_k = z_{k} - z_{k-1} = z(t_k) - z(t_{k-1})$ where $\bra{t_0<t_1<\dots < t_n}$ is a partition of $[a,b]$. Let $\lm = \max_{1\leq k\leq n}\abs{t_k - t_{k-1}}$ and take the limit
\be
\lim_{\lm\to 0 } \sum^{n}_{k=1} f(\xi_k)\Delta z_k.
\ee

%If the above limit exists, we say
%the function $f(z)$ is said to be integrable along the contour $C$. 

Then by Theorem \ref{thm:riemann_stieljes_integral_complex} the limit exists and is called contour integral of $f(z)$ along the contour $C$. In particular, we write
\be
\int_C f(z) dz := \lim_{\lm\to 0} \sum^{n}_{k=1} f(\xi_k)\Delta z_k.
\ee

If the contour is simple closed, the contour integral can be expressed by
\be
\oint_C f(z)dz.
\ee
\end{definition}

\begin{remark}
Contour integral depends on both $f$ and $C$.
\end{remark}

%\item the relation between contour integral and line integral

\begin{theorem}\label{thm:continuous_function_between_contour_integral_line_integral}
Let $\sD$ be an open connected set which contains contour $C$ and $f(z)$ be a continuous function along $C$. Then the contour integral of $f(z)$ along the contour $C$ (with points $z(t) = x(t) + iy(t)$, $t\in [a,b]$) can be expressed by
\be
\int_C f(z)dz = \int^b_a f(z(t)) \frac{dz(t)}{dt} dt.
\ee
\end{theorem}

\begin{remark}
This is another version of Theorem \ref{thm:integral_along_piecewise_smooth_path_equals_product_with_derivative}.
\end{remark}

\begin{proof}[\bf Proof]
Write $f(z) = u(x,y) + iv(x,y)$ and $dz = dx + idy$. Then we have
\beast
\int_C f(z)dz & = & \lim_{\lm\to 0} \sum^{n}_{k=1} f(\xi_k)\Delta z_k = \lim_{\lm\to 0} \sum^{n}_{k=1} \bb{u(\xi_k) + iv(\xi_k)}\bb{\Delta x_k + i\Delta y_k} \\
& = & \lim_{\lm\to 0} \sum^{n}_{k=1} \bb{u(x(t_k),y(t_k)) + iv(x(t_k),y(t_k))}\bb{\frac{\Delta x_k}{\Delta t_k} + i\frac{\Delta y_k}{\Delta t_k}} \Delta t_k
\eeast
where $\Delta t_k = t_{k+1} - t_k$ and it goes to 0 as $z'(t)$ always exists. Therefore,
\beast
\int_C f(z)dz & = & \int^b_a u(x(t),y(t))\frac {dx(t)}{dt} dt - \int^b_a v(x(t),y(t))\frac {dy(t)}{dt} dt + i\int^b_a v(x(t),y(t))\frac {dx(t)}{dt} dt + i\int^b_a u(x(t),y(t))\frac {dy(t)}{dt} dt \\
& = & \int^b_a \bb{u(x(t),y(t)) + i v(x(t),y(t))}\bb{\frac {dx(t)}{dt} + i \frac {dy(t)}{dt}}dt = \int^b_a f(z(t)) \frac{dz(t)}{dt} dt.
\eeast
\end{proof}




%\item example of relation of line integral and contour integral

\begin{example}
To evaluate the integral
\be
\oint_C \frac 1{z-z_0}dz
\ee
where $C$ is a circle centered at $z_0$ and of any radius. The circle $C$ can be parameterized by
\be
z(t) = z_0 + re^{it},\qquad 0\leq t\leq 2\pi,
\ee
where $r$ is any positive number. Then the contour integral becomes
\be
\oint_C \frac 1{z-z_0}dz = \int^{2\pi}_0 \frac{1}{z(t)-z_0} \frac{dz(t)}{dt}dt = \int^{2\pi}_0 \frac{ire^{it}}{re^{it}}dt = i\int^{2\pi}_0 dt = 2\pi i.
\ee

Interestingly, the value of the integral is independent of the radius of the circle.
\end{example}



\begin{remark}
Since a contour integral can be expressed in terms of real line integral, the usual properties of real line integrals are carried over to their complex counterparts. In particular, $\int_C f(z)dz$ is independent of the parametrization of $C$. %\item [(ii)] $\int_{-C} f(z)dz = -\int_C f(z)dz$, where $-C$ is the opposite curve of $C$.%\item [(iii)] The integral of $f(z)$ along a string of contours is equal to the sum of the integrals of $f(z)$ along each of these contours.%\een
\end{remark}


\subsection{Properties of contour integral}

\begin{proposition}[properties of contour integral]\label{pro:contour_integral_continuous_basic_properties}
Let $X$ an open connected set and $C$ be any contour contained in $X$. Let $f,g$ be continuous functions along $C$.
\ben
\item [(i)] For any $\alpha,\beta\in \C$,
\be
\int_C (\alpha f(z) + \beta g(z))dz = \alpha \int_C f(z)dz + \beta\int_C g(z)dz.
\ee
\item [(ii)] If the contour consists of smooth curves $\gamma_1,\dots \gamma_n$,
\be
\int_C f(z)dz = \int_{\gamma_1} f(z)dz +\int_{\gamma_2} f(z)dz + \dots + \int_{\gamma_n} f(z)dz.
\ee
\item [(iii)] If $-C$ if $C$ with reverse orientation, then
\be
\int_{-C} f(z)dz = - \int_C f(z)dz.
\ee
\item [(iv)] (modulus inequality). Let $M$ be the maximum value of $\abs{f(z)}$ along $C$\footnote{This maximum is guaranteed. Since $\abs{f(z(t))}$ is continuous, we have the maximum by Theorem \ref{thm:continuous_real_with_closed_bound_interval_attains_bounds}} and $L$ be the arc length of the contour $C$. Then
    \be
    \abs{\int_C f(z)dz } \leq ML.
    \ee
\een
\end{proposition}%he set $z([a,b])$ is also closed and bounded as $z$ is differentiable and thus continuous. Then $f(z(t))$ is closed and $[a,b]$ is closed and bounded, t bounded



\begin{proof}[\bf Proof]
\ben
\item [(i)] By  Theorem \ref{thm:continuous_function_between_contour_integral_line_integral} and Proposition \ref{pro:complex_line_integral_properties}.(iii)
    \beast
    \int_C (\alpha f(z) + \beta g(z))dz & = & \int^b_a  (\alpha f(z(t)) + \beta g(z(t))) z'(t) dt = \alpha \int^b_a f(z(t) z'(t) dt + \beta \int^b_a g(z(t)) z'(t) dt \\
    & = & \alpha \int_C f(z)dz + \beta\int_C g(z)dz.
    \eeast
\item [(ii)] Assume $a=t_0, t_1,\dots, t_n = b$ with $\gamma_k$ defined on $[t_{k-1},t_k]$, then by Theorem \ref{thm:continuous_function_between_contour_integral_line_integral} and Proposition \ref{pro:complex_line_integral_properties}.(iv),
    \beast
     \int_{C} f(z)dz & = & \int^b_a f(z(t))z'(t)dt = \sum^n_{k=1}\int^{t_k}_{t_{k-1}} f(z(t))z'(t)dt = \sum^n_{k=1} \int_{\gamma_k} f(z)dz.
    \eeast
\item [(iii)] Clearly, we can use Theorem \ref{thm:continuous_function_between_contour_integral_line_integral} and Definition of Riemann integral (Definition \ref{def:riemann_integrable}),
    \be
    \int_{-C} f(z)dz = \int^a_b f(z(t))z'(t)dt = - \int^b_a f(z(t))z'(t)dt =  - \int_C f(z)dz.
    \ee
\item [(iv)] By Theorem \ref{thm:continuous_function_between_contour_integral_line_integral} and Proposition \ref{pro:complex_line_integral_properties}.(v),
\beast
\abs{\int_C f(z)dz} & = & \abs{\int^b_a f(z(t))\frac{dz(t)}{dt}dt} \leq \int^b_a \abs{f(z(t))}\abs{\frac{dz(t)}{dt}}dt \leq \int^b_a M\abs{\frac{dz(t)}{dt}}dt \\
& = & M \int^b_a \sqrt{\bb{\frac{dx(t)}{dt}}^2 +\bb{\frac{dy(t)}{dt}}^2} dt = ML.
\eeast
\een
\end{proof}



\begin{example}\label{exa:contour_integral_one_over_z_square}
Evaluate the integral
\be
\int_C \frac 1{z^2} dz
\ee
along the following two paths.

\ben
\item [(i)] The straight line segment joining 1 and $2+i$. The parametric form of the straight line segment joining 1 and $2+i$ is given by \be
    z(t) = 1 + (1+i)t,\qquad t\in [0,1].
    \ee

    The contour integral can be expressed as
    \beast
    \int_C \frac 1{z^2} dz & = & \int^1_0 \frac 1{z^2(t)}z'(t)dt = \int^1_0 \frac{1+i}{\bb{1+(1+i)t}^2}dt \\
    & = & (1+i)\int^1_0 \frac{(1+t - it)^2}{(2t^2 + 2t+1)^2}dt = (1+i)\int^1_0 \frac{1+2t - it(1+t)}{(2t^2 + 2t+1)^2}dt.
    \eeast

For the real part,
\be
\int^1_0 \frac{1+2t}{(2t^2 + 2t+1)^2}dt = \left.-\frac{1}{2(2t^2+2t+1)}\right|^1_0 = \frac 25.
\ee

For imaginary part,
\be
-\int^1_0 \frac{t(1+t)}{(2t^2 + 2t+1)^2}dt = \left.\frac{1+2t}{2(2t^2+2t+1)}\right|^1_0 = -\frac 15.
\ee

Thus,
\be
\int_C \frac 1{z^2} dz = (1+i)\bb{\frac 25 - \frac 15 i} = \frac{3+i}{5}.
\ee

\item [(ii)] The horizontal line from 1 to 2, then the vertical line from 2 to $2+i$. The contour integral can be expressed as
\beast
\int_C \frac 1{z^2} dz & = & \int^2_1 \frac 1{x^2}dx + \int^1_0 \frac i{(2+iy)^2} dy = \left.-\frac{1}{x}\right|^2_1 + \int^1_0 \frac {4y+i(4-y^2)}{(4+y^2)^2} dy \\
& = & \frac 12 - \left. \frac 2{4+y^2}\right|^1_0  + i \left. \frac y{4+y^2}\right|^1_0 = \frac 12 + \frac 1{10} + \frac{i}{5} = \frac{3+i}{5}.
\eeast
\een
\end{example}

\begin{example}
Evaluate the integral
\be
\int_C \abs{z}^2 dz
\ee
along the following two contours.

\ben
\item [(i)] The line segment with initial point -1 and final point $i$. Parameterized the line segment by
\be
z(t) = -1 + (1+i)t,\qquad t\in [0,1],
\ee
so that
\be
\abs{z}^2 = (-1+t)^2 + t^2.
\ee

Then
\be
\int_C \abs{z}^2 dz = (1+i)\int^1_0 (2t^2 - 2t+1) dt = (1+i) \bb{\frac 23 - 1 + 1} = \frac 23 (1+i).
\ee

\item [(ii)] The arc of the unit circle $\abs{z}=1$ traversed in the clockwise direction with initial point -1 and final point $i$. We have
\be
z = i\theta,\qquad dz = ie^{i\theta} d\theta
\ee
and the initial and final points of the path correspond to $\theta = \pi$ and $\theta = \pi/2$, respectively. Then
\be
\int_C \abs{z}^2 dz = \int^{\pi/2}_{\pi} 1 \cdot ie^{i\theta}d\theta = \left.e^{i\theta}\right|^{\pi/2}_{\pi} = 1+i.
\ee
\een

Hence, the value of this contour integral does depend on the path of integration. We will see later that this is due to the fact that $\abs{z}^2$ does not have any primitive function. This can be proved by checking Cauchy-Riemann equation.
\end{example}


\begin{example}
Let $C$ be the simple closed contour consisting of four straight line segments, $\Re z = \pm a$ and $\Im z = \pm$ $(a>0)$, oriented in anticlockwise direction ($C$ represents a square of sides $2a$). Evaluate the integral
\be
\oint_C \Re(z) dz.
\ee

The simple closed contour $C$ consists of the four line segments
\beast
C_1 & = & \bra{z : z(t) = a+it,t\in [-a,a]},\qquad dz = idt, \\
C_2 & = & \bra{z : z(t) = -t + ia,t\in [-a,a]},\qquad dz = -dt, \\
C_3 & = & \bra{z : z(t) = -a-it,t\in [-a,a]},\qquad dz = -idt, \\
C_4 & = & \bra{z : z(t) = t-ia,t\in [-a,a]},\qquad dz = dt,
\eeast
where $C = C_1 + C_2 + C_3 + C_4$.

\begin{center}
\psset{yunit=1.2cm,xunit=1.2cm}
\begin{pspicture}(-2.5,-2.5)(2.5,2.5)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[labels=none,ticks=none]{->}(0,0)(-2.5,-2.5)(2.5,2.5)%axesstyle=frame,dx=2,dy=2
  \psset{algebraic,linewidth=1.5pt}

\pstGeonode[PointSymbol=none,PointName=none,dotscale=1,linecolor=blue](2,2){A}(-2,2){B}(-2,-2){C}(2,-2){D}(2,1){AA}(-1,2){BB}(-2,-1){CC}(1,-2){DD}
  %\psplot[linecolor=green]{-3.1416}{3.1416}{2*sin(x/2)}
  %\psplot[linecolor=blue,linewidth=1pt]{-1.05}{3.05}{x^3 - 3*x^2+1} %,linestyle=dashed

\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](A)(B)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](B)(C)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](C)(D)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](D)(A)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(D)(AA)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(A)(BB)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(B)(CC)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(C)(DD)

\rput[cb](2.2,0.3){\textcolor{blue}{$C_1$}}
\rput[cb](0.2,2.15){\textcolor{blue}{$C_2$}}
\rput[cb](-2.2,0.3){\textcolor{blue}{$C_3$}}
\rput[cb](0.2,-2.2){\textcolor{blue}{$C_4$}}

\rput[cb](1.95,2.15){\textcolor{blue}{$\bb{a,a}$}}
\rput[cb](-2.2,2.15){\textcolor{blue}{$\bb{-a,a}$}}
\rput[cb](-2.2,-2.15){\textcolor{blue}{$\bb{-a,-a}$}}
\rput[cb](1.95,-2.15){\textcolor{blue}{$\bb{a,-a}$}}

\end{pspicture}
\end{center}

The respective contour integrals along the line segments are found to be
\beast
\int_{C_1} \Re z dz & = &  \int^a_{-a} a idt  = 2a^2 i,\\
\int_{C_2} \Re z dz & = &  \int^a_{-a} (-t) (-dt)  = 0,\\
\int_{C_3} \Re z dz & = &  \int^a_{-a} (-a) (-idt)  = 2a^2 i,\\
\int_{C_4} \Re z dz & = &  \int^a_{-a} t dt  = 0.
\eeast

The contour integral around $C$ is given by the sum of the contour integrals along $C_1,C_2,C_3,C_4$. Adding the four contour integrals together, we obtain
\be
\oint_C \Re z dz = \int_{C_1} \Re z dz+ \int_{C_2} \Re z dz + \int_{C_3} \Re z dz  + \int_{C_4} \Re z dz = 4a^2 i.
\ee
\end{example}

\subsection{Fundamental theorem of calculus}%\subsection{Primitive function}

\begin{definition}[primitive function\index{primitive function!complex}]
Suppose $f$ is a complex-valued function on an open set $A$. Then a primitive function (or antiderivative function\index{antiderivative function!complex}) for $f$ on $A$ is a function $F$ that is differentiable on $A$ and such that $F'(z) = f(z)$ for all $z\in A$.%If $f$ is continuous in $A$, we call the antiderivative function primitive.
\end{definition}

\begin{theorem}\label{thm:contour_integral_primitive_function}
Let $f$ be a continuous function on an open connected set $\sD$. Then the following statements are equivalent.
\ben
\item [(i)] $f$ has a primitive function $F$ throughout $\sD$.
\item [(ii)] The integrals of $f(z)$ along contours lying entirely in $\sD$ and extending from any fixed point $\alpha$ to any fixed point $\beta$ all have the same value, namely %and $C$ is a contour in $\sD$ that begins at $z_1$ and ends at $z_2$, then
\be
\int_C f(z)dz = \int^{\beta}_{\alpha} f(z)dz = \left.F(z)\right|^{\beta}_{\alpha} = F(\beta) - F(\alpha).
\ee

\item [(iii)] The integrals of $f(z)$ around closed contours lying entirely in $\sD$ all have value zero.
\een
\end{theorem}

\begin{remark}
This theorem can be considered as the complex version of the fundamental theorem of real calculus (Theorem \ref{thm:fundamental_theorem_of_calculus_riemann_integral}).
\end{remark}

\begin{proof}[\bf Proof]
(i) $\ra$ (ii). Consider single smooth curve $\gamma$ first. By Theorem \ref{thm:continuous_function_between_contour_integral_line_integral} and Corollary \ref{cor:primitive_funtion_equation}, we have
\be
\int_\gamma f(z)dz = \int^b_a f(z(t))z'(t)dt =  \int^b_a F'(z(t))z'(t)dt = \int^b_a \frac{dF(z(t))}{dt}dt = F(z(b)) - F(z(a)).
\ee

If $C$ is a contour consists of smooth curves $\gamma_1,\dots,\gamma_n$ with joint points $a=a_0,a_1,\dots,a_{n-1},a_n =b$, we have
\be
\int_C f(z)dz = \sum^n_{k=1} \int_{\gamma_k} f(z)dz = \sum^n_{k=1} F(z(a_k)) - F(z(a_{k-1})) = F(z(a_n)) - F(z(a_0)) = F(z(b)) - F(z(a))
\ee
as required.

(ii) $\ra$ (iii). Let $\alpha$ and $\beta$ denote two points on any closed contour $C$ lying in $\sD$ and form two paths $C_1$ and $C_2$, each with initial point $\alpha$ and final point $\beta$. By (ii), we have that the integration is independent of path in $\sD$,
\be
\int_{C_1} f(z)dz = F(\beta) - F(\alpha) = \int_{C_2} f(z)dz \ \ra\ \int_{C_1} f(z)dz + \int_{-C_2} f(z)dz = 0. 
\ee

That is, the integral of $f(z)$ around the closed contour $C = C_1-C_2$ has value zero.

(iii) $\ra$ (i). Suppose the integrals of $f(z)$ around closed contours in $X$ always have the zero value. It is obvious that the integration is independent of path in $\sD$. Thus, for fixed $z_0\in \sD$ and for any $z\in \sD$, there exists a contour (piecewise smooth curve) $C$ which goes from $z_0$ to $z$ by Theorem \ref{thm:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_complex}. Therefore, we can define the function on $X$, 
\be%Proposition \ref{pro:open_set_is_contour_connected_iff_connected_complex}
F(z) = \int_C f(w)dw = \int^z_{z_0} f(w) dw.
\ee 

We want to show that $F'(z) = f(z)$ everywhere in $\sD$. We do this by letting $z+\Delta z\in X$ be any point distinct from $z$ and lying in some neighbourhood of $z$ that is small enough to be contained in $X$ (since $\sD$ is open). Then
\be
F(z+\Delta z) - F(z) = \int^{z+\Delta z}_{z_0} f(w)dw - \int^{z}_{z_0} f(w)dw = \int^{z+\Delta z}_{z} f(w)dw
\ee
where the path of integration may be selected as line segment $C$. Then $C$ can be parameterized by $w = z_0 + t\Delta z$ and thus 
\be
\int^{z+\Delta z}_{z} dw = \int_C dw = \int^1_0 \frac{dw}{dt} dt = \int^1_0 \Delta z dt = \Delta z.
\ee

Therefore, we can write
\be
f(z) = \frac 1{\Delta z} \int^{z+\Delta z}_{z} f(z)dw
\ee
and it follows that
\be
\frac{F(z+\Delta z) - F(z)}{\Delta z} - f(z) = \frac 1{\Delta z}\int^{z+\Delta z}_{z} (f(w)-f(z))dw.
\ee

But $f$ is continuous at the point $z$. Hence, for any $\ve>0$, there exists $\delta>0$ such that $\abs{f(w)-f(z)}< \ve$ whenever $\abs{w-z}<\delta$. Consequently, if the point $z+ \Delta z$ is close enough to $z$ so that $\abs{\Delta z}< \delta$, then
\be
\abs{\frac{F(z+\Delta z) - F(z)}{\Delta z} - f(z)} < \frac 1{\abs{\Delta z}}\abs{\Delta z}\ve = \ve
\ee
by Proposition \ref{pro:contour_integral_continuous_basic_properties}. That is,
\be
\lim_{\Delta z \to 0} \frac{F(z+\Delta z) - F(z)}{\Delta z} = f(z),
\ee
or $F'(z)= f(z)$.
\end{proof}%fundamental theorem of calculus\footnote{real version}

\begin{example}
Recall Example \ref{exa:contour_integral_one_over_z_square}. The function $1/z^2$ is continuous in the disc $\abs{z - 2-i}\leq 2$ and its primitive function is $-1/z$. Thus, we can apply Theorem \ref{thm:contour_integral_primitive_function}, we have
\be
\int_C \frac 1{z^2}dz = \int^{2+i}_{1} \frac 1{z^2}dz = - \left.\frac 1z\right|^{2+i}_1 = 1 - \frac 1{2+i} = \frac{5 - 2+i}{5} = \frac {3+i}5
\ee
which is consistent with the results corresponding to different paths.
\end{example}

\begin{example}
Evaluate the integral
\be
\int^{\beta}_{\alpha} \cos z e^{\sin z}dz,
\ee
where $\alpha$ and $\beta$ are any complex constants.

The function $e^{\sin z}$ is a primitive function of $\cos z e^{\sin z}$, and they are both entire function. Then by Theorem \ref{thm:contour_integral_primitive_function}, we have
\be
\int^{\beta}_{\alpha} \cos z e^{\sin z}dz = \left.e^{\sin z}\right|^{\beta}_{\alpha} = e^{\sin \beta} - e^{\sin \alpha}.
\ee
\end{example}

%\begin{corollary}
%Let $f$ be a continuous function with a primitive function $F$ on a set $\sD$ and $C$ is closed contour in $\sD$. Then
%\be
%\oint_C f(z)dz = 0.
%\ee
%\end{corollary}
%
%\begin{proof}[\bf Proof]
%Direct result from Theorem \ref{thm:contour_integral_primitive_function}.
%\end{proof}

\begin{example}
The function $f(z) = 1/z$ does not have a primitive in the open set $\C\bs \bra{0}$, since if $C$ is the unit circle parameterized by $z(t) = e^{it}$, $t\in [0,2\pi]$, we have
\be
\oint_C f(z)dz = \int^{2\pi}_0 \frac{ie^{it}}{e^{it}} dt = 2\pi i \neq 0.
\ee
\end{example}


\begin{corollary}\label{cor:holomorphic_derivative_zero_on_open_connected_set_implies_constant}%{pro:holomorphic_derivative_zero_implies_constant}
Let $f:\C \to \C$ be a differential function with $f'=0$ in an open connected set $X$. Then $f$ is constant in $X$.
\end{corollary}

\begin{remark}
This another approach of Theorem \ref{thm:holomorphic_derivative_zero_on_open_connected_set_implies_constant}.
\end{remark}

\begin{proof}[\bf Proof]%% \ref{pro:open_set_is_contour_connected_iff_connected_complex}
Fix a point $z_0 \in \sD$. It suffices to show that $f(z) = f(z_0)$ for any $z\in\sD$.

Since $\sD$ is connected, for any $z\in \sD$, by Theorem \ref{thm:open_set_is_piecewise_smoothly_pathwise_connected_iff_connected_complex} there exists a contour (piecewise smooth curve) $C$ which goes from $z_0$ to $z$. Clearly, $f$ has a primitive of $f'$ and then we have
\be
\int_C f'(z)dz = f(z) - f(z_0)
\ee
by Theorem \ref{thm:contour_integral_primitive_function}. By assumption, $f'=0$ so the integral on the left is 0. Hence we have the required result.
\end{proof}

\begin{remark}
If $\sD$ is disconnected, we would not have the required conclusion by the following argument. %Since $f$ is holomorphic on a set $A$, it is differenitable at any point $z = x+iy\in A$. 
Assume that $f(z) = u(x,y) + iv(x,y)$. Thus, by Theorem \ref{thm:cauchy_riemann_equation}, we have 
\be
0 = f'(z)= u_x(x,y) + iv_x(x,y) = v_y(x,y) - iu_y(x,y) \ \ra\ u_x(x,y) = v_x(x,y) = u_y(x,y) = v_y(x,y) = 0.
\ee

Then by Corollary \ref{cor:derivative_greater_equal_to_zero}, we have $u$ and $v$ are constants.\footnote{Note that we get $u(x,y) = u(y)$ by considering $x$ as the single variable.} So $f(z) = u+iv$ is a complex constant.

The reason for this is that we cannot apply Corollary \ref{cor:derivative_greater_equal_to_zero} for $x$ or $y$ with disjoint intervals. For instance, let $f$ be a function defined on the set which is the union of two discs with constants value $K_1$ and $K_2$. Then we have that
\be
u_x = u_y =v_x = v_y = 0.
\ee

However, the function of the whole set is not constant at all.
\end{remark}

\subsection{Contour integral of infinite series}

\begin{theorem}
Let $\sD$ be an open connected set and $C$ be any contour contained in $\sD$. Let $\sum^\infty_{k=1}f_k(z)$ be a uniformly convergent series of continuous functions $f_k(z)$ along $C$.

Then we can interchange the order of integral and summation. That is,
\be
\int_C \sum^\infty_{k=1}f_k(z) dz = \sum^\infty_{k=1} \int_C f_k(z) dz.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Since the series is uniformly convergent, we have that $\sum^\infty_{k=1}f_k(z)$ is also continuous in $\sD$ by uniform convergence theorem (Theorem \ref{thm:uniform_convergence_continuous_complex}). Thus, we can write
\be
\sum^\infty_{k=1}f_k(z) = f_1(z) + f_2(z) + \dots + f_n(z) + R_n(z).
\ee

Thus, by Proposition \ref{pro:contour_integral_continuous_basic_properties}.(i),
\be
\int_C\sum^\infty_{k=1}f_k(z) = \int_C f_1(z)dz +\int_C f_2(z)dz + \dots + \int_C f_n(z)dz + \int_C R_n(z)dz.
\ee

Clearly, $R_n(z)$ is continuous function so $\int_C R_n(z)dz$ is well-defined. Since the series is uniformly convergent, given any $\ve>0$ there exists $N$ such that for all $n\geq N$ we have for all $z\in \sD$
\be
\abs{R_n(z)} = \abs{\sum^\infty_{k=1}f_k(z) - f_1(z)  - f_2(z) - \dots - f_n(z)} < \ve.
\ee

Let $L$ be the length of the contour $C$ of integral. Then by Proposition \ref{pro:contour_integral_continuous_basic_properties}.(iv) we have
\be
\abs{\int_C R_n(z) dz} < \ve L \ \ra\ \abs{\int_C\sum^\infty_{k=1}f_k(z) = \int_C f_1(z)dz +\int_C f_2(z)dz + \dots + \int_C f_n(z)dz} \to 0
\ee
which implies the required result.
\end{proof}


\section{Cauchy's Theorem and Integral Theorem}

\subsection{Cauchy theorem}

\begin{theorem}[Cauchy theorem\index{Cauchy theorem!complex closed integral}]
Let $f(z)$ be holomorphic on and inside a set $\sD$ enclosed by a simple closed contour $C$ and let $f'(z)$ be continuous on and inside $C$. Then
\be
\oint_C f(z) dz = 0.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Suppose $f(z) = u(x,y) + iv(x,y)$ with $z = x+iy$. Then we have
\be
\oint_C f(z)dz = \oint_C (u(x,y)dx - v(x,y)dy) + i\oint_C (vdx + udy).
\ee

By Cauchy-Riemann equation (Theorem \ref{thm:cauchy_riemann_equation}), we can have
\be
f'(z) = u_x(x,y) + iv_x(x,y) = v_y(x,y) -iu_y(x,y)
\ee
for all points $(x,y)$ on and inside $C$. This implies $u(x,y)$ and $v(x,y)$ have continuous derivatives on and inside $C$ by Proposition \ref{pro:complex_continuous_iff_real_imaginary_parts_continuous}. Using Green's theorem (Theorem \ref{thm:green_multiple_integral}), the two real line integrals can be tansformed into double integrals. This gives
\be
\oint_C f(z)dz = \iint_{\sD} (-v_x - u_y)dxdy + i\iint_{\sD} (u_x - v_y)dxdy.
\ee

Both integrands in the double integrals are equal to zero due to Cauchy-Riemann equations, hence
\be
\oint_C f(z) dz = 0.
\ee
as required.
\end{proof}



%\begin{theorem}[Cauchy's theorem for a disc]
%If $f$ is holomorphic in a disc, then
%\be
%\int_C f(z)dz = 0
%\ee
%for any closed contour $C$ in that disc.
%\end{theorem}


\subsection{Goursat's theorem}

In 1903, Goursat was able to obtain the same conclusion of Cauchy theorem without assuming the continuity of $f'(z)$. This stronger version is called Goursat theorem. First, we proof the following lemma.

\begin{lemma}\label{lem:holomorphic_function_with_cover_of_finitely_many_squares}
Let $f$ be holomorphic throughout a closed set $\sD$ consisting of the points interior to a positively oriented simple closed contour $C$ together with the points on $C$ itself. Then for any positive number $\ve$, the set $\sD$ can be covered with a finite number of squares and partial squares, indexed by $i=1,2,\dots,n$, such that in each one there is a fixed point $z_i$ for which the inequality
\be
\abs{\frac{f(z) - f(z_i)}{z-z_i} - f'(z_i)} < \ve\qquad \qquad (*)
\ee
is satisfied by all points other than $z_i$ in that square or partial square.
\end{lemma}

%Suppose that there is some square or partial square in which no point $z_i$ exists such that inequality ($*$) holds for all other points $z$ in it. If that subset is a square, we construct four smaller squares by drawing line segments joining the midpoints of its opposite sides. If the subset is a partial square, we treat the whole square in the same manner and then let the portions that lie outside of $R$ be discarded. If in any one of these smaller subsets, no point $z_i$ exists such that inequality ($*$) holds for all other points $z$ in it, we construct still smaller squares and partial square, etc. When this is done to each of original subsets that requires it, we find that after a finite number of squares and partial squares such that the lemma is true.

\begin{proof}[\bf Proof]%We consider the possibility that in the covering constructed just prior to the statement of the lemma,
Suppose that the needed points $z_i$ do not exists after subdividing one of the original subsets a finite number of times and reach a contradiction.

We let $\sigma_0$ denote that subset if it is square; if it is a partial square, we let $\sigma_0$ denote the entire square of which it is a part. After we subdivide $\sigma_0$, at least one of the four smaller squares, denoted by $\sigma_1$, must contain points of $\sD$ but no appropriate point $z_i$. We then subdivide $\sigma_1$ and continue in this manner. It may be that after a square $\sigma_{k-1}$ ($k=1,2,\dots$) has been subdivided, more than one of the four smaller squares constructed from it can be chosen. %To make a specific choice, we take $\sigma_k$ to be the one lowest and then furthest to the left.


\begin{center}\psset{yunit=1.2cm,xunit=1.2cm}  %%%%%%% this is wrong as t is theta
\begin{pspicture}[algebraic](-0.5,-0.5)(9,5.5)
\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-0.5)(9,5.5)
\psccurve[linewidth=1pt](1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
%\pscustom[fillstyle=solid,fillcolor=blue!20]{%fillstyle=crosshatch
%\psplot{1}{7}{sin(x)+4}
%\psplot{7}{1}{(x-2)*(x-5)/5+1}}
%
%\psplot[linecolor=green,linewidth=2pt]{1}{7}{sin(x)+4}
%\psplot[linecolor=red,linewidth=2pt]{7}{1}{(x-2)*(x-5)/5+1}
%
\psline[linestyle=dashed](1.7,1.5)(7,1.5)
\psline[linestyle=dashed](1.9,3)(7,3)
\psline[linestyle=dashed](2.85,4.5)(6,4.5)

\psline[linestyle=dashed](3,0.45)(3,4.6)
\psline[linestyle=dashed](4.5,0.55)(4.5,5.05)
\psline[linestyle=dashed](6,1)(6,4.5)

\psline[linestyle=dashed](5.25,4.5)(5.25,3)
\psline[linestyle=dashed](4.5,3.75)(6,3.75)

%\psline[](1.5,5.5)(1.5,-0.5)%(7.5,-0.5)(7.5,5.5)(1.5,5.5)

%%\psaxes[axesstyle=polar,xAxisLabel=some,subticks=2,tickcolor=red,tickwidth=1pt,subtickcolor=green]{->}(0,0)(-2.5,2.5)(2.5,2.5)%axesstyle=frame,dx=2,dy=2
\rput[cb](2,4){$C$}%{\textcolor{blue}
\rput[cb](4.9,4.1){$\sigma_0$}%{\textcolor{blue}
\rput[cb](5.6,4.1){$\sigma_1$}%{\textcolor{blue}
%\rput[cb](5,0.5){\large \textcolor{red}{$C_1$}}%{\textcolor{blue}
%\rput[cb](5,3.5){\large \textcolor{green}{$C_3$}}%{\textcolor{blue}
%\rput[cb](7.5,4){\large \textcolor{orange}{$C_2$}}%{\textcolor{blue}
%\rput[cb](0.5,3){\large \textcolor{cyan}{$C_4$}}%{\textcolor{blue}
\end{pspicture}
\end{center}


In view of the manner in which the nested infinite sequence $\sigma_0,\sigma_1,\sigma_2,\dots,\sigma_{k},\dots$ of squares is constructed, there is a point $z_0$ common to each $\sigma_k$ by Proposition \ref{pro:square_binary_division_common_point}; also, each of these squares contains points of $\sD$ other than possibly $z_0$. Recall the sizes of the squares in the sequence are decreasing, and note that any $\delta$ neighbourhood $\abs{z-z_0}< \delta$ of $z_0$ contains such squares when their diagonals have length less than $\delta$. Then every $\delta$ neighbourhood $\abs{z-z_0}< \delta$ contains points of $R$ distinct from $z_0$, and this means that $z_0$ is a limit point of $\sD$. Since the set $R$ is closed set, it follows that $z_0 \in \sD$.

The function $f$ is holomorphic throughout $\sD$ and, in particular, at $z_0$. Consequently, $f'(z_0)$ exists. Then for any $\ve>0$, there exists $\delta>0$ such that $\abs{z-z_0}< \delta$ and
\be
\abs{\frac{f(z) - f(z_0)}{z-z_0} -f'(z_0)} < \ve
\ee
is satisfied by all distinct from $z_0$ in that neighbourhood. But the neighbourhood $\abs{z-z_0}< \delta$ contains a square $\sigma_K$ when the integer $K$ is large enough that the length of a diagonal of that square is less than $\delta$. Consequently, $z_0$ serves as the point $z_i$ in inequality ($*$) for the subsets consisting of the square $\sigma_K$ or a part of $\sigma_K$. Contrary to the way in which the square sequence was formed, it is not necessary to subdivide $\sigma_K$. Thus, we arrive at a contradiction.
\end{proof}

\begin{theorem}[Goursat theorem]\label{thm:goursat_simple_closed_contour}
Let $f(z)$ be holomorphic on and inside a set $\sD$ enclosed by a simple closed contour $C$. Then
\be
\oint_C f(z) dz = 0.
\ee
\end{theorem}

\begin{remark}
The omission of the continuity assumption is important. Based on Goursat theorem, we can show later that the derivative $f'$ is also holomorphic without assuming continuity of $f'$.
\end{remark}

\begin{proof}[\bf Proof]
Given any $\ve>0$, we consider the covering of $\sD$ and $z_i$ in Lemma \ref{lem:holomorphic_function_with_cover_of_finitely_many_squares}. Then define on the $i$th square or partial square a function $\delta_i(z)$ whose values are $\delta_i(z_i) = 0$ and
\be
\delta_i(z) = \frac{f(z) - f(z_i)}{z-z_i} - f'(z_i),\qquad z\neq z_i.
\ee

By Lemma \ref{lem:holomorphic_function_with_cover_of_finitely_many_squares}, $\abs{\delta_i(z)} < \ve$ at all points $z$ in the subset on which $\delta_i(z)$ is defined. Also, the function $\delta_i(z)$ is continuous throughout the subset since $f(z)$ is continuous there and 
\be
\lim_{z\to z_i} \delta_i(z) = f'(z_i) - f'(z_i) = 0.
\ee

Then we let $C_i$ (i=1,2,\dots,n) denote the positively oriented boundaries of the above squares or partial squares covering $\sD$. By the definition of $\delta_i(z)$, the value of $f$ at a point $z$ on any particular $C_i$ can be written by
\be
f(z) = f(z_i) - z_i f'(z_i) + f'(z_i)z + (z-z_i)\delta_i(z)
\ee
and this means that
\be
\oint_{C_i} f(z)dz = \bb{f(z_i) - z_i f'(z_i)}\oint_{C_i}dz + f'(z_i)\oint_{C_i}zdz + \oint_{C_i}(z-z_i)\delta_i(z)dz.
\ee

But 
\be
\oint_{C_i} dz = 0,\qquad \oint_{C_i} zdz = 0
\ee
since the function 1 and $z$ posses antiderivatives everywhere in the finite plane. So we have for $i = 1,2,\dots, n$,
\be
\oint_{C_i} f(z)dz = \oint_{C_i}(z-z_i)\delta_i(z)dz.
\ee

The sum of all $n$ integrals on the left in the above equation can be written by
\be
\sum^n_{i=1}\oint_{C_i} f(z)dz = \int_C f(z)dz
\ee
since the two integrals along the common boundary of every pair of adjacent subsets cancel each other, the integral being taken in one sense along that line segment in one subset and in the opposite sense in other (see the graph below). Only the integrals along the curves that are parts of $C$ remain. 

Thus, we have
\be
\int_C f(z)dz = \sum^n_{i=1} \oint_{C_i}(z-z_i)\delta_i(z)dz 
\ee
and so
\be
\abs{\int_C f(z)dz} \leq \sum^n_{i=1} \abs{\oint_{C_i}(z-z_i)\delta_i(z)dz}.
\ee


\begin{center}\psset{yunit=1cm,xunit=1cm}  %%%%%%% this is wrong as t is theta
\def\myLine#1(#2)(#3)#4{{%
  \pnode(#2){myA}\pnode(#3){myB}%
  \pcline[linestyle=solid,tbarsize=15pt]{#1}(myA)(myB)%
  \ncput*{#4}}}
\begin{pspicture}[algebraic](-0.5,-1)(9,7)
\psaxes[ticks=none,labels=none]{->}(0,0)(-0.5,-1)(9,7)
\psccurve[linewidth=1pt](1.5,1)(2,2)(2,3.5)(4,5)(6,4.5)(7,3)(7.5,2)(7,1.5)(4,0.5)
%\pscustom[fillstyle=solid,fillcolor=blue!20]{%fillstyle=crosshatch
%\psplot{1}{7}{sin(x)+4}
%\psplot{7}{1}{(x-2)*(x-5)/5+1}}
%
%\psplot[linecolor=green,linewidth=2pt]{1}{7}{sin(x)+4}
%\psplot[linecolor=red,linewidth=2pt]{7}{1}{(x-2)*(x-5)/5+1}
%
\psline[linestyle=dashed](3,1.5)(6,1.5)
\psline[linestyle=dashed](3,3)(6,3)
\psline[linestyle=dashed](4.5,4.5)(6,4.5)

\psline[linestyle=dashed](3,0.45)(3,3)
\psline[linestyle=dashed](4.5,0.55)(4.5,4.5)
\psline[linestyle=dashed](6,1)(6,4.5)

\psline[linestyle=dashed](5.25,4.5)(5.25,3)
\psline[linestyle=dashed](4.5,3.75)(6,3.75)

\psline[](1,6.5)(1,-0.5)(8,-0.5)(8,6.5)(1,6.5)
\myLine{<->}(1,5.8)(8,5.8){$S$}


\psline[arrowscale=2]{->}(2.9,0.6)(2.9,1.3)
\psline[arrowscale=2]{->}(3.1,1.3)(3.1,0.6)

\psline[arrowscale=2]{->}(4.4,0.6)(4.4,1.3)
\psline[arrowscale=2]{->}(4.6,1.3)(4.6,0.6)

\psline[arrowscale=2]{->}(4.4,2)(4.4,2.7)
\psline[arrowscale=2]{->}(4.6,2.7)(4.6,2)

\psline[arrowscale=2]{->}(4.2,1.4)(3.3,1.4)
\psline[arrowscale=2]{->}(3.3,1.6)(4.2,1.6)

\psline[arrowscale=2]{->}(5.7,2.9)(4.8,2.9)
\psline[arrowscale=2]{->}(4.6,3.1)(5.2,3.1)
\psline[arrowscale=2]{->}(5.3,3.1)(5.9,3.1)

\psline[arrowscale=2]{->}(4,0.5)(4.1,0.5)
%%\psaxes[axesstyle=polar,xAxisLabel=some,subticks=2,tickcolor=red,tickwidth=1pt,subtickcolor=green]{->}(0,0)(-2.5,2.5)(2.5,2.5)%axesstyle=frame,dx=2,dy=2
\rput[cb](2,4){$C$}%{\textcolor{blue}
\rput[cb](2.5,3){$\sD$}%{\textcolor{blue}
%\rput[cb](2,4.1){$\sigma_1$}%{\textcolor{blue}
%\rput[cb](5,0.5){\large \textcolor{red}{$C_1$}}%{\textcolor{blue}
%\rput[cb](5,3.5){\large \textcolor{green}{$C_3$}}%{\textcolor{blue}
%\rput[cb](7.5,4){\large \textcolor{orange}{$C_2$}}%{\textcolor{blue}
%\rput[cb](0.5,3){\large \textcolor{cyan}{$C_4$}}%{\textcolor{blue}
\end{pspicture}
\end{center}


Then by Proposition \ref{pro:contour_integral_continuous_basic_properties} we can find an upper bound for each modulus on the right of the above inequality. To do this, we first recall that each $C_i$ coincides either entirely or partially with the boundary of a square. In either case, we let $S_i$ denote the length of a side of that square. Since in the $i$th integral, both the variable $z$ and the point $z_i$ lie in that square, we have
\be
\abs{z - z_i} \leq \sqrt{2}S_i.
\ee

Then we have that 
\be
\abs{(z - z_i)\delta_i(z)} = \abs{z-z_i}\abs{\delta_i(z)} < \sqrt{2}S_i \ve.
\ee

As for the length of the curve $C_i$, it is $4S_i$ if $C_i$ is the boundary of a square. In that case, we let $A_i$ denote the area of the square and observe that by  Proposition \ref{pro:contour_integral_continuous_basic_properties}
\be
\abs{\oint_{C_i}(z-z_i)\delta_i(z)dz} < \sqrt{2}S_i \ve \cdot 4S_i = 4\sqrt{2}A_i \ve.
\ee

If $C_i$ is the boundary of a partial square, it length does not exceed $4S_i+ L_i$, where $L_i$ is the length of that part of $C_i$ which is also a part of $C$. Again letting $A_i$ denote the area of the full square, we find that
\be
\abs{\oint_{C_i}(z-z_i)\delta_i(z)dz} < \sqrt{2}S_i \ve \cdot (4S_i+ L_i) = 4\sqrt{2}A_i \ve + \sqrt{2}SL_i \ve.
\ee
where $S$ is the length of a side of some square that encloses the entire contour $C$ as well as all of the squares originally used in covering $\sD$. This $S$ must exist since $C$ is a contour (piecewise smooth, that is, it has continuous path on closed interval). Note that the sum of all the $A_i$'s does not exceed $S^2$.

If $L$ denotes the length of $C$, it follows that 
\be
\abs{\oint_C f(z)dz} < \bb{4\sqrt{2}S^2 + \sqrt{2}SL}\ve.
\ee

Since the value of the positive number $\ve$ is arbitrary, we can choose it so that the right-hand side of the above inequality is as small as possible. Then the left-hand side, which is independent of $\ve$, must therefore be equal to zero. This implies the required result.
\end{proof}

\begin{example}
Evaluate the integral
\be
\oint_C \bb{\abs{z} - e^{z}\sin z^2 + \ol{z}}dz
\ee
where $C$ is the circle $\abs{z} = a$. The integral can be split into three individual integrals as
\be
\oint_C \bb{\abs{z} - e^{z}\sin z^2 + \ol{z}}dz = \oint_C \abs{z} dz - \oint_C e^{z}\sin z^2 dz + \oint_C  \ol{z}dz
\ee
by Proposition \ref{pro:contour_integral_continuous_basic_properties}.(i). The second integral equals zero by Goursat theorem (Theorem \ref{thm:goursat_simple_closed_contour}) since the integrand $e^z \sin z^2$ is an entire function. The first integral is found to be
\be
\oint_C \abs{z} dz = a \oint_C  dz = 0.
\ee
since $C$ is the circle $\abs{z} = a$. To compute the third integral, we write $z = ae^{i\theta}$ and substitute $\ol{z}$ with $ae^{-i\theta}$ and $dz$ with $aie^{i\theta}$. This gives 
\be
\oint_C  \ol{z}dz = \int^{2\pi}_0 a e^{-i\theta} ai e^{i\theta} d\theta = a^2 i \int^{2\pi}_0 d\theta = 2\pi a^2 i.
\ee

Combining the results, the value of integral is $2\pi a^2 i$.
\end{example}

\begin{example}
Let $\sD$ be the open connected set that contains the whole complex plane except the origin and the negative real axis. We want to evaluate the integral
\be
\int_C \frac{dz}{z}
\ee
where $C$ is an arbitrary contour, lying completely inside $\sD$, that starts from 1 and ends at a point $\alpha$. 

\begin{center}
\psset{yunit=3cm,xunit=3cm}
\begin{pspicture}(-1.5,-0.2)(2,1.5)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[labels=none,ticks=none]{->}(0,0)(-1.5,-0.2)(2,1.5)%axesstyle=frame,dx=2,dy=2
  \psset{algebraic,linewidth=1pt,linecolor=blue}
\pstGeonode[PointSymbol=none,PointName=none,dotscale=1,linecolor=blue](0,0){O}(1.5,0){A}(0.75,1.3){B}(1,0){C}(1,0.745){D}%(-2,0){C}(2,0){D}(2,1){AA}(-1,2){BB}(-2,1){CC}(1,0){DD}
  %\psplot[linecolor=green]{-3.1416}{3.1416}{2*sin(x/2)}
  %\psplot[linecolor=blue,linewidth=1pt]{-1.05}{3.05}{x^3 - 3*x^2+1} %,linestyle=dashed
\pstArcOAB[]{O}{A}{B}
\pscurve[](0.75,1.3)(1.05,0.4)(1,0)%(1.5,0)%(0.5,-0.3)(0.6,-0.7)(0,-1)(-0.6,-0.7)(-0.5,-0.3)
\psline(C)(A)

\psline[linewidth=2pt,linecolor=red](0,0)(-1.5,0)

\psset{arrows=->,arrowscale=1.5}
\pstArcOAB[]{O}{A}{D}
\psline(C)(1.3,0)
\psline(1.049,0.41)(1.05,0.4)

%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](A)(B)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](B)(C)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](C)(D)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](D)(A)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(D)(AA)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(A)(BB)
%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(B)(CC)
%%\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(C)(DD)
%
\rput[cb](1.25,0.1){$C_1$}
\rput[cb](1.25,1){$C_2$}
\rput[cb](0.95,0.5){$C$}
%\rput[cb](0.2,-0.2){\textcolor{blue}{$C_1$}}
%\rput[cb](1.95,2.15){\textcolor{blue}{$\bb{a,b}$}}
%\rput[cb](-2.2,2.15){\textcolor{blue}{$\bb{-a,b}$}}
\rput[cb](0.7,1.35){$\alpha$}
\rput[cb](1.5,-.1){$\abs{\alpha}$}
\rput[cb](1,-.1){1}
\rput[cb](-0.55,.1){branch cut of $\Log z$}
\end{pspicture}
\end{center}

Let $C_1$ be the line segment from 1 to $\abs{\alpha}$ along the real axis, and $C_2$ be the circular arc centered at the origin and of radius $\abs{\alpha}$ which extends from $\abs{\alpha}$ to $\alpha$. The union $C_1 + C_2 - C$ forms a simple closed contour. Since the integrand $1/z$ is holomorphic everywhere inside $\sD$, by Goursat theorem (Theorem \ref{thm:goursat_simple_closed_contour}), we have
\be
\int_C \frac {dz}{z} = \int_{C_1} \frac {dz}{z} + \int_{C_2} \frac {dz}{z}.
\ee

Since $\alpha$ does not lie on the negative real axis, $\Arg \alpha$ cannot assume the value of $\pi$. If we write 
\be
\alpha = \abs{\alpha} e^{i\Arg \alpha},\qquad -\pi < \Arg\alpha < \pi,
\ee
then
\be
\int_{C_1} \frac {dz}{z} = \int^{\abs{\alpha}}_1 \frac {dt}{t} = \log\abs{\alpha},\qquad \int_{C_2} \frac {dz}{z} = \int_0^{\Arg \alpha} \frac {ir e^{i\theta}}{re^{i\theta}}d\theta = i\Arg \alpha.
\ee

Combining the results, the integral is found to be
\be
\int_{C} \frac {dz}{z} = \log\abs{\alpha} + i\Arg \alpha = \Log \alpha.
\ee

The primitive function of $1/z$ is $\Log z$. The above result can be obtained by applying Theorem \ref{thm:contour_integral_primitive_function}. Note that the given open connected set $\sD$ is the domain of definition of $\Log z$, the principal branch of the complex logarithm function. The branch cut is taken to be the negative real axis and the branch points are $z=0$ and $z=\infty$. By excluding the origin and the negative real axis in $\sD$, we avoid multi-valuedness of the integral.
\end{example}


\begin{proposition}
For fixed $b\in \R$, %Evaluate the integral
\be
\int^\infty_{-\infty} e^{-x^2} e^{\pm 2ibx}dx = \int^\infty_{-\infty} e^{-x^2} \cos(2bx) dx = e^{-b^2}.
\ee

Also, 
\be
\int^\infty_{-\infty} e^{-x^2} \sin(2bx) dx = 0.
\ee
\end{proposition}

\begin{remark}
This result is called the Poisson integral. Note that
\be
\int^\infty_{-\infty} e^{-x^2} e^{\pm 2ibx}dx = \lim_{a\to\infty} \int^a_{-a} e^{-x^2} e^{\pm 2ibx}dx.
\ee
\end{remark}


\begin{proof}[\bf Proof]
Consider the integration of the function $e^{-z^2}$ around the rectangle contour $C$ with vertices $\pm a$, $\pm a + ib$ and oriented positively.  

\begin{center}
\psset{yunit=1.5cm,xunit=1.5cm}
\begin{pspicture}(-2.5,-0.5)(2.5,2.5)
  %\psgrid[griddots=10,gridlabels=0pt, subgriddiv=0, gridcolor=black!40]
  \psaxes[labels=none,ticks=none]{->}(0,0)(-2.5,-0.5)(2.5,2.5)%axesstyle=frame,dx=2,dy=2
  \psset{algebraic,linewidth=1.5pt}
\pstGeonode[PointSymbol=none,PointName=none,dotscale=1,linecolor=blue](2,2){A}(-2,2){B}(-2,0){C}(2,0){D}(2,1){AA}(-1,2){BB}(-2,1){CC}(1,0){DD}
  %\psplot[linecolor=green]{-3.1416}{3.1416}{2*sin(x/2)}
  %\psplot[linecolor=blue,linewidth=1pt]{-1.05}{3.05}{x^3 - 3*x^2+1} %,linestyle=dashed

\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](A)(B)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](B)(C)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](C)(D)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2](D)(A)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(D)(AA)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(A)(BB)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(B)(CC)
\psline[linecolor=blue,linestyle=solid,linewidth=1pt,arrowscale=2]{->}(C)(DD)

\rput[cb](2.2,0.9){\textcolor{blue}{$C_2$}}
\rput[cb](0.2,2.15){\textcolor{blue}{$C_3$}}
\rput[cb](-2.2,0.9){\textcolor{blue}{$C_4$}}
\rput[cb](0.2,-0.2){\textcolor{blue}{$C_1$}}
\rput[cb](1.95,2.15){\textcolor{blue}{$\bb{a,b}$}}
\rput[cb](-2.2,2.15){\textcolor{blue}{$\bb{-a,b}$}}
\rput[cb](-2.2,-.15){\textcolor{blue}{$\bb{-a,-0}$}}
\rput[cb](1.95,-.15){\textcolor{blue}{$\bb{a,-0}$}}
\end{pspicture}
\end{center}

Since $e^{-z^2}$ is an entire function, we have 
\be
\oint_{C} e^{-z^2}dz = 0
\ee
by Goursat theorem (Theorem \ref{thm:goursat_simple_closed_contour}). The closed contour $C$ consists of four line segments: $C = C_1 + C_2 + C_3 + C_4$, where
\beast
C_1 & = & \bra{x:-a\leq x \leq a}, \\
C_2 & = & \bra{a+iy:0\leq y \leq b}, \\
C_3 & = & \bra{x+ib:-a\leq x \leq a}, \\
C_4 & = & \bra{-a+iy:0\leq y \leq b}, 
\eeast
and $C$ is oriented in the anticlockwise direction. The contour integral can be split into four contour integrals, namely,
\be
\oint_C e^{-z^2}dz = \int_{C_1} e^{-z^2}dz + \int_{C_2} e^{-z^2}dz + \int_{C_3} e^{-z^2}dz + \int_{C_4} e^{-z^2}dz.
\ee

The four contour integrals can be expressed as real integrals as follows:
\beast
\int_{C_1} e^{-z^2}dz & = & \int^a_{-a} e^{-x^2}dx,\\
\int_{C_2} e^{-z^2}dz & = & \int^b_0 e^{-(a+iy)^2}i dy,\\
\int_{C_3} e^{-z^2}dz & = & \int^{-a}_a e^{-(x+ib)^2} dx = -e^{b^2} \bb{\int^a_{-a} e^{-x^2}\cos(2bx)dx - i \int^a_{-a} e^{-x^2}\sin(2bx)dx},\\
\int_{C_4} e^{-z^2}dz & = & \int^0_b e^{-(a+iy)^2}i dy.
\eeast

First, we consider the bound on the modulus of the second integral. By the modulus inequality (Proposition \ref{pro:contour_integral_continuous_basic_properties}), we have
\beast
\abs{\int_{C_2} e^{-z^2}dz} & \leq & \int^b_0 \abs{e^{-(a+iy)^2}i}dy = \int^b_0 \abs{e^{-(a^2-y^2 + 2iay)}i}dy   = e^{-a^2}\int^b_0 e^{y^2}dy \\
& \leq & e^{-a^2} \int^b_0 e^{b^2}dy = b e^{b^2 -a^2} \to 0
\eeast
as $a\to \infty$ since $0\leq y\leq b$. Using a similar argument, the fourth integral can be shown to be zero as $a\to\infty$. Thus, by taking the limit $a\to \infty$ but keeping $b$ fixed, the contour integral around $C$ is found to be equal to the sum of the first and third integrals. That is
\be
0 = \lim_{a\to\infty} \oint_C e^{-z^2}dz = \lim_{a\to\infty} \bb{\int^a_{-a} e^{-x^2}dx - e^{b^2} \int^a_{-a} e^{-x^2}\cos(2bx)dx} + ie^{b^2}\lim_{a\to\infty} \bb{ \int^a_{-a} e^{-x^2}\sin(2bx)dx}.
\ee

Since we know that\footnote{proposition needed.}
\be
\int^\infty_{-\infty} e^{-x^2} dx = \sqrt{\pi},
\ee

we obtain
\be
\int^a_{-a} e^{-x^2}\cos(2bx)dx - i \int^a_{-a} e^{-x^2}\sin(2bx)dx = e^{-b^2}\int^\infty_{-\infty} e^{-x^2} dx  = e^{-b^2}\sqrt{\pi}.
\ee
By equating the imaginary parts of the above equation, we observe
\be
\int^a_{-a} e^{-x^2}\sin(2bx)dx = 0.
\ee

Finally, by Euler formula (Theorem \ref{thm:euler_formula_exponential})
\be
\int^\infty_{-\infty} e^{-x^2} e^{\pm 2ibx}dx = \int^\infty_{-\infty} e^{-x^2} \cos(2bx) dx = e^{-b^2}.
\ee
\end{proof}


\begin{theorem}[Goursat theorem, simply connected set]\label{thm:goursat_simply_connected_set}
Let $f(z)$ be holomorphic throughout a simply connected (open) set $\sD$. Then
\be
\oint_C f(z) dz = 0
\ee
for every closed contour $C$ lying in $\sD$.
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{corollary}
Let $f$ be a holomorphic function throughout a simply connected (open) set $\sD$. Then $f$ has a primitive function $F$ throughout $\sD$.
\end{corollary}

\begin{remark}
The corollary tells us that the entire functions always possess primitive functions.
\end{remark}

\begin{proof}[\bf Proof]% Thus, $\sD$ is a connected set by Proposition \ref{pro:pathwise_connected_implies_connected_complex}.
Since $\sD$ is simply connected, it must be open connected. Then we can get the result from Theorem \ref{thm:contour_integral_primitive_function} and Goursat theorem (Theorem \ref{thm:goursat_simply_connected_set}).
\end{proof}




\subsection{Cauchy's integral formula}

\begin{theorem}
Suppose $f$ is holomorphic in an open set that contains the closure of a disc $D$. If $C$ denotes the boundary circle of this disc with positive orientation, then
\be
f(z) = \frac 1{2\pi i}\int_C \frac{f(\xi)}{\xi-z}d\xi, \qquad \forall z\in D.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

%\begin{theorem}
%Let $f$ be analytic function on and inside contour $C$\footnote{checking needed.}. Then for any point $a$ within the contour $C$. Then
%\be
%f(a) = \frac 1{2\pi i}\int_C\frac{f(z)dz}{z-a}.
%\ee
%\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{theorem}
Suppose $f$ is holomorphic in an open set $X$, then $f$ has infinitely many complex derivatives in $X$. Moreover, if $C\subseteq X$ is a circle whose interior is also contained in $X$, then
\be
f^{(n)}(z) = \frac {n!}{2\pi i}\int_C \frac{f(\xi)}{\bb{\xi-z}^{n+1}}d\xi
\ee
for all $z$ in the interior of $C$.
\end{theorem}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}



%\begin{theorem}\label{thm:differentiation_of_integrals_containing_a_parameter}
%For $t\in \R, z\in \C$, if $f(t,z)$ possesses a Riemann integral with respect to $t$ and $\fp{f(t,z)}{z}$ is a continuous function of both the variables $t$ and $z$, then\footnote{checking needed.}
%\be
%\frac{d}{dz}\bb{\int^b_a f(t,z) dt} = \int^b_a \fp{f(t,z)}{t}dt.
%\ee
%\end{theorem}


%\begin{theorem}
%Let $t\in \R, z\in \C$. Let $f(t,z)$ satisfy the following conditions\footnote{checking needed.} when $t$ lies on a certain path of integration $(a,b)$ and $z$ is any point of a region $S$:
%\ben
%\item [(i)] $f$ and $\fp{f}{z}$ are continuous functions of $t$.
%\item [(ii)] $f$ is an analytic function of $z$.
%\item [(iii)] The continuity of $\fp{f}{z}$ qua function of $z$ is uniform with respect to the variable $t$.
%\een

%Then $\int^b_a f(t,z)dt$ is an analytic function of $z$. Furthermore, it has the unique derivative $\int^b_a \fp{f(t,z)}{z}dt$ (by Theorem \ref{thm:differentiation_of_integrals_containing_a_parameter}).
%\end{theorem}




\begin{theorem}\label{thm:complex_exponential_function_f_integral_exists}
Let $f(t):\R \to \C$ be a continuous complex-valued analytic function with
\be
\abs{f(t)} < Ke^{rt}, \quad \text{where $K$ and $r$ are independent of $t$}.
\ee

Then the integral
\be
\int^\infty_0 e^{-tz}f(t) dt
\ee
is an analytic function of $z$ when $\Re z \geq r_1 >r$.
\end{theorem}


\begin{proof}[\bf Proof]
\footnote{proof needed. see Whittaker and Watson, 4.431(I).}
\end{proof}


\subsection{Cauchy's Residue Theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{proposition}
Let $c$ be $n$th order pole of function $f$\footnote{type needed.}. Then
\be
\res\bsb{f,c} = \frac 1{(n-1)!} \lim_{z\to c} \frac{d^{n-1}}{dz^{n-1}}\bb{(z-c)^n f(z)}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{theorem}[Cauchy's residue theorem\index{Cauchy's residue theorem}]\label{thm:cauchy_residue_complex}
\footnote{need statement.}
\end{theorem}

\begin{example}\label{exa:sinx_over_x_integral}
\be
\lim_{N\to \infty} \int^N_{-N} \frac{\sin x}x dx = \pi.
\ee
\end{example}


\begin{example}\label{exa:sin2x_over_x2_integral}
\be
\int^\infty_{-\infty} \frac{\sin^2 x}{x^2} dx = \pi.
\ee
\end{example}



\section{The Expansion of Functions in Infinite Series}

\subsection{The expansion of a class of functions as infinite fractions}



\subsection{The expansion of a class of functions as infinite products}

\begin{theorem}[the expansion of a class of functions as infinite products]\label{thm:expansion_of_function_infinite_products}
Let $f(z)$ be a complex function which has simple zeros at the point $a_1,a_2,\dots$ with $a_n\neq 0$ where $\lim_{n\to\infty}\abs{a_n}$ is infinite and $f(z)$ be analytic for all values of $z$. Then\footnote{see a course of modern analysis, Whittaker and Watson p137}
\be
f(z) = f(0)e^{\frac{f'(0)}{f(0)}z} \prod^\infty_{n=1}\bb{\bb{1-\frac z{a_n}}e^{\frac{z}{a_n}}}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Since $f(z)$ be analytic for all values of $z$, $f'(z)$ is analytic for all values of $z$ (\footnote{details needed. sec 5.22}), so $\frac{f'(z)}{f(z)}$ can have singularities only the points $a_1,a_2,\dots$. Consequently, by Taylor's theorem (Theorem \footnote{theorem needed.}), for point $a_r$ (with simple zero)%\item Sine function infinite product (see a course of modern analysis, Whittaker and Watson p137)
\be
f(z) = f(a_r) + (z-a_r)f'(a_r) + \frac{(z-a_r)^2}2 f''(a_r)+ \dots = (z-a_r)f'(a_r) + \frac{(z-a_r)^2}2 f''(a_r)+ \dots 
\ee
and
\be
f'(z) = f'(a_r) + (z-a_r)f''(a_r) + \dots.
\ee

It follows immediately that at each of the points $a_r$, the function $\frac{f'(z)}{f(z)}$ has a simple pole, with residue +1\footnote{details needed.}. If then we can find a sequence of circles $c_m$\footnote{of the nature described in sec 7.4}, such that $\frac{f'(z)}{f(z)}$ is bounded on $c_m$ as $m\to \infty$, it follows, from the expansion\footnote{given in sec7.4} that

\be
\frac{f'(z)}{f(z)} = \frac{f'(0)}{f(0)} + \sum^\infty_{n=1}\bb{\frac 1{z-a_n} + \frac 1{a_n}}.
\ee

Since this series converges uniformly when the terms are suitably grouped\footnote{given in sec7.4}, we may integrate term-by-term. Doing so, and taking the exponential of each side, we get
\be
f(z) = ce^{\frac{f'(0)}{f(0)}z} \prod^\infty_{n=1}\bb{\bb{1-\frac z{a_n}}e^{\frac{z}{a_n}}},
\ee
where $c$ is independent of $z$. Putting $z= 0$, we see that $f(0)=c$, and thus the general result becomes
\be
f(z) = f(0)e^{\frac{f'(0)}{f(0)}z} \prod^\infty_{n=1}\bb{\bb{1-\frac z{a_n}}e^{\frac{z}{a_n}}}.
\ee
\end{proof}

\begin{example}%This is actually Theorem\footnote{theorem needed.} 
Let $f(z) = \frac {\sin z}z$, which has simple zeros at the points $k\pi$, where $k$ is any positive or negative integer. In this case we have
\be
f(0) = 1 ,\quad f'(0) = 0
\ee
by L'h\^opital's rule\footnote{theorem needed.} so the theorem gives immediately
\be
\frac{\sin z}{z} = \prod^\infty_{n=1} \bb{\bb{1-\frac z{n\pi}}e^{\frac z{n\pi}}}\bb{\bb{1+\frac z{n\pi}}e^{-\frac z{n\pi}}} =  \prod^\infty_{n=1} \bb{1-\frac {z^2}{n^2\pi^2}}
\ee
for it is easily seen that the condition concerning the behavior of $\frac{f'(z)}{f(z)}$ as $\abs{z}\to \infty$ is fulfilled.\footnote{details needed.}
\end{example}


\begin{example}
For $f(z) = \cos z$, the zeros are at $a_n \in \bra{\pm (2k-1)\pi/2, \ k\in \Z^+}$ with $f(0) = 1$ and $f'(0) = 0$. Therefore, we have
\beast
f(z) & = & f(0) e^{\frac {f'(0)}{f(0)}z}\prod^\infty_{n=1}\bb{\bb{1-\frac z{a_n}}e^{\frac{z}{a_n}}} \\
& = & \prod^\infty_{k=1}\bb{1-\frac z{(2k-1)\pi/2}}\bb{1+\frac z{(2k-1)\pi/2}} = \prod^\infty_{k=1}\bb{1-\frac {4z^2}{(2k-1)^2\pi^2}}.
\eeast

Then for $z = \pi/4$, we have
\beast
0.707 \approx \frac {\sqrt{2}}2 = \cos\bb{\frac {\pi}4} & = & \prod^\infty_{k=1}\bb{1-\frac {1}{4(2k-1)^2}} =  \frac 34 \prod^\infty_{k=2}\bb{1-\frac {1}{4(2k-1)^2}} = \frac 34 \cdot \frac{107}{108} \prod^\infty_{k=3}\bb{1-\frac {1}{4(2k-1)^2}}\\
& = & \frac{107}{144} \prod^\infty_{k=3}\bb{1-\frac {1}{4(2k-1)^2}} = 0.743 \prod^\infty_{k=3}\bb{1-\frac {1}{4(2k-1)^2}} = \dots.
\eeast
\end{example}


%\begin{problem}
%Prove that
%\be
%\bb{1+\bb{\frac kx}^2}\bb{1 + \bb{\frac{k}{x - 2\pi}}^2}\bb{1 + \bb{\frac{k}{x+2\pi}}^2}\bb{1 + \bb{\frac{k}{x-4\pi}}^2}\bb{1 + \bb{\frac{k}{x+ 4\pi }}^2} \dots = \frac{\cosh k - \cos x}{1-\cos x}.\nonumber
%\ee
%\end{problem}
%
%\begin{solution}[\bf Solution.]
%Since the simple zeros are $2n\pi + ki$ for $n\in \Z$, By Theorem \ref{thm:expansion_of_function_infinite_products} we have $f(0) = $ and $f'(0) = $ and thus %\footnote{solution needed.}
%\be
%f(z) = f(0)e^{\frac{f'(0)}{f(0)}z} \prod^\infty_{n=1}\bb{\bb{1-\frac z{a_n}}e^{\frac{z}{a_n}}}.
%\ee
%\end{solution}


\subsection{Applications}

\section{Summary}

complex case: completeness axiom $\ra$ nested set theorem $\ra$ Bolzano-Weierstrass theorem

$\ba{l}
\text{simply connected set} \\
\text{multiply connected set}
\ea$ $\subseteq$ open connected set $\subseteq$ pathwise connected set $\subseteq$ connected set

Let $f(z) = u(x,y) + iv(x,y)$ with $z = x+iy$ and $z_n =x_n + iy_n$. Then
\beast
z_n \text{ converges} & \lra & x_n,y_n\text{ converge}, \\
f(z) \text{ is continuous} & \lra & u(z),v(z)\text{ is continuous}, \\
f(z) \text{ is differentiable} & \lra & u(x,y),v(x,y)\text{ are differentiable } + \text{Cauchy-Riemann equations}.
\eeast

For an open $X$ in $\C$ we have
\beast
\text{$X$ is connected} & \lra & \text{$X$ is pathwise connected}  \\
& \lra & \text{$X$ is smoothly pathwise connected} \\
& \lra & \text{$X$ is piecewise smoothly pathwise connected} \\
& \lra & \text{$X$ is polygonally connected} .
\eeast

Curve is rectifiable, path is continuous.



\section{Problems}



\subsection{Contour integral}



\begin{problem}
Show that
\ben
\item [(i)] $\abs{\int_C (x^2 + iy^2)dz} \leq 2$, where $C$ is the line segment joining $-i$ to $i$.

\item [(ii)] $\abs{\int_C (x^2 + iy^2)dz} \leq \pi$, where $C$ is the right half circle, $\abs{z} =1$ and $\Re z\geq 0$.

\item [(iii] $\abs{\int_C \frac 1{z^2}dz}\leq 2$, where $C$ is the line segment joining $-1+i$ and $1+i$.
\een
\end{problem}

\begin{solution}[\bf Solution.]
\ben
\item [(i)] Using modulus inequality and triangle inequality, we have $z(t) = it$ and 
\be
\abs{x^2 + iy^2} \leq \abs{x^2} + \abs{iy^2} = \abs{x^2}+ \abs{y^2} \leq 1.
\ee

Thus,
\beast
\abs{\int_C (x^2 + iy^2)dz} & = & \abs{\int^1_{-1} (x^2 + iy^2)\frac{dz}{dt} dt} \leq \int^1_{-1} \abs{x^2 + iy^2} dt \\
& \leq & \int^1_{-1} \bb{\abs{x}^2+ \abs{y}^2} dt \leq \int^1_{-1} dt = 2.
\eeast

\item [(ii)] Similar, we use modulus inequality to have $z(t) = e^{it}$, $t\in [-\pi/2,\pi/2]$,
\be
\abs{\int_C (x^2 + iy^2)dz} \leq \int^{\pi/2}_{-\pi/2} \bb{\abs{x}^2 + \abs{y}^2} \abs{ie^{it}} dt = \int^{\pi/2}_{-\pi/2} dt = \pi.
\ee

\item [(iii)] Along the contour $C$, we have $z = t+i$, $t\in [-1,1]$, so $1\leq \abs{z}\leq \sqrt{2}$ and correspondingly,
\be
\frac 12 \leq \frac 1{\abs{z}^2} \leq 1.
\ee

Here, $M := \max_{z\in C} \frac 1{\abs{z}^2} = 1$ and the arc length $L=2$. Then using modulus inequality we have
\be
\abs{\int_C \frac 1{z^2}dz} \leq ML = 1\cdot 2 = 2.
\ee
\een
\end{solution}


\subsection{Power series}



\begin{problem}
Find the radii of convergence of the following power series:
\beast
\text{(i)}\ \sum^\infty_{k=1} \frac 1k (z-i)^k,\quad \text{(ii)}\ \sum^\infty_{k=1} k^{\ln k} (z-2)^k,\quad \text{(iii)} \ \sum^\infty_{k=1}\bb{\frac zk}^k ,\quad \text{(iv)}\ \sum^\infty_{k=1} \bb{1+\frac 1k}^{k^2} z^k,\quad \text{(v)}\ \sum^\infty_{k=1}(-1)^k z^{2k}.
\eeast
\end{problem}

\begin{solution}[\bf Solution.]
\ben
\item [(i)] By ratio test (Proposition \ref{pro:ratio_test_convergence_radius}), we have
\be
R = \lim_{k\to \infty} \frac{\frac 1k}{\frac 1{k+1}} = 1
\ee
so the radius of convergence is $\abs{z-i} = 1$.

\item [(ii)] Using the root test (Proposition \ref{pro:root_test_convergence_radius}), we have
\be
\frac 1R = \lim_{k\to \infty} \sqrt[k]{\abs{a_k}} = \lim_{k\to \infty}\sqrt[k]{k^{\ln k}}.
\ee

To evaluate the limit, we consider the logarithm since it is continuous,
\be
\ln \bb{\lim_{k\to \infty}\sqrt[k]{k^{\ln k}}} = \lim_{k\to \infty}\ln \bb{\sqrt[k]{k^{\ln k}}} = \lim_{k\to \infty} \frac{\bb{\ln k}^2}k = 0.
\ee

So we have
\be
\frac 1R = \lim_{k\to \infty}\sqrt[k]{k^{\ln k}} = e^0 = 1.
\ee

The radius of convergence is $\abs{z-2} =1$.

\item [(iii)] By the ratio test (Proposition \ref{pro:ratio_test_convergence_radius}), we have
\be
\frac 1R = \lim_{k\to \infty} \frac{\bb{\frac 1{k+1}}^{k+1}}{\bb{\frac 1k}^k} = \lim_{k\to \infty} \frac 1{k+1} \lim_{k\to \infty} \frac 1{\bb{1+\frac 1k}^k} = 0 \cdot \frac 1e = 0.
\ee

So the radius of convergence is the whole complex plane.

\item [(iv)] By the root test (Proposition \ref{pro:root_test_convergence_radius}), we have
\be
\frac 1R = \lim_{k\to \infty} \sqrt[k]{\bb{1+\frac 1k}^{k^2}} = \lim_{k\to \infty}\bb{1+\frac 1k}^k = e,
\ee
so the radius of convergence is $\abs{z} = \frac 1e$.

\item [(v)] The coefficients are of the form
\be
a_n = \left\{\ba{ll}
0 & n\neq 2^k \\
(-1)^k \quad\quad & n= 2^k
\ea\right.
\ee
so
\be
\frac 1R = \limsup_{n\to \infty} \sqrt[n]{\abs{a_n}} = 1.
\ee

The radius of convergence is then found to be $\abs{z} =1$.
\een
\end{solution}

