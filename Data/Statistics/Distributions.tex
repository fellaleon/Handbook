
\chapter{Distributions}

\section{Distributions Related to Poisson Distribution}

\subsection{Skellam distribution}

\begin{definition}[Skellam random variables]\label{def:skellam_rv}
A random variable $X$ in $\Z$ is Skellam distributed\index{Skellam random variable} if, for $\lm_1,\lm_2>0$, has probability mass function
\be
\pro(X=k) = e^{-(\lm_1+ \lm_2)} \brb{\frac{\lm_1 }{\lm_2}}^{k/2} I_k\brb{2\sqrt{\lm_1\lm_2}},\qquad  k\in \bra{\dots,-1,0,1,\dots}.
\ee
where $I_k(\cdot)$ is the modified Bessel function of the first kind. We write $X\sim \sked(\lm_1,\lm_2)$.%
\end{definition}

\begin{proposition}
For $X_1\sim \pd(\lm_1)$ and $X_2 \sim \pd(\lm_2)$, we have that
\be
X_1 - X_2 \sim \sked (\lm_1,\lm_2).
\ee
\end{proposition}


\begin{remark}
This distribution is usually applied to model the goal difference of football matches as the goal number of each team can be considered as Poisson distributed random variable.
\end{remark}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}\label{pro:pgf_poisson}
Suppose $X\sim \sked(\lm_1,\lm_2)$. Then for $z,\theta,t\in \R$,
\be
G_X(z) = \exp\brb{\lm_1(z-1) + \lm_2\brb{\frac 1z-1}},\qquad M_X(\theta) = e^{-(\lm_1+\lm_2)} \exp\brb{\lm_1 e^\theta + \lm_2e^{-\theta}} ,
\ee
\be
\phi_X(t) = e^{-(\lm_1+\lm_2)} \exp\brb{\lm_1 e^{it} + \lm_2e^{-it}} .
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Suppose $X\sim \sked(\lm_1,\lm_2)$. Then
\beast
\text{(i)}\ \E X = \lm_1 - \lm_2 ,\quad\quad \text{(ii)}\ \var X = \lm_1 + \lm_2,
\eeast
\beast
\text{(iii)}\ \skewness(X) = \frac{\lm_1 - \lm_2}{\brb{\lm_1+\lm_2}^{3/2}},\quad\quad\text{(iv)}\ \ekurt(X) = \frac 1{\lm_1 + \lm_2}.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}[bounds on weight above zero]
Let $X\sim \sked(\lm_1,\lm_2)$ with $\lm_1<\lm_2$. Then
\beast
\frac{\exp\brb{-\brb{\sqrt{\lm_1}- \sqrt{\lm_2}}^2}}{(\lm_1 +\lm_2)^2} - \frac{\exp\brb{-(\lm_1 + \lm_2)}}{2\sqrt{\lm_1\lm_2}} - \frac{\exp\brb{-(\lm_1 + \lm_2)}}{4\lm_1\lm_2} \leq \pro(X\geq 0) \leq \exp\brb{-\brb{\sqrt{\lm_1}- \sqrt{\lm_2}}^2}
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\section{Distributions Related to Uniform Distribution}

\subsection{Distributions in spherical space}


\begin{proposition}
Let $V$ be a unit vector with random direction in $\R^2$. Let $L$ be the length of the projection of $V$ on a fixed line, say the $x$-axis. Then $L$ has density function
\be
f_L(x) = \frac{2}{\pi\sqrt{1-x^2}}, \qquad x\in (0,1)
\ee
and $\E L = 2/\pi$.
\end{proposition}

\begin{proof}[\bf Proof]
Let $\theta$ be the angle between the random direction and the $y$-axis, then $L = \abs{\sin \theta}$ and hence for $0<x<1$ we get by symmetry
\be
\pro\brb{L \leq x} = \pro\brb{0<\theta< \arcsin x} = \frac 2{\pi} \arcsin x.
\ee

Then the assertion follows by differentiation.
\end{proof}

Note that the projections might be different types based on different numbers of dimensions.

\begin{proposition}
Let $V$ be a unit vector with random direction in $\R^3(x_1,x_2,x_3)$.
\ben
\item [(i)] Let $L$ be the length of the projection of $V$ on a fixed line, say the $x$-axis. Then $L\sim \sU[0,1]$ and $\E L = \frac 12$.
\item [(ii)] Let $U$ be the length of the projection of $V$ on a fixed plane, say $x,y$-plane. Then $U$ has density function
\be
f_U(u) = \frac{u}{\sqrt{1-u^2}},\qquad u\in (0,1)
\ee
with $\E U =\pi/4$.
\een
\end{proposition}

\begin{proof}[\bf Proof]
Recall Theorem \ref{thm:spherical_area_between_parallel_planes_proportional_to_height}, we have for $0<t<1$, the event $\bra{L\leq t}$ is represented by the zone $\abs{x_1}\leq t$ of height $2t$. Therefore, the probability of $\bra{L\leq t}$ is $2t/2 = t$. Thus, $U$ is uniformly distributed, that is $U \sim \sU[0,1]$.

With the same argument, we have that for $0<u<1$, the event $\bra{U\leq u}$ is represented by the zone $\abs{x_3} \geq \sqrt{1-u^2}$ of total height $2-2\sqrt{1-u^2}$. Then
\be
\pro\brb{U\leq u} = \frac{2-2\sqrt{1-u^2}}2 = 1 -\sqrt{1-u^2}.
\ee

Then the density is given by it differentiation
\be
f_U(u) = - \frac 12 \cdot (-2u) (1-u^2)^{-1/2} =  \frac{u}{\sqrt{1-u^2}}.
\ee

Then its expectation is
\beast
\int^1_0 \frac{u^2}{\sqrt{1-u^2}}du & = & \int^{\pi/2}_0 \frac{\sin^2\theta}{\cos \theta} d\sin\theta = \int^{\pi/2}_0 \sin^2\theta d\theta = \frac 12\int^{\pi/2}_0 \brb{1- \cos 2\theta} d\theta = \frac {\pi}4.
\eeast
\end{proof}

\section{Distributions Related to Gaussian Distribution}

\subsection{Gaussian distribution}

Recall Definition \ref{def:gaussian_rv}
\be
\phi(x) = \frac 1{\sqrt{2\pi}}e^{-x^2/2},
\ee
we see that the important points of the standard normal distribution function are
\begin{table}[hp]\label{tab:guassian_distribution_confidence_level}
\caption{Gaussian distribution confidence level}
\begin{center}
\begin{tabular}{cccccc}
$x$ & 1.2816 & 1.6449 & 1.9600 & 2.3263 & 2.5758 \\
\hline
$\Phi(x)$ & 0.900 & 0.950 & 0.975 & 0.990 & 0.995\\
\end{tabular}
\end{center}
\end{table}

The third of these points leads to an important observation: for $X \sim \sN\brb{\mu,\sigma^2}$,

\be
\pro\brb{\mu-2\sigma \leq X \leq \mu + 2\sigma} = \pro\brb{\abs{\frac{X-\mu}{\sigma} }\leq 2} \geq \pro\brb{\abs{\frac{X-\mu}{\sigma} } \leq 1.96} = 0.95,
\ee

\begin{center}
\psset{yunit=8cm,xunit=2cm}
\begin{pspicture}(-4,-0.1)(4,0.5)
% \psgrid[griddots=10,gridlabels=0pt, subgriddiv=0]
\psaxes[Dy=0.1]{->}(0,0)(-4.2,0)(4.2,0.5)%Dy=0.25,dy=0.25
%\rput[-90]
\rput[lb](-3,0.3){standard normal pdf}
\rput[lb](-2.5,0.15){$x= -1.96$}
\rput[lb](1.6,0.15){$x= 1.96$}
\rput[lb](2.8,0.15){Area = 0.025}
\rput[lb](0.1,0.42){$\phi(x)$}

%\pstGeonode[PointSymbol=*,PointName=none,dotscale=1](-1.96){AA}%(0,4){B}
\psGauss[sigma=1,mue=0,linecolor=black,linewidth=1pt]{-4}{4}%
%\psGaussI[linewidth=1pt]{-2}{2}%
%\psGauss[linecolor=green, mue=0.6, linewidth=2pt]{-1.75}{1.75}%cyan
%\psGauss[sigma=1, linecolor=blue, linewidth=2pt]{-1.75}{1.75}
\pscustom[fillstyle=solid,fillcolor=red!30]{%linestyle=dashed,
\psline(-1.96,0)(-3,0)
\psGauss[sigma=1,mue=0,linecolor=black,linewidth=1pt]{-4}{-1.96}
}%

\pscustom[fillstyle=solid,fillcolor=red!30]{%linestyle=dashed,
\psGauss[sigma=1,mue=0,linecolor=black,linewidth=1pt]{1.96}{4}
\psline(3,0)(1.96,0)}%

\psline[linestyle=dashed](-1.96,0)(-1.96,0.14)
\psline[linestyle=dashed](1.96,0)(1.96,0.14)
\psline{->}(2.7, 0.13)(2.3, 0.05)
\end{pspicture}
\end{center}

which is usually summed up in the statement ``more than 95\% of the normal distribution is within two standard deviations of the mean".



\subsection{Chi-squared random variables}

\begin{definition}[chi-squared random variable]\label{def:chi_squared_rv}
If $Z_1, \dots, Z_k$ are independent, standard normal random variables, then the sum of their squares,
\be
X = \sum_{i=1}^k Z_i^2,
\ee
is called chi-squared distributed\index{chi squared-distributed random variable} with $k\in \N$ degrees of freedom. Its density function is
\be
f_X(x) = \frac{1}{\Gamma\left(k/2\right)} 2^{-k/2} x^{k/2-1} e^{-x/2},\qquad x\in [0,\infty)
\ee

We write $X \sim \chi_k^2$.
\end{definition}

\begin{center}
 \psset{xunit=1.2cm,yunit=10cm,plotpoints=200}
 \begin{pspicture*}(-0.75,-0.1)(9.5,.65)
% \rput[lb](5,0.5){blue!\iblue=1{$k=0.5$}}
\rput[lb](0.6,0.5){\textcolor{red}{$k=1$}}
\rput[lb](6,0.15){\textcolor{blue}{$k=5$}}
 %\rput[lb](5,0.4){\textcolor{blue}{$k=1.2$, $\lambda =0.5$}}
 %\rput[lb](5,0.3){\textcolor{green}{$k=2$, $\lambda =0.5$}}
 \multido{\rnue=0.5+0.5,\iblue=0+10}{10}{% from k=1 to k=5 with step 0.5
 \psChiIIDist[linewidth=1pt,linecolor=blue!\iblue,nue=\rnue]{0.01}{9}}
 \psChiIIDist[linewidth=1pt,linecolor=red,nue=1]{0.01}{9}
 \psaxes[Dy=0.1]{->}(0,0)(9.5,.6)
 \end{pspicture*}
\end{center}


\begin{proposition}\label{pro:pdf_chi_squared}
Suppose that $X \sim \chi_k^2$. Then its density function is the form in Definition \ref{def:chi_squared_rv}.
\end{proposition}

\begin{proof}[\bf Proof]
We start from the case $k=1$,
\be
\pro\brb{X\leq x} = \pro\brb{Z^2 \leq x} = \pro\brb{-\sqrt{x} \leq Z \leq \sqrt{x}} = \frac 1{\sqrt{2\pi}} \int^{\sqrt{x}}_{-\sqrt{x}} e^{-y^2/2}dy.
\ee

Then taking the differentiation, we have ($\Gamma(1/2) = \sqrt{\pi}$ from Proposition \ref{pro:gamma_half_values})
\be
f_X(x) = \frac 1{\sqrt{2\pi}}2\brb{\frac 12 x^{-1/2}e^{-x/2} } = \frac 1{\sqrt{2\pi}} x^{-1/2}e^{-x/2} = \frac 1{\Gamma(1/2)}2^{-1/2}x^{1/2-1}e^{-x/2}.
\ee

Now assume the formula is true for $k-1$ degree. With the convolution of density functions, we have
\beast
f_X^k(x) & = & \int^x_0 f^{k-1}_X(y)f_X^1(x-y)dy = \int^x_0 \frac{1}{\Gamma\left((k-1)/2\right)} 2^{-(k-1)/2} y^{(k-1)/2-1} e^{-y/2} \frac 1{\sqrt{2\pi}} (x-y)^{-1/2}e^{-(x-y)/2} dy\\
& = &  2^{-k/2}  e^{-x/2}  \int^x_0 \frac 1{\Gamma(1/2)} \frac{1}{\Gamma\left((k-1)/2\right)}y^{(k-1)/2-1}  (x-y)^{-1/2} dy \\
& = & \frac 1{\Gamma(k/2)}2^{-k/2} x^{k/2-1} e^{-x/2}  \int^1_0 \frac{1}{B(1/2, (k-1)/2)}z^{(k-1)/2-1}  (1-z)^{-1/2} dz = \frac 1{\Gamma(k/2)}2^{-k/2} x^{k/2-1} e^{-x/2}.
\eeast
by Beta distribution.
\end{proof}

\begin{proposition}\label{pro:mgf_chi_squared}
Suppose $X \sim \chi_k^2$. Then for $\theta < \frac 12$ and $t\in \R$,
\be
M_X(\theta) = \brb{\frac 1{1 - 2\theta}}^{k/2},\quad\quad \phi_X(t) =  \brb{\frac 1{1 - 2it}}^{k/2}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
From Definition \ref{def:mgf_probability},
\beast
M_X(\theta) & = & \E\brb{e^{\theta X}} = \int^\infty_0 e^{\theta x} \frac{1}{\Gamma\left(k/2\right)} 2^{-k/2} x^{k/2-1} e^{-x/2} dx \\
& = & \brb{\frac{1/2}{1/2-\theta}}^{k/2} \int^\infty_0 \frac{1}{\Gamma\left(k/2\right)} 2^{-k/2} \brb{\frac{(1/2-\theta)}{1/2} x}^{k/2-1} e^{-\brb{\frac{(1/2-\theta)}{1/2}}x/2} d \frac{(1/2-\theta)}{1/2}x \\
& = & \brb{\frac 1{1 - 2\theta}}^{k/2} \int^\infty_0 \frac{1}{\Gamma\left(k/2\right)} 2^{-k/2} y^{k/2-1} e^{-y/2} d y =  \brb{\frac 1{1 - 2\theta}}^{k/2}.
\eeast

Similarly for $\phi_X(t)$.
\end{proof}

\begin{proposition}\label{pro:moments_chi_squared}
Suppose $X \sim \chi_k^2$. Then \beast \text{(i)}\ \E X = k,\quad \text{(ii)}\ \var X = 2k,\quad\text{(iii)}\ \skewness(X) = \sqrt{8/k},\quad\text{(iv)}\ \ekurt(X) = 12/k. \eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
With Propositions \ref{pro:mgf_chi_squared}, \ref{pro:mgf_finite_moment},
\beast
\E X = \left.\frac {d M_X(\theta)}{d\theta}\right|_{\theta=0} = \left. k(1 -2\theta)^{-k/2-1}\right|_{\theta=0} = k,\qquad \E X^2 = \left.\frac {d^2 M_X(\theta)}{d\theta^2}\right|_{\theta=0} = \left. k(k+2)(1 -2\theta)^{-k/2-2} \right|_{\theta=0} = k^2 + 2k.
\eeast

Thus, $\var X = \E X^2 - \brb{\E X}^2 = k^2 + 2k - k^2 = 2k$. Also,
\be
\E X^3 = \left.\frac {d^3 M_X(\theta)}{d\theta^3}\right|_{\theta=0} = \left. k(k+2)(k+4)(1 -2\theta)^{-k/2-3}  \right|_{\theta=0} = k(k+2)(k+4).
\ee

Thus,
\be
\E\brb{X-\mu}^3 = \E X^3 - 3\mu\E X^2 + 3\mu^2 \E X - \mu^3 =  k(k+2)(k+4) - 3k (k^2 + 2k) + 2k^3 = 8k.
\ee

By Definition \ref{def:skewness}, $\skewness(X) = \frac{8k}{(2k)^{3/2}} = \sqrt{8/k}$. Furthermore,
\be
\E X^4 = \left.\frac {d^4 M_X(\theta)}{d\theta^4}\right|_{\theta=0} = \left. k(k+2)(k+4)(k+6)(1 -2\theta)^{-k/2-4} \right|_{\theta=0}  = k(k+2)(k+4)(k+6).
\ee

Thus,
\beast
\E\brb{X-\mu}^4 & = & \E X^4 - 4\mu\E X^3 + 6\mu^2 \E X^2 - 4\mu^3\E X + \mu^4 \\
& = & k(k+2)(k+4)(k+6) - 4k k(k+2)(k+4) + 6k^3 (k+ 2) - 3k^4 = 12k^2 + 48k.
\eeast

By Definition \ref{def:kurtosis}, we have $\ekurt(X) = \frac{12k^2+48k}{4k^2} -3 = 12/k$.%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,be\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.\ee
\end{proof}

We can extend to more general case.%\footnote{need general chi-squared distribution}

\begin{definition}[non-central chi-squared random variable]\label{def:chi_squared_rv_non_central}
Let $Z_i$ be $k$ independent, normally distributed random variables with means $\mu_i$ and variances $\sigma_i^2$. Then the random variable
\be
X = \sum_{i=1}^k \left(\frac{Z_i}{\sigma_i}\right)^2
\ee
is distributed according to the noncentral chi-squared distribution. It has two parameters: $k$ which specifies the number of degrees of freedom (i.e. the number of $Z_i$), and $\lm$ which is related to the mean of the random variables $Z_i$ by:
\be
\lm = \sum_{i=1}^k \left(\frac{\mu_i}{\sigma_i}\right)^2.
\ee

$\lm$ is called the noncentrality parameter. It density function is
\be
f_X(x) = \frac{1}{2}e^{-(x+\lm)/2}\left (\frac{x}{\lm} \right)^{k/4-1/2} I_{k/2-1}\brb{\sqrt{\lambda x}}
\ee
where $I_\nu(z)$ is modified Bessel function of the first kind. We write $X \sim \chi^2_k(\lm)$.
\end{definition}

\begin{remark}
If $\lm \to 0$, from Proposition \ref{pro:modified_bessel_function_first_close_to_zero} (if $z\to 0$, $I_\nu(z) \sim \left.\brb{\frac 12z}^\nu\right/\Gamma(\nu+1)$) we have
\be
f_X(x) \sim \frac{1}{2}e^{-(x+\lm)/2}\left (\frac{x}{\lm} \right)^{k/4-1/2} \left.\brb{\frac 12\sqrt{\lm x}}^{k/2-1}\right/\Gamma(k/2) = \frac 1{\Gamma(k/2)}2^{-k/2}x^{k/2-1} e^{-x/2}
\ee
which is consistent with Definition \ref{def:chi_squared_rv}
\end{remark}

\begin{proposition}\label{pro:pdf_chi_squared_non_central}
Suppose that $X \sim \chi_k^2(\lm)$. Then its density function is the form in Definition \ref{def:chi_squared_rv_non_central}.
\end{proposition}

\begin{proof}[\bf Proof]
We start from the case $k=1$,
\be
\pro\brb{X\leq x} = \pro\brb{Z^2 \leq \sigma^2x} = \pro\brb{-\sigma\sqrt{x} \leq Z \leq \sigma\sqrt{x}} = \frac 1{\sqrt{2\pi}\sigma} \int^{\sigma\sqrt{x}}_{-\sigma\sqrt{x}} e^{-(y-\mu)^2/2\sigma^2}dy.
\ee

Then taking the differentiation, we have ($\Gamma\brb{\frac 12 +n} = \frac{(2n)!}{4^n n!}\sqrt{\pi}$ from Proposition \ref{pro:gamma_half_values})%{pro:gamma_half})
\beast
f_X(x) & = & \frac {\sigma}{\sqrt{2\pi}\sigma}\brb{\frac 12 x^{-1/2}e^{-(\sigma\sqrt{x}-\mu)^2/2\sigma^2} + \frac 12 x^{-1/2}e^{-(\sigma\sqrt{x}+\mu)^2/2\sigma^2}} = \frac 12 e^{-(x+\lm)/2} x^{-1/2} \frac 1{\sqrt{2\pi}} \brb{e^{\frac{\mu}{\sigma}\sqrt{x}} + e^{-\frac{\mu}{\sigma}\sqrt{x}}} \\
& = & \frac 12 e^{-(x+\lm)/2} x^{-1/2} \frac 1{\sqrt{2\pi}} \brb{2\sum^\infty_{n=0} \frac{(\sqrt{\lm x})^{2n}}{(2n)!}} = \frac 12 e^{-(x+\lm)/2} x^{-1/2} \brb{\sqrt{2}\sum^\infty_{n=0} \frac{(\lm x)^{n}}{(2n)!\sqrt{\pi}}} \\
& = & \frac 12 e^{-(x+\lm)/2} x^{-1/2} \brb{\sqrt{2}\sum^\infty_{n=0} \frac{(\lm x)^{n}}{\Gamma\brb{\frac 12 + n}4^n n!}} = \frac 12 e^{-(x+\lm)/2} x^{-1/2} \sqrt{2} \brb{\frac 2{\sqrt{\lm x}}}^{-\frac 12} I_{-1/2}(\sqrt{\lm x}).
\eeast %Proposition \ref{pro:modified_bessel_function_first_ascending_series}
by Definition \ref{def:modified_bessel_function_first_kind} ($I_\nu(z) = \brb{\frac 12 z}^\nu \sum^\infty_{k=0} \frac{\brb{\frac 14z^2}^k}{k!\Gamma(\nu+k+1)}$). This result is consistent with Definition \ref{def:chi_squared_rv_non_central}.

Now assume the formula is true for $k-1$ degree. With the convolution of density functions, we have $\lm = \sum^{k-1}_{i=0} \brb{\frac{\mu_i}{\sigma_i}}^2$ and $\lm' = \brb{\frac{\mu_k}{\sigma_k}}^2$, the density function $f_X^k(x)$ is
\beast
\int^x_0 f^{k-1}_X(y)f_X^1(x-y)dy & = &  \int^x_0 \frac{1}{2}e^{-(y+\lm)/2}\left (\frac{y}{\lm} \right)^{k/4-3/4} I_{k/2-3/2}\brb{\sqrt{\lambda y}} \frac{1}{2}e^{-(x-y+\lm')/2}\left (\frac{x-y}{\lm'} \right)^{-1/4} I_{-1/2}\brb{\sqrt{\lm' (x-y)}}  dy\\
& = & \frac 12  e^{-(x + \lm + \lm')/2} \int^x_0 \frac{1}{2} \left (\frac y{\lm } \right)^{k/4-3/4} I_{k/2-3/2}\brb{\sqrt{\lm y}} \left (\frac {x-y}{\lm'} \right)^{-1/4} I_{-1/2}\brb{\sqrt{\lm' (x-y)}}  dy
\eeast

Thus,
\beast
I & := & \int^x_0 \frac{1}{2} \left (\frac y{\lm } \right)^{k/4-3/4}  \left (\frac {x-y}{\lm'} \right)^{-1/4} I_{k/2-3/2}\brb{\sqrt{\lm y}} I_{-1/2}\brb{\sqrt{\lm' (x-y)}}  dy \\
& = & \int^x_0 \frac{1}{2} \left (\frac y{\lm } \right)^{k/4-3/4}  \left (\frac {x-y}{\lm'} \right)^{-1/4} \brb{\frac 12 \sqrt{\lm y}}^{k/2-3/2} \brb{\frac 12\sqrt{\lm' (x-y)}}^{-1/2} \sum^\infty_{n=0} \frac{\brb{\frac 14 \lm y}^n}{n!\Gamma((k-1)/2 + n)}  \sum^\infty_{m = 0}\frac{\brb{\frac 14 \lm' (x-y)}^m}{m!\Gamma(1/2 + m)}   dy \\
& = & \int^x_0 \brb{\frac{1}{2}}^{k/2-1} y^{k/2-3/2}  (x-y)^{-1/2} \sum^\infty_{n=0} \frac{\brb{\frac 14 \lm y}^n}{n!\Gamma((k-1)/2 + n)}  \sum^\infty_{m = 0}\frac{\brb{\frac 14 \lm' (x-y)}^m}{m!\Gamma(1/2 + m)}   dy .
\eeast

%Again, by Proposition \ref{pro:gamma_half} ($\Gamma\brb{1/2 +n} = \frac{(2n)!}{4^n n!}\sqrt{\pi}$),
%\beast
%I & = & \int^x_0 \brb{\frac{1}{2}}^{k/2-1} \left (\frac {y^2}{x} \right)^{k/4-3/4}  \left (\frac {(x-y)^2}{x} \right)^{-1/4} \sum^\infty_{n=0} \frac{\brb{\frac 14 \lm y}^n}{n!\Gamma((k-1)/2 + n)}  \sum^\infty_{m = 0}\frac{\brb{\lm' (x-y)}^m}{(2m)!\sqrt{\pi}}   dy \\
%& = & \int^x_0 \brb{\frac{1}{2}}^{k/2-1} \left (\frac {y^2}{x} \right)^{k/4-3/4}  \left (\frac {(x-y)^2}{x} \right)^{-1/4} \frac 1{2\sqrt{\pi}} \brb{e^{\sqrt{\lm' (x-y)}} + e^{-\sqrt{\lm' (x-y)}}} \sum^\infty_{n=0} \frac{\brb{\frac 14 \lm y}^n}{n!\Gamma((k-1)/2 + n)}    dy.
%\eeast

%\beast
%& = & \\
%& = & \frac 1{\Gamma(k/2)}2^{-k/2} x^{k/2-1} e^{-x/2}  \int^1_0 \frac{1}{B(1/2, (k-1)/2)}z^{(k-1)/2-1}  (1-z)^{-1/2} dz = \frac 1{\Gamma(k/2)}2^{-k/2} x^{k/2-1} e^{-x/2}.
%\eeast
%by Beta distribution.

Then by Proposition \ref{pro:modified_bessel_function_first_ascending_series},
\beast
I & = & \sum^\infty_{n=0}  \sum^\infty_{m = 0}\brb{\frac{1}{2}}^{k/2-1} \frac{\brb{\frac 14 \lm }^n \brb{\frac 14 \lm' }^m}{n!m!}\int^x_0  \frac{\brb{y}^{n+k/2-3/2}(x-y)^{m-1/2}}{\Gamma((k-1)/2 + n)\Gamma(1/2 + m)} dy \\
& = & \sum^\infty_{n=0}  \sum^\infty_{m = 0}\brb{\frac{1}{2}}^{k/2-1} \frac{\brb{\frac 14 \lm }^n \brb{\frac 14 \lm' }^m x^{k/2+n+m-1}}{n!m!\Gamma(k/2+n+m)} = \brb{\frac{1}{2}}^{k/2-1} \sum^\infty_{l=0} \frac{x^{k/2+l-1}}{\Gamma(k/2+l)} \sum^l_{n = 0} \frac{\brb{\frac 14 \lm }^n \brb{\frac 14 \lm' }^{l-n} }{n!(l-n)!} \\
& = &  \brb{\frac{x}{2}}^{k/2-1} \sum^\infty_{l=0} \frac{\brb{\frac 14(\lm  + \lm')x}^l}{l!\Gamma(k/2+l)}  =   \brb{\frac{x}{2}}^{k/2-1}\brb{\frac 2{\sqrt{(\lm+\lm')x}}}^{k/2 -1 } I_{k/2-1}\brb{\sqrt{(\lm + \lm')x}}
\eeast
as required. Note that the density function can also be achieved by the product of moment generating function.
\end{proof}

\begin{proposition}\label{pro:mgf_chi_squared_non_central}
Suppose $X \sim \chi_k^2(\lm)$. Then for $\theta < \frac 12$ and $t\in \R$,
\be
M_X(\theta) = \frac{\exp\left(\frac{ \lm \theta}{1-2\theta }\right)}{(1-2 \theta)^{k/2}} ,\quad\quad \phi_X(t) =  \frac{\exp\left(\frac{i \lm t}{1-2it }\right)}{(1-2 it)^{k/2}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
From Definition \ref{def:mgf_probability},
\beast
M_X(\theta) & = & \E\brb{e^{\theta X}} = \int^\infty_0 e^{\theta x} \frac{1}{2}e^{-(x+\lm)/2}\left (\frac{x}{\lm} \right)^{k/4-1/2} I_{k/2-1}\brb{\sqrt{\lambda x}} dx \\
& = & \brb{\frac 1{1-2\theta}}^{k/4-1/2} \int^\infty_0 \frac{1}{2}e^{-(x(1-2\theta)+\lm)/2}\left (\frac{x(1-2\theta)}{\lm} \right)^{k/4-1/2} I_{k/2-1}\brb{\sqrt{\frac{\lambda}{(1-2\theta)} x(1-2\theta)}} dx \\
& = & \brb{\frac 1{1-2\theta}}^{k/4+1/2} \int^\infty_0 \frac{1}{2}e^{-(x+\frac{\lm}{1-2\theta})/2}\left (\frac{x}{\lm} \right)^{k/4-1/2} I_{k/2-1}\brb{\sqrt{\frac{\lambda}{(1-2\theta)} x}} dx \\
& = & \brb{\frac 1{1-2\theta}}^{k/2} \int^\infty_0 \frac{1}{2}e^{-(x+\frac{\lm}{1-2\theta})/2}e^{-\lm \brb{1-\frac 1{1-2\theta}}/2}\left (\frac{x(1-2\theta)}{\lm} \right)^{k/4-1/2} I_{k/2-1}\brb{\sqrt{\frac{\lambda}{(1-2\theta)} x}} dx \\
& = & \frac{\exp\left(\frac{ \lm \theta}{1-2\theta }\right)}{(1-2 \theta)^{k/2}}.
\eeast

Similarly for $\phi_X(t)$.
\end{proof}


\begin{proposition}\label{pro:moments_chi_squared_non_central}
Suppose $X \sim \chi_k^2(\lm)$. Then \beast \text{(i)}\ \E X = k + \lm,\quad \text{(ii)}\ \var X = 2(k + 2\lm),\quad\text{(iii)}\ \skewness(X) = \frac{2^{3/2}(k+3\lambda)}{(k+2\lambda)^{3/2}},\quad\text{(iv)}\ \ekurt(X) =
\frac{12(k+4\lambda)}{(k+2\lambda)^2}. \eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
With Propositions \ref{pro:mgf_chi_squared_non_central}, \ref{pro:mgf_finite_moment},
\beast
\E X & = & \left.\frac {d M_X(\theta)}{d\theta}\right|_{\theta=0} = \left. k(1 -2\theta)^{-k/2-1}\exp\brb{\frac{ \lm \theta}{1-2\theta }} + \lm (1 -2\theta)^{-k/2-2}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \right|_{\theta=0} \\
& = & \left.(1 -2\theta)^{-k/2-2}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \brb{k(1-2\theta)+ \lm} \right|_{\theta=0} = k + \lm.
\eeast

\beast
\E X^2 & = & \left.\frac {d^2 M_X(\theta)}{d\theta^2}\right|_{\theta=0} = \left. (1 -2\theta)^{-k/2-4}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \brb{\brb{(k+4)(1-2\theta) + \lm}\brb{k(1-2\theta)+ \lm} -2k(1-2\theta)^2  }   \right|_{\theta=0} \\
& = & \left. (1 -2\theta)^{-k/2-4}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \brb{k(k+2)(1-2\theta)^2 + 2\lm (k+2)(1-2\theta)+ \lm^2  }   \right|_{\theta=0} = k(k + 2) + 2\lm(k+2) + \lm^2.
\eeast

Thus, $\var X = \E X^2 - \brb{\E X}^2 = k(k + 2) + 2\lm(k+2) + \lm^2 - \brb{k+\lm}^2 = 2(k+2\lm)$. Also,
\beast
& & \E X^3 = \left.\frac {d^3 M_X(\theta)}{d\theta^3}\right|_{\theta=0} \\
& = & \left. (1 -2\theta)^{-k/2-6}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \brb{(k+8)(1-2\theta) + \lm}\brb{k(k+2)(1-2\theta)^2 + 2\lm (k+2)(1-2\theta)+ \lm^2  } \right|_{\theta=0} \\
&  & \qquad +\left. (1 -2\theta)^{-k/2-6}\exp\brb{\frac{ \lm \theta}{1-2\theta }} (1-2\theta)^2 \brb{-4k(k+2)(1-2\theta) - 4\lm(k+2)} \right|_{\theta=0} \\
& = & \left. (1 -2\theta)^{-k/2-6}\exp\brb{\frac{ \lm \theta}{1-2\theta }} \brb{k(k+2)(k+4)(1-2\theta)^3 + 3\lm(k + 2)(k+4)(1-2\theta)^2 + 3\lm^2(k+4)(1-2\theta) + \lm^3} \right|_{\theta=0}\\
& = & k(k+2)(k+4) + 3\lm(k+2)(k + 4) + 3\lm^2(k+4) + \lm^3.
\eeast

Thus,
\beast
& & \E\brb{X-\mu}^3 = \E X^3 - 3\mu\E X^2 + 3\mu^2 \E X - \mu^3 \\
& = & k(k+2)(k+4) + 3\lm(k+2)(k + 4) + 3\lm^2(k+4) + \lm^3 - 3(k+\lm)\brb{k(k + 2) + 2\lm(k+2) + \lm^2} + 2(k+\lm)^3 \\
& = & 8k + 24\lm.
\eeast

By Definition \ref{def:skewness}, $\skewness(X) = \frac{8k+24\lm}{2^{3/2}(k+2\lm)^{3/2}} = \frac{2^{3/2}(k+3\lm)}{(k+2\lm)^{3/2}}$. Furthermore,
\beast
& & \E X^4 = \left.\frac {d^4 M_X(\theta)}{d\theta^4}\right|_{\theta=0} \\
& = & \left. \frac{(k+12)(1-2\theta)+\lm} {(1 -2\theta)^{k/2+8}}e^{\frac{ \lm \theta}{1-2\theta }}\brb{k(k+2)(k+4)(1-2\theta)^3 + 3\lm(k + 2)(k+4)(1-2\theta)^2 + 3\lm^2(k+4)(1-2\theta) + \lm^3} \right|_{\theta=0}\\
& & \qquad + \left. \frac{(1 -2\theta)^2} {(1 -2\theta)^{k/2+8}}e^{\frac{ \lm \theta}{1-2\theta }}\brb{-6k(k+2)(k+4)(1-2\theta)^2 - 12\lm(k + 2)(k+4)(1-2\theta) - 6\lm^2(k+4)} \right|_{\theta=0}\\
& = & \left.  e^{\frac{ \lm \theta}{1-2\theta }}\frac{(k+6)\brb{k(k+2)(k+4)(1-2\theta)^4 + 4\lm(k + 2)(k+4)(1-2\theta)^3 + 6\lm^2(k+4)(1-2\theta)^2 + 4\lm^3(1-2\theta)} + \lm^4}{(1 -2\theta)^{k/2+8}} \right|_{\theta=0}\\
& = & (k+6)\brb{k(k+2)(k+4) + 4\lm(k + 2)(k+4) + 6\lm^2(k+4) + 4\lm^3} + \lm^4
\eeast

Thus,
\beast
& & \E\brb{X-\mu}^4 = \E X^4 - 4\mu\E X^3 + 6\mu^2 \E X^2 - 4\mu^3\E X + \mu^4 \\
& = & (k+6)\brb{k(k+2)(k+4) + 4\lm(k + 2)(k+4) + 6\lm^2(k+4) + 4\lm^3} + \lm^4 - 3(k+\lm)^4\\
& & \qquad - 4(k+\lm) \brb{k(k+2)(k+4) + 3\lm(k+2)(k + 4) + 3\lm^2(k+4) + \lm^3} + 6(k+\lm)^2\brb{k(k + 2) + 2\lm(k+2) + \lm^2}\\
& = & 12k(k+4) + 48\lm(k+4) + 48\lm^2.
\eeast

By Definition \ref{def:kurtosis}, we have $\ekurt(X) = \frac{12k(k+4) + 48\lm(k+4) + 48\lm^2}{4(k+2\lm)^2} -3 = \frac{12(k+4\lambda)}{(k+2\lambda)^2}$.%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,be\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.\ee
\end{proof}

\begin{theorem}\label{thm:normal_rv_sample_mean_variance}
Let $X_1,\dots,X_n$ be i.i.d. $\sN(\mu,\sigma^2)$ random variables. Let
\be
\ol{X} = \frac 1n \sum^n_{i=1} X_i,\qquad S_{XX} = \sum^n_{i=1} \brb{X_i - \ol{X}}^2.
\ee

Then $\ol{X}$ and $S_{XX}$ are independent and
\be
\ol{X} \sim \sN\brb{\mu, \frac 1n \sigma^2},\qquad S_{XX} \sim \sigma^2 \chi^2_{n-1}.
\ee
\end{theorem}

\begin{proof}[\bf Proof]
Let $X = \brb{X_1,\dots,X_n}^T$. Then $X\sim \sN\brb{\mu\ind_{n\times 1},\sigma^2 I_n}$.

Let $A$ be any orthogonal $n\times n$ matrix whose entries in the first row are all equal to $1/\sqrt{n}$, and let $Y = AX$. Then $Y\sim \sN\brb{A\mu\ind_{n\times 1},\sigma^2 I}$. Let $A_i$ denote the $i$th row of $A$ where $i = 1,\dots,n$. Then $i$th row of $A\mu\ind_{n\times 1}$ is $A_i\mu\ind_{n\times 1} = \sqrt{n}\mu A_iA_1^T = \sqrt{n}\mu\delta_{1i}$ because $A$ is orthogonal. Thus, $A\mu = \brb{\sqrt{n}\mu,0,\dots,0}^T$.

Hence, $Y_1 \sim \sN\brb{\sqrt{n}\mu,\sigma^2}$, but $\ol{X}= Y_1/\sqrt{n}$, so $\ol{X} \sim \sN\brb{\mu,\frac 1n \sigma^2}$. Also, for Euclidean norm $\dabs{\cdot}$,
\be
S_{XX} = \sum^n_{i=1}\brb{X_i - \ol{X}}^2 = \sum^n_{i=1} X_i^2 - n\ol{X}^2 = \dabs{X}^2 - n\ol{X}^2 \stackrel{\text{\footnote{proposition needed here}}}{=} \dabs{Y}^2 - Y_1^2 = \sum^n_{i=2} Y_i^2 \sim \sigma^2 \chi^2_{n-1}.
\ee

Finally, $\bra{Y_1,\dots,Y_n}$ are mutually independent, so $\ol{X}$ (which is $Y_1$) and $S_{XX}\brb{Y_2,\dots,Y_n}$ are independent by Proposition \ref{thm:random_variable_function_indenpence}.
\end{proof}

Combining Proposition \ref{pro:normal_chi_square_t}, we have the following corollary.

\begin{corollary}
Let $X_1,\dots,X_n$ be i.i.d. $\sN(\mu,\sigma^2)$ random variables. Then
\be
Y := \frac{\sqrt{n}}{\sigma}\brb{\ol{X}-\mu} \sim \sN(0,1),\qquad Z:= \frac{\sqrt{n}\brb{\ol{X}-\mu}}{\sqrt{S_{XX}/(n-1)}} = \frac{\frac{\sqrt{n}}{\sigma}\brb{\ol{X}-\mu}}{\frac 1{\sigma}\sqrt{S_{XX}/(n-1)}} \sim T(n-1).
\ee
\end{corollary}



\begin{proposition}\label{pro:multivariate_normal_convert_to_chi_square}
Let $X= (X_1,\dots,X_n)^T$ be multivariate Gaussian random variable with $X\sim \sN(0,\Sigma)$ where $\Sigma\in M_{n}(\R)$ is nonsingular. Then $X^T\Sigma^{-1}X \sim \chi^2_n$.
\end{proposition}

\begin{proof}[\bf Proof]
For the scalar case ($n=1$), observe that if $X\sim \sN(0,\sigma^2)$, then $X/\sigma \sim \sN(0,1)$ and thus
\be
X^T\brb{\sigma^{2}}^{-1}X = X\sigma^{-2}X = \brb{X/\sigma}^2 \sim \chi^2_1,
\ee
as asserted by the proposition.

For vector case, since $\Sigma$ is symmetric, by spectral theorem (Theorem \ref{thm:spectral_hermitian_matrices}) there exists a orthogonal matrix $Q$ such that $\sigma = Q^T\Lambda Q$ where $\Lambda$ contains the eigenvalues $\lm_i, i=1,\dots,n$ of $\Sigma$. Since $\Sigma$ is positive definite, the diagonal elements of $\Lambda$ are positive by Proposition \ref{pro:positive_definite_matrix_positive_eigenvalue}. Then
\beast
X^T\Sigma^{-1} X & = & X^T\brb{Q^T \Lambda Q}^{-1} X = X^T Q^{-1} \Lambda^{-1} Q^{-T}X = X^T Q^T \Lambda^{-1} Q X  \\
& = & (QX)^T \Lambda^{-1} (QX)  = Y^T \Lambda^{-1}Y = \sum^n_{i=1} Y_i^2/\lm_i
\eeast
where $Y = QX = (Y_1,\dots,Y_n)^T$. Notice that by Theorem \ref{thm:multivariate_gaussian_rv_property}.(i) $Y$ is multivariate Gaussian with mean zero and variance
\be
Q\Sigma Q^T = Q (Q^T \Lambda Q) Q^T = I \Lambda I = \Lambda.
\ee

Thus, $\sum^n_{i=1} Y_i^2/\lm_i$ is the sum of squares of $n$ independent Gaussian random variables, each divided by its variance $\lm_i$. It accordingly has a $\chi^2_n$ distribution, as claimed.
\end{proof}

\subsection{$F$-distribution}

\begin{definition}[$F$ random variable\index{f-distributed random variable@F-distributed random variable}]\label{def:f_rv}
A random variable $X \in [0,+\infty)$ is called $F$-distributed if, for some positive integers $a,b >0$ (degree of freedom), its density function is \be f_X(x) = \frac{1}{B\left(\frac{a}{2},\frac{b}{2}\right)}
\left(\frac{a}{b}\right)^{\frac{a}{2}} x^{\frac{a}{2} - 1} \left(1+\frac{a}{b}\,x\right)^{-\frac{a+b}{2}}, \ee where $B(a,b)$ is Beta function. We write $X \sim F(a, b)$.
\end{definition}

\begin{remark}
Note that the cdf of $F$-distribution is $I_{\frac{a x}{ax +b}}\brb{\frac{a}2,\frac{b}2}$ where $I$ is regularized incomplete beta function (see \ref{def:regularized_incomplete_beta_function})\footnote{need to prove}.
\end{remark}

\begin{center}
 \psset{xunit=2cm,yunit=10cm,plotpoints=100}
 \begin{pspicture*}(-0.5,-0.07)(5.5,0.8)
 \rput[lb](3,0.6){\textcolor{red}{$a=12$, $b =3$}}
 \rput[lb](3,0.5){\textcolor{blue}{$a=3$, $b =12$}}
 \rput[lb](3,0.4){\textcolor{black}{$a=1$, $b =1$}}
 \psline[linestyle=dashed](0.5,0)(0.5,0.75)
 \psline[linestyle=dashed](! 2 7 div 0)(! 2 7 div 0.75)
 \psset{linewidth=1pt}
 \psFDist{0.1}{5}
 \psFDist[linecolor=red,nue=3,mue=12]{0.01}{5}
 \psFDist[linecolor=blue,nue=12,mue=3]{0.01}{5}
 \psaxes[Dy=0.1]{->}(0,0)(5,0.75)
 \end{pspicture*}
\end{center}

\begin{proposition}\label{pro:independent_chi_square_ratio_implies_f}
If $U \sim \chi^2_{a}, V \sim \chi^2_{b}$ are independent, then $X:=\frac{U / a}{V / b} \sim F(a, b)$.
\end{proposition}

\begin{proof}[\bf Proof]
\beast \pro\brb{\frac{U/a}{V/b} \leq x} & = & \pro\brb{U \leq \frac{Vax}{b}} = \int^\infty_0 \int^{\frac{vax}{b}}_{0} \frac{1}{\Gamma\left(a/2\right)} 2^{-a/2} u^{a/2-1} e^{-u/2} \frac{1}{\Gamma\left(b/2\right)} 2^{-b/2}
v^{b/2-1} e^{-v/2}  du dv \eeast

Taking the differentiation wrt $x$ under the integral sign, we have (by Theorem \ref{thm:differentiation_under_integral_sign}) \beast
f_X(x) & = & \frac{1}{\Gamma\left(a/2\right)\Gamma\left(b/2\right)} 2^{-(a+b)/2} \int^\infty_0 \frac{va}{b} \brb{\frac{vax}{b}}^{a/2-1} v^{b/2-1} e^{-\brb{\frac{vax}{b}+1}v/2} dv \\
& = & \frac{1}{\Gamma\left(a/2\right)\Gamma\left(b/2\right)} 2^{-(a+b)/2} \brb{\frac{a}{b}}^{a/2} x^{a/2-1} \int^\infty_0  v^{(a+b)/2-1} e^{-\brb{\frac{vax}{b}+1}v/2} dv \\
& = & \frac{\Gamma\brb{(a+b)/2}}{\Gamma\left(a/2\right)\Gamma\left(b/2\right)}  \brb{\frac{a}{b}}^{\frac{a}{2}} x^{\frac{a}2-1}\left(1+\frac{a}{b}\,x\right)^{-\frac{a+b}{2}} = \frac{1}{B\left(\frac{a}{2},\frac{b}{2}\right)}
\brb{\frac{a}{b}}^{\frac{a}{2}} x^{\frac{a}2-1}\left(1+\frac{a}{b}\,x\right)^{-\frac{a+b}{2}} \eeast which is the density function of $F$-distribution.
\end{proof}

\begin{proposition}\label{pro:k_moments_f}
Suppose $X \sim F(a,b)$. Then \be \E X^k = \brb{\frac{b}{a}}^k \frac{\Gamma\brb{\frac{a}{2}+k}\Gamma\brb{\frac{b}{2}-k}}{\Gamma\brb{\frac{a}{2}}\Gamma\brb{\frac{b}{2}}}. \ee
\end{proposition}

\begin{proof}[\bf Proof]
Using the distribution of beta prime distribution, %for $b$
\beast
\E X^k & = & \int^\infty_0 \frac{1}{B\left(\frac{a}{2},\frac{b}{2}\right)} \left(\frac{a}{b}\right)^{\frac{a}{2}} x^{\frac{a}{2} +k-1 } \left(1+\frac{a}{b}\,x\right)^{-\frac{a+b}{2}} dx = \int^\infty_0 \frac{1}{B\left(\frac{a}{2},\frac{b}{2}\right)} \left(\frac{a}{b}\right)^{-k} x^{\frac{a}{2}+k-1} \left(1+x\right)^{-\frac{a+b}{2}} dx\\
& = & \frac{1}{B\left(\frac{a}{2},\frac{b}{2}\right)} \left(\frac{a}{b}\right)^{-k} B\brb{\frac{a}{2}+k,\frac{b}{2}-k} = \brb{\frac{b}{a}}^k
\frac{\Gamma\brb{\frac{a}{2}+k}\Gamma\brb{\frac{b}{2}-k}}{\Gamma\brb{\frac{a}{2}}\Gamma\brb{\frac{b}{2}}} \eeast as required.
\end{proof}


\begin{proposition}\label{pro:moments_f}
Suppose $X \sim F(a,b)$. Then
\beast
\text{(i)}\ \E X = \begin{cases} \frac{b}{b - 2}  & b > 2 \\ \infty & \text{otherwise} \end{cases}, \qquad \text{(ii)}\ \var X = \begin{cases} \frac{2b^2(a+b-2)}{a (b-2)^2 (b-4)}  & b >
4\\ \infty & 2 < b \leq 4\\ \text{undefined} & \text{otherwise} \end{cases}, \eeast \beast \text{(iii)}\ \skewness(X) = \begin{cases} \frac{(2 a + b - 2) \sqrt{8 (b-4)}}{(b-6) \sqrt{a (a + b -2)}} & b > 6 \\ \infty & 4 < b
\leq 6\\ \text{undefined} & \text{otherwise} \end{cases}, \qquad  \text{(iv)}\ \ekurt(X) = \begin{cases} 12\frac{a(5b-22)(a+b-2)+(b-4)(b-2)^2}{a(b-6)(b-8)(a+b-2)} & b > 8 \\ \infty & 6 < b \leq 8\\ \text{undefined} &
\text{otherwise} \end{cases}.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or %With Propositions \ref{pro:mgf_t}, \ref{pro:mgf_finite_moment}, (1-1)\int^{1}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  x^{\frac{\nu-1}2-1} (1-x)^{1-1} dx = 0 \eeast
From Proposition \ref{pro:k_moments_f}, we have that if $b > 2$, we have \be \E X = \frac{b}{a} \frac{\frac{a}{2}}{\frac{b}{2}-1} = \frac{b}{b - 2}. \ee

Otherwise, the expectation is infinity. For $b > 4$, \be \E X^2 = \brb{\frac{b}{a}}^2 \frac{\frac{a}{2}\brb{\frac{a}{2}+1}}{\brb{\frac{b}{2}-2}\brb{\frac{b}{2}-1}} = \frac{b^2(a + 2)}{a(b - 2)(b - 4)}. \ee

If $b \leq 4$, $\E X^2 = \infty$. Thus, if $b > 4$, we have \be \var X = \frac{b^2(a + 2)}{a(b - 2)(b - 4)} -  \frac{b^2}{(b - 2)^2} = \frac{2b^2(a+b-2)}{a (b-2)^2 (b-4)}. \ee

If $2< b \leq 4$, we have $\var X = \infty$ and if $b\leq 2$ it is undefined. For $b > 6$, \be \E X^3 = \brb{\frac{b}{a}}^3
\frac{\frac{a}{2}\brb{\frac{a}{2}+1}\brb{\frac{a}{2}+2}}{\brb{\frac{b}{2}-3}\brb{\frac{b}{2}-2}\brb{\frac{b}{2}-1}} = \frac{b^3(a + 2)(a + 4)}{a^2(b - 2)(b - 4)(b - 6)}. \ee

If $b \leq 6$, $\E X^2 = \infty$. Thus, if $b > 6$, we have \beast
\skewness X & = & \left.\brb{\frac{b^3(a + 2)(a + 4)}{a^2(b - 2)(b - 4)(b - 6)} - 3 \frac{b}{b - 2}\frac{b^2(a + 2)}{a(b - 2)(b - 4)} + 2\brb{\frac{b}{b - 2}}^3}\right/\brb{\frac{2b^2(a+b-2)}{a (b-2)^2 (b-4)}}^{3/2}\\
& = & \left.\brb{\frac{8(2a+b -2)(a+b -2)}{a^2(b - 4)(b - 6)}} \right/\brb{\frac{2(a+b-2)}{a (b-4)}}^{3/2} = \frac{(2 a + b - 2) \sqrt{8 (b-4)}}{(b-6) \sqrt{a (a + b -2)}}. \eeast

If $4< b \leq 6$, we have $\skewness X = \infty$ and if $b\leq 4$ it is undefined (for $\infty/\infty$). For $b > 8$, \be \E X^4 = \brb{\frac{b}{a}}^4
\frac{\frac{a}{2}\brb{\frac{a}{2}+1}\brb{\frac{a}{2}+2}\brb{\frac{a}{2}+3}}{\brb{\frac{b}{2}-4}\brb{\frac{b}{2}-3}\brb{\frac{b}{2}-2}\brb{\frac{b}{2}-1}} = \frac{b^4(a + 2)(a + 4)(a + 6)}{a^3(b - 2)(b - 4)(b - 6)(b - 8)}. \ee

If $b \leq 8$, $\E X^2 = \infty$. Thus, if $b > 8$, we have\footnote{need mathematica to prove} \beast
\ekurt X & = & \left.\brb{\frac{b^4(a + 2)(a + 4)(a + 6)}{a^3(b - 2)(b - 4)(b - 6)(b - 8)}- \frac{4b^4(a + 2)(a + 4)}{a^2(b - 2)^2(b - 4)(b - 6)} + \frac{6b^4(a + 2)}{a(b - 2)^3(b - 4)}- \frac{3b^4}{(b - 2)^4}}\right/\\
& & \qquad \brb{\frac{2b^2(a+b-2)}{a (b-2)^2 (b-4)}}^2- 3\\
& = & 12\frac{a(5b-22)(a+b-2)+(b-4)(b-2)^2}{a(b-6)(b-8)(a+b-2)}. \eeast

If $6< b \leq 8$, we have $\ekurt X = \infty$ and if $b\leq 6$ it is undefined.
\end{proof}



\subsection{Weibull random variables}

\begin{definition}[Weibull random variable\index{Weibull random variable!standard}]\label{def:weibull_rv}
A random variable $X$ in $[0,\infty)$ is called Weibull-distributed if, for some $\lm,k >0$, its density function is
\be
f_X(x) = \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-\brb{\frac x{\lm}}^{k}} .
\ee

We write $X \sim \weid(k,\lm)$.
\end{definition}

% check needed!!! 20170825
%\begin{center}
%\psset{unit=2}
% \begin{pspicture*}(-0.5,-0.5)(2.6,2.6)
% \psaxes{->}(0,0)(2.5,2.5)[$x$,-90][$y$,180]
% \multido{\rAlpha=0.5+0.5}{5}{%
% \psWeibull[alpha=\rAlpha]{0}{2.5}
% \psWeibullI[alpha=\rAlpha,linestyle=dashed]{0}{2.4}}
% \end{pspicture*}
 %

% \begin{pspicture*}(-0.5,-0.5)(2.6,2.6)
% \psaxes{->}(0,0)(2.5,2.5)[$x$,-90][$y$,180]
% \multido{\rAlpha=0.5+0.5,\rBeta=0.2+0.2}{5}{%
% \psWeibull[alpha=\rAlpha,beta=\rBeta]{0}{2.5}
% \psWeibullI[alpha=\rAlpha,beta=\rBeta,linestyle=dashed]{0}{2.4}}
% \end{pspicture*}
%\end{center}

\begin{proposition}\label{pro:moments_weibull}
Suppose $X \sim \weid(k,\lm)$. Then
\beast
\text{(i)}\ \E X = \lm\Gamma\brb{1+\frac 1k},\quad \text{(ii)}\ \var X = \lm^2\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac 1k}}^2}, \eeast \beast \text{(iii)}\ \skewness(X) =
\frac{\Gamma\brb{1+\frac 3k} - 3 \Gamma\brb{1+\frac 2k}\Gamma\brb{1+\frac 1k}+ 2\brb{\Gamma\brb{1+\frac 1k}}^3}{\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac 1k}}^2}^{3/2}},
\eeast
\beast \text{(iv)}\ \ekurt(X) =
\frac{\Gamma\brb{1+\frac 4k} - 4 \Gamma\brb{1+\frac 3k}\Gamma\brb{1+\frac 1k} + 6\Gamma\brb{1+\frac 2k}\brb{\Gamma\brb{1+\frac 1k}}^2 - 3\brb{\Gamma\brb{1+\frac 1k}}^4}{\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac
1k}}^2}^2}-3.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
We have these properties by applying the definition of gamma distribution. For $r\in \R$, we can see that %$\E X^n = \lm^n \Gamma\brb{1+\frac nk}$.
\be
\E X^r = \int^\infty_0 x^r \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} dx = \lm^r \int^\infty_0 x^{r/k} e^{-x} dx = \lm^r \Gamma\brb{1+\frac rk}.
\ee
\ben
\item [(i)] For the mean, $\E X = \lm \Gamma\brb{1+\frac 1k} :=\mu$.
\item [(ii)] For the second moment, $\E X^2 = \lm^2 \Gamma\brb{1+\frac 2k}$. Therefore,
\be
\var X = \E X^2 - (\E X)^2 = \lm^2\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac 1k}}^2} := \sigma^2.
\ee
\item [(iii)] For the third moment, $\E X^3 = \lm^3 \Gamma\brb{1+\frac 3k}$. Therefore,
\beast
\skewness(X) = \frac{\E X^3 - 3\mu \E X^2 + 2\mu^3}{\brb{\var X}^{3/2}} = \frac{\Gamma\brb{1+\frac 3k} - 3 \Gamma\brb{1+\frac 2k}\Gamma\brb{1+\frac 1k}+ 2\brb{\Gamma\brb{1+\frac 1k}}^3}{\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac 1k}}^2}^{3/2}}.
\eeast

\item [(iv)] Similarly, $\E X^4 = \lm^4\Gamma\brb{1+\frac 4k}$. Then
\beast
\ekurt(X) & = & \frac{\E X^4 - 4\mu \E X^3 + 6\mu^2 \E X^2 - 3\mu^4}{\brb{\var X}^{2}} - 3\\
& = & \frac{\Gamma\brb{1+\frac 4k} - 4 \Gamma\brb{1+\frac 3k}\Gamma\brb{1+\frac 1k} + 6\Gamma\brb{1+\frac 2k}\brb{\Gamma\brb{1+\frac 1k}}^2 - 3\brb{\Gamma\brb{1+\frac 1k}}^4}{\brb{\Gamma\brb{1+\frac 2k} - \brb{\Gamma\brb{1+\frac 1k}}^2}^2}-3.
\eeast
\een
\end{proof}

\begin{proposition}\label{pro:mgf_weibull}
Suppose $X \sim \weid(k,\lm)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) = \sum_{n=0}^\infty \frac{\theta^n\lambda^n}{n!}\Gamma\brb{1+\frac nk},\quad\quad \phi_X(t) =  \sum_{n=0}^\infty \frac{(it)^n\lambda^n}{n!}\Gamma\brb{1+\frac nk}.
\ee
\end{proposition}

%\begin{remark}
% by Proposition \ref{pro:mgf_finite_moment}.
%\end{remark}

\begin{proof}[\bf Proof]
We can express that $e^{\theta X} = \sum^\infty_{n=0} \frac {x^n}{n!}$. Then by Fubini theorem (Theorem \ref{thm:fubini} as integrand is non-negative)
\beast
\E\brb{e^{\theta X}} & = & \int^\infty_0 e^{\theta x}\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}}dx = \int^\infty_0 \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} \sum^\infty_{n=1}\frac{\theta^nx^n}{n!}dx \\
& = & \sum^\infty_{n=1} \frac{\theta^n}{n!} \int^\infty_0 x^n \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} dx = \sum^\infty_{n=1} \frac{\theta^n\lm^n}{n!} \Gamma\brb{1+\frac nk}.
\eeast%\footnote{proof needed. Might need $k\geq 1$.}

Similarly, we can apply Fubini theorem again because
\be
\abs{\phi_X(t)} = \abs{\int^\infty_0 e^{itx} \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}}dx} \leq \int^\infty_0 \abs{\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}}}dx = 1.
\ee

So the integrand is integrable and therefore we have the required result.
\end{proof}

Similarly, we have translated Weibull random variable.

\begin{definition}[translated Weibull random variable\index{Weibull random variable!translated}]\label{def:weibull_translated_rv}
A random variable $X$ in $[\mu,\infty)$ ($\mu \in\R$) is called translated Weibull-distributed if, for some $\lm,k >0$, its density function is
\be
f_X(x) = \frac{k}{\lambda}\left(\frac{x-\mu}{\lambda}\right)^{k-1}e^{-\brb{\frac{x-\mu}{\lm}}^{k}} .
\ee
We write $X \sim \weid(\mu,k,\lm)$.
\end{definition}

\section{Logistic Distribution}

\begin{definition}[logistic random variable]
A random variable $X\in \brb{-\infty,\infty}$ is called logistic distributed if, for some $\mu\in \R$ and $\sigma >0$, its density function is
\be
f_X(x) = \frac{\exp\brb{-\frac{x-\mu}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x-\mu}{\sigma}}}^2}
\ee
where $\mu$ is the location parameter and $\sigma$ is the scale parameter. We write $X\sim \logd(\mu,\sigma)$. Also,
\be
F_X(x) = \frac{1}{1+\exp\brb{-\frac{x-\mu}{\sigma}}}.
\ee
\end{definition}

\begin{proposition}
Suppose $X\sim \logd(\mu,\sigma)$. Then for $\theta\in \brb{-1/\sigma,1/\sigma}$, $t\in \R$,
\be
M_X(\theta) = e^{\mu\theta} B\brb{1-\sigma\theta,1+\sigma\theta},\qquad \phi_X(t) = e^{i\mu t}\frac{\pi \sigma t}{\sinh(\pi \sigma t)}
\ee
where $B(\cdot,\cdot)$ is the beta function.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Suppose $X\sim \logd(\mu,\sigma)$. Then
\be
\text{(i) }\E X = \mu,\quad \text{(ii) }\var X = \sigma^2\pi^2/3,\quad \text{(iii) }\skewness X = 0,\quad \text{(iv) }\ekurt(X) = \frac 65.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First we have
\beast
\int^{\infty}_{-\infty} (x-\mu)\frac{\exp\brb{-\frac{x-\mu}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x-\mu}{\sigma}}}^2} dx & = & \int^{\infty}_{-\infty} \frac{x \exp\brb{-\frac{x}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x}{\sigma}}}^2} dx =\sigma\int^{0}_{\infty}  \frac{ \ln y}{(1+y)^2}dy \\
& = & -\sigma\int^1_0 \frac{ \ln y}{(1+y)^2}dy + \sigma\int^1_0  \frac{ \ln (1/z)}{(1+1/z)^2}d(1/z) \\ %\left. x\brb{\frac{ 1}{1+\exp\brb{-\frac{x}{\sigma}}}}\right|^\infty_{-\infty} - \int^{\infty}_{-\infty} \frac{ 1}{1+\exp\brb{-\frac{x}{\sigma}}}dx
& = & -\sigma\int^1_0 \frac{ \ln y}{(1+y)^2}dy + \sigma\int^1_0  \frac{- z^2 \ln z}{-z^2 (1+z)^2}dz = 0.
\eeast%Then we can let $\theta = \arctan y$ and the integral becomes
%\be\int^{0}_{\pi/2} \frac{ \ln \brb{\arctan \theta }}{(1+y)^2}dy\ee

\beast
\int^{\infty}_{-\infty} (x-\mu)^2\frac{\exp\brb{-\frac{x-\mu}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x-\mu}{\sigma}}}^2} dx & = & \int^{\infty}_{-\infty} \frac{x^2 \exp\brb{-\frac{x}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x}{\sigma}}}^2} dx = -\sigma^2\int^{0}_{\infty}  \frac{ \brb{\ln y}^2}{(1+y)^2}dy \\
& = & \sigma^2\int^1_0 \frac{ \brb{\ln y}^2}{(1+y)^2}dy - \sigma^2\int^1_0  \frac{ \ln^2 (1/z)}{(1+1/z)^2}d(1/z) \\
& = & 2\sigma^2\int^1_0 \frac{ \ln^2 y}{(1+y)^2}dy = \sigma^2\pi^2/3.
\eeast

Similarly, we have
\be
\int^{\infty}_{-\infty} (x-\mu)^3\frac{\exp\brb{-\frac{x-\mu}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x-\mu}{\sigma}}}^2} dx = 0,
\ee
and
\be
\int^{\infty}_{-\infty} (x-\mu)^4\frac{\exp\brb{-\frac{x-\mu}{\sigma}}}{\sigma\brb{1+\exp\brb{-\frac{x-\mu}{\sigma}}}^2} dx = 7\sigma^4\pi^4/15.
\ee%\footnote{theorem needed for $\int^1_0 \frac{ \ln^2 y}{(1+y)^2}dy = \pi^2/6$}, \footnote{$\int^1_0 \frac{ \ln^4 y}{(1+y)^2}dy = 7\pi^4/30$}
by Proposition \ref{pro:integral_ln_even_power_over_one_plus_x_square}. Therefore, $\skewness(X) = 0$ and $\ekurt(X) = \frac{7\sigma^4\pi^4/15}{\sigma^4\pi^4/9} - 3 = \frac 65$.
\end{proof}

\begin{proposition}
\ben
\item [(i)] If $X\sim \ud[0,1]$, then $\mu + \beta\ln\brb{\frac{X}{1-X}} \sim \logd\brb{\mu,\sigma}$.

\item [(ii)] If $X,Y\sim \gumd(\mu, \sigma)$ are independent, then $X-Y \sim \logd\brb{0,\sigma}$ and $X+Y \sim \logd\brb{2\mu,\sigma}$.

\item [(iii)] If $X\sim\sE(1)$, then $\mu +\sigma\ln\brb{e^X-1} \sim \logd\brb{\mu,\sigma}$.

\item [(iv)] If $X,Y \sim \sE(1)$ are independent, then $\mu -\sigma\ln\brb{\frac{X}{Y}}\sim\logd(\mu,\sigma)$.
\een
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{Proof needed.}
\end{proof}


\begin{proposition}
Let $X\sim \logd\brb{\mu,\sigma}$. Then for $n\in \Z^+$,
\be
\E\brb{X-\mu}^n = \sigma^n\pi^n\brb{2^n-2}\cdot\abs{B_n}
\ee
where $B_n$ are Bernoulli numbers (of the first kind).
\end{proposition}

\begin{proof}[\bf Proof]
It is easy to see that
\be
\E(X-\mu)^n = \sigma^n\int^1_0 \bsb{\ln\brb{\frac t{1-t}}}^n dt
\ee
by the inverse cumulative distribution function of logistic distribution. Then by Proposition \ref{pro:logarithm_integral_x_divided_1-x} we have the required result.
\end{proof}

\section{Distributions Related to Gamma Distribution}


\subsection{Generalized gamma distribution}

\begin{definition}[generalized gamma random variable\index{generalized gamma random variable}]\label{def:generalized_gamma_rv}
A random variable $X$ in $[0,\infty)$ is called generalized gamma-distributed if, for some $\lm,k,d >0$, its density function is
\be
f_X(x) = \frac{k}{\lm^d \Gamma\brb{\frac d k}} x^{d-1}e^{-\brb{\frac x{\lm}}^{k}} .
\ee

We write $X \sim G\Gamma(k,d,\lm)$.
\end{definition}

\begin{remark}
When $d=k$, we have that $X\sim \weid(k,\lm)$. When $k=1$, we have that $X\sim \Gamma\brb{d,\lm}$.

By the definition of Weibull distribution, the integral of density is
\be
\frac 1{\lm^{d-k}\Gamma\brb{\frac d k} } \int^\infty_0 \frac{k }{\lm^k } x^{d-k} x^{k-1}e^{-\brb{\frac x{\lm}}^{k}} dx = \frac 1{\lm^{d-k}\Gamma\brb{\frac d k} } \lm^{d-k} \Gamma\brb{1+\frac{d-k}{k}} = 1.
\ee
\end{remark}

\begin{proposition}\label{pro:moments_generalized_gamma}
Suppose $X \sim G\Gamma(k,d,\lm)$. \beast \text{(i)}\ \E X = \frac{\lm\Gamma\brb{\frac{1+d}{k}}}{\Gamma\brb{\frac{d}{k}}} ,\quad \text{(ii)}\ \var X = \frac{\lm^2 \brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} -
\Gamma\brb{\frac{1+d}{k}}^2} }{\Gamma\brb{\frac{d}{k}}^2}, \eeast \beast \text{(iii)}\ \skewness(X) = \frac{\Gamma\brb{\frac{3+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^2- 3
\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{1+d}{k}}\Gamma\brb{\frac{d}{k}} + 2\brb{\Gamma\brb{\frac{1+d}{k}}}^3 }{\brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} - \Gamma\brb{\frac{1+d}{k}}^2 }^{3/2}}, \eeast \beast
\text{(iv)}\ \ekurt(X) = \frac{\Gamma\brb{\frac{4+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^3- 4 \Gamma\brb{\frac{3+d}{k}}\Gamma\brb{\frac{1+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^2 + 6
\Gamma\brb{\frac{2+d}{k}}\brb{\Gamma\brb{\frac{1+d}{k}}}^2\Gamma\brb{\frac{d}{k}} - 3\brb{\Gamma\brb{\frac{1+d}{k}}}^4 }{\brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} - \Gamma\brb{\frac{1+d}{k}}^2 }^{2}}-3. \eeast
\end{proposition}

\begin{proof}[\bf Proof]
For $r\in\R$,
\be
\E X^r = \frac 1{\lm^{d-k}\Gamma\brb{\frac d k} } \int^\infty_0 \frac{k }{\lm^k } x^{r+d-k} x^{k-1}e^{-\brb{\frac x{\lm}}^{k}} dx = \frac 1{\lm^{d-k}\Gamma\brb{\frac d k} } \lm^{r+d-k} \Gamma\brb{1+\frac{r+d-k}{k}} =  \frac{\lm^r\Gamma\brb{\frac{r+d}{k}}}{\Gamma\brb{\frac{d}{k}}}.
\ee

Thus,
\be
\E X  = \frac{\lm\Gamma\brb{\frac{1+d}{k}}}{\Gamma\brb{\frac{d}{k}}},
\ee
and
\be
\var X = \E X^2 - (\E X)^2 = \frac{\lm^2\Gamma\brb{\frac{2+d}{k}}}{\Gamma\brb{\frac{d}{k}}} - \frac{\lm^2\Gamma\brb{\frac{1+d}{k}}^2}{\Gamma\brb{\frac{d}{k}}^2} = \frac{\lm^2 \brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} - \Gamma\brb{\frac{1+d}{k}}^2 }}{\Gamma\brb{\frac{d}{k}}^2}.
\ee

Furthermore, we have
\beast
\skewness(X) = \frac{\frac{\lm^3\Gamma\brb{\frac{3+d}{k}}}{\Gamma\brb{\frac{d}{k}}}- 3\frac{\lm^2\Gamma\brb{\frac{2+d}{k}}}{\Gamma\brb{\frac{d}{k}}}\frac{\lm\Gamma\brb{\frac{1+d}{k}}}{\Gamma\brb{\frac{d}{k}}}+ 2\brb{\frac{\lm\Gamma\brb{\frac{1+d}{k}}}{\Gamma\brb{\frac{d}{k}}}}^3 }{\brb{\var X}^{3/2}} = \frac{\Gamma\brb{\frac{3+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^2- 3 \Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{1+d}{k}}\Gamma\brb{\frac{d}{k}} + 2\brb{\Gamma\brb{\frac{1+d}{k}}}^3 }{\brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} - \Gamma\brb{\frac{1+d}{k}}^2 }^{3/2}}.
\eeast

Similarly, we have \beast \ekurt(X) =  \frac{\Gamma\brb{\frac{4+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^3- 4 \Gamma\brb{\frac{3+d}{k}}\Gamma\brb{\frac{1+d}{k}}\brb{\Gamma\brb{\frac{d}{k}}}^2 + 6
\Gamma\brb{\frac{2+d}{k}}\brb{\Gamma\brb{\frac{1+d}{k}}}^2\Gamma\brb{\frac{d}{k}} - 3\brb{\Gamma\brb{\frac{1+d}{k}}}^4 }{\brb{\Gamma\brb{\frac{2+d}{k}}\Gamma\brb{\frac{d}{k}} - \Gamma\brb{\frac{1+d}{k}}^2 }^{2}} -3. \eeast
\end{proof}

With the same argument with Proposition \ref{pro:mgf_weibull}, we have

\begin{proposition}\label{pro:mgf_generalized_gamma}
Suppose $X \sim G\Gamma(k,d,\lm)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) = \frac 1{\Gamma\brb{\frac dk}}\sum_{n=0}^\infty \frac{\theta^n\lambda^n}{n!}\Gamma\brb{\frac {n+d}k},\quad\quad \phi_X(t) = \frac 1{\Gamma\brb{\frac dk}} \sum_{n=0}^\infty \frac{(it)^n\lambda^n}{n!}\Gamma\brb{\frac {n+d}k}.
\ee
\end{proposition}


\subsection{Inverse gamma distribution}\label{subsec:inverse_gamma}

\begin{definition}[inverse gamma random variable\index{inverse gamma random variable}]\label{def:inverse_gamma_rv}
A random variable $X$ in $(0,\infty)$ is called inverse gamma-distributed if, for some $\lm,k >0$, its density function is
\be
f_X(x) = \frac{\lm^k}{\Gamma(k)} x^{-k - 1} \exp \brb{\frac{-\lm}{x}}.
\ee

We write $X \sim \Gamma^{-1}(k,\lm)$.
\end{definition}

\begin{remark}
If $X \sim \Gamma(k,\lm)$, then $X^{-1} \sim \Gamma^{-1}(k,\lm)$.
\end{remark}

\begin{proposition}\label{pro:moments_inverse_gamma}
Suppose $X \sim \Gamma^{-1}(k,\lm)$. Then
\beast
\text{(i)}\ \E X = \begin{cases}\frac {\lm}{k-1} & k > 1 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad \text{(ii)}\ \var X = \begin{cases} \frac{\lm^2}{(k-1)^2(k-2)} & k > 2\\ %\infty & 1 < \nu \leq 2\\
\text{undefined} & \text{otherwise} \end{cases},
\eeast
\beast
\text{(iii)}\ \skewness(X) = \begin{cases}\frac{4\sqrt{k-2}}{k-3} & k > 3 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad  \text{(iv)}\ \ekurt(X) = \begin{cases} \frac{6(5k-11)}{(k-3)(k-4)} & k > 4\\ %\infty & 2 < \nu \leq 4\\
\text{undefined} & \text{otherwise} \end{cases}.
\eeast
\end{proposition}


\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or%With Propositions \ref{pro:mgf_t}, \ref{pro:mgf_finite_moment},
For $k>1$,
\be
\E X = \int^\infty_{-\infty} \frac{\lm\lm^{k-1}}{\Gamma(k)} x^{-(k-1) - 1} \exp \brb{\frac{-\lm}{x}} dx = \frac{\lm\Gamma(k-1)}{\Gamma(k)} = \frac{\lm}{k-1}.
\ee

For $k>2$, we have%when $\nu-1 > 0$ since the integral is well-defined by Definition \ref{def:beta_function}.
\be
\E X^2 = \frac{\lm^2\lm^{k-2}}{\Gamma(k)} x^{-(k-2) - 1} \exp \brb{\frac{-\lm}{x}} dx = \frac{\lm^2\Gamma(k-2)}{\Gamma(k)} = \frac{\lm^2}{(k-1)(k-2)}.
\ee

Thus,
\be
\var X = \E X^2 - (\E X )^2 =  \frac{\lm^2}{(k-1)(k-2)} -\brb{ \frac{\lm}{(k-1)}}^2 =  \frac{\lm^2}{(k-1)^2(k-2)}.
\ee

\be
\E X^3 = \frac{\lm^3\lm^{k-3}}{\Gamma(k)} x^{-(k-3) - 1} \exp \brb{\frac{-\lm}{x}} dx = \frac{\lm^3\Gamma(k-3)}{\Gamma(k)} = \frac{\lm^3}{(k-1)(k-2)(k-3)}.
\ee

Thus,
\be
\skewness(X) = \frac{\frac{\lm^3}{(k-1)(k-2)(k-3)} - 3 \frac{\lm^2}{(k-1)(k-2)}\frac{\lm}{k-1} + 2 \brb{\frac{\lm}{k-1}}^3}{\brb{\frac{\lm^2}{(k-1)^2(k-2)}}^{3/2}} = \frac{4\sqrt{k-2}}{k-3}.
\ee

Furthermore,
\be
\E X^4 = \frac{\lm^4\lm^{k-4}}{\Gamma(k)} x^{-(k-4) - 1} \exp \brb{\frac{-\lm}{x}} dx = \frac{\lm^4\Gamma(k-4)}{\Gamma(k)} = \frac{\lm^4}{(k-1)(k-2)(k-3)(k-4)}.
\ee

Thus, we have
\beast
\ekurt(X) & = & \frac{\frac{\lm^4}{(k-1)(k-2)(k-3)(k-4)} - 4 \frac{\lm^3}{(k-1)(k-2)(k-3)}\frac{\lm}{k-1} + 6\frac{\lm^2}{(k-1)(k-2)}\brb{\frac{\lm}{k-1}}^2 - 3 \brb{\frac{\lm}{k-1}}^4}{\brb{\frac{\lm^2}{(k-1)^2(k-2)}}^{2}} -3 \\
& = & \frac{3(k+5)(k-2)}{(k-3)(k-4)} -3 = \frac{6(5k-11)}{(k-3)(k-4)}.
\eeast
\end{proof}

%With the same argument with Proposition \ref{pro:mgf_weibull}, we have

\begin{proposition}\label{pro:mgf_t_inverse_gamma}
Suppose $X \sim \Gamma^{-1}(k,\lm)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) = \frac{2\brb{-\lm \theta}^{k/2}}{\Gamma(k)}K_{k}\brb{\sqrt{-4\lm \theta}}\text{  does not exist as real valued function},\quad\quad \phi_X(t) = \frac{2\brb{-i\lm t}^{k/2}}{\Gamma(k)}K_{k}\brb{\sqrt{-4i\lm t}}.
\ee
where $K_\nu(x)$ is modified Bessel function of the second kind.
\end{proposition}


\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Let $X\sim \Gamma(k,\lm)$. Then $X^{-1}\sim \Gamma^{-1}(k,\lm)$.
\end{proposition}

\begin{proof}[\bf Proof]
Let $y = 1/x$ and then $dx = -\frac 1{y^2}dy $. Thus, making the substitution we have
\be
\int^\infty_0 \frac{\lm^kx^{k-1}}{\Gamma(k)}e^{-\lm x} dx = -\int_\infty^0 \frac{\lm^k y^{-(k-1)}}{\Gamma(k)}\frac 1{y^2}e^{-\frac{\lm}y} dy = \int^\infty_0 \frac{\lm^k y^{-k-1}}{\Gamma(k)}e^{-\frac{\lm}y} dy.
\ee

Thus, the density function of $Y = 1/X$ is pdf of inverse gamma distribution as required.
\end{proof}



\subsection{\levy\ distribution}

\begin{definition}[\levy\ distribution]\label{def:levy_random_variable}
A random varible $X$ is called \levy\ distributed if its density function is
\be
f_X(x) = \sqrt{\frac{\sigma}{2\pi}} (x-\mu)^{-3/2} \exp\brb{-\frac{\sigma}{2(x-\mu)} },\qquad x\in (\mu,\infty)
\ee
where the location parameter $\mu\in \R$ and the scale parameter $\sigma>0$. It is denoted by $X\sim \levyd\brb{\mu,\sigma}$.
\end{definition}

\begin{remark}
Actually, \levy\ distribution is a special case of stable distribution as $\sS\brb{\frac 12,1,\mu,\sigma}$ (see stable distribution) where stability parameter $\alpha = \frac 12$ and skewness parameter $\beta=1$.
\end{remark}

For simplicity, we consider the probability density function
\be
f_X(x) = \sqrt{\frac{\sigma}{2\pi}} x^{-3/2} \exp\brb{-\frac{\sigma}{2x} },\qquad x\in (0,\infty)
\ee
which is $\Gamma^{-1}\brb{\frac 12, \frac{\sigma}2}$. Then by Proposition \ref{pro:moments_inverse_gamma} and \ref{pro:mgf_t_inverse_gamma} as $k<1$, we have the following propositions.

\begin{proposition}
Let $X\sim \levyd\brb{\mu,\sigma}$. Then $\E X = \infty$, $\var X = \infty$ and $\skewness(X), \ekurt(X)$ are undefined.
\end{proposition}

\begin{proposition}\label{pro:characteristic_function_levy_distribution}
Let $X\sim \levyd\brb{\mu,\sigma}$. Then for $\theta,t\in \R$, the moment generating function $M_X(\theta)$ is undefined and the characteristic function is
\be
\phi_X(t) = \exp\brb{i\mu t - \sqrt{-2i \sigma t}}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Substitute the parameters into the characteristic function of inverse gamma distribution, we have
\beast
\phi_X(t) & = & e^{i\mu t}\frac{2\brb{-\frac{i\sigma t}{2}}^{1/4}}{\Gamma\brb{\frac 12}} K_{1/2}\brb{\sqrt{-2i\sigma t}} = e^{i\mu t}\frac{2\brb{-\frac{i\sigma t}{2}}^{1/4}}{\Gamma\brb{\frac 12}} \sqrt{\frac{\pi}{2\sqrt{-2i\sigma t}}}\exp\brb{-\sqrt{-2i\sigma t}} \\
& =& e^{i\mu t} \frac{2\brb{\frac{1}{2}}^{1/4}}{\sqrt{\pi}} \sqrt{\frac{\pi}{2\sqrt{2}}}\exp\brb{-\sqrt{-2i\sigma t}} =  \exp\brb{i\mu t-\sqrt{-2i\sigma t}}
\eeast
by Proposition \ref{pro:modified_bessel_function_second_nu_special_value}.
\end{proof}

\begin{remark}
Let $\phi_X(t)$ stable distribution ($X\sim \sS\brb{\frac 12, 1,\mu,\sigma}$ ) with characteristic function\footnote{details needed.}
\be
\phi_X(t) = \left\{\ba{ll}
\exp\brb{it\mu - \abs{\sigma t}^\alpha \brb{1-i\beta\sgn(t)\tan\brb{\frac{\pi \alpha}2}}} \quad\quad & \alpha \neq 1\\
\exp\brb{it\mu - \sigma\abs{t}\brb{1+ i\frac{2\beta}{\pi}\sgn(t)\ln\abs{t}}} & \alpha = 1
\ea\right..
\ee

%

If $\alpha = \frac 12$, $\beta = 1$, % and $\sigma' = \sigma^2$,
the stable distribution $\sS\brb{\frac 12, 1,\mu,\sigma}$ has characteristic function
\beast
\phi_X(t) & = & \exp\brb{it\mu - \abs{\sigma t}^{1/2} \brb{1-i\sgn(t)\tan\brb{\frac{\pi}4}}} = \exp\brb{it\mu - \abs{\sigma t}^{1/2} \brb{1-i\sgn(t)}} \\
& = & \exp\brb{it\mu - \abs{\sigma t}^{1/2} \sqrt{2}\brb{e^{-\frac{i\pi\sgn(t)}2}}^{1/2} } = \exp\brb{it\mu - \abs{\sigma t}^{1/2} \sqrt{2}\brb{-i\sgn(t)}^{1/2} } \\
& = & \exp\brb{it\mu - \sqrt{-2i\sigma\abs{t}\sgn(t)} } = \exp\brb{it\mu - \sqrt{-2i\sigma t} }
\eeast%as $\sS\brb{\frac 12,1,\mu,\sigma^2}$ (see stable distribution) where stability parameter $\alpha = \frac 12$ and skewness parameter $\beta=1$.
which is the characteristic function of \levy\ distribution.
\end{remark}


\begin{proposition}
Let $X\sim \sN(0,\sigma^2)$ and $Y = X^{-2}$. Then $Y \sim \levyd\brb{0,\sigma^{-2}}$.
\end{proposition}

\begin{remark}
\levy\ random variable can also be considered as the inverse of chi-square random variable.
\end{remark}

\begin{proof}[\bf Proof]
For $y>0$,
\beast
F_Y(y) & = & \pro\brb{Y\leq y} = \pro\brb{X^2\geq 1/y} = 2\pro\brb{X\geq 1/\sqrt{y}} = \sqrt{\frac{2}{\pi\sigma^2}} \int^\infty_{1/\sqrt{y}}\exp\brb{-\frac{x^2}{2\sigma^2}}dx.
\eeast

Differentiating this expression with respect to $y$, we obtain
\be
p_Y(y) = \sqrt{\frac{1}{2\pi\sigma^2}} y^{-3/2} \exp\brb{-\frac{1}{2\sigma^2 y}}.
\ee

Thus, $Y\sim \levyd\brb{0,\sigma^{-2}}$.
\end{proof}


%\section{Beta random variables and related random variables}

\subsection{Beta random variables}

\begin{definition}[beta random variable\index{beta-distributed random variable}]\label{def:beta_rv}
A random variable $X$ in $[0,1]$ is called beta-distributed if, for some $a,b >0$, its density function is
\be
f_X(x) = \frac{x^{a-1}(1-x)^{b-1}} {B(a,b)},
\ee
where $B(a,b)$ is Beta function (see Definition \ref{def:beta_function}). We write $X \sim \betad(a, b)$.
\end{definition}

\begin{center}
\psset{xunit=10cm,yunit=5cm}
 \begin{pspicture*}(-0.1,-0.15)(1.1,2.05)
 \psset{linewidth=1pt}
 \multido{\rbeta=0.25+0.25,\ired=0+5,\rblue=50.0+-2.5}{20}{%
 \psBetaDist[beta=\rbeta,linecolor=red!\ired!blue!\rblue]{0.01}{0.99}}
 \psaxes[Dy=0.2,Dx=0.1]{->}(0,0)(1,2.01)
 \end{pspicture*}
\end{center}

%\begin{proposition}\label{pro:mgf_beta}
%Suppose $X \sim \betad(a,b)$. Then for $\theta,t\in \R$,
%\be
%M_X(\theta) = ,\quad\quad \phi_X(t) = .
%\ee
%\end{proposition}

%\begin{proof}[\bf Proof]
%From Definition \ref{def:mgf_probability},
%\be
%M_X(\theta) = \E\brb{e^{\theta X}} = \int^\infty_0 e^{\theta x} \frac{1}{\Gamma(k)} \lm^k x^{k - 1} e^{-\lm x} dx = \frac{\lm^k}{(\lm - \theta)^k} \int^\infty_0 \frac{1}{\Gamma(k)} (\lm - \theta )^kx^{k-1} e^{-(\lm - \theta)x} dx = \brb{\frac{\lm}{\lm - \theta}}^k.
%\ee
%\end{proof}

\begin{proposition}\label{pro:moments_beta}
Suppose $X \sim \betad(a,b)$. Then \beast \text{(i)}\ \E X = \frac a{a+b},\quad \text{(ii)}\ \var X = \frac{ab}{(a+b)^2(a+b+1)},\quad\text{(iii)}\ \skewness(X) = \frac{2(b-a)\sqrt{a+b+1}}{(a+b+2)\sqrt{ab}}, \eeast \beast
\text{(iv)}\ \ekurt(X) = \frac{6\brb{(a-b)^2 (a+b + 1) - ab (a+b+ 2)}}{ab (a+b + 2) (a+b + 3)}. \eeast
\end{proposition}

\begin{proof}[\bf Proof]%\footnote{need proof.}
For $r\in\R^+$, we have
\be
\E X^r = \int^1_0 \frac{x^{a+r-1}(1-x)^{b-1}} {B(a,b)} dx = \frac{B(a+r,b)}{B(a,b)} = \frac{\Gamma(a+r)\Gamma(a+b)}{\Gamma(a)\Gamma(a+r+b)}.
\ee

For the first moment, we have
\be
\E X = \frac{\Gamma(a+1)\Gamma(a+b)}{\Gamma(a)\Gamma(a+1+b)} = \frac{a\Gamma(a)\Gamma(a+b)}{(a+b)\Gamma(a)\Gamma(a+b)} = \frac{a}{a+b}.
\ee

For the variance, we have
\beast
\var X & = & \E X^2 - (\E X)^2 = \frac{\Gamma(a+2)\Gamma(a+b)}{\Gamma(a)\Gamma(a+b+2)} - \brb{\frac {a}{a+b}}^2 = \frac{a(a+1)\Gamma(a)\Gamma(a+b)}{(a+b)(a+b+1)\Gamma(a)\Gamma(a+b)} - \brb{\frac {a}{a+b}}^2 \\
& = & \frac{a(a+1)(a+b)-a^2(a+b+1)}{(a+b)^2(a+b+1)} = \frac{ab}{(a+b)^2(a+b+1)}.
\eeast

Furthermore,
\be
\E X^3 = \frac{\Gamma(a+3)\Gamma(a+b)}{\Gamma(a)\Gamma(a+3+b)} = \frac{a(a+1)(a+2)}{(a+b)(a+b+1)(a+b+2)}.
\ee

Therefore,
\beast
\skewness(X) & = & \frac{\frac{a(a+1)(a+2)}{(a+b)(a+b+1)(a+b+2)} - 3\frac{a(a+1)}{(a+b)(a+b+1)}\frac{a}{a+b} + 2\brb{\frac a{a+b}}^3 }{\brb{\frac{ab}{(a+b)^2(a+b+1)}}^{3/2}}  \\
& = & \frac{\frac{a(a+1)(a+2)(a+b)^2 - 3a^2(a+1)(a+b)(a+b+2) + 2a^3(a+b+1)(a+b+2)}{(a+b)^3(a+b+1)(a+b+2)} }{\brb{\frac{ab}{(a+b)^2(a+b+1)}}^{3/2}}\\
& = & \frac{\frac{2ab(b-a)}{(a+b)^3(a+b+1)(a+b+2)} }{\brb{\frac{ab}{(a+b)^2(a+b+1)}}^{3/2}} = \frac{2(b-a)\sqrt{a+b+1}}{(a+b+2)\sqrt{ab}}.
\eeast

Also,
\be
\E X^4 = \frac{\Gamma(a+4)\Gamma(a+b)}{\Gamma(a)\Gamma(a+4+b)} = \frac{a(a+1)(a+2)(a+3)}{(a+b)(a+b+1)(a+b+2)(a+b+3)}.
\ee

Therefore,
\beast
\ekurt(X) & = & \frac{\frac{a(a+1)(a+2)(a+3)}{(a+b)(a+b+1)(a+b+2)(a+b+3)} - 4\frac{a(a+1)(a+2)}{(a+b)(a+b+1)(a+b+2)}\frac{a}{a+b} + 6\frac{a(a+1)}{(a+b)(a+b+1)}\brb{\frac{a}{a+b}}^2 - 3\brb{\frac a{a+b}}^4 }{\brb{\frac{ab}{(a+b)^2(a+b+1)}}^{2}} -3 \\
& = & \frac{\frac{a(a+1)(a+2)(a+3)(a+b)^3 - 4a^2(a+1)(a+2)(a+b)^2(a+b+3) + 6a^3(a+1)(a+b)(a+b+2)(a+b+3) - 3a^4(a+b+1)(a+b+2)(a+b+3)}{(a+b)^4(a+b+1)(a+b+2)(a+b+3) }}{\brb{\frac{ab}{(a+b)^2(a+b+1)}}^{2}}-3\\
& = & \frac{3(a+b+1)(2a^2 -2ab + 2b^2 + a^2b + ab^2)}{ab(a+b+2)(a+b+3)}-3 = \frac{6\brb{(a-b)^2 (a+b + 1) - ab (a+b+ 2)}}{ab (a+b + 2) (a+b + 3)}.
\eeast

%By Definition \ref{def:skewness}, $\skewness(X) = \frac{2k/\lm^3}{k^{3/2}/\lm^3} = \frac 2{\sqrt{k}}$. Furthermore,
%\be
%\E X^4 = \left.\frac {d^4 M_X(\theta)}{d\theta^4}\right|_{\theta=0} = \left. \frac{k(k+1)(k+2)(k+3)\lm^k}{(\lm -\theta)^{k+4}}  \right|_{\theta=0}  = \frac{k(k+1)(k+2)(k+3)}{\lm^4}.
%\ee

%Thus,
%\beast
%\E\brb{X-\mu}^4 & = & \E X^4 - 4\mu\E X^3 + 6\mu^2 \E X^2 - 4\mu^3\E X + \mu^4 \\
%& = & \frac{k(k+1)(k+2)(k+3)}{\lm^4} - 4\frac{k}{\lm}\frac{k(k+1)(k+2)}{\lm^3} + 6\frac{k^2}{\lm^2}\frac{k(k+1)}{\lm^2}- 4\frac{k^3}{\lm^3}\frac{k}{\lm} + \frac{k^4}{\lm^4} = \frac{3k^2 + 6k}{\lm^4} .
%\eeast

%By Definition \ref{def:kurtosis}, we have $\kurt(X) = \frac{3k(k+2)/\lm^4}{k^2/\lm^4} -3 = \frac 6k$.

%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,
%\be
%\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.
%\ee
\end{proof}

\begin{proposition}\label{pro:mgf_beta}
Suppose $X \sim \betad(a,b)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) =1  +\sum_{k=1}^{\infty} \brb{ \prod_{r=0}^{k-1} \frac{a+r}{a+b+r} } \frac{\theta^k}{k!},\quad\quad \phi_X(t) = \chf{1}{1}(a, a+b, it).
\ee
where $\chf{1}{1}(\cdot)$ is confluent hypergeometric function\footnote{definition needed}.
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}
Let $U\sim \Gamma(a,\lm)$ and $V \sim \Gamma(b,\lm)$ for $a,b,\lm>0$. Then $X:=U/(U+V) \sim \betad(a,b)$.
\end{proposition}

\begin{proof}[\bf Proof]
It's obvious to see that $\pro(X\leq 0) = 0$ and $\pro\brb{X \leq 1} = 1$. For $x \in (0,1)$

\beast \pro \brb{X \leq x} & = & \pro\brb{U \leq x(U+V)} = \pro\brb{U \leq \frac{x}{1-x}V} \\
& = & \int^\infty_0 \frac 1{\Gamma(b)} \lm^b v^{b-1}\exp\brb{-\lm v } \int^{\frac{vx}{1-x}}_0 \frac 1{\Gamma(a)} \lm^a u^{a-1}\exp\brb{-\lm u } du dv.\eeast

Taking the differentiation wrt $x$ under the integral sign, we have (by Theorem \ref{thm:differentiation_under_integral_sign})

\beast f_X(x) & = & \int^\infty_0 \frac 1{\Gamma(b)} \lm^b v^{b-1}\exp\brb{-\lm v } \frac{v\brb{1-x + x}}{(1-x)^2} \frac 1{\Gamma(a)} \lm^a \brb{\frac{vx}{1-x}}^{a-1}\exp\brb{-\frac{\lm vx}{1-x} } dv \\
& = & \frac {x^{a-1}\brb{1-x}^{b-1}}{\Gamma(a)\Gamma(b)} \int^\infty_0  \brb{\frac{\lm}{1-x}}^{a+b} v^{a+b-1} \exp\brb{-\frac{\lm v}{1-x} } dv\\
& = & \frac {x^{a-1}\brb{1-x}^{b-1}}{\Gamma(a)\Gamma(b)} \Gamma(a+b) = \frac {x^{a-1}\brb{1-x}^{b-1}}{B(a,b)} \eeast
which is the density function of beta distribution.%as required.
\end{proof}

\subsection{Beta prime distribution}

\begin{definition}[beta prime random variable\index{beta prime distributed random variable}]\label{def:beta_prime_rv}
A random variable $X\in [0,+\infty)$ is called beta prime distributed (inverted beta distribution or beta distribution of the second kind) if, for some positive integers $a,b >0$, its density function is
\be
f_X(x) = \frac{x^{a-1} (1+x)^{-a-b}}{B(a,b)},
\ee
where $B(a,b)$ is Beta function. We write $X \sim \betad'(a, b)$.
\end{definition}

\begin{remark}
If we make the substitution for $Y = \frac{X}{1+X}$, the distribution becomes beta distribution $Y\sim \betad(a,b)$.
\end{remark}

\begin{proposition}
If $U \sim \Gamma(a,\lm), V\sim \Gamma(b,\lm)$ for $a,b,\lm >0$, then $X = \frac{U}{V}\sim \betad'(a,b)$.
\end{proposition}

\begin{proof}[\bf Proof]%\footnote{need proof}
\beast \pro\brb{\frac{U}{V} \leq x} & = & \pro\brb{U \leq Vx} = \frac{\lm^{a+b}}{\Gamma(a)\Gamma(b)}\int^\infty_0 \int^{vx}_{0} u^{a - 1} e^{-\lm u} v^{b - 1} e^{- \lm v} du dv. \eeast

Taking the differentiation wrt $x$ under the integral sign, we have (by Theorem \ref{thm:differentiation_under_integral_sign})
\beast
f_X(x) & = & \frac{\lm^{a+b}}{\Gamma(a)\Gamma(b)} \int^\infty_0 v (vx)^{a - 1} e^{-\lm vx} v^{b - 1} e^{-\lm v} dv = \frac{\lm^{a+b}x^{a - 1}}{\Gamma(a)\Gamma(b)} \int^\infty_0 v^{a +b- 1} e^{-\lm v(1+x)} dv \\
& = & \frac{\lm^{a+b}}{\Gamma(a)\Gamma(b)} x^{a - 1} (1+x)^{-a-b} \int^\infty_0 t^{a+b-1} e^{-\lm t} dt = x^{a - 1} (1+x)^{-a-b} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} = \frac{x^{a-1} (1+x)^{-a-b}}{B(a,b)} \eeast which is
the density function of beta prime distribution.
\end{proof}

\begin{proposition}
Suppose $X \sim \betad'(a, b)$. Then
\be
\E X = \frac{a}{b-1},\quad b>1,\qquad \var X = \frac{a(a+b-1)}{(b-1)^2(b-2)},\quad b>2,
\ee
\be
\skewness(X) = \frac{2(2a+b-1)}{b-3}\sqrt{\frac{b-2}{a(a+b-1)}},\quad b>3.
\ee
\end{proposition}


\begin{proof}[\bf Proof]
If $b>1$
\beast
\E X & = & \int^\infty_{0} \frac{x^{a}(1+x)^{-a-b}}{B(a,b)} dx = \int^\infty_{0} \frac{x^{(a+1)-1}(1+x)^{-(a+1)-(b-1)}\Gamma(a+b)}{\Gamma(a)\Gamma(b)} dx \\
& = & \int^\infty_{0} \frac{x^{(a+1)-1}(1+x)^{-(a+1)-(b-1)}a\Gamma(a+1+b-1)}{\Gamma(a+1)(b-1)\Gamma(b-1)} dx \\
& = & \frac{a}{b-1}\int^\infty_{0} \frac{x^{(a+1)-1}(1+x)^{-(a+1)-(b-1)}\Gamma(a+1+b-1)}{\Gamma(a+1)\Gamma(b-1)} dx = \frac{a}{b-1}.
\eeast

If $b>2$,
\beast
\E X^2 & = & \int^\infty_{0} \frac{x^{a+1}(1+x)^{-a-b}}{B(a,b)} dx = \int^\infty_{0} \frac{x^{(a+2)-1}(1+x)^{-(a+2)-(b-2)}\Gamma(a+b)}{\Gamma(a)\Gamma(b)} dx \\
& = & \int^\infty_{0} \frac{x^{(a+2)-1}(1+x)^{-(a+2)-(b-2)}a(a+1)\Gamma(a+2+b-2)}{\Gamma(a+2)(b-1)(b-2)\Gamma(b-2)} dx \\
& = & \frac{a(a+1)}{(b-1)(b-2)}\int^\infty_{0} \frac{x^{(a+2)-1}(1+x)^{-(a+2)-(b-2)}\Gamma(a+2+b-2)}{\Gamma(a+2)\Gamma(b-2)} dx = \frac{a(a+1)}{(b-1)(b-2)}.
\eeast

Thus,
\beast
\var X & = & \E X^2 - (\E X)^2 = \frac{a(a+1)}{(b-1)(b-2)} - \brb{\frac{a}{b-1}}^2 = \frac{a}{(b-1)^2(b-2)}\brb{(a+1)(b-1) - a(b-2)} \\
& = & \frac{a}{(b-1)^2(b-2)}\brb{b-a-1 + 2a} = \frac{a(a+b-1)}{(b-1)^2(b-2)}.
\eeast
\footnote{skewness needed.}
\end{proof}

\begin{proposition}
Let $X \sim \betad'(a, b)$. Then for $-a<k< b$ with $k\in \Z$
\be
\E X^k = \frac{B(a+k,b-k)}{B(a,b)}.
\ee

For $-k< b$ with $k\in \N$,
\be
\E X^k = \prod^k_{i=1} \frac{a+i-1}{b-i}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\subsection{Generalized beta prime distribution}


\begin{definition}[generalized beta prime random variable]
A random variable $X\in [0,+\infty)$ is called generalized beta prime distributed if for some positive integers $a,b,p,q>0$, it density function is
\be
f(x) = \frac{p\brb{\frac{x}{q}}^{ap-1}\brb{1+ \brb{\frac{x}{q}}^p}^{-a-b}}{qB(a,b)}.
\ee

$p$ is the shape parameter and $q$ is the scale parameter. We write $X \sim GBP(a,b,p,q)$.
\end{definition}

\begin{remark}
It is beta prime distribution if $p=q=1$.
\end{remark}

\begin{proposition}
Let $X \sim GBP(a,b,p,q)$. Then
\be
\E X = \frac{q\Gamma\brb{a + \frac 1p}\Gamma\brb{b-\frac 1p}}{\Gamma(a)\Gamma(b)},\qquad bp > 1.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
If $b>1/p$,
\beast
\E X & = & \int^\infty_{0} x\frac{\brb{\frac{x}{q}}^{p(a-1)}\brb{1+ \brb{\frac{x}{q}}^p}^{-a-b}}{B(a,b)} d\brb{\frac{x}{q}}^{p}  = q \int^\infty_{0} \frac{x^{(a+1/p)-1}(1+x)^{-(a+1/p)-(b-1/p)}\Gamma(a+b)}{\Gamma(a)\Gamma(b)} dx \\
& = & \frac{q\Gamma\brb{a + \frac 1p}\Gamma\brb{b-\frac 1p}}{\Gamma(a)\Gamma(b)} \int^\infty_{0} \frac{x^{(a+1/p)-1}(1+x)^{-(a+1/p)-(b-1/p)}\Gamma(a+1/p+b-1/p)}{\Gamma\brb{a + \frac 1p}\Gamma\brb{b-\frac 1p}} dx = \frac{q\Gamma\brb{a + \frac 1p}\Gamma\brb{b-\frac 1p}}{\Gamma(a)\Gamma(b)}.
\eeast
\end{proof}

\section{Student-$t$ Distribution}

\subsection{Standard Student-$t$ random variables}

A statistical distribution published by William Gosset in 1908 under his pseudonym ``Student''.

\begin{definition}[standard Student's $t$ random variable\index{Student's $t$ distributed random variable!standard}]\label{def:t_rv}
A random variable $X \in (-\infty,\infty)$ is called standard Student's $t$-distributed if, for some $\nu >0$, its density function is
\be
f_X(x) = \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} = \frac{1}{\sqrt{\nu}\, B \left (\frac{1}{2}, \frac{\nu}{2}\right )} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}}
\ee
where $\nu$ is the degree of freedom and $\Gamma(x)$ is Gamma function. We write $X \sim T(\nu)$.
\end{definition}

\begin{remark}
We need to guarantee the integral of the density function is 1. Take the substitution $x = \sqrt{\nu}\tan\theta$ with $\theta \in [-\pi/2,\pi/2]$.%For $\phi_X(t)$,
\beast
& & \int^{\pi/2}_{-\pi/2} \frac{1}{\sqrt{\nu}\, B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \left(1+\frac{\nu \tan^2\theta}{\nu} \right)^{-\frac{\nu+1}{2}}  \sqrt{\nu} \sec^2 \theta d\theta\\
& = & \int^{\pi/2}_{-\pi/2} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\sec^2\theta}^{-\frac{\nu - 1}2} d\theta = 2\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac{\nu - 1}2} \frac{-1}{2\cos \theta \sin \theta} d\cos^2 \theta\\
& = & -\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac {\nu}2 - 1} \brb{\sin^2\theta}^{\frac 12 - 1} d\cos^2 \theta = \int^1_0 \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  x^{\frac {\nu}2 - 1} \brb{1-x}^{\frac 12 - 1} dx = 1
\eeast
by beta distribution.
\end{remark}

\begin{center}
\psset{xunit=1.25cm,yunit=10cm}
 \begin{pspicture}(-6,-0.1)(6,.5)
 \psaxes[Dy=0.1]{->}(0,0)(-4.5,0)(5.5,0.5)
 \psset{linewidth=1pt,plotpoints=100}
 \psGauss[mue=0,sigma=1]{-4.5}{4.5}
 \psTDist[linecolor=blue]{-4}{4}
 \psTDist[linecolor=red,nue=4]{-4}{4}
\rput[lb](3,0.4){\textcolor{black}{Gaussian, $\mu=0$, $\sigma =1$}}
\rput[lb](3,0.3){\textcolor{red}{T, $\nu =4$}}
\rput[lb](3,0.2){\textcolor{blue}{T, $\nu=1$}}
 \end{pspicture}
\end{center}

\begin{remark}
The tail behaviour of $X\sim T(\nu)$ is
\be
f_X(x) \sim \text{const}\abs{x}^{-\nu -1}\quad\text{as }x\to \pm\infty.
\ee
\end{remark}

\begin{proposition}\label{pro:mgf_cf_t}
Suppose $X \sim T(\nu)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) \text{ is undefined},\quad\quad \phi_X(t) = \frac{K_{\nu/2} \left(\sqrt{\nu}|t|)(\sqrt{\nu}|t| \right)^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}.
\ee
where $K_\nu(x)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{proof}[\bf Proof]
By Proposition \ref{pro:modified_bessel_function_second_cos_integral},%Take the substitution $x = \sqrt{\nu}\tan\theta$, $\theta \in [-\pi/2,\pi/2]$.%For $\phi_X(t)$, we have $e^{itx} = \sum_{n=0}^{+\infty} \frac {(itx)^n} {n!}$ and thus
\beast
\phi_X(t) & = & \E\brb{e^{it X}} = \int^\infty_{-\infty} e^{itx} \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} dx = 2\frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \nu^{\frac{\nu+1}2} \int^\infty_0 \cos\brb{\abs{t}x} \left(\nu+ x^2 \right)^{-\frac{\nu+1}{2}} dx \\
& = & 2^{1-\frac {\nu}2}\frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\pi}\,\Gamma(\frac{\nu}{2})} (2\nu)^{\frac{\nu}2} \int^\infty_0 \cos\brb{\abs{t}x} \left(\nu+ x^2 \right)^{-\frac{\nu+1}{2}} dx = \frac{K_{\nu/2} \left(\sqrt{\nu}|t|)(\sqrt{\nu}|t| \right)^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}} %\int^{\pi/2}_{-\pi/2} e^{it\sqrt{\nu}\tan \theta} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\sec^2\theta}^{-\nu + 1} d\theta = \int^{\pi/2}_{-\pi/2} e^{it\sqrt{\nu}\tan \theta} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\nu - 1} \frac{-1}{2\cos \theta \sin \theta} d\cos \theta .
\eeast
as required.
%Therefore,
%\beast
%\phi_X(t) = \int^\infty_0 \sum_{n=0}^{\infty} \frac{1}{\Gamma(k)} \lm^k x^{k - 1} e^{-\lm x} \frac {(itx)^n} {n!} dx = \sum_{n=0}^{\infty} \frac {(it)^n} {n!}  \int^\infty_0  \frac{1}{\Gamma(k)} \lm^k x^{n+k - 1} e^{-\lm x} dx
%\eeast
%by Fubini Theorem (Theorem \ref{thm:fubini}) since $\abs{\E\brb{e^{it X}}} \leq \E\abs{e^{itX}} = 1 < \infty$. Thus,
%\be
%\phi_X(t) = \sum_{n=0}^{\infty} \frac {(it)^n} {n!} \frac{\Gamma(n+k)}{\lm^n\Gamma(k)} \int^\infty_0  \frac{1}{\Gamma(n+k)} \lm^{n+k} x^{n+k -1} e^{-\lm x} dx  = \sum_{n=0}^{\infty} \frac {(it)^n} {\lm^n n!} \frac{\Gamma(n+k)}{\Gamma(k)} = \sum_{n=0}^{\infty}  \binom {n+k-1} {n} \brb{\frac{it}{\lm}}^n
%\ee
\end{proof}

\begin{proposition}\label{pro:moments_t}
Suppose $X \sim T(\nu)$. Then \beast \text{(i)}\ \E X = \begin{cases}0 & \nu > 1 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad \text{(ii)}\ \var X = \begin{cases} \frac{\nu}{\nu-2} & \nu > 2\\ \infty & 1 < \nu
\leq 2\\ \text{undefined} & \text{otherwise} \end{cases}, \eeast \beast \text{(iii)}\ \skewness(X) = \begin{cases}0 & \nu > 3 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad  \text{(iv)}\ \ekurt(X) =
\begin{cases} \frac{6}{\nu-4} & \nu > 4\\ \infty & 2 < \nu \leq 4\\ \text{undefined} & \text{otherwise} \end{cases}. \eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
%With Propositions \ref{pro:mgf_t}, \ref{pro:mgf_finite_moment},
\beast
\E X & = & \int^\infty_{-\infty} x \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} dx = \int^{\pi/2}_{-\pi/2} \frac{\sqrt{\nu} \tan \theta}{\sqrt{\nu}\, B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \left(1+\frac{\nu \tan^2\theta}{\nu} \right)^{-\frac{\nu+1}{2}}  \sqrt{\nu} \sec^2 \theta d\theta\\
& = & \int^{\pi/2}_{-\pi/2} \frac{\sqrt{\nu}}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\sec^2\theta}^{-\frac{\nu - 1}2} \tan \theta d\theta = (1-1)\sqrt{\nu}\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac{\nu - 1}2} \frac{-1}{2\cos^2 \theta } d\cos^2 \theta \\
& = & (1-1)\frac{\sqrt{\nu}}2\int^{1}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  x^{\frac{\nu-1}2-1} (1-x)^{1-1} dx = 0
\eeast
when $\nu-1 > 0$ since the integral is well-defined by Definition \ref{def:beta_function}.

\beast
\E X^2 & = & \int^\infty_{-\infty} x^2 \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} dx = \int^{\pi/2}_{-\pi/2} \frac{\nu \tan^2 \theta}{\sqrt{\nu}\, B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \left(1+\frac{\nu \tan^2\theta}{\nu} \right)^{-\frac{\nu+1}{2}}  \sqrt{\nu} \sec^2 \theta d\theta\\
& = & \int^{\pi/2}_{-\pi/2} \frac{\nu}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\sec^2\theta}^{-\frac{\nu - 1}2} \tan^2 \theta d\theta = 2\nu\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac{\nu - 1}2} \frac{-\sin \theta}{2\cos^3 \theta } d\cos^2 \theta \\
& = & \nu\frac{B \left (\frac{3}{2}, \frac{\nu}{2} -1\right )} {B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \int^{1}_{0} \frac{1}{B \left (\frac{3}{2}, \frac{\nu}{2} -1\right )}   x^{\frac{\nu}2-2} (1-x)^{\frac 32-1} dx .
\eeast

Thus, if $\nu > 2$, $B \left (\frac{3}{2}, \frac{\nu}{2} -1\right )$ is well-defined. Thus,
\be
\E X^2 = \frac{\nu B \left (\frac{3}{2}, \frac{\nu}{2} -1\right )} {B \left (\frac{1}{2}, \frac{\nu}{2}\right )} = \frac{\nu\Gamma\brb{\frac 32}\Gamma\brb{\frac{\nu}2 -1 }}{\Gamma\brb{\frac 12}\Gamma\brb{\frac{\nu}2}} = \frac{\nu \frac 12}{\frac{\nu}2 -1 } = \frac{\nu}{\nu - 2}.
\ee

Meanwhile, it is easy to see that if $\nu \leq 2$ the integral is infinity. Thus, we have the required result (since $\var X = \E X^2 - (\E X )^2$).

\beast
\E X^3 & = & \int^\infty_{-\infty} x^3 \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} dx = (1-1)\nu^{3/2}\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac{\nu - 1}2} \frac{-\sin^2\theta }{2\cos^4 \theta } d\cos^2 \theta \\
& = & (1-1)\frac{\nu^{3/2}}2\int^{1}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  x^{\frac{\nu-1}2-2} (1-x)^{2-1} dx = 0
\eeast
when $\frac {\nu-1}2-1 > 0 \ \ra \ \nu > 3$ since the integral is well-defined by Definition \ref{def:beta_function}.

By Definition \ref{def:skewness}, $\skewness(X) = 0$ for $\nu > 3$. Furthermore,
\beast
\E X^4 & = & \int^\infty_{-\infty} x^4 \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}} dx = 2\nu^2\int^{\pi/2}_{0} \frac{1}{B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \brb{\cos^2\theta}^{\frac{\nu - 1}2} \frac{-\sin^3 \theta}{2\cos^5 \theta } d\cos^2 \theta \\
& = & \nu^2\frac{B \left (\frac{5}{2}, \frac{\nu}{2} -2\right )} {B \left (\frac{1}{2}, \frac{\nu}{2}\right )}  \int^{1}_{0} \frac{1}{B \left (\frac{5}{2}, \frac{\nu}{2} -2\right )}   x^{\frac{\nu}2-3} (1-x)^{\frac 52-1} dx .
\eeast

Thus, if $\nu > 2$, $B \left (\frac{3}{2}, \frac{\nu}{2} -1\right )$ is well-defined. Thus,
\be
\E X^4 = \frac{\nu^2 B \left (\frac{5}{2}, \frac{\nu}{2} -2\right )} {B \left (\frac{1}{2}, \frac{\nu}{2}\right )} = \frac{\nu^2\Gamma\brb{\frac 52}\Gamma\brb{\frac{\nu}2 -2 }}{\Gamma\brb{\frac 12}\Gamma\brb{\frac{\nu}2}} = \frac{\nu^2 \frac 32\frac 12}{\brb{\frac{\nu}2 -1 }\brb{\frac{\nu}2 - 2}} = \frac{3\nu^2}{(\nu - 2)(\nu - 4)}.
\ee

In this case, by Definition \ref{def:kurtosis}, we have \be \ekurt(X) = \frac{\frac{3\nu^2}{(\nu - 2)(\nu - 4)}}{\frac{\nu^2}{(\nu - 2)^2} } -3 = \frac{3(\nu-2)}{(\nu - 4)} - 3 = \frac {6}{\nu - 4}. \ee

Meanwhile, it is easy to see that if $\nu \leq 4$ the integral is infinity. Thus, we have the required result.
%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,
%\be
%\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.
%\ee
\end{proof}

\begin{proposition}
Let $X\sim T(\nu)$. The raw moments of $X$ are
\be
\E X^k=\begin{cases} 0 & k \text{ odd},\quad 0<k< \nu\\ \frac{1}{\sqrt{\pi}\Gamma\left(\frac{\nu}{2}\right)}\brb{\Gamma\left(\frac{k+1}{2}\right)\Gamma\left(\frac{\nu-k}{2}\right)\nu^{\frac{k}{2}}}  & k \text{ even}, \quad 0<k< \nu\\ \text{undefined} & k \text{ odd},\quad 0<\nu\leq k\\ \infty & k\text{ even},\quad 0<\nu\leq k \end{cases}
\ee
\end{proposition}

\begin{proposition}\label{pro:normal_chi_square_t}
Student's $t$-distribution with $\nu$ degrees of freedom can be defined as the distribution of the random variable $X$ with
\be
X=\frac{Z}{\sqrt{V/\nu}} = Z \sqrt{\frac{\nu}{V}} ,
\ee
where $Z$ is normally distributed with expected value 0 and variance 1, $V$ has a chi-squared distribution with $\nu$ degree of freedom; $Z$ and $V$ are independent.
\end{proposition}

\begin{proof}[\bf Proof]
For standard normal $Z$ and standard chi-squared distributed $V$ with drgree of freedom $\nu$, we have
\be
f_Z(z) = \frac 1{\sqrt{2\pi}}e^{-z^2/2},\qquad f_V(u) = \frac{1}{\Gamma\left(\nu/2\right)} 2^{-\nu/2} u^{\nu/2-1} e^{-u/2}.
\ee

Then
\beast
\pro\brb{X \leq x} & = & \pro\brb{Z \sqrt{\frac{\nu}{V}} \leq x} = \int^\infty_0 \int^{x\sqrt{u}/\sqrt{\nu}}_{-\infty} \frac 1{\sqrt{2\pi}}e^{-z^2/2} \frac{1}{\Gamma\left(\nu/2\right)} 2^{-\nu/2} u^{\nu/2-1} e^{-u/2}dz du
\eeast

Taking the differentiation wrt $x$ under the integral sign, we have (by Theorem \ref{thm:differentiation_under_integral_sign})
\beast
f_X(x) & = & \int^\infty_0 \frac{\sqrt{u}}{\sqrt{\nu}} \frac 1{\sqrt{2\pi}}e^{-\frac{ux^2}{2\nu}} \frac{1}{\Gamma\left(\nu/2\right)} 2^{-\nu/2} u^{\nu/2-1} e^{-u/2} du = \frac 1{\sqrt{2\pi\nu}}  \int^\infty_0  \frac{1}{\Gamma\left(\nu/2\right)} 2^{-\nu/2} u^{\nu/2-1/2} e^{-u\brb{1+\frac{x^2}{\nu}}/2} du\\
& = & \frac 1{\sqrt{\pi\nu}} \brb{1+\frac{x^2}{\nu}}^{-\frac{\nu + 1}2} \frac{\Gamma\left((\nu+1)/2\right)}{\Gamma\left(\nu/2\right)} \int^\infty_0  \frac{1}{\Gamma\left((\nu+1)/2\right)} 2^{-(\nu+1)/2} x^{(\nu+1)/2-1} e^{-x/2} dx \\
& = & \frac {\Gamma\left((\nu+1)/2\right)}{\sqrt{\pi\nu}\Gamma\left(\nu/2\right)} \brb{1+\frac{x^2}{\nu}}^{-\frac{\nu + 1}2}
\eeast
which is the density function of $t$-distribution.
\end{proof}

\subsection{Non-central scaled $t$-distribution}

\begin{definition}[non-central scaled $t$ random variable\index{Student's $t$ distributed random variable!non-central scaled}]\label{def:t_non_central_scaled_rv}
A random variable $X \in (-\infty,\infty)$ is called non-central scaled Student's $t$-distributed if, for some $\nu >0$, $\sigma >0$ and $\mu\in \R$, its density function is
\be
f_X(x) = \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\pi\nu\sigma^2}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)^{-\frac{\nu+1}{2}} = \frac{1}{\sqrt{\nu\sigma^2} B \left (\frac{1}{2}, \frac{\nu}{2}\right )} \left(1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)^{-\frac{\nu+1}{2}}
\ee
where $\nu$ is the degree of freedom and $\Gamma(x)$ is Gamma function. We write $X \sim T(\mu,\sigma^2,\nu)$.
\end{definition}

\begin{remark}
In fact, $X =\mu + \sigma Y$ where $Y \sim T(\nu)$ ($Y$ is a standard Student's $t$ random variable).
\end{remark}

By the above remark and Proposition \ref{pro:mgf_cf_t} and Proposition \ref{pro:moments_t}

\begin{proposition}\label{pro:mgf_cf_t_non_central_scaled}
Suppose $X \sim T(\mu,\sigma^2,\nu)$. Then for $t\in \R$,
\be
M_X(\theta) \text{ is undefined},\quad\quad \phi_X(t) =  \frac{ e^{i\mu t} K_{\nu/2} \left(\sqrt{\nu}\sigma |t|)(\sqrt{\nu}\sigma |t| \right)^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}.
\ee
where $K_\nu(x)$ is modified Bessel function of the second kind.
\end{proposition}


\begin{proposition}\label{pro:moments_t_non_central_scaled}
Suppose $X \sim T(\mu,\sigma^2,\nu)$. Then \beast \text{(i)}\ \E X = \begin{cases}\mu & \nu > 1 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad \text{(ii)}\ \var X = \begin{cases}  \frac{\nu \sigma^2}{\nu-2} &
\nu > 2\\ \infty & 1 < \nu \leq 2\\ \text{undefined} & \text{otherwise} \end{cases}, \eeast \beast \text{(iii)}\ \skewness(X) = \begin{cases}0 & \nu > 3 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad
\text{(iv)}\ \ekurt(X) = \begin{cases} \frac{6}{\nu-4} & \nu > 4\\ \infty & 2 < \nu \leq 4\\ \text{undefined} & \text{otherwise} \end{cases}. \eeast
\end{proposition}


\subsection{Skewed $t$-disbribution}

There are several definitions presented in the literature that can be regarded as competing skew Student's $t$-definitions. It is proposed by Hansen (see \cite{Hansen_1994}) and given $\nu$ and $\lm$, its density function is defined as
\be
f_X(x) = \left\{
\ba{ll}
bc\brb{1+\frac{1}{\nu-2}\brb{\frac{a+bx}{1-\lm}}^2}^{-(\nu+1)/2} \quad\quad & x< -a/b\\
bc\brb{1+\frac{1}{\nu-2}\brb{\frac{a+bx}{1+\lm}}^2}^{-(\nu+1)/2} & x\geq -a/b
\ea\right.
\ee
where $\nu\in(2,+\infty)$ is the degree of freedom and $\lm \in (-1,1)$ is the skewness parameter. $a,b,c$ are three constants given by
\be
a = 4\lm c\brb{\frac{\nu -2}{\nu-1}},\quad b^2 = 1+3\lm^2 - a^2,\quad c= \frac{\Gamma\brb{\frac{\nu+1}{2}}}{\sqrt{\pi(\nu-2)}\Gamma\brb{\frac{\nu}{2}}}.
\ee

When $\lm = 0$, we can get the Student's $t$-distribution. The tail behaviour is
\be
f_X(x) \sim \text{const} \abs{x}^{-\nu -1}\quad \text{as }x\to \pm \infty.
\ee

We can also skew the symmetric Student's $t$-distribution by continuously piecing together two differently scaled halves of the symmetric base distribution (see \cite{Fernandez_Steel_1998}). The density function is on the form
\be
f_X(x) = \frac{2\beta}{1+\beta^2}\brb{t_\nu(\beta x)\ind_{x<0} + t_\nu\brb{\frac{x}{\beta}}\ind_{x\geq 0}},
\ee
where $\beta >0$ and $t_\nu(\cdot)$ is the density of the standard Student's $t$-distribution with $\nu$ degrees of freedom.

When $\beta = 1$, $f$ reduces to the standard Student's $t$-distribution with $\nu$ degree of freedom. The tail behaviour is that of the $t_{\nu}(\cdot)$ distribution, i.e.
\be
f_X(x) \sim \text{const} \abs{x}^{-\nu -1}\quad \text{as }x\to \pm \infty.
\ee

Furthermore, we can have an alternative skew $t$-distribution based on order statistics, introduced by Jones and Faddy (see \cite{Jones_Faddy_2003}). Its density is given by
\be
f_X(x) = \frac{1}{B(\alpha,\beta)2^{\alpha +\beta -1}(\alpha + \beta)^{1/2}}\brb{1+\frac{x}{\sqrt{\alpha +\beta + x^2}}}^{\alpha + 1/2} \brb{1-\frac{x}{\sqrt{\alpha +\beta + x^2}}}^{\beta + 1/2}
\ee
where $B(\cdot,\cdot)$ denotes the beta function, and $\alpha,\beta >0$. When $\alpha=\beta$, $f$ corresponds to the standard Student's $t$-distribution with $2\alpha$ degrees of freedom. When $\alpha <\beta$ or $\alpha >\beta$, $f$ is negatively or positive skewed respectively. In the tails, the density behaves as\footnote{check needed}
\be
f_X(x) \sim \left\{ \ba{ll} \text{const}\abs{x}^{-2\alpha -1} \quad\quad & x\to -\infty\\
\text{const}\abs{x}^{-2\beta -1} \quad\quad & x\to +\infty
\ea\right.
\ee

Another option is
\be
f_X(x) = 2t_\nu (x)T_\nu(\beta x)
\ee
where $t_\nu$ is the density of the standard Student's $t$-distribution with $\nu$ degrees of freedom and $T_{\nu+1}(\cdot)$ is the cumulative distribution function of the standard $t$-distribution with $\nu+1$ degrees of freedom\footnote{tail property needed}.

Additionally, a skewed $t$-distribution proposed by Azzalini and Capitanio (see \cite{Azzalini_Capitanio_2003}) which coincides with the skew $t$-distribution of Branco and Dey (see \cite{Branco_Day_2001}), having a density function on the form
\be
f_X(x) = 2t_\nu(x)T_{\nu +1}\brb{\beta x\sqrt{\frac{\nu+1}{x^2 +\nu}}},
\ee
where $t_\nu$ is the density of the standard Student's $t$-distribution with $\nu$ degrees of freedom and $T_{\nu+1}(\cdot)$ is the cumulative distribution function of the standard $t$-distribution with $\nu+1$ degrees of freedom ($\nu >0$).

When $\beta = 0$, it is reduced to the standard $t$-distribution with $\nu$ degrees of freedom. Its heaviest tail decays as\footnote{check needed}
\be
f_X(x) \sim \text{const}\abs{x}^{-\nu -1} \quad \text{when}\left\{\ba{l}
\beta <0, x\to -\infty\\
\beta >0, x\to +\infty
\ea\right.
\ee
and the lightest as
\be
f_X(x) \sim \text{const}\abs{x}^{-2\nu -1} \quad \text{when}\left\{\ba{l}
\beta <0, x\to +\infty\\
\beta >0, x\to -\infty
\ea\right.
\ee

Hence, all the above versions of the skewed $t$-distribution presented in this section have two tails behaving as polynomials. This means that they should fit heavy-tailed data well, but they may not handle substantial skewness. We will give generalized hyperbolic skewed Student's $t$-distribution in Section \ref{sec:generalized_hyperbolic_family}.

\section{Inverse Gaussian Family}

\subsection{Inverse Gaussian random variables}

\begin{definition}[inverse Gaussian random variable]\label{def:inverse_gaussian_rv}
A random variable $X$ in $(0,\infty)$ is called inverse Gaussian distributed\index{inverse Gaussian distributed random variable} if, for some $\mu >0$ and $\lm >0$, its density function is
\be
f_X(x) = \brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda (x-\mu)^2}{2 \mu^2 x}}
\ee
where $\mu$ is the mean and $\lm$ is the shape parameter. We write $X \sim IG(\mu,\lm)$.
\end{definition}

\begin{remark}
As $\lm$ tends to infinity, the inverse Gaussian distribution becomes more like a normal (Gaussian) distribution. The inverse Gaussian distribution has several properties analogous to a Gaussian distribution. The name can be misleading: it is an ``inverse'' only in that, while the Gaussian describes a Brownian Motion's level at a fixed time, the inverse Gaussian describes the distribution of the time a Brownian Motion with positive drift takes to reach a fixed positive level.

Its cumulant generating function (logarithm of the characteristic function) is the inverse of the cumulant generating function of a Gaussian random variable.
\end{remark}

First we need to guarantee that the integral of the density function is 1.
\begin{proposition}
\be
I = \int^\infty_0  \brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda (x-\mu)^2}{2 \mu^2 x}} dx = 1.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First, we have
\be
I = \int^\infty_0  \brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda \brb{\sqrt{\frac x{\mu}}- {\sqrt{\frac{\mu} x}}}^2}{2 \mu }} dx
= \brb{\frac{\lambda}{2 \pi \mu}}^{1/2}  \int^\infty_0 x^{-3/2} \exp\brb{-\frac{\lambda \brb{\sqrt{x}- \frac 1{\sqrt{x}}}^2}{2 \mu }} dx
\ee
Taking the substitution $y = 1/x$, we have that
\be
I = \brb{\frac{\lambda}{2 \pi \mu}}^{1/2}  \int^0_\infty y^{3/2}  \exp\brb{-\frac{\lambda \brb{\sqrt{y}- \frac 1{\sqrt{y}}}^2}{2 \mu }}\brb{-\frac1{y^2}} dy
= \brb{\frac{\lambda}{2 \pi \mu}}^{1/2}  \int^\infty_0 x^{-1/2}  \exp\brb{-\frac{\lambda \brb{\sqrt{x}- \frac 1{\sqrt{x}}}^2}{2 \mu }} dx.
\ee

Therefore,
\beast
I & = & \frac 12 \brb{\frac{\lambda}{2 \pi \mu}}^{1/2} \brb{\int^\infty_0 \brb{x^{-3/2} + x^{-1/2}} \exp\brb{-\frac{\lambda \brb{\sqrt{x}- \frac 1{\sqrt{x}}}^2}{2 \mu }} dx } \\
& = & \brb{\frac{\lambda}{2 \pi \mu}}^{1/2} \brb{\int^\infty_0 \exp\brb{-\frac{\lambda \brb{\sqrt{x}- \frac 1{\sqrt{x}}}^2}{2 \mu }} d\brb{x^{1/2} - x^{-1/2}}  } = \brb{\frac{\lambda}{2 \pi \mu}}^{1/2} \int^\infty_{-\infty}\exp\brb{-\frac{\lambda x^2}{2 \mu }} dx\\
& = & \frac 1{\sqrt{2\pi} }\int^\infty_{-\infty} e^{-x^2/2}dx = 1
\eeast
by normal distribution.
\end{proof}

\begin{proposition}\label{pro:mgf_inverse_gaussian}
Suppose $X \sim IG(\mu,\lm)$. Then for $t\in \R$,
\be
M_X(\theta) = \exp\brb{\frac{\lambda}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}} ,\quad\quad \phi_X(t) = \exp\brb{\frac{\lambda}{\mu}\brb{1-\sqrt{1-\frac{2i\mu^2 t}{\lm}}}} .
\ee%where $K_\nu(x)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{proof}[\bf Proof]
\beast
M_X(\theta)& = & \int^\infty_0 \exp\brb{\theta x}\brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda (x-\mu)^2}{2 \mu^2 x}} dx \\
& = & \exp\brb{\frac{2\lambda\mu }{2\mu^2}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}} \int^\infty_0 \brb{\frac{\lambda}{2 \pi x^3}}^{1/2}  \exp\brb{-\frac{\lambda \brb{x\sqrt{1-\frac{2\mu^2 \theta}{\lm}} - \mu}^2}{2 \mu^2 x}} dx\\
& = & \exp\brb{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}.
\eeast

Similarly for $\phi_X(t)$.
\end{proof}

\begin{proposition}\label{pro:moments_inverse_gaussian}
Suppose $X \sim IG(\mu,\lm)$. Then \beast \text{(i)}\ \E X = \mu,\quad \text{(ii)}\ \var X = \frac{\mu^3}{\lm},\quad\text{(iii)}\ \skewness(X) = 3\brb{\frac{\mu}{\lm}}^{1/2},\quad\text{(iv)}\ \ekurt(X) = \frac{15\mu }{\lm}.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
With Propositions \ref{pro:mgf_inverse_gaussian}, \ref{pro:mgf_finite_moment},
\be
\E X = \left.\frac {d M_X(\theta)}{d\theta}\right|_{\theta=0} = \left. \mu \brb{1-\frac{2\mu^2\theta}{\lm}}^{-1/2}\exp\brb{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}} \right|_{\theta=0} = \mu.
\ee

\beast
\E X^2 = \left.\frac {d^2 M_X(\theta)}{d\theta^2}\right|_{\theta=0}
= \left.\brb{\mu^2 \brb{1-\frac{2\mu^2\theta}{\lm}}^{-1} + \frac{\mu^3}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3/2} }\exp\brb{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}   \right|_{\theta=0} = \mu^2 + \frac{\mu^3}{\lm}.
\eeast

Thus, $\var X = \E X^2 - \brb{\E X}^2 = \mu^2 + \frac{\mu^3}{\lm} - \mu^2  = \frac{\mu^3}{\lm}$. Also,
\beast
\E X^3 = \left.\frac {d^3 M_X(\theta)}{d\theta^3}\right|_{\theta=0}
& = & \left. \brb{\mu^3 \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3/2} + \frac{\mu^4}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-2} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}    \right|_{\theta=0} \\
& & \qquad + \left. \brb{\frac{2\mu^4}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-2} + \frac{3\mu^5}{\lm^2}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}    \right|_{\theta=0} \\
& = & \left. \brb{\mu^3 \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3/2} + \frac{3\mu^4}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-2} + \frac{3\mu^5}{\lm^2}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}    \right|_{\theta=0} \\
& = & \mu^3 + \frac{3\mu^4}{\lm} + \frac{3\mu^5}{\lm^2}.
\eeast

Thus,
\be
\E\brb{X-\mu}^3 = \E X^3 - 3\mu\E X^2 + 3\mu^2 \E X - \mu^3  = \mu^3 + \frac{3\mu^4}{\lm} + \frac{3\mu^5}{\lm^2}  - 3\mu \brb{ \mu^2 + \frac{\mu^3}{\lm}} + 2\mu^3 =  \frac{3\mu^5}{\lm^2}.
\ee

By Definition \ref{def:skewness}, $\skewness(X) = \frac{3\mu^5/\lm^2}{\mu^{9/2}/\lm^{3/2}} = 3\brb{\frac{\mu}{\lm}}^{1/2}$. Furthermore,
\beast
\E X^4 & = & \left.\frac {d^4 M_X(\theta)}{d\theta^4}\right|_{\theta=0} \\
& = & \left. \brb{\mu^4 \brb{1-\frac{2\mu^2\theta}{\lm}}^{-2} + \frac{3\mu^5}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2}  + \frac{3\mu^6}{\lm^2}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}     \right|_{\theta=0}\\
& & + \left. \brb{\frac{3\mu^5}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2} + \frac{12 \mu^6}{\lm^2} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3}  +  \frac{15\mu^7}{\lm^3}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-7/2} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}   \right|_{\theta=0}\\
& = & \mu^4 + \frac{6\mu^5}{\lm} + \frac{15\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3}.
\eeast

Thus,
\beast
\E\brb{X-\mu}^4 & = & \E X^4 - 4\mu\E X^3 + 6\mu^2 \E X^2 - 4\mu^3\E X + \mu^4 \\
& = & \mu^4 + \frac{6\mu^5}{\lm} + \frac{15\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3} - 4\mu\brb{\mu^3 + \frac{3\mu^4}{\lm} + \frac{3\mu^5}{\lm^2}} + 6 \mu^2 \brb{\mu^2 + \frac{\mu^3}{\lm}} - 3\mu^4 = \frac{3\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3}.
\eeast

By Definition \ref{def:kurtosis}, we have \be \ekurt(X) = \frac{\frac{3\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3} }{\frac{\mu^6}{\lm^2}} -3 = \frac{15\mu }{\lm}.
\ee%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,be\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.
\end{proof}

\subsection{Generalized inverse Gaussian random variables}

\begin{definition}[generalized inverse Gaussian random variable]\label{def:generalized_inverse_gaussian_rv}
A random variable $X \in (0,\infty)$ is called generalized inverse Gaussian distributed\index{generalized inverse Gaussian distributed random variable} if, for some $a \geq 0,b \geq 0,p\in \R$ with conditions
\be
\left\{\ba{ll}
a >0,b\geq 0\quad\quad & p > 0\\
a >0,b> 0\quad\quad & p = 0\\
a \geq 0,b > 0\quad\quad & p < 0
\ea\right.\qquad (*)
\ee
its density function is
\be
f_X(x) = \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} e^{-(ax + b/x)/2}
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. We write $X \sim GIG(a,b,p)$.
\end{definition}

\begin{remark}
\ben
\item [(i)] The inverse Gaussian and gamma distributions are special cases of the generalized inverse Gaussian distribution for $p = -1/2$ and $b = 0$, respectively. Specifically, an inverse Gaussian distribution of the form
\be
f_X(x) = \brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda (x-\mu)^2}{2 \mu^2 x}}
\ee
is a GIG with $a = \lambda/\mu^2$, $b = \lambda$, and $p=-1/2$.

A Gamma distribution of the form
\be
f_X(x) = \frac{1}{\Gamma(k)} \lm^{k} x^{k-1} e^{-\lm x}
\ee
is a GIG with $a = 2 \lm$, $b = 0$, and $p = k$.%Other special cases include the inverse-gamma distribution, for $a=0$, and the hyperbolic distribution, for $p=0$.

\item [(ii)] The conditions ($*$) in the above definition are implied by Proposition \ref{pro:modified_bessel_function_second_close_to_zero}.
\een
\end{remark}

First we need to guarantee that the integral of the density function is 1.

\begin{proposition}\label{pro:gig_density_integral}
\be
I = \int^\infty_0  \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} e^{-(ax + b/x)/2}dx = 1.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
First, we have
\beast
I & = & \int^\infty_0  \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} e^{-(ax + b/x)/2}dx = \int^\infty_0 \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} \exp\brb{-\frac{\sqrt{ab}}2\brb{\sqrt{\frac{a}b}x + \sqrt{\frac b{a}}\frac 1x}}  dx\\
& = & \frac{1}{2 K_p(\sqrt{ab})} \int^\infty_0  t^{(p-1)} \exp\brb{-\frac{\sqrt{ab}}2\brb{t + \frac 1t}}  dt.
\eeast
Taking the substitution $t = e^x$, we have that
\beast
I & = & \frac{1}{2 K_p(\sqrt{ab})} \int^\infty_{-\infty}  e^{(p-1)x} \exp\brb{-\sqrt{ab} \cosh x}  de^x  = \frac{1}{2 K_p(\sqrt{ab})} \int^\infty_{-\infty}  e^{px} \exp\brb{-\sqrt{ab} \cosh x}  dx\\
& = & \frac{1}{K_p(\sqrt{ab})} \int^\infty_0  \cosh \brb{px} \exp\brb{-\sqrt{ab} \cosh x}  dx = \frac{1}{K_p(\sqrt{ab})} K_p(\sqrt{ab}) = 1
\eeast
by Proposition \ref{pro:modified_bessel_function_second_cosh_integral}.
\end{proof}

\begin{proposition}\label{pro:mgf_generalized_inverse_gaussian}
Suppose $X \sim GIG(a,b,p)$. Then for $t\in \R$,
\be
M_X(\theta) = \left(\frac{a}{a-2\theta}\right)^{\frac{p}{2}}\frac{K_p(\sqrt{b(a-2\theta})}{K_p(\sqrt{ab})} ,\quad\quad \phi_X(t) = \left(\frac{a}{a-2it}\right)^{\frac{p}{2}}\frac{K_p(\sqrt{b(a-2it})}{K_p(\sqrt{ab})} .
\ee%where $K_\nu(x)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{remark}
If we let $a = \lambda/\mu^2$, $b = \lambda$, and $p=-1/2$, then by Proposition \ref{pro:modified_bessel_function_second_nu_special_value},
\be
M_X(\theta) = \left(\frac{a}{a-2\theta}\right)^{-1/4}\frac{\brb{b(a-2\theta)}^{-1/4} e^{-\sqrt{b(a-2\theta)}}}{\brb{ab}^{-1/4}e^{-\sqrt{ab}}} = e^{\sqrt{ab}\brb{1-\sqrt{1-\frac{2\theta}a}}} = \exp\brb{\frac{\lambda}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}
\ee
which is pdf of inverse gaussian distribution.

If we let $a = 2 \lm$, $b = 0$, and $p = k$, then by Proposition \ref{pro:modified_bessel_function_second_close_to_zero}, $z\to 0$, $K_\nu(z) \sim \frac 12 \Gamma(\nu) \brb{\frac 12z}^{-\nu}$
\be
M_X(\theta) = \left(\frac{a}{a-2\theta}\right)^{k/2}\frac{\frac 12 \Gamma(k) \brb{\frac 12\sqrt{b(a-2\theta} }^{-k} }{\frac 12 \Gamma(k) \brb{\frac 12\sqrt{ba} }^{-k} } =  \left(\frac{a}{a-2\theta}\right)^{k} = \left(\frac{\lm}{\lm -\theta}\right)^{k}
\ee
which is pdf of Gamma distribution.
\end{remark}

\begin{proof}[\bf Proof]
For moment generating function,
\beast
M_X(\theta)& = & \int^\infty_0 e^{\theta x} \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{p-1} e^{-(ax + b/x)/2} dx \\
& = & \int^\infty_0 \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} \exp\brb{-\frac{\sqrt{(a-2\theta)b}}2\brb{\sqrt{\frac{a-2\theta}b}x + \sqrt{\frac b{a-2\theta}}\frac 1x}}  dx\\
& = & \frac{1}{2 K_p(\sqrt{ab})}\brb{\frac{a}{a-2\theta}}^{p/2} \int^\infty_0  t^{(p-1)} \exp\brb{-\frac{\sqrt{(a-2\theta)b}}2\brb{t + \frac 1t}}  dt.
\eeast

Taking the substitution $t = e^x$, we have that
\beast
M_X(\theta) & = & \frac{1}{2 K_p(\sqrt{ab})}\brb{\frac{a}{a-2\theta}}^{p/2}  \int^\infty_{-\infty}  e^{(p-1)x} \exp\brb{-\sqrt{(a-2\theta)b}\cosh x}  dx\\
& = & \frac{1}{K_p(\sqrt{ab})}\brb{\frac{a}{a-2\theta}}^{p/2}  \int^\infty_0  \cosh \brb{px} \exp\brb{-\sqrt{(a-2\theta)b}\cosh x}  dx = \left(\frac{a}{a-2\theta}\right)^{\frac{p}{2}}\frac{K_p(\sqrt{b(a-2\theta})}{K_p(\sqrt{ab})}
\eeast
by Proposition \ref{pro:modified_bessel_function_second_cosh_integral}. Similarly for $\phi_X(t)$.
\end{proof}

\begin{proposition}\label{pro:moments_generalized_inverse_gaussian}
Suppose $X \sim GIG(a,b,p)$. Then
\beast
\text{(i)}\ \E X = \frac{\sqrt{b}\ K_{p+1}(\sqrt{a b}) }{ \sqrt{a}\ K_{p}(\sqrt{a b})} ,\qquad \text{(ii)}\ \var X = \left(\frac{b}{a}\right)\brb{\frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})}-\left(\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}\right)^2},\qquad \text{(iii)}\ \E X^n = \brb{\frac{b}{a}}^{n/2} \frac{K_{p+n}(\sqrt{ab})}{K_p(\sqrt{ab})}.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
With Propositions \ref{pro:mgf_generalized_inverse_gaussian}, \ref{pro:mgf_finite_moment},
\beast
\E X^n = \int^\infty_0 \frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{p+n-1} e^{-(ax + b/x)/2} dx = \brb{\frac{b}{a}}^{n/2}\int^\infty_0 \frac{(a/b)^{p+n/2}}{2 K_p(\sqrt{ab})} x^{p+n-1} e^{-(ax + b/x)/2} dx = \brb{\frac{b}{a}}^{n/2} \frac{K_{p+n}(\sqrt{ab})}{K_p(\sqrt{ab})}.
\eeast

Therefore,
\be
\E X = \frac{\sqrt{b}\ K_{p+1}(\sqrt{a b}) }{ \sqrt{a}\ K_{p}(\sqrt{a b})} ,\qquad \var X = \left(\frac{b}{a}\right)\brb{\frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})}-\left(\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}\right)^2}.
\ee
%Then $\E X^3 = \brb{\frac{b}{a}}^{3/2} \frac{K_{p+3}(\sqrt{ab})}{K_p(\sqrt{ab})}$. Thus,
%\beast
%\E\brb{X-\E X}^3 & = & \brb{\frac{b}{a}}^{3/2} \frac{K_{p+3}(\sqrt{ab})}{K_p(\sqrt{ab})} - 3\brb{\brb{\frac{b}{a}}^{1/2} \frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})} }\brb{\frac{b}{a} \frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})} } + 2\brb{\brb{\frac{b}{a}}^{1/2} \frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}}^3\\
%& = & \brb{\frac{b}{a}}^{3/2}\brb{\frac{K_{p+3}(\sqrt{ab})}{K_p(\sqrt{ab})} - 3\frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})}\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})} + 2\brb{\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}}^3}
%\eeast
%By Definition \ref{def:skewness},
%\beast
%& & \skewness(X) \\
%& = &  \left.\brb{\frac{b}{a}}^{3/2}\brb{\frac{K_{p+3}(\sqrt{ab})}{K_p(\sqrt{ab})} - 3\frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})}\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})} + 2\brb{\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}}^3}\right/ \brb{\left(\frac{b}{a}\right)\brb{\frac{K_{p+2}(\sqrt{ab})}{K_p(\sqrt{ab})}-\left(\frac{K_{p+1}(\sqrt{ab})}{K_p(\sqrt{ab})}\right)^2}}^{3/2}\\
%& = & \left.\brb{K_{p+3}(\sqrt{ab}) - 3K_{p+2}(\sqrt{ab})K_{p+1}(\sqrt{ab}) + 2K_{p+1}(\sqrt{ab})^3}\right/\brb{}
%\eeast
%Furthermore,
%\beast
%\E X^4 = \left.\frac {d^4 M_X(\theta)}{d\theta^4}\right|_{\theta=0} & = & \left. \brb{\mu^4 \brb{1-\frac{2\mu^2\theta}{\lm}}^{-2} + \frac{3\mu^5}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2}  + \frac{3\mu^6}{\lm^2}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}     \right|_{\theta=0}\\
%& & + \left. \brb{\frac{3\mu^5}{\lm} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-5/2} + \frac{12 \mu^6}{\lm^2} \brb{1-\frac{2\mu^2\theta}{\lm}}^{-3}  +  \frac{15\mu^7}{\lm^3}  \brb{1-\frac{2\mu^2\theta}{\lm}}^{-7/2} }e^{\frac{\lm}{\mu}\brb{1-\sqrt{1-\frac{2\mu^2\theta}{\lm}}}}   \right|_{\theta=0}\\
%& = & \mu^4 + \frac{6\mu^5}{\lm} + \frac{15\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3}.
%\eeast
%Thus,
%\beast
%\E\brb{X-\mu}^4 & = & \E X^4 - 4\mu\E X^3 + 6\mu^2 \E X^2 - 4\mu^3\E X + \mu^4 \\
%& = & \mu^4 + \frac{6\mu^5}{\lm} + \frac{15\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3} - 4\mu\brb{\mu^3 + \frac{3\mu^4}{\lm} + \frac{3\mu^5}{\lm^2}} + 6 \mu^2 \brb{\mu^2 + \frac{\mu^3}{\lm}} - 3\mu^4 = \frac{3\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3}.
%\eeast
%By Definition \ref{def:kurtosis}, we have
%\be
%\kurt(X) = \frac{\frac{3\mu^6}{\lm^2} + \frac{15\mu^7}{\lm^3} }{\frac{\mu^6}{\lm^2}} -3 = \frac{15\mu }{\lm}.
%\ee%For (v), we know that $\frac {d^n M_X(\theta)}{d\theta^n} = \lm^k k(k+1)\dots (n+k-1)/(\lm -\theta)^{n+k}$,be\E X^n = \left.\frac {d^n M_X(\theta)}{d\theta^n}\right|_{\theta=0} = \frac {k(k+1)\dots (n+k-1)}{\lm^n}.
\end{proof}

\section{Generalized Extreme Value Distribution}

\subsection{Fr\'echet distribution}

\begin{definition}[Fr\'echet distribution\index{Fr\'echet distribution}]\label{def:frechet_distribution}
A random variable $X\in (\mu,\infty)$ is called Fr\'echet distributed if, for some $\alpha >0$, $\mu\in \R$ and $\sigma > 0$. Its density function is
\be
f_X(x) = \frac{\alpha}{\sigma} \brb{\frac{x-\mu}{\sigma}}^{-1-\alpha} \exp\brb{-\brb{\frac{x-\mu}{\sigma}}^{-\alpha}}
\ee

We write $X\sim \fred\brb{\alpha,\mu,\sigma}$.
\end{definition}

\begin{proposition}
Suppose $X\sim \fred\brb{\alpha,\mu,\sigma}$. Then
\be
\text{(i)}\quad \E X = \left\{\ba{ll} \mu+\sigma\Gamma \brb{1-\frac 1{\alpha}} \quad\quad & \alpha >1 \\ \infty & \text{otherwise}\ea\right.
\ee

\be
\text{(ii)}\quad \var X = \left\{\ba{ll} \sigma^2\brb{\Gamma \brb{1-\frac 2{\alpha}} - \Gamma^2 \brb{1-\frac 1{\alpha}}}  \quad\quad & \alpha >2 \\ \infty & \text{otherwise}\ea\right.
\ee

\be
\text{(iii)}\quad \skewness X = \begin{cases} \frac{\Gamma \brb{1-\frac 3{\alpha}}- 3\Gamma \brb{1-\frac 2{\alpha}}\Gamma \brb{1-\frac 1{\alpha}} + 2\Gamma^3 \brb{1-\frac 1{\alpha}}}{\brb{\Gamma \brb{1-\frac 2{\alpha}} - \Gamma^2 \brb{1-\frac 1{\alpha}}}^{3/2}}  \quad\quad & \alpha >3 \\ \infty & \text{otherwise}\end{cases}
\ee

\be
\text{(iv)}\quad \ekurt X = \left\{\ba{ll} -6+ \frac{\Gamma \brb{1-\frac 4{\alpha}}- 4\Gamma \brb{1-\frac 3{\alpha}}\Gamma \brb{1-\frac 1{\alpha}} + 3\Gamma^2 \brb{1-\frac 2{\alpha}}}{\brb{\Gamma \brb{1-\frac 2{\alpha}} - \Gamma^2 \brb{1-\frac 1{\alpha}}}^2}  \quad\quad & \alpha >4 \\ \infty & \text{otherwise}\ea\right.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\subsection{Gumbel distribution}

\begin{definition}[Gumbel distribution\index{Gumbel distribution}\index{double exponential distribution}]\label{def:gumbel_distribution}
A random variable $X\in \R$ is called Gumbel distributed if, for some $\mu \in\R$, $\sigma >0$. Its density function is
\be
f_X(x) = \frac{1}{\sigma} \exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}}
\ee

We write $X\sim \gumd\brb{\mu,\sigma}$.
\end{definition}

\begin{remark}
We can check the integral of the density function
\beast
\int^\infty_{-\infty} f_X(x)dx & = & -\int^\infty_{-\infty}\exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}} d\brb{-\frac{x-\mu}{\sigma}} = -\int^{-\infty}_{\infty}\exp\brb{x - \exp\brb{x}} dx \\
& = &  -\int^{-\infty}_{\infty}\exp\brb{-\exp\brb{x}} d\exp(x) =  -\int^{0}_{\infty}\exp\brb{-x} dx = \left.\exp\brb{-x}\right|^0_\infty = 1.
\eeast
\end{remark}


\begin{proposition}\label{pro:moments_gumbel}
Suppose $X\sim \gumd\brb{\mu,\sigma}$. Then
\beast
\text{(i)}\quad \E X = \mu + \sigma \gamma\qquad  \text{(ii)}\quad \var X = \frac{\pi^2\sigma^2}{6}\qquad  \text{(iii)}\quad \skewness(X) = \frac {12\sqrt{6}}{\pi^3}\zeta(3) \approx 1.14\qquad  \text{(iv)}\quad \ekurt(X)= \frac{12}5
\eeast
where $\gamma$ is Euler's constant.
\end{proposition}

\begin{proof}[\bf Proof]
\ben
\item [(i)] For the mean we calculate the integral and let $\ln y = x$
\beast
\int^\infty_{-\infty} xf_X(x)dx & = &\sigma \int^\infty_{-\infty}\frac{x-\mu}{\sigma} \exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}} d\brb{\frac{x-\mu}{\sigma}} + \mu \\
& = & \mu +\sigma \int^{-\infty}_{\infty} x \exp\brb{x - \exp\brb{x}} dx = \mu + \sigma \int^0_{\infty}\ln y \exp\brb{- y}y  d(\ln y) \\
& = & \mu - \sigma \int^{\infty}_{0}\exp\brb{- y} \ln y  dy = \mu + \sigma \gamma
\eeast
by Proposition \ref{pro:gamma_integral_exp_x_power_of_ln_x}. %Proposition \ref{pro:gamma_integral_equivalent_forms}.

\item [(ii)] For the variance we have% $\ln y = x^{1/2}$
\beast
\int^\infty_{-\infty} (x-\mu)^2 f_X(x)dx & = &\sigma^2 \int^\infty_{-\infty} \brb{\frac{x-\mu}{\sigma}}^2 \exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}} d\brb{\frac{x-\mu}{\sigma}} \\
& = & \sigma^2 \int^{\infty}_{-\infty} x^2 \exp\brb{x - \exp\brb{x}} dx = \sigma^2 \int^{\infty}_0 \brb{\ln y}^2 \exp\brb{- y}y  d(\ln y) \\
& = & \sigma^2 \int^{\infty}_0 \brb{\ln y}^2 \exp\brb{- y} d y = \sigma^2\brb{\gamma^2 + \frac{\pi^2}6}
\eeast
by Proposition \ref{pro:gamma_integral_exp_x_power_of_ln_x}. Then
\be
\var X = \E\brb{X-\mu - \sigma\gamma}^2 = \E\brb{X-\mu}^2 - \sigma^2 \gamma^2 = \frac{\pi^2\sigma^2}{6}.
\ee

\item [(iii)] For skewness we have
\beast
\int^\infty_{-\infty} (x-\mu)^3 f_X(x)dx & = &\sigma^3 \int^\infty_{-\infty} \brb{\frac{x-\mu}{\sigma}}^3 \exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}} d\brb{\frac{x-\mu}{\sigma}} \\
& = & \sigma^3 \int^{-\infty}_{\infty} x^3 \exp\brb{x - \exp\brb{x}} dx = \sigma^3 \int^0_{\infty} \brb{\ln y}^3 \exp\brb{- y}y  d(\ln y) \\
& = & -\sigma^3 \int^{\infty}_0 \brb{\ln y}^3 \exp\brb{- y} d y = \sigma^3\brb{\gamma^3 + \frac{\gamma\pi^2}2 + 2\zeta(3)}
\eeast
by Proposition \ref{pro:gamma_integral_exp_x_power_of_ln_x}. Then
\beast
\skewness(X) & = & \frac{\E\brb{X-\mu - \sigma\gamma}^3}{\brb{\var X}^{3/2}} = \frac{\E\brb{X-\mu}^3 - 3\sigma\gamma\E\brb{X-\mu}^2 + 2\sigma^3\gamma^3}{\brb{\frac{\pi^2\sigma^2}6}^{3/2}} \\
& = & \frac{\sigma^3\brb{\gamma^3 + \frac{\gamma\pi^2}2 + 2\zeta(3)} - 3\gamma \sigma^3\brb{\gamma^2 + \frac{\pi^2}6}  + 2\sigma^3\gamma^3}{\brb{\frac{\pi^2\sigma^2}6}^{3/2}}= \frac{12\sqrt{6}\sigma^3\zeta(3)}{\pi^3\sigma^3} =  \frac {12\sqrt{6}}{\pi^3}\zeta(3) .
\eeast

\item [(iv)] For excess kurtosis we have
\beast
\int^\infty_{-\infty} (x-\mu)^4 f_X(x)dx & = &\sigma^4 \int^\infty_{-\infty} \brb{\frac{x-\mu}{\sigma}}^4 \exp\brb{-\brb{\frac{x-\mu}{\sigma} + \exp\brb{-\frac{x-\mu}{\sigma}}}} d\brb{\frac{x-\mu}{\sigma}} \\
& = & \sigma^4 \int^{\infty}_{-\infty} x^4 \exp\brb{x - \exp\brb{x}} dx = \sigma^4 \int^{\infty}_0 \brb{\ln y}^4 \exp\brb{- y}y  d(\ln y) \\
& = & \sigma^4 \int^{\infty}_0 \brb{\ln y}^4 \exp\brb{- y} d y = \sigma^4\brb{\gamma^4 + \pi^2 \gamma^2 + 8 \gamma \zeta(3) + \frac{3\pi^4}{20}}
\eeast
by Proposition \ref{pro:gamma_integral_exp_x_power_of_ln_x}. Then
\beast
\ekurt(X) & = & \frac{\E\brb{X-\mu - \sigma\gamma}^4}{\brb{\var X}^{2}} -3 = \frac{\E\brb{X-\mu}^4 -4\sigma\gamma\E\brb{X-\mu}^3 + 6 \sigma^2\gamma^2 \E\brb{X-\mu}^2- 3\sigma^4\gamma^4}{\brb{\frac{\pi^2\sigma^2}6}^{2}} -3 \\
& = & \frac{\sigma^4\brb{\gamma^4 + \pi^2 \gamma^2 + 8 \gamma \zeta(3) + \frac{3\pi^4}{20}} - 4\gamma \sigma^4\brb{\gamma^3 + \frac{\gamma\pi^2}2 + 2\zeta(3)}  + 6\gamma^2\sigma^4 \brb{\gamma^2 + \frac{\pi^2}6}  -3 \sigma^4\gamma^4}{\brb{\frac{\pi^2\sigma^2}6}^{2}} -3 \\
& = & \frac{3\sigma^4\pi^4/20}{\pi^4\sigma^4/36} -3 =  \frac {27}{5} - 3 = \frac{12}5 .
\eeast
\een%\footnote{proof needed.}
\end{proof}

\begin{proposition}\label{pro:mgf_cf_gumbel}
Let $X\sim \gumd\brb{\mu,\sigma}$. Then for $\theta,t\in \R$ with $\theta \neq n/\sigma,n\in \Z^+$,
\be
M_x(\theta) = \Gamma(1-\sigma \theta)e^{\mu \theta},\qquad \phi_x(t) = \Gamma(1- i\sigma t)e^{i\mu  t}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\subsection{Reversed Weibull distribution}

\begin{definition}[reversed Weibull distribution\index{reversed Weibull distribution}]\label{def:reversed_weibull_distribution}
A random variable $X\in (-\infty, \mu)$ is called reversed Weibull distributed if, for some $\alpha >0$, $\mu\in \R$ and $\sigma>0$. Its density function is
\be
f_X(x) = \frac{\alpha}{\sigma} \brb{-\frac{x-\mu}{\sigma}}^{\alpha-1} \exp\brb{-\brb{-\frac{x-\mu}{\sigma}}^{\alpha}}
\ee

We write $X\sim RW\brb{\alpha,\mu,\sigma}$.
\end{definition}


\subsection{Generalized extreme value distribution}

\begin{definition}[generalized extreme value distribution\index{generalized extreme value distribution}]
A random variable $X\in (-\infty, \mu)$ is called generalized extreme value distributed if, for some $\xi \in \R$, $\mu\in \R$ and $\sigma>0$. Its density function is
\be
f(x) = \begin{cases}
\frac 1{\sigma}\brb{1+ \xi\brb{\frac{x-\mu}{\sigma}}}^{-1/\xi-1} \exp\brb{-\brb{1+ \xi\brb{\frac{x-\mu}{\sigma}}}^{-1/\xi}} \quad\quad & \xi \neq 0 \\
\frac 1{\sigma} \exp\brb{-\frac{x-\mu}{\sigma}}\exp\brb{-\exp\brb{-\frac{x-\mu}{\sigma}}} & \xi = 0
\end{cases}
\ee


Its cumulative distribution function is
\be
F(x) = \begin{cases}
\exp\brb{-\brb{1+ \xi\brb{\frac{x-\mu}{\sigma}}}^{-1/\xi}} \quad\quad & \xi \neq 0 \\
\exp\brb{-\exp\brb{-\frac{x-\mu}{\sigma}}} & \xi = 0
\end{cases}
\ee

We write $X \sim GEV(\mu,\sigma,\xi)$.
\end{definition}

\begin{proposition}\label{pro:moments_general_extreme_value}
Let $X\sim GEV(\mu,\sigma,\xi)$. Then
\be
\E X = \left\{\ba{ll}
\mu + \sigma \brb{\Gamma(1-\xi)-1}/\xi \quad \quad & \xi <1, \ \xi \neq 0 \\
\mu + \sigma \gamma & \xi = 0 \\
\infty & \xi \geq 1
\ea\right.\qquad  \var X = \left\{\ba{ll}
\sigma^2 \brb{\Gamma(1-2\xi) - \Gamma^2(1-\xi)}/\xi^2 \quad \quad & \xi \neq 0,\ \xi < \frac 12 \\
\brb{\sigma^2\pi^2}/6 & \xi = 0 \\
\infty & \xi \geq \frac 12
\ea\right.
\ee

\be
\skewness(X) = \left\{\ba{ll}
\brb{\Gamma(1-3\xi) - 3\Gamma(1-\xi)\Gamma(1-2\xi) + \Gamma^3(1-\xi)}\brb{\Gamma(1-2\xi) - \Gamma^2(1-\xi)}^{-3/2} & \xi >0 \\
- \brb{\Gamma(1-3\xi) - 3\Gamma(1-\xi)\Gamma(1-2\xi) + \Gamma^3(1-\xi)}\brb{\Gamma(1-2\xi) - \Gamma^2(1-\xi)}^{-3/2}\quad \quad & \xi <0 \\
\frac{12\sqrt{6}}{\pi^3}\zeta(3)  & \xi =0
\ea\right.
\ee

\be
\ekurt(X) = \left\{\ba{ll}
\frac{\Gamma(1-4\xi) - 4\Gamma(1-\xi)\Gamma(1-3\xi) + 6\Gamma(1-2\xi)\Gamma^2(1-\xi) - 3\Gamma^4(1-\xi)}{\brb{\Gamma(1-2\xi) - \Gamma^2(1-\xi)}^{2}}-3\quad \quad & \xi \neq 0,\ \xi  < \frac 14 \\
\frac {12}5 & \xi =0  \\
\infty & \xi \geq \frac 14
\ea\right.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\section{Generalized Pareto Family}


\subsection{Generalized Pareto distribution}

\begin{definition}[generalized Pareto random variable]\label{def:generalized_pareto_rv}
A random variable $X$ in $[0,\infty)$ is called generalized Pareto distributed\index{generalized Pareto distributed random variable} if, for some $\mu\in \R, \sigma>0, \xi \in \R$, its density function is
\be
f_X(x) = \begin{cases}
\frac 1{\sigma}\left(1+{\frac  {\xi (x-\mu )}{\sigma }}\right)^{-\frac 1{\xi}-1 }\quad\quad & \xi \neq 0,\\
\frac 1{\sigma}\exp \left(-{\frac  {x-\mu }{\sigma }}\right) & \xi =0.
\end{cases}
\ee
for $x\geq \mu$ when $\xi \geq 0$ and $\mu\leq x\leq \mu - \sigma/\xi$ when $\xi <0$. $\mu$ is location parameter, $\sigma$ is scale parameter and $\xi$ is shape parameter. Its cumulative distribution function is
\be
F_X(x)=\begin{cases}
1-\left(1+{\frac  {\xi (x-\mu )}{\sigma }}\right)^{{-1/\xi }}\quad\quad & \xi \neq 0,\\
1-\exp \left(-{\frac  {x-\mu }{\sigma }}\right) & \xi =0.
\end{cases}
\ee

We write $X \sim GP(\mu, \sigma, \xi)$.
\end{definition}

\begin{proposition}\label{pro:moments_generalized_pareto}
Let $X \sim GP(\mu, \sigma, \xi)$. Then
\be
\text{(i)}\ \E X = \begin{cases}
\mu + \frac{\sigma}{1-\xi} \quad\quad & \xi <1 \\
\text{undefined} & \xi \geq 1
\end{cases}\qquad
\text{(ii)}\ \var X = \begin{cases}
\frac{\sigma^2}{(1-\xi)^2(1-2\xi)} \quad\quad & \xi <1/2 \\
\text{undefined} & \xi \geq 1/2
\end{cases}
\ee
\be
\text{(iii)}\ \skewness(X) = \begin{cases}
\frac{2(1+\xi)\sqrt{1-2\xi}}{1-3\xi} \quad\quad & \xi <1/3 \\
\text{undefined} & \xi \geq 1/3
\end{cases}\qquad
\text{(iv)}\ \ekurt(X) = \begin{cases}
\frac{3(1-2\xi)\brb{2\xi^2 + \xi + 3}}{(1-3\xi)(1-4\xi)}-3 \quad\quad & \xi <1/4 \\
\text{undefined} & \xi \geq 1/4
\end{cases}
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\section{Generalized Hyperbolic Family}\label{sec:generalized_hyperbolic_family}

\subsection{Normal-inverse Gaussian random variables}

\begin{definition}[normal-inverse Gaussian random variable]\label{def:normal_inverse_gaussian_rv}
A random variable $X$ in $(-\infty,\infty)$ is called normal-inverse Gaussian distributed\index{normal-inverse Gaussian distributed random variable} if, for some $\mu,\alpha,\beta,\delta\in \R$ with $0 < \abs{\beta} \leq \alpha $, $\delta >0$ and $\gamma = \sqrt{\alpha^2 - \beta^2} \geq 0$ , its density function is
\be
f_X(x) = \frac{\alpha\delta K_1 \left(\alpha\sqrt{\delta^2 + (x - \mu)^2}\right)}{\pi \sqrt{\delta^2 + (x - \mu)^2}}  e^{\delta \gamma + \beta (x - \mu)}
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. $\mu$ is location parameter, $\beta$ asymmetry parameter and $\delta$ is scale parameter. We write $X \sim NIG(\mu, \alpha,\beta, \delta)$.
\end{definition}

It can be shown that in the tails, the NIG distribution behaves as\footnote{see \cite{Aas_Haff_2006}}
\be
f_X(x) \sim \text{const} \abs{x}^{-3/2}\exp\brb{-\alpha\abs{x} + \beta x} \quad\text{as }x\to \pm \infty.
\ee

More specifically, the heaviest tail decays as
\be
f_X(x) \sim \text{const} \abs{x}^{-3/2}\exp\brb{-\alpha\abs{x} + \beta \abs{x}} \quad \text{if }\left\{\ba{l} \beta < 0, x\to -\infty\\ \beta >0, x\to+\infty \ea\right.
\ee

and the lightest as
\be
f_X(x) \sim \text{const} \abs{x}^{-3/2}\exp\brb{-\alpha\abs{x} - \beta \abs{x}} \quad \text{if }\left\{\ba{l} \beta < 0, x\to +\infty\\ \beta >0, x\to -\infty \ea\right.
\ee

Thus, the two tails behave differentaly, but they are both semi-heavy\footnote{need definition for semi-heavy tail}. One would therefore expect NIG to model skewness rather well, at least in cases where the tails are not too heavy.


\subsection{Variance-gamma random variables}

\begin{definition}[variance-gamma random variable]\label{def:variance_gamma_rv}
A random variable $X$ in $(-\infty,\infty)$ is called variance-gamma distributed\index{variance-gamma distributed random variable} if, for some $\mu,\alpha,\beta,\lm\in \R$ with $\lm >0$ and $\gamma = \sqrt{\alpha^2 - \beta^2}>0$\footnote{see generalized hyperbolic distribution for details}, its density function is
\be
f_X(x) = \frac{\gamma^{2\lambda} | x - \mu|^{\lambda-1/2} K_{\lambda-1/2} \left(\alpha|x - \mu|\right)}{\sqrt{\pi} \Gamma (\lambda)(2 \alpha)^{\lambda-1/2}}  e^{\beta (x - \mu)}
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. $\mu$ is location parameter, $\beta$ is asymmetry parameter. We write $X \sim VG(\mu, \alpha,\beta, \lm)$.
\end{definition}


\begin{proposition}\label{pro:moments_variance_gamma}
Suppose $X \sim VG(\mu,\alpha,\beta,\lm)$. Then
\beast
\text{(i)}\ \E X = \mu + \frac{2\lm \beta }{\gamma^2} ,\qquad \text{(ii)}\ \var X = \frac{2\lm \brb{1 + 2\beta^2 /\gamma^2}}{\gamma^2} .
\eeast
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}

\begin{proposition}\label{pro:mgf_variance_gamma}
Suppose $X \sim VG(\mu,\alpha,\beta,\lm)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) = e^{\mu \theta}\brb{\gamma\left/\sqrt{\alpha^2 - (\beta + \theta)^2}\right.}^{2\lm}, \qquad \phi_X(t) = e^{i\mu t}\brb{\gamma\left/\sqrt{\alpha^2 - (\beta + it)^2}\right.}^{2\lm}.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
\footnote{proof needed.}
\end{proof}


\subsection{Hyperbolic random variables}

\begin{definition}[hyperbolic random variable]\label{def:hyperbolic_rv}
A random variable $X$ in $(-\infty,\infty)$ is called hyperbolic distributed\index{hyperbolic distributed random variable} if, for some $\mu,\alpha,\beta,\delta \in \R$ with $\delta \geq 0$ and $\gamma = \sqrt{\alpha^2 - \beta^2}>0$, its density function is
\be
f_X(x) = \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. $\mu$ is location parameter, $\beta$ asymmetry parameter and $\delta$ is scale parameter. We write $X \sim H(\mu, \alpha,\beta, \delta)$.
\end{definition}

\begin{proposition}
\be
\frac{\gamma}{2\alpha\delta K_1(\delta \gamma)}   \int^\infty_{-\infty}\exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}dx =1.
\ee
\end{proposition}

\begin{proof}[\bf Proof]
Taking the substitutions, we have (by Proposition \ref{pro:hyperbolic_function_relation})
\beast
I & = & \int^\infty_{-\infty}\exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}dx = \int^\infty_{-\infty}\exp\brb{-\alpha\sqrt{\delta^2 + x^2}+ \beta x}dx \\
& = & \delta \int^\infty_{-\infty}\exp\brb{-\alpha \delta \cosh t + \beta \delta \sinh t}d\sinh t = \delta \int^\infty_{-\infty}\exp\brb{-\gamma \delta \cosh (t-a)}\cosh t dt\\
& = & \delta \int^\infty_{-\infty}\exp\brb{-\gamma \delta \cosh t}\cosh (t+a) dt = 2\delta\cosh a  \int^\infty_0\exp\brb{-\gamma \delta \cosh t}\cosh t dt
\eeast
where $\cosh a = \frac{\alpha}{\gamma}$ and $\sinh a = \frac{\beta}{\gamma}$. Thus,
\be
I = 2 \delta \frac{\alpha}{\gamma} \int^\infty_0 \exp\brb{-\gamma \delta \cosh t}\cosh t d t = 2 \delta \frac{\alpha}{\gamma} K_1\brb{\gamma \delta }
\ee
by Proposition \ref{pro:modified_bessel_function_second_cosh_integral}. Thus, we have the required result.
\end{proof}

\begin{proposition}\label{pro:mgf_hyperbolic}
Suppose $X \sim H(\mu,\alpha,\beta,\delta)$. Then for $\theta,t\in \R$,
\be
M_X(\theta) = \frac{e^{\mu \theta}\gamma K_1\brb{\delta \sqrt{\alpha^2 -(\beta + \theta)^2}}}{\sqrt{\alpha^2 -(\beta + \theta)^2}K_1 (\delta \gamma)} ,\quad\quad \phi_X(t) = \frac{e^{i\mu t}\gamma K_1\brb{\delta \sqrt{\alpha^2 -(\beta + it)^2}}}{\sqrt{\alpha^2 -(\beta + it)^2}K_1 (\delta \gamma)} .
\ee
where $K_\nu(z)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{proof}[\bf Proof]
We have
\beast
M_X(\theta) & = & \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{\theta x}\exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}dx \\
& = & \frac{e^{\mu\theta}\gamma }{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ (\beta +\theta) \brb{x - \mu}}dx \\
& = & \frac{e^{\mu\theta}\gamma }{2\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\alpha \delta \cosh t+ (\beta +\theta) \delta \sinh t}\cosh t dt = \frac{e^{\mu\theta}\gamma }{2\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\delta \gamma'\cosh (t-b) }\cosh t dt \\
& = & \frac{e^{\mu\theta}\gamma }{2\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\delta \gamma'\cosh t }\cosh (t+b) dt = \frac{e^{\mu\theta}\gamma }{\alpha K_1(\delta \gamma)} \int^\infty_0 \exp\brb{-\delta \gamma'\cosh t }\cosh t dt
\eeast
where $\gamma' = \sqrt{\alpha^2 - (\beta + \theta)^2}$, $\cosh b = \frac{\alpha}{\gamma'}$ and $\sinh b = \frac{\beta + \theta}{\gamma'}$.

Thus, by Proposition \ref{pro:modified_bessel_function_second_cosh_integral}, we have
\be
M_X(\theta) = \frac{e^{\mu \theta}\gamma K_1\brb{\delta \sqrt{\alpha^2 -(\beta + \theta)^2}}}{\sqrt{\alpha^2 -(\beta + \theta)^2}K_1 (\delta \gamma)}.
\ee

Similarly, we have the characteristic function.
\end{proof}

\begin{proposition}\label{pro:moments_hyperbolic}
Suppose $X \sim H(\mu,\alpha,\beta,\delta)$. Then
\beast
\text{(i)}\ \E X = \mu + \frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)} ,\qquad \text{(ii)}\ \var X = \frac{\delta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)} + \frac{\beta^2\delta^2}{\gamma^2}\left(\frac{K_{3}(\delta\gamma)}{K_{1}(\delta\gamma)} -\frac{K_{2}^2(\delta\gamma)}{K_{1}^2(\delta\gamma)} \right).%,\qquad \text{(iii)}\ \E X^n = \brb{\frac{b}{a}}^{n/2} \frac{K_{p+n}(\sqrt{ab})}{K_p(\sqrt{ab})}.
\eeast
\end{proposition}

\begin{proof}[\bf Proof]%(i) and (ii) can be done using integration by parts. Or
With Propositions \ref{pro:mgf_generalized_inverse_gaussian}, \ref{pro:mgf_finite_moment},
\beast
\E X & = & \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} x \exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}dx = \mu + \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} x \exp\brb{-\alpha\sqrt{\delta^2 + x^2}+ \beta x}dx \\
& = & \mu + \frac{\gamma\delta }{2\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \sinh t \exp\brb{-\delta\gamma \cosh (t - a)}\cosh t dt  = \mu + \frac{\gamma\delta }{4\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\delta\gamma \cosh (t - a)}\sinh 2t dt \\
& = & \mu + \frac{\gamma\delta }{4\alpha K_1(\delta \gamma)} \int^\infty_{-\infty} \exp\brb{-\delta\gamma \cosh t}\sinh 2(t+a) dt = \mu + \frac{\gamma\delta \sinh(2a)}{2\alpha K_1(\delta \gamma)} \int^\infty_0 \exp\brb{-\delta\gamma \cosh t}\cosh 2t dt.
\eeast

Therefore,
\be
\E X = \mu + \frac{\gamma\delta \sinh(2a)}{2\alpha K_1(\delta \gamma)}K_2(\delta \gamma) = \mu + \frac{\gamma\delta \sinh a\cosh a}{\alpha K_1(\delta \gamma)}K_2(\delta \gamma)= \mu + \frac{\gamma\delta  \frac{\beta}{\gamma}\frac{\alpha}{\gamma}K_2(\delta \gamma) }{\alpha K_1(\delta \gamma)} = \mu + \frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}.
\ee

\beast
\E X^2 & = & \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} x^2 \exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}dx \\
& = & \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} (x-\mu)^2  \exp\brb{-\alpha\sqrt{\delta^2 + (x-\mu)^2}+ \beta (x-\mu)}dx + 2\mu\brb{\mu + \frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}} - \mu^2 \\
& = & \frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} x^2  \exp\brb{-\alpha\sqrt{\delta^2 + x^2}+ \beta x}dx + \mu\brb{\mu + 2\frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}}  .
\eeast

Then make the substitution, (also $4\cosh^3 t = \cosh (3t) + 3\cosh t$)
\beast
& & \frac{\gamma\delta^3}{2\alpha\delta K_1(\delta \gamma)} \int^\infty_{-\infty} \brb{\cosh^3(t+a)-\cosh(t+a)}  \exp\brb{-\gamma \delta \cosh t}dt \\
& = & \frac{\gamma\delta^2}{4\alpha K_1(\gamma)} \int^\infty_0 \brb{\cosh 3(t+a)-\cosh(t+a)}  \exp\brb{-\gamma \delta \cosh t}dt \\
& = & \frac{\gamma\delta^2}{4\alpha K_1(\gamma)} \int^\infty_0 \brb{\cosh (3t)\cosh (3a) - \cosh t \cosh a}  \exp\brb{-\gamma \delta \cosh t}dt \\
& = & \frac{\gamma\delta^2}{4\alpha K_1(\gamma)} \brb{K_3(\delta \gamma)\cosh (3a) - K_1(\delta \gamma)\cosh a} = \frac{\gamma\delta^2}{4\alpha K_1(\gamma)} \brb{K_3(\delta \gamma)\brb{4\cosh^3 a - 3\cosh a} - K_1(\delta \gamma)\cosh a}\\
& = & \frac{\delta^2 \beta^2 K_3(\delta \gamma)}{\gamma^2 K_1(\delta \gamma)} + \frac{\delta^2}{4 K_1(\delta \gamma)}\brb{K_3(\delta \gamma) - K_1(\delta \gamma)}
\eeast

By Proposition \ref{pro:modified_bessel_function_second_difference}, $K_{3}(z) - K_{1}(z) = \frac {4}z K_2(z)$ ($e^{(\nu-1)\pi i}K_{\nu - 1}(z) - e^{(\nu+1)\pi i} K_{\nu+1}(z) = \frac {2\nu}z e^{\nu \pi i} K_\nu(z)$). Thus,
\beast
\E X^2 & = & \frac{\delta^2 \beta^2 K_3(\delta \gamma)}{\gamma^2 K_1(\delta \gamma)} + \frac{\delta^2}{4 K_1(\delta \gamma)}\brb{K_3(\delta \gamma) - K_1(\delta \gamma)} + \mu\brb{\mu + 2\frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}} \\
& = & \frac{\delta^2 \beta^2 K_3(\delta \gamma)}{\gamma^2 K_1(\delta \gamma)} + \frac{\delta K_2(\delta \gamma)}{\gamma K_1(\delta \gamma)} + \mu\brb{\mu + 2\frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}}.
\eeast

Thus,
\beast
\var X & = & \frac{\delta^2 \beta^2 K_3(\delta \gamma)}{\gamma^2 K_1(\delta \gamma)} + \frac{\delta K_2(\delta \gamma)}{\gamma K_1(\delta \gamma)} + \mu\brb{\mu + 2\frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}} - \brb{\mu + \frac{\delta \beta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)}}^2\\
& = & \frac{\delta K_{2}(\delta \gamma)}{\gamma K_1(\delta\gamma)} + \frac{\beta^2\delta^2}{\gamma^2}\left(\frac{K_{3}(\delta\gamma)}{K_{1}(\delta\gamma)} -\frac{K_{2}^2(\delta\gamma)}{K_{1}^2(\delta\gamma)} \right).
\eeast
\end{proof}

\subsection{Generalized hyperbolic skewed $t$ random variables}

\begin{definition}[generalized hyperbolic skewed $t$ random variable]\label{def:generalized_hyperbolic_skewed_t_rv}
A random variable $X \in(-\infty,\infty)$ is called generalized hyperbolic skewed $t$-distributed\index{generalized hyperbolic skewed $t$ distributed random variable} if, for some $\mu,\beta,\delta,\nu \in \R$ with $\nu>0,\delta > 0$, its density function is
\be
f_X(x) =
\left\{\ba{ll}
\frac{2^{\frac{1-\nu}2}\delta^\nu \abs{\beta}^{\frac{\nu +1}2}K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}}\exp\brb{\beta(x-\mu)}}{\Gamma\brb{\frac{\nu}{2}}\sqrt{\pi}\brb{\sqrt{\delta^2 + (x-\mu)^2}}^{\frac{\nu+1}{2}}}\quad \quad & \beta \neq 0\\
\frac{\Gamma\brb{\frac{\nu+1}{2}}}{\sqrt{\pi}\delta\Gamma\brb{\frac{\nu}{2}}}\brb{1+\frac{(x-\mu)^2}{\delta^2}}^{-(\nu+1)/2} & \beta = 0
\ea
\right.
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. $\mu$ is location parameter, $\beta$ asymmetry parameter and $\delta$ is scale parameter. We write $X \sim ST(\mu, \beta, \delta,\nu)$ (see \cite{Aas_Haff_2006}).
\end{definition}

\begin{remark}
\ben
\item [(i)] Note that we have generalized hyperbolic skewed $t$-distribution by letting $\lm = -\nu/2$ and $\alpha \to \abs{\beta}$ (as $\alpha \geq \abs{\beta}$ and $\alpha$ can achieve $\abs{\beta}$) for Generalized hyperbolic distribution.
\item [(ii)] Note that when $\beta = 0$, the density function can be recognised as the density function of a non-central scaled Student's $t$-distribution (see Definition
    \ref{def:t_non_central_scaled_rv}) with $\nu$ degrees of freedom where ($\nu = \nu$, $\mu = \mu$ and $\delta = \sigma\sqrt{\nu}$). \een
\end{remark}

It follows that in the tails, the skewed $t$ density is given by (we can use Proposition \ref{pro:modified_bessel_function_second_asymptotic_expansions} here)
\be
f_X(x) \sim\text{const} \abs{x}^{-\nu/2-1}\exp\brb{-\abs{\beta} \abs{x} + \beta x}\quad \text{as }x\to \pm\infty.
\ee

Hence, the heaviest tail decays as
\be
f_X(x) \sim \text{const}\abs{x}^{\nu/2-1}\qquad \text{when }\left\{\ba{l}
\beta <0, x\to -\infty\\
\beta >0, x\to +\infty
\ea\right.
\ee
and the lightest as
\be
f_X(x) \sim \text{const}\abs{x}^{-\nu/2-1}\exp\brb{-2\abs{\beta}\abs{x}}\qquad \text{when }\left\{\ba{l}
\beta <0, x\to +\infty\\
\beta >0, x\to -\infty
\ea\right.
\ee

Thus, the generalized hyperbolic skewed $t$-distribution has one heavy and one semi-heavy tail.

\begin{proposition}\label{pro:hyperbolic_skewed_t_density_integral}
\be
\frac{2^{\frac{1-\nu}2}\delta^\nu \abs{\beta}^{\frac{\nu +1}2}}{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} \frac{K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}}\exp\brb{\beta(x-\mu)}}{\sqrt{\pi}\brb{\sqrt{\delta^2 + (x-\mu)^2}}^{\frac{\nu+1}{2}}} dx =1.
\ee
\end{proposition}

\begin{proof}[\bf Proof]%\footnote{check needed}
With Proposition \ref{pro:gig_density_integral}, we know that
\be
K_{\frac{\nu+1}2}(\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}) = \frac 12\int^\infty_0  \brb{\sqrt{\delta^2 + (x-\mu)^2}/\abs{\beta}}^{\frac{\nu+1}2} z^{\frac{\nu-1}2} \exp\brb{-\frac 12\brb{\brb{\delta^2 + (x-\mu)^2}z + \beta^2/z}}dz
\ee

Thus, by Fubini theorem (Theorem \ref{thm:fubini}) the integral becomes
\beast
& & \frac{2^{\frac{-\nu-1}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} \int^\infty_0  \frac{ z^{\frac{\nu-1}2}}{\sqrt{\pi}} \exp\brb{-\frac 12\brb{\brb{\delta^2 + (x-\mu)^2}z + \beta^2/z}} \exp\brb{\beta(x-\mu)} dz  dx\\
& = & \frac{2^{\frac{-\nu}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \frac 1{\sqrt{2\pi/z}}\int^{+\infty}_{-\infty} \exp\brb{-\frac{(x-\mu-\beta/z)^2}{2/z} } dx  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz  \\
& = & \frac{(\delta^2/2)^{\frac{\nu}2}}{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz = 1
\eeast
by using the integrals of Gaussian and gamma density functions.
%By Proposition \ref{pro:modified_bessel_function_second_sinh_integral}, we have that
%\be
%K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}} = \frac{\sqrt{\pi}\brb{\frac 12\abs{\beta} \sqrt{\delta^2 + (x-\mu)^2} }^{(\nu+1)/2}}{\Gamma\brb{\nu/2+1}} \int^\infty_0 e^{-\abs{\beta} \sqrt{\delta^2 + (x-\mu)^2} \cosh t}(\sinh t)^{\nu+1} dt.%\frac{2^{\frac{1-\nu}2}\delta^\nu \abs{\beta}^{\frac{\nu +1}2}}{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} \frac{K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}}\exp\brb{\beta(x-\mu)}}{\sqrt{\pi}\brb{\sqrt{\delta^2 + (x-\mu)^2}}^{\frac{\nu+1}{2}}} dx =
%\ee
%Hence, the whole integral becomes
%\be
%\int^{+\infty}_{-\infty} \int^\infty_0 \frac{2^{-\nu}\delta^\nu \abs{\beta}^{\nu +1}}{\Gamma\brb{\nu/2}\Gamma\brb{\nu/2+1}} \exp\brb{-\abs{\beta} \sqrt{\delta^2 + (x-\mu)^2} \cosh t+\beta(x-\mu)} (\sinh t)^{\nu+1} dt dx
%\ee
\end{proof}

\begin{proposition}\label{pro:moments_hyperbolic_skewed_t}
Suppose $X \sim ST(\mu, \beta, \delta,\nu)$ with $\beta \neq 0$. Then
\beast
& &\text{(i)}\ \E X = \begin{cases}\mu + \frac{\beta \delta^2}{\nu -2}& \nu > 2 \\ \text{undefined} & \text{otherwise} \end{cases}, \qquad \text{(ii)}\ \var X = \begin{cases}  \frac{\delta^2}{\nu-2} + \frac{2\beta^2 \delta^4}{(\nu-2)^2(\nu -4)} & \nu > 4\\ \infty & 2 < \nu \leq 4\\ \text{undefined} & \text{otherwise} \end{cases},\\
& & \text{(iii)}\ \skewness(X) = \begin{cases} \frac{2(\nu - 4)^{1/2}\beta\delta}{\brb{2\beta^2 \delta^2 + (\nu-2)(\nu-4)}^{3/2}}\brb{3(\nu-2) + \frac{8\beta^2\delta^2}{\nu-6}} & \nu > 6 \\ \text{undefined} & \text{otherwise} \end{cases}, \\
& & \text{(iv)}\ \ekurt(X) = \begin{cases} \frac{6}{\brb{2\beta^2\delta^2 + (\nu-2)(\nu-4)}^2}\brb{(\nu-2)^2(\nu-4) + \frac{16\beta^2\delta^2(\nu-2)(\nu-4)}{\nu-6} + \frac{8\beta^4\delta^4(5\nu-22)}{(\nu-6)(\nu-8)}} & \nu >
8\\ \infty & 6 < \nu \leq 8\\ \text{undefined} & \text{otherwise} \end{cases}. \eeast
\end{proposition}

\begin{remark}
Note that this is a bit different from $\beta = 0$ case (non-central scaled $t$-distribution with $\nu>1$ for the expectation) as $\nu >2$ is needed for the expectation.
\end{remark}

\begin{proof}[\bf Proof]
We apply the same trick in the proof of Proposition \ref{pro:hyperbolic_skewed_t_density_integral}. Also, it will be feasible to apply Fubini Theorem (Theorem \ref{thm:fubini}) and Proposition \ref{pro:moments_gaussian} for moments of Gaussian random variables.
\ben
\item [(i)] We have for $\nu >2$,
\beast
\E X & = & \mu + \frac{2^{\frac{-\nu-1}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} x \int^\infty_0  \frac{ z^{\frac{\nu-1}2}}{\sqrt{\pi}} \exp\brb{-\frac 12\brb{\brb{\delta^2 + x^2}z + \beta^2/z}} \exp\brb{\beta x} dz  dx\\
& = & \mu + \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \frac 1{\sqrt{2\pi/z}}\int^{+\infty}_{-\infty} x \exp\brb{-\frac{(x-\beta/z)^2}{2/z} } dx  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz  \\
& = & \mu + \frac{(\delta^2/2)^{\frac{\nu}2} \beta}{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 z^{\frac{\nu}2-2} \exp\brb{-\frac 12 \delta^2 z}  dz = \mu + \frac{\beta\delta^2\Gamma\brb{\frac{\nu}2-1}}{2\Gamma\brb{\frac{\nu}{2}}}  = \mu + \frac{\beta \delta^2}{\nu -2}.
\eeast

\item [(ii)] For $2<\nu \leq 4$, $\E X^2$ is positive infinity as the integrand is non-negative. For $\nu>4$, we have
\beast
\E (X-\mu)^2 & = & \frac{2^{\frac{-\nu-1}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} x^2 \int^\infty_0  \frac{ z^{\frac{\nu-1}2}}{\sqrt{\pi}} \exp\brb{-\frac 12\brb{\brb{\delta^2 + x^2}z + \beta^2/z}} \exp\brb{\beta x} dz  dx\\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \frac 1{\sqrt{2\pi/z}}\int^{+\infty}_{-\infty} x^2 \exp\brb{-\frac{(x-\beta/z)^2}{2/z} } dx  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz  \\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \brb{\frac{\beta^2+z}{z^2}} z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz = \frac{(\delta^2/2)^{2} \beta^2\Gamma\brb{\frac{\nu}2-2}}{\Gamma\brb{\frac{\nu}{2}}} + \frac{\delta^2 \Gamma\brb{\frac{\nu}2-1}}{2\Gamma\brb{\frac{\nu}{2}}} \\
& = & \frac{\beta^2 \delta^4}{(\nu -2)(\nu-4)} + \frac{\delta^2}{\nu-2}.
\eeast

Thus,
\beast
\var X & = & \E X^2 - (\E X)^2 = \E(X-\mu)^2 + 2\mu\E X - \mu^2 - (\E X)^2\\
& = & \frac{\beta^2 \delta^4}{(\nu -2)(\nu-4)} + \frac{\delta^2}{\nu-2} + 2\mu \brb{\mu + \frac{\beta \delta^2}{\nu -2}} -\mu^2 - \brb{\mu + \frac{\beta \delta^2}{\nu -2}}^2 \\
& = & \frac{\delta^2}{\nu-2} + \frac{2\beta^2 \delta^4}{(\nu-2)^2(\nu -4)}.
\eeast

\item [(iii)] For $\nu>6$, we have
\beast
\E (X-\mu)^3 & = & \frac{2^{\frac{-\nu-1}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} x^3 \int^\infty_0  \frac{ z^{\frac{\nu-1}2}}{\sqrt{\pi}} \exp\brb{-\frac 12\brb{\brb{\delta^2 + x^2}z + \beta^2/z}} \exp\brb{\beta x} dz  dx\\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \frac 1{\sqrt{2\pi/z}}\int^{+\infty}_{-\infty} x^3 \exp\brb{-\frac{(x-\beta/z)^2}{2/z} } dx  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz  \\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \brb{\frac{\beta^3+ 3\beta z}{z^3}} z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz = \frac{(\delta^2/2)^{3} \beta^3\Gamma\brb{\frac{\nu}2-3}}{\Gamma\brb{\frac{\nu}{2}}} + \frac{3\beta (\delta^2/2)^2 \Gamma\brb{\frac{\nu}2-2}}{\Gamma\brb{\frac{\nu}{2}}} \\
& = & \frac{\beta^3 \delta^6}{(\nu -2)(\nu-4)(\nu-6)} + \frac{3\beta \delta^4}{(\nu-2)(\nu-4)}.
\eeast

Thus,
\beast
\E\brb{ X -\mu - \frac{\beta \delta^2}{\nu -2} }^3& = & \E (X-\mu)^3 - \frac{3\beta \delta^2}{\nu -2}\E (X-\mu)^2 + 2\brb{\frac{\beta \delta^2}{\nu -2}}^3\\
& = & \frac{\beta^3 \delta^6}{(\nu -2)(\nu-4)(\nu-6)} + \frac{3\beta \delta^4}{(\nu-2)(\nu-4)} - \frac{3\beta \delta^2}{\nu -2}\brb{\frac{\beta^2 \delta^4}{(\nu -2)(\nu-4)} + \frac{\delta^2}{\nu-2}} + 2\brb{\frac{\beta \delta^2}{\nu -2}}^3\\
& = & \frac{\beta \delta^4}{(\nu -2)}\brb{\frac{\beta^2 \delta^2}{(\nu-4)(\nu-6)} + \frac{3}{(\nu-4)} - 3\brb{\frac{\beta^2\delta^2 }{(\nu -2)(\nu-4)} + \frac{1}{\nu-2}} + \frac{2\beta^2 \delta^2}{(\nu -2)^2}}\\
& = & \frac{2\beta \delta^4}{(\nu-2)^2(\nu-4)} \brb{\frac{8\beta^2\delta^2 }{(\nu -2)(\nu-6)} + 3}.
\eeast

Hence,
\be
\skewness(X) = \frac{\E\brb{ X -\mu - \frac{\beta \delta^2}{\nu -2} }}{(\var X)^{3/2}} = \frac{2(\nu - 4)^{1/2}\beta\delta}{\brb{2\beta^2 \delta^2 + (\nu-2)(\nu-4)}^{3/2}}\brb{3(\nu-2) + \frac{8\beta^2\delta^2}{\nu-6}}.
\ee

\item [(iv)] For $6 <\nu \leq 8$, $\E X^4$ is positive infinity as the integrand is non-negative. For $\nu>8$, we have
\beast
\E (X-\mu)^4 & = & \frac{2^{\frac{-\nu-1}2}\delta^\nu }{\Gamma\brb{\frac{\nu}{2}}}\int^{+\infty}_{-\infty} x^4 \int^\infty_0  \frac{ z^{\frac{\nu-1}2}}{\sqrt{\pi}} \exp\brb{-\frac 12\brb{\brb{\delta^2 + x^2}z + \beta^2/z}} \exp\brb{\beta x} dz  dx\\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \frac 1{\sqrt{2\pi/z}}\int^{+\infty}_{-\infty} x^4 \exp\brb{-\frac{(x-\beta/z)^2}{2/z} } dx  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz  \\
& = & \frac{(\delta^2/2)^{\frac{\nu}2} }{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 \brb{\frac{\beta^4+6\beta^2z + 3z^2}{z^4}} z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}  dz \\
& = & \frac{(\delta^2/2)^{4} \beta^4\Gamma\brb{\frac{\nu}2-4}}{\Gamma\brb{\frac{\nu}{2}}} + \frac{6(\delta^2/2)^{3} \beta^2\Gamma\brb{\frac{\nu}2-3}}{\Gamma\brb{\frac{\nu}{2}}} + \frac{3(\delta^2/2)^2 \Gamma\brb{\frac{\nu}2-2}}{\Gamma\brb{\frac{\nu}{2}}} \\
& = & \frac{\beta^4 \delta^8}{(\nu -2)(\nu-4)(\nu-6)(\nu-8)} + \frac{6\beta^2 \delta^6}{(\nu -2)(\nu-4)(\nu-6)} + \frac{3\delta^4}{(\nu -2)(\nu-4)}.
\eeast

Thus,
\beast
&&\E\brb{ X -\mu - \frac{\beta \delta^2}{\nu -2} }^4 - 3\brb{\var X}^2\\
& = & \E (X-\mu)^4 - \frac{4\beta \delta^2}{\nu -2}\E (X-\mu)^3 + 6\brb{\frac{\beta \delta^2}{\nu -2}}^2\E (X-\mu)^2 - 3 \brb{\frac{\beta \delta^2}{\nu -2}}^4 - 3\brb{\frac{\delta^2}{\nu-2} + \frac{2\beta^2 \delta^4}{(\nu-2)^2(\nu -4)}}^2\\
& = & \frac{\beta^4 \delta^8}{(\nu -2)(\nu-4)(\nu-6)(\nu-8)} + \frac{6\beta^2 \delta^6}{(\nu -2)(\nu-4)(\nu-6)} + \frac{3\delta^4}{(\nu -2)(\nu-4)} - 3\brb{\frac{\delta^2}{\nu-2} + \frac{2\beta^2 \delta^4}{(\nu-2)^2(\nu -4)}}^2\\
& & \qquad - \frac{4\beta \delta^2}{\nu -2} \brb{\frac{\beta^3 \delta^6}{(\nu -2)(\nu-4)(\nu-6)} + \frac{3\beta \delta^4}{(\nu-2)(\nu-4)}} + 6\brb{\frac{\beta \delta^2}{\nu -2}}^2 \brb{\frac{\beta^2 \delta^4}{(\nu -2)(\nu-4)} + \frac{\delta^2}{\nu-2}} - 3 \brb{\frac{\beta \delta^2}{\nu -2}}^4 \\
& = & \frac{6\delta^4}{(\nu-2)^2(\nu-4)} + \frac{96\beta^2\delta^6}{(\nu-2)^3(\nu-4)(\nu-6)} + \frac{240\nu - 1056}{(\nu-2)^4(\nu-4)^2(\nu-6)(\nu-8)}\\
& = & \frac{6\delta^4}{(\nu-2)^4(\nu-4)^2}\brb{(\nu-2)^2(\nu-4) + \frac{16\beta^2\delta^2(\nu-2)(\nu-4)}{\nu-6} + \frac{8\beta^4\delta^4\brb{5\nu - 22}}{(\nu-6)(\nu-8)}}.
\eeast

Hence, we have \be \ekurt(X) = \frac{6}{\brb{2\beta^2\delta^2 + (\nu-2)(\nu-4)}^2}\brb{(\nu-2)^2(\nu-4) + \frac{16\beta^2\delta^2(\nu-2)(\nu-4)}{\nu-6} + \frac{8\beta^4\delta^4(5\nu-22)}{(\nu-6)(\nu-8)}}. \ee \een
\end{proof}

\begin{proposition}
Suppose $X \sim ST(\mu, \beta, \delta,\nu)$. Then for $t\in \R$,
\be
\phi_X(t) = %\left\{\ba{ll}
\frac{ e^{i\mu t} K_{\nu/2} \brb{\delta \sqrt{t^2 - 2i\beta t}}\brb{\delta \sqrt{t^2 - 2i\beta t} }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}  %  \quad\quad & \beta \neq 0 \\ \quad\quad & \beta = 0 \ea\right.
\ee where $K_\nu(z)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{proof}[\bf Proof]
For $\beta = 0$, we can substitute $\sigma = \delta /\sqrt{\nu}$ into Proposition \ref{pro:moments_t_non_central_scaled} as it is non-central scaled $t$-distribution (see Definition
\ref{def:t_non_central_scaled_rv}). For this case, we have
\be
\phi_X(t) = \frac{ e^{i\mu t} K_{\nu/2} \brb{\delta |t|}\brb{\delta |t| }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}.
\ee

For $\beta \neq 0$, %\be
%\phi_X(t) = e^{i\mu t}\int^\infty_{-\infty} \frac{2^{\frac{1-\nu}2}\delta^\nu \abs{\beta}^{\frac{\nu +1}2}K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + x^2}}}\exp\brb{\beta(x-\mu)}\exp\brb{itx}}{\Gamma\brb{\frac{\nu}{2}}\sqrt{\pi}\brb{\sqrt{\delta^2
%+ x^2}}^{\frac{\nu+1}{2}}} dx
%\ee
%
using the same method with Proposition \ref{pro:hyperbolic_skewed_t_density_integral}, we have\footnote{Note that we might need some complex analysis here.}
\beast
\phi_X(t) = \E\brb{e^{itX}} & = & \frac{e^{i\mu t}(\delta^2/2)^{\frac{\nu}2}}{\Gamma\brb{\frac{\nu}{2}}} \int^\infty_0 z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta^2 z}\exp\brb{\frac{2i\beta t - t^2}{2z}} dz \\
& = & \frac{e^{i\mu t}(\delta^2/2)^{\frac{\nu}2}}{\Gamma\brb{\frac{\nu}{2}}} \brb{\frac{\sqrt{t^2 - 2i\beta t} }{\delta}}^{\nu/2} \int^\infty_0  z^{\frac{\nu}2-1} \exp\brb{-\frac 12 \delta \sqrt{t^2 - 2i\beta t} \brb{z + \frac 1z}}  dz
\eeast

Letting $z = e^y$, we have
\be
\phi_X(t) = \frac{2e^{i\mu t}(\delta^2/2)^{\frac{\nu}2}}{\Gamma\brb{\frac{\nu}{2}}} \brb{\frac{\sqrt{t^2 - 2i\beta t} }{\delta}}^{\nu/2} \int^\infty_0  \cosh \brb{\frac {\nu}2 y} \exp\brb{- \delta \sqrt{t^2 - 2i\beta t} \cosh y}  dy
\ee

Then by Proposition \ref{pro:modified_bessel_function_second_cosh_integral}, we have
\beast
\phi_X(t) = \frac{2e^{i\mu t}(\delta^2/2)^{\frac{\nu}2}}{\Gamma\brb{\frac{\nu}{2}}} \brb{\frac{\sqrt{t^2 - 2i\beta t} }{\delta}}^{\nu/2} K_{\nu/2} \brb{\delta \sqrt{t^2 - 2i\beta t}}
= \frac{ e^{i\mu t} K_{\nu/2} \brb{\delta \sqrt{t^2 - 2i\beta t}}\brb{\delta \sqrt{t^2 - 2i\beta t} }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}.
\eeast
%Then we can use the integral of density function of generalized inverse Gaussian random variable and get that\footnote{Details are needed since the density function is only for the real number $a$ and $b$ but not complex.}%proof needed for $\beta \neq 0$.}
%\beast
%\phi_X(t) & = & \frac{ e^{i\mu t} K_{\nu/2} \brb{\delta \sqrt{t^2 - 2i\beta t}}\brb{\delta \sqrt{t^2 - 2i\beta t} }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}} \\
%
%\eeast

When $\beta \to 0$, the result is consistent with the case $\beta = 0$.
\end{proof}


\subsection{Generalized hyperbolic random variables}

\begin{definition}[generalized hyperbolic random variable]\label{def:generalized_hyperbolic_rv}
A random variable $X \in(-\infty,\infty)$ is called generalized hyperbolic distributed\index{generalized hyperbolic distributed random variable} if,
for some $\mu,\alpha,\beta,\delta,\lm \in \R$ and $\gamma = \sqrt{\alpha^2 - \beta^2}$ with conditions (see \cite{Aas_Haff_2006})%see Prause 1999, The generalized hyperbolic models: estimation,financial derivatives and risk management. Phd Thesis, Mathematics Faculty, University of Freiburg}
\be
\left\{\ba{ll}
\delta\geq 0, \abs{\beta}< \alpha \quad\quad & \lm >0\\
\delta > 0, \abs{\beta} < \alpha & \lm =0\\
\delta > 0, \abs{\beta} \leq \alpha & \lm <0
\ea
\right.,
\ee
its density function is
\be
f_X(x) = \frac{(\gamma/\delta)^\lambda e^{\beta (x - \mu)} }{\sqrt{2\pi}K_\lambda(\delta \gamma)}   \frac{K_{\lambda - 1/2}\left(\alpha \sqrt{\delta^2 + (x - \mu)^2}\right)}{\left(\sqrt{\delta^2 + (x - \mu)^2} / \alpha\right)^{1/2 - \lambda}}
\ee
where $K_\nu(z)$ is a modified Bessel function of the second kind. $\mu$ is location parameter, $\beta$ asymmetry parameter and $\delta$ is scale parameter. We write $X \sim GH(\mu, \alpha,\beta, \delta,\lm)$.
\end{definition}

\begin{remark}
\ben
\item [(i)] It can be shown (by using Proposition \ref{pro:modified_bessel_function_second_asymptotic_expansions}) that in the tails, the generalized hyperbolic distribution behaves as
\be
f_X(x) \sim \text{const} \abs{x}^{\lm -1}\exp\brb{-\alpha \abs{x} + \beta x}\qquad \text{as }x\to \pm\infty,
\ee
for all values of $\lm$. Hence, as long as $\abs{\beta} \neq \alpha$, the generalized hyperbolic distribution has two semi-heavy tails.
\item [(ii)] This class is closed under linear operations\footnote{check needed}.
\een
\end{remark}

%\ref{pro:hyperbolic_skewed_t_density_integral}, we have\footnote{Note that we might need some complex analysis here.}
%{pro:generalized_hyperbolic_density_integral}

\begin{proposition}\label{pro:generalized_hyperbolic_density_integral}
\be
\int^\infty_{-\infty} \frac{(\gamma/\delta)^\lm e^{\beta (x - \mu)} }{\sqrt{2\pi}K_{\lm}(\delta \gamma)}   \frac{K_{\lm - 1/2}\left(\alpha \sqrt{\delta^2 + (x - \mu)^2}\right)}{\left(\sqrt{\delta^2 + (x - \mu)^2} / \alpha\right)^{1/2 - \lm}} dx = 1.
\ee%Suppose that $X\sim GH(\mu, \alpha,\beta, \delta,\lm)$. Then $
\end{proposition}

\begin{proof}[\bf Proof]
By Proposition \ref{pro:gig_density_integral},
\beast
K_{\lm - 1/2}\brb{\alpha \sqrt{\delta^2 + (x - \mu)^2}} & = & K_{1/2 -\lm}\brb{\alpha \sqrt{\delta^2 + (x - \mu)^2}} \\
& = & \frac 12 \int^\infty_0  \brb{\sqrt{\delta^2 + (x - \mu)^2}/\alpha} ^{1/2 - \lm } z^{-1/2 - \lm} e^{-\brb{\brb{\delta^2 + (x - \mu)^2}z + \alpha^2/z}/2}dz .
\eeast

Thus, the integral of density function is
\be
\frac 12\int^\infty_{-\infty} \frac{(\gamma/\delta)^\lm e^{\beta (x - \mu)} }{\sqrt{2\pi}K_{\lm}(\delta \gamma)} \int^\infty_0   z^{-1/2 - \lm } e^{-\brb{\brb{\delta^2 + (x - \mu)^2}z + \alpha^2/z}/2}dz dx
= \frac 12 \int^\infty_0 \frac{(\delta/\gamma)^{-\lm }}{K_{-\lm}(\delta \gamma)}    z^{-1 - \lm } e^{-\frac 12\brb{\delta^2 z + \gamma^2/z}}dz
\ee
by changing the order of integral (by Fubini theorem (Theorem \ref{thm:fubini}) and the fact $K_{\nu}(z) = K_{-\nu}(z)$). Then we apply Proposition \ref{pro:gig_density_integral} again and get the required result.
\end{proof}

\begin{proposition}\label{pro:gig_generalized_hyperbolic}
Suppose that $Y\sim \sN(0,1)$ and $Z\sim GIG(\gamma^2,\delta^2,\lm)$ and for some $\mu \in\R$,
\be
X = \mu + \beta Z + \sqrt{Z}Y.
\ee

Then $X \sim GH(\mu, \alpha,\beta, \delta,\lm)$ where $\alpha = \sqrt{\beta^2+\gamma^2}$.
\end{proposition}

\begin{remark}
\ben
\item [(i)] This conclusion explains why the conditions ($*$) in Definition \ref{def:generalized_hyperbolic_rv} are consistent with the conditions in Definition \ref{def:generalized_inverse_gaussian_rv}.
\item [(ii)] Clearly, we have $X|Z \sim \sN(\mu + \beta Z, Z)$.
\een
\end{remark}

\begin{proof}[\bf Proof]
First we have
\beast
\pro(X\leq x) & = & \pro\brb{\mu + \beta Z + \sqrt{Z}Y \leq x} = \pro\brb{Y \leq \frac{X-\mu -\beta Z}{\sqrt{Z}}} \\
& = & \int^\infty_0 \int^{\frac{x-\mu-\beta z}{\sqrt{z}}}_{-\infty} \frac{1}{\sqrt{2\pi}}e^{-y^2/2}dy \brb{\frac{\gamma}{\delta}}^\lm \frac{z^{\lm-1}}{2K_{\lm}(\gamma\delta)}\exp\brb{-\frac 12\brb{\gamma^2z + \delta^2/z}}dz.
\eeast%\footnote{check needed}

By Theorem \ref{thm:differentiation_under_integral_sign}, we take the differentiation of $\pro(X\leq x)$ and get
\beast
f_X(x) & = & \int^\infty_0 \frac{1}{\sqrt{2\pi z}} e^{-\frac{(x-\mu-\beta z)^2}{2z}} \brb{\frac{\gamma}{\delta}}^\lm \frac{z^{\lm-1}}{2K_{\lm}(\gamma\delta)}\exp\brb{-\frac 12\brb{\gamma^2z + \delta^2/z}}dz \\
& = & \frac{\brb{\gamma/\delta}^\lm  e^{\beta (x - \mu)} }{\sqrt{2\pi }K_{\lm}(\gamma\delta)} \int^\infty_0  \frac{z^{\lm-3/2}}{2}\exp\brb{-\frac 12\brb{(\beta^2+\gamma^2)z + \brb{(x-\mu)^2+\delta^2}/z}}dz \\
& = & \frac{(\gamma/\delta)^\lm e^{\beta (x - \mu)} }{\sqrt{2\pi}K_\lambda(\delta \gamma)}   \frac{K_{\lambda - 1/2}\left(\alpha \sqrt{\delta^2 + (x - \mu)^2}\right)}{\left(\sqrt{\delta^2 + (x - \mu)^2} / \alpha\right)^{1/2 - \lambda}}
\eeast
by Proposition \ref{pro:gig_density_integral}.
\end{proof}

\begin{proposition}
Let $X=\mu + \beta Z + \sqrt{Z}Y$ with $Y\sim \sN(0,1)$ and $Z \sim GIG(\gamma^2, \delta^2, \lm)$. We have that
\be
Z|X \sim GIG\brb{\alpha^2,(X-\mu)^2 + \delta^2,\lm -1/2}
\ee
where $\alpha = \sqrt{\beta^2 + \gamma^2}$.
\end{proposition}

\begin{proof}[\bf Proof]
First, we have
\beast
f_{X,Z}(x,z) = f_{X|Z}(x|z)f_Z(z) & = & \frac 1{\sqrt{2\pi z}}\exp\brb{-\frac{(x-\mu-\beta z)^2}{2z}} \brb{\frac{\gamma}{\delta}}^\lm \frac{z^{\lm-1}}{2K_{\lm}(\gamma\delta)}\exp\brb{-\frac 12\brb{\gamma^2z + \delta^2/z}}\\
& = & \frac{\brb{\gamma /\delta}^\lm z^{\lm-3/2}e^{\beta(x-\mu)}}{2{\sqrt{2\pi } K_{\lm}(\gamma\delta)}} \exp\brb{-\frac 12\brb{\alpha^2z + ((x-\mu)^2+\delta^2)/z}} .
\eeast

Thus,
\be
f_{Z|X}(z|x) = \frac{f_{X,Z}(x,z)}{f_X(x)} = \frac{\brb{\alpha^2/\sqrt{\delta^2 + (x - \mu)^2}}^{\lm-1/2} z^{\lm-3/2}}{2 K_{\lambda - 1/2}\left(\alpha \sqrt{\delta^2 + (x - \mu)^2}\right)} \exp\brb{-\frac 12\brb{\alpha^2z + ((x-\mu)^2+\delta^2)/z}}
\ee
as required (see Definition \ref{def:generalized_inverse_gaussian_rv}).
\end{proof}

\begin{proposition}\label{pro:mgf_generalized_hyperbolic}
Suppose $X \sim GH(\mu,\alpha,\beta,\delta,\lm)$. Then for $\theta,t\in \R$,%\footnote{$\abs{\alpha} > \abs{\beta+\theta}$? If mgf of GH exists, why not its special case skewed $t$-distribution?},
\be          %M_X(\theta) = \frac{e^{\mu \theta}\gamma^\lambda}{(\sqrt{\alpha^2 -(\beta +\theta)^2})^\lambda} \frac{K_\lambda(\delta \sqrt{\alpha^2 -(\beta +\theta)^2})}{K_\lambda (\delta \gamma)} ,\quad\quad
\phi_X(t) = \frac{e^{i\mu t}\gamma^\lambda}{(\sqrt{\alpha^2 -(\beta +it)^2})^\lambda} \frac{K_\lambda(\delta \sqrt{\alpha^2 -(\beta +it)^2})}{K_\lambda (\delta \gamma)}.
\ee
where $K_\nu(z)$ is modified Bessel function of the second kind.
\end{proposition}

\begin{proof}[\bf Proof]
using the same method with Proposition \ref{pro:generalized_hyperbolic_density_integral}, we have\footnote{Note that we might need some complex analysis here.}
\beast
\phi_X(t) & = & \frac 12 e^{i\mu t}  \int^\infty_0 \frac{(\delta/\gamma)^{-\lm }}{K_{-\lm}(\delta \gamma)}  z^{-1 - \lm } \exp\brb{-\frac 12\brb{\delta^2 z + \brb{\alpha^2- \brb{\beta + it}^2}/z}}dz  \\
& = &  \frac{e^{i\mu t}\gamma^\lambda}{(\sqrt{\alpha^2 -(\beta +it)^2})^\lambda} \frac{K_{-\lm}(\delta \sqrt{\alpha^2 -(\beta +it)^2})}{K_{-\lm} (\delta \gamma)}
= \frac{e^{i\mu t}\gamma^\lambda}{(\sqrt{\alpha^2 -(\beta +it)^2})^\lambda} \frac{K_{\lm}(\delta \sqrt{\alpha^2 -(\beta +it)^2})}{K_{\lm} (\delta \gamma)}
\eeast
by applying Proposition \ref{pro:gig_density_integral} and \ref{pro:modified_bessel_function_first_second_relation}.  %\footnote{need proof. Might use Proposition \ref{pro:gig_density_integral}.}
\end{proof}

\subsection{Relation between the members of generalized hyperbolic family}

The following table gives the special cases of generalized hyperbolic distribution where $\gamma = \sqrt{\alpha^2-\beta^2}$.

%\footnote{need to add parameters}
\begin{center}
%\begin{table}
\begin{tabular}{cccc}
\hline
distribution & pdf & cf & parameters for GH\\ \hline
\\

\vspace{4mm}

%inverse Gaussian & IG & $\brb{\frac{\lambda}{2 \pi x^3}}^{1/2} \exp\brb{-\frac{\lambda (x-\mu)^2}{2 \mu^2 x}}$ &  &  & \\
%\vspace{4mm}

$NIG$ & $\frac{\alpha\delta K_1 \left(\alpha\sqrt{\delta^2 + (x - \mu)^2}\right)}{\pi \sqrt{\delta^2 + (x - \mu)^2}} \exp\brb{\delta \gamma + \beta (x - \mu)}$ &  $e^{i\mu t + \delta (\gamma - \sqrt{\alpha^2 -(\beta + it)^2})}$ & $GH(\mu, \alpha,\beta, \delta,-1/2)$ \\

%\vspace{4mm}
%general inverse Gaussian & GIG & $\frac{(a/b)^{p/2}}{2 K_p(\sqrt{ab})} x^{(p-1)} \exp\brb{-(ax + b/x)/2}$ & & & \\

\vspace{4mm}

$VG$ & $\frac{\gamma^{2\lambda} | x - \mu|^{\lambda-1/2} K_{\lambda-1/2} \left(\alpha|x - \mu|\right)}{\sqrt{\pi} \Gamma (\lambda)(2 \alpha)^{\lambda-1/2}}  \exp\brb{\beta (x - \mu)}$ & $e^{i\mu t} \left(\gamma/\sqrt{\alpha^2 -(\beta+it)^2}\right)^{2\lm}$  & $GH(\mu, \alpha,\beta,0,\lm)$ \\

\vspace{4mm}

$H$ & $\frac{\gamma}{2\alpha\delta K_1(\delta \gamma)} \exp\brb{-\alpha\sqrt{\delta^2 + (x - \mu)^2}+ \beta (x - \mu)}$ & $\frac{e^{i\mu t}\gamma K_1(\delta \sqrt{ \alpha^2 -(\beta +it)^2)}}{\sqrt{\alpha^2 -(\beta + it)^2}K_1 (\delta \gamma)}$   & $GH(\mu, \alpha,\beta, \delta,1)$\\

\vspace{4mm}

$ST$ & $\frac{2^{\frac{1-\nu}2}\delta^\nu \abs{\beta}^{\frac{\nu +1}2}K_{\frac{\nu+1}2}\brb{\sqrt{\beta^2\brb{\delta^2 + (x-\mu)^2}}}\exp\brb{\beta(x-\mu)}}{\Gamma\brb{\frac{\nu}{2}}\sqrt{\pi}\brb{\sqrt{\delta^2 + (x-\mu)^2}}^{\frac{\nu+1}{2}}}$ & $\frac{ e^{i\mu t} K_{\nu/2} \brb{\delta \sqrt{t^2 - 2i\beta t}}\brb{\delta \sqrt{t^2 - 2i\beta t} }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}$ & $GH(\mu, \abs{\beta},\beta, \delta,-\nu/2)$\\

%$ST(\beta = 0)$ & $\frac{\Gamma\brb{\frac{\nu+1}{2}}}{\sqrt{\pi}\delta\Gamma\brb{\frac{\nu}{2}}}\brb{1+\frac{(x-\mu)^2}{\delta^2}}^{-(\nu+1)/2}$ & $\frac{ e^{i\mu t} K_{\nu/2} \brb{\delta |t|}\brb{\delta |t| }^{\nu/2}}{\Gamma(\nu/2)2^{\nu/2-1}}$ & $GH(\mu, 0, 0, \delta,-\nu/2)$\\

\hline
\end{tabular}
Note that we apply Proposition \ref{pro:modified_bessel_function_second_close_to_zero} ($\delta = 0$) when it is variance-gamma.
%\caption{Special case of generalized hyperbolic distribution}
%\end{table}
\end{center}

%\footnote{need to add parameters}

For $Y\sim \sN(0,1)$ and $\mu,\beta\in \R$,
\begin{center}
%\begin{table}
\begin{tabular}{cc}
\hline
$Z$ & $X = \mu+\beta Z +\sqrt{Z}Y$ \\ \hline

inverse Gaussian distribution & normal inverse Gaussian ($NIG$)\\

gamma distribution & variance gamma ($VG$) \\

 & hyperbolic distribution ($H$)\\

inverse gamma distribution & skewed $t$ distribution ($ST$)\\

generalized inverse Gaussian $(GIG)$ & generalized hyperbolic ($GH$)\\

\hline
\end{tabular}
%\caption{Special case of generalized hyperbolic distribution}
%\end{table}
\end{center}

%\section{Truncated Distributions}




\section{Truncated distribution}

Now we consider the truncated random variable case.

\subsection{Truncated normal distribution}

\begin{definition}[truncated normal distribution]
Let $X\sim \sN(\mu,\sigma^2)$ has a normal distribution and lies within the interval $X\in (a,b)$ where $-\infty\leq a<b\leq \infty$. Then $X$ conditional on $X\in (a,b)$ has a truncated normal distribution and its probability density function for $x\in [a,b]$ is given by
\be
f(x) = \frac{\phi\brb{\frac{x-\mu}{\sigma}}}{\sigma\brb{\Phi\brb{\frac{b-\mu}{\sigma}}-\Phi\brb{\frac{a-\mu}{\sigma}}}}
\ee
where $\phi$ is the probability density function of the standard normal distribution and $\Phi$ is its cumulative distribution function
\be
\phi(x) = \frac 1{\sqrt{2\pi}}\exp\brb{-\frac 12x^2},\qquad \Phi(x) = \frac 1{\sqrt{2\pi}}\int^x_{-\infty} \exp\brb{-\frac 12 t^2}dt = \frac 12\brb{1+\erf\brb{\frac x{\sqrt{2}}}}.
\ee
\end{definition}

\begin{remark}
By definition, if $b=\infty$ then $\Phi\brb{\frac {b-\mu}{\sigma}} = 1$ and similarly if $a=-\infty$ then $\Phi\brb{\frac{a-\mu}{\sigma}} =0$.
\end{remark}


\begin{proposition}
Let $X\in (a,b)$ be a truncated normal distribution with parameters $(\mu,\sigma^2)$. Then
\beast
\E\brb{X|X\in (a,b)} & = & \mu + \sigma\frac{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}, \\
\var\brb{X|X\in (a,b)} & = & \sigma^2\brb{1+ \frac{\frac{a-\mu}{\sigma}\phi\brb{\frac{a-\mu}{\sigma}} - \frac{b-\mu}{\sigma} \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}} -\brb{\frac{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}}^2}.
\eeast

For one sided truncation of lower tail $b= \infty$,
\beast
\E\brb{X|X>a} & = & \mu +\frac{ \sigma\phi\brb{\frac{a-\mu}{\sigma}}}{1 - \Phi\brb{\frac{a-\mu}{\sigma}}}, \\
\var\brb{X|X>a} & = & \sigma^2\brb{1+ \frac{\frac{a-\mu}{\sigma}\phi\brb{\frac{a-\mu}{\sigma}} }{1- \Phi\brb{\frac{a-\mu}{\sigma}}} -\brb{\frac{\phi\brb{\frac{a-\mu}{\sigma}} }{1 - \Phi\brb{\frac{a-\mu}{\sigma}}}}^2}
\eeast

For one sided truncation of upper tail $a= -\infty$,
\beast
\E\brb{X|X<b} & = & \mu -\frac{ \sigma\phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}}}, \\
\var\brb{X|X<b} & = & \sigma^2\brb{1- \frac{\frac{b-\mu}{\sigma}\phi\brb{\frac{b-\mu}{\sigma}} }{\Phi\brb{\frac{b-\mu}{\sigma}}} -\brb{\frac{\phi\brb{\frac{b-\mu}{\sigma}} }{\Phi\brb{\frac{b-\mu}{\sigma}}}}^2}
\eeast
\end{proposition}


\begin{proof}[\bf Proof]
By definition of normal distribution $\sN(\mu,\sigma^2)$,
\beast
\pro\brb{X\in (a,b)} = \frac 1{\sqrt{2\pi}\sigma}\int^b_a \exp\brb{-\frac {(x-\mu)^2}{2\sigma^2}}dx = \frac 1{\sqrt{2\pi}}\int^{\frac{b-\mu}{\sigma}}_{\frac{a-\mu}{\sigma}}  \exp\brb{-\frac {x^2}{2}}dx = \Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}.
\eeast

\beast
\E\brb{X\ind_{X\in(a,b)}} & = & \frac 1{\sqrt{2\pi}\sigma}\int^b_a x \exp\brb{-\frac {(x-\mu)^2}{2\sigma^2}}dx = \frac {\sigma}{\sqrt{2\pi}}\int^{\frac{b-\mu}{\sigma}}_{\frac{a-\mu}{\sigma}} x \exp\brb{-\frac {x^2}{2}}dx + \mu\frac 1{\sqrt{2\pi}}\int^{\frac{b-\mu}{\sigma}}_{\frac{a-\mu}{\sigma}}  \exp\brb{-\frac {x^2}{2}}dx \\
& = & \sigma \brb{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}} + \mu\brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}
\eeast

Thus,
\beast
\E\brb{X|X\in (a,b)} = \frac{\E\brb{X\ind_{X\in(a,b)}}}{\pro\brb{X\in (a,b)} } = \frac{\sigma \brb{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}} + \mu\brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}= \mu + \sigma\frac{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}.
\eeast

Similarly,
\beast
& & \E\brb{X^2\ind_{X\in(a,b)}} \\
& = & \frac 1{\sqrt{2\pi}\sigma}\int^b_a x^2 \exp\brb{-\frac {(x-\mu)^2}{2\sigma^2}}dx = \frac {\sigma^2}{\sqrt{2\pi}}\int^b_a \frac{(x-\mu)^2 + 2\mu (x-\mu) + \mu^2}{\sigma^2} \exp\brb{-\frac {(x-\mu)^2}{2\sigma^2}}d\brb{\frac{x}{\sigma}} \\
& = & \frac {\sigma^2}{\sqrt{2\pi}}\int^{\frac{b-\mu}{\sigma}}_{\frac{a-\mu}{\sigma}} x^2 \exp\brb{-\frac {x^2}{2}}dx + 2\mu\sigma \brb{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}} + \mu^2 \brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}} \\
& = & \sigma^2\brb{\frac{a-\mu}{\sigma}\phi\brb{\frac{a-\mu}{\sigma}} - \frac{b-\mu}{\sigma} \phi\brb{\frac{b-\mu}{\sigma}}} + 2\mu\sigma \brb{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}} + \brb{\mu^2 +\sigma^2} \brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}
\eeast

Thus,
\beast
\E\brb{X^2|X\in(a,b)} & = & \frac{\E\brb{X^2\ind_{X\in(a,b)}}}{\pro\brb{X\in (a,b)}} = \sigma^2\frac{\brb{\frac{a-\mu}{\sigma}\phi\brb{\frac{a-\mu}{\sigma}} - \frac{b-\mu}{\sigma} \phi\brb{\frac{b-\mu}{\sigma}}}}{\brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}} + 2\mu\sigma \frac{\brb{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}}}{\brb{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}} + \brb{\mu^2 +\sigma^2}
\eeast

Hence,
\beast
\var\brb{X|X\in(a,b)} & = & \E\brb{X^2|X\in(a,b)} - \brb{\E\brb{X|X\in (a,b)}}^2 \\
& = & \sigma^2\brb{1+ \frac{\frac{a-\mu}{\sigma}\phi\brb{\frac{a-\mu}{\sigma}} - \frac{b-\mu}{\sigma} \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}} -\brb{\frac{\phi\brb{\frac{a-\mu}{\sigma}} - \phi\brb{\frac{b-\mu}{\sigma}}}{\Phi\brb{\frac{b-\mu}{\sigma}} - \Phi\brb{\frac{a-\mu}{\sigma}}}}^2}.
\eeast
\end{proof}


\subsection{Correlation of truncated distribution}

\begin{proposition}
Let $X,Y$ be bivariate normal distributed with correlation $\rho$ and their joint density function \be f(x,y) = \frac 1{2\pi\sqrt{1-\rho^2}} \exp\brb{\frac{x^2 - 2\rho xy + y^2}{2\brb{1-\rho^2}}} . \ee

If we discard all $X$ values outside the region $[a,b]$ where $a<b$, then the new correlation \be\wh{\rho} = \rho\sqrt{\frac{ 1 + \frac 1P \brb{af(a) -b f(b)}  - \frac 1{P^2}\brb{f(a)-f(b)}^2}{ 1 + \frac {\rho^2}P \brb{af(a)
-b f(b)} - \frac {\rho^2}{P^2}\brb{f(a)-f(b)}^2}}.\ee
\end{proposition}

\begin{remark}
If $b=\infty$, we have that (see \cite{Aitkin_1964}) \be \wh{\rho} = \rho\sqrt{\frac{ 1 + \frac {a}{R(a)}  - \frac 1{R^2(a)}}{ 1 + \frac {\rho^2a}{R(a)}  - \frac {\rho^2}{R^2(a)}}} = \rho\sqrt{\frac{R^2(a) + aR(a) -
1}{R^2(a) + \rho^2\brb{aR(a) - 1}}} \ee where $R(x) = e^{x^2/2}\int^\infty_x e^{-t^2/2}dt$. If $a>0$, From Proposition \ref{pro:bound_of_gaussian_law}, we have that $R(a) \leq 1/a$. Also, if $a\leq 0$, we still have
$aR(a)\leq 1$. Thus, the correlation will be decreased in magnitude by truncation unless $\rho = 0,\pm 1$.

If $a<0,b>0$ and $-a = b$, we have $f(a) = f(b)$ and \be \wh{\rho} = \rho\sqrt{\frac{ 1 + \frac 1P \brb{af(a) -b f(b)} }{ 1 + \frac {\rho^2}P \brb{af(a) -b f(b)} }} = \rho\sqrt{\frac{ 1 + \frac 1P 2af(a)}{ 1 + \frac {\rho^2}P
2 af(a) }}.\ee

Thus, $af(a) <0$, the correlation will be decreased in magnitude by truncation unless $\rho = 0,\pm 1$.

Similarly, if we discard the region inside $[a,b]$. The correlation becomes \be \wh{\rho} = \rho\sqrt{\frac{ 1 + \frac 1{1-P} \brb{bf(b) - af(a)}  - \frac 1{(1-P)^2}\brb{f(a)-f(b)}^2}{ 1 + \rho^2\brb{\frac 1{1-P} \brb{bf(b) -
af(a)}  - \frac 1{(1-P)^2}\brb{f(a)-f(b)}^2}}}. \ee

If $a<0,b>0$ and $-a = b$, we have $f(a) = f(b)$ and \be \wh{\rho} = \rho\sqrt{\frac{ 1 + \frac 1{1-P} 2bf(b)}{ 1 + \frac {\rho^2}{1-P} 2 bf(b) }}.\ee

Hence, $bf(b) >0$ and the correlation will be increased in magnitude by truncation unless $\rho = 0,\pm 1$.
\end{remark}

\begin{proof}[\bf Proof]
By discarding all $X$ values outside the region $[a,b]$ we have the new density fucntion \be f'(x,y) = f(x,y)/P \ee where $P := \pro\brb{X\in [a,b]} = \int^b_a \int^\infty_{-\infty} f(x,y) dy dx = \int^b_a f(x)dx$. Thus, we
can express any bivariate moment $\E \brb{x^my^n}$ as the sum of a series of terms of the form $\E \brb{He_i(x)He_j(y)}$. By Theorem \ref{thm:mehler_formula_extension}, we have \be f(x,y) = f(x) f(y)\sum_{k=0}^\infty
\frac{\rho^k}{k!} He_k(x) He_k(y)\ee

%\int^b_a He_i(x)f(x)dx \int^\infty_{-\infty} He_j(y)dy +

Thus, we have \beast \E \brb{He_i(x)He_j(y)} & = & \frac 1P \int^b_a \int^\infty_{-\infty}He_i(x)He_j(y) f(x,y) dxdy \\
& = & \frac 1P \brb{\sum_{k=0}^\infty \frac{\rho^k}{k!} \int^b_a He_i(x) He_k(x) f(x)dx \int^\infty_{-\infty} He_i(y) He_k(y) f(y)dy } \eeast

By Orthogonality of Hermite polynomials (Proposition \ref{pro:orthogonality_hermite_polynomials}), we have \be \E \brb{He_i(X)He_j(Y)} =  \frac 1P \sum_{k=0}^\infty \frac{\rho^k}{k!} \sqrt{2 \pi} j! \delta_{kj} \int^b_a
He_i(x) He_j(x) f(x)dx  = \frac {\rho^j}P \int^b_a He_i(x) He_j(x) f(x)dx . \ee

Obviously, we have \be  \E\brb{ He_n(X)} = \frac 1P \int^b_a He_n(x)f(x)dx = \frac 1P\int^b_a \brb{-\frac{d^n}{dx^n}}f(x)dx = - \frac 1P \int^b_a d\brb{-\frac{d^{n-1}}{dx^{n-1}}f(x)} = \frac 1P \left.H_{n-1}(x)f(x)\right|^a_b\nonumber
.\ee

Therefore, by Proposition \ref{pro:polynomials_hermite_polynomials}, \be \E X =  \E\brb{ He_1(X)} =\frac 1P \left.H_0(x)f(x)\right|^a_b = \frac 1P\brb{f(a)-f(b)} . \ee

\be \E Y =  \E\brb{ He_1(Y)} =  \frac {\rho}P\int^b_a He_1(x)f(x)dx  = \frac {\rho}P\brb{f(a)-f(b)}. \ee

\be \E X^2 = \E\brb{He_2(x) + He_0(x)} = \left.\frac 1P H_1(x)f(x)\right|^a_b + 1 = \frac 1P \brb{af(a) -b f(b)} + 1.\ee

\be \E Y^2 = \E\brb{He_2(y) + He_0(y)} = \rho^2 \E\brb{He_2(x)} + 1 = \frac {\rho^2}P \brb{af(a) -b f(b)} + 1.\ee

\be \E \brb{XY} = \E\brb{ He_1(X) He_1(Y)} = \frac {\rho}P \int^b_a He_1(x) He_1(x) f(x)dx = \rho \E X^2 = \rho\brb{\frac 1P \brb{af(a) -b f(b)} + 1} \ee


Hence, \beast \var X & = & 1 + \frac 1P \brb{af(a) -b f(b)}  - \frac 1{P^2}\brb{f(a)-f(b)}^2,\\
\var Y & = & 1 + \frac {\rho^2}P \brb{af(a) -b f(b)} - \frac {\rho^2}{P^2}\brb{f(a)-f(b)}^2,\\
\cov(X,Y) & = & \rho\brb{\frac 1P \brb{af(a) -b f(b)} + 1 - \frac 1{P^2}\brb{f(a)-f(b)}^2} . \eeast

Hence, \be \wh{\rho} = \frac{\cov (X,Y)}{\sqrt{\var X \var Y}} = \rho\sqrt{\frac{ 1 + \frac 1P \brb{af(a) -b f(b)}  - \frac 1{P^2}\brb{f(a)-f(b)}^2}{ 1 + \frac {\rho^2}P \brb{af(a) -b f(b)} - \frac
{\rho^2}{P^2}\brb{f(a)-f(b)}^2}}. \ee
\end{proof}

\section{Limit Distributions}

\section{Domain of Attraction of Distribution}

\subsection{Domain of attraction}

\begin{definition}[domain of attraction]
The distribution $F_X$ of the independent random variables $X_i$ belongs to the domian of attraction of a distribution $F$ if there exist norming constants $a_n>0$, $b_n$ such that for $S_n  = \sum^n_{i=1}X_i$ %the distribution of
\be
\frac 1{a_n}\brb{S_n -b_n} \stackrel{d}{\to} F ,\qquad \text{as $n\to \infty$.}
\ee
\end{definition}

\begin{example}%\footnote{example needed.}
Let $X_i$ be independent and identically distributed random variables with finite variance. Then by central limit theorem (Theorem \ref{thm:central_limit}), we have that $a_n = \sqrt{n}$, $b_n = n\mu$ where $\mu$ is the mean of $X_i$ and
\be
\frac {S_n -n\mu}{\sqrt{n}} \stackrel{d}{\to} \sN(0,\sigma^2)
\ee
where $\sigma^2$ is the variance of $X_i$. Hence, any random variable with finite variance is in the domain of attraction of normal distribution.
\end{example}

\section{Summary}

\begin{center}
\begin{longtable}{cccc}%\begin{tabular}{cccc}
\hline
distribution & expression & distribution & expression\\ \hline
Bernoulli & $\berd$ & binomial & $\bd$ \\
geometric & $\geo$ & negative binomial & $NB$ \\
Poisson & $\pd$ & uniform & $\sU$ \\
Skellam & $\sked$ & \levy & $\levyd$ \\
& & logistic & $\logd$ \\
exponential & $\sE$ & normal & $\sN$ \\
gamma & $\Gamma$ & beta & $\betad$ \\
chi-square & $\chi^2$ & student-t & $T$\\
Cauchy & $\sC$ & Fr\'echet & $\fred$ \\
reversed Weibull & $RW$ & Gumbel & $\gumd$ \\
Weibull & $\weid$ & generalized gamma & $GG$ \\
inverse Gaussian & $IG$ & generalized inverse Gaussian & $GIG$ \\
normal-inverse Gaussian & $NIG$ & variance-gamma & $VG$ \\
hyperbolic & $H$ & generalized hyperbolic & $GH$ \\
& & (generalized hyperbolic) skewed $t$ & $ST$ \\
\hline
\end{longtable}%\end{tabular}
\end{center}
